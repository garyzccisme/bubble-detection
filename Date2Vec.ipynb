{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7365c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21906375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x141283870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9264c",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71205409",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(range(1000), columns=['stamp'])\n",
    "dataset['date'] = pd.date_range(start='2021-01-04', periods=dataset.shape[0])\n",
    "\n",
    "# Event happens by frequency\n",
    "freq = 7\n",
    "dataset['event'] = dataset['stamp'].apply(lambda x: 1 if x % freq == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1f315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/bb77p1fj09d0s_0z7g249tchjddcwy/T/ipykernel_92856/2062272195.py:8: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  dataset['week'] = dataset['date'].dt.weekofyear\n"
     ]
    }
   ],
   "source": [
    "dataset['year'] = dataset['date'].dt.year\n",
    "dataset['year'] = dataset['year'] - dataset['year'].min()\n",
    "dataset['dayofyear'] = dataset['date'].dt.dayofyear\n",
    "\n",
    "dataset['month'] = dataset['date'].dt.month\n",
    "dataset['dayofmonth'] = dataset['date'].dt.day\n",
    "\n",
    "dataset['week'] = dataset['date'].dt.weekofyear\n",
    "dataset['dayofweek'] = dataset['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4115deb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stamp', 'date', 'event', 'year', 'dayofyear', 'month', 'dayofmonth',\n",
       "       'week', 'dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d99ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(feature, split_loc=300):\n",
    "    return (dataset[feature][:split_loc].values, dataset['event'][:split_loc].values, \n",
    "            dataset[feature][split_loc:].values, dataset['event'][split_loc:].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e1c58",
   "metadata": {},
   "source": [
    "# T2V Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64e4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T2V(nn.Module):\n",
    "    def __init__(self, linear_channel, period_channel):\n",
    "        super().__init__()\n",
    "        self.linear_channel = linear_channel\n",
    "        self.period_channel = period_channel\n",
    "        \n",
    "        self.linear_fc = nn.Linear(1, linear_channel)\n",
    "        self.period_fc = nn.Linear(1, period_channel)\n",
    "        self.period_activation = torch.sin\n",
    "    \n",
    "    def forward(self, x):\n",
    "        linear_vec = self.linear_fc(x)\n",
    "        period_vec = self.period_activation(self.period_fc(x))\n",
    "        return torch.cat([linear_vec, period_vec], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c8229",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f48671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, network, max_epoch=100):\n",
    "        self.network = network\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "#         self.scheduler = ReduceLROnPlateau(self.optimizer, factor=0.1, patience=1000, verbose=1)\n",
    "        self.max_epoch = max_epoch\n",
    "        self.dataloader = None\n",
    "        self.train_dataset = None\n",
    "        self.valid_dataset = None\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        \n",
    "    def get_tensor(self, array):\n",
    "        return torch.tensor(array).float()\n",
    "        \n",
    "    def generate_dataloader(self, x, y):\n",
    "        valid_size = 200\n",
    "        train_x, valid_x, train_y, valid_y = x[:-valid_size], x[-valid_size:], y[:-valid_size], y[-valid_size:]\n",
    "        self.train_dataset = TensorDataset(train_x, train_y)\n",
    "        self.valid_dataset = TensorDataset(valid_x, valid_y)\n",
    "        self.dataloader = DataLoader(self.train_dataset, batch_size=1024, shuffle=True)\n",
    "        \n",
    "    def train(self, x, y):\n",
    "        x = self.get_tensor(x)\n",
    "        y = self.get_tensor(y)\n",
    "        self.generate_dataloader(x, y)\n",
    "        for epoch in range(self.max_epoch):\n",
    "            self.batch_train()\n",
    "            \n",
    "            train_loss = self.get_loss(self.train_dataset)\n",
    "            valid_loss = self.get_loss(self.valid_dataset)\n",
    "            self.train_loss.append(train_loss.item())\n",
    "            self.valid_loss.append(valid_loss.item())\n",
    "            \n",
    "#             self.scheduler.step(valid_loss)\n",
    "            print(f\"Epoch: {epoch}, Train Loss: {train_loss.item()}, Valid Loss: {valid_loss.item()}\")\n",
    "            \n",
    "    def get_loss(self, dataset):\n",
    "        x, y = dataset[:]\n",
    "        pred = self.predict(x)\n",
    "        loss = self.loss(pred, y)\n",
    "        return loss\n",
    "        \n",
    "    def batch_train(self):\n",
    "        for x, y in self.dataloader:\n",
    "            self.network.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            pred = self.predict(x)\n",
    "            loss = self.loss(pred, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        \n",
    "    def predict(self, x):\n",
    "        self.network.eval()\n",
    "        return self.network(self.get_tensor(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d172f2f8",
   "metadata": {},
   "source": [
    "# Time2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864cfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_dataset(feature=['stamp'], split_loc=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f66aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StampNet(nn.Module):\n",
    "    def __init__(self, linear_channel, period_channel):\n",
    "        super().__init__()\n",
    "        self.t2v = T2V(linear_channel, period_channel)\n",
    "        self.fc = nn.Linear(linear_channel + period_channel, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.t2v(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f97d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = StampNet(1, 16)\n",
    "model = Model(network, max_epoch=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f30f98ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/bb77p1fj09d0s_0z7g249tchjddcwy/T/ipykernel_92856/3253151976.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(array).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 2.576810598373413, Valid Loss: 6.046105861663818\n",
      "Epoch: 1, Train Loss: 2.5421106815338135, Valid Loss: 5.954711437225342\n",
      "Epoch: 2, Train Loss: 2.5064897537231445, Valid Loss: 5.866480827331543\n",
      "Epoch: 3, Train Loss: 2.470064401626587, Valid Loss: 5.781005859375\n",
      "Epoch: 4, Train Loss: 2.433366060256958, Valid Loss: 5.697362899780273\n",
      "Epoch: 5, Train Loss: 2.396886110305786, Valid Loss: 5.614432334899902\n",
      "Epoch: 6, Train Loss: 2.360736608505249, Valid Loss: 5.531495571136475\n",
      "Epoch: 7, Train Loss: 2.3247575759887695, Valid Loss: 5.4479756355285645\n",
      "Epoch: 8, Train Loss: 2.288809299468994, Valid Loss: 5.363989353179932\n",
      "Epoch: 9, Train Loss: 2.252732276916504, Valid Loss: 5.279745101928711\n",
      "Epoch: 10, Train Loss: 2.216512441635132, Valid Loss: 5.195602893829346\n",
      "Epoch: 11, Train Loss: 2.180096387863159, Valid Loss: 5.112420082092285\n",
      "Epoch: 12, Train Loss: 2.143482208251953, Valid Loss: 5.030714988708496\n",
      "Epoch: 13, Train Loss: 2.1068389415740967, Valid Loss: 4.949587821960449\n",
      "Epoch: 14, Train Loss: 2.0702643394470215, Valid Loss: 4.868165969848633\n",
      "Epoch: 15, Train Loss: 2.0336875915527344, Valid Loss: 4.786098957061768\n",
      "Epoch: 16, Train Loss: 1.9970133304595947, Valid Loss: 4.7029595375061035\n",
      "Epoch: 17, Train Loss: 1.9601682424545288, Valid Loss: 4.6184844970703125\n",
      "Epoch: 18, Train Loss: 1.9233300685882568, Valid Loss: 4.532259941101074\n",
      "Epoch: 19, Train Loss: 1.8867621421813965, Valid Loss: 4.444072723388672\n",
      "Epoch: 20, Train Loss: 1.85057532787323, Valid Loss: 4.3545637130737305\n",
      "Epoch: 21, Train Loss: 1.814669132232666, Valid Loss: 4.264959335327148\n",
      "Epoch: 22, Train Loss: 1.7788509130477905, Valid Loss: 4.176385879516602\n",
      "Epoch: 23, Train Loss: 1.742991328239441, Valid Loss: 4.089443206787109\n",
      "Epoch: 24, Train Loss: 1.7070802450180054, Valid Loss: 4.0040974617004395\n",
      "Epoch: 25, Train Loss: 1.6711970567703247, Valid Loss: 3.9198474884033203\n",
      "Epoch: 26, Train Loss: 1.6354573965072632, Valid Loss: 3.8359715938568115\n",
      "Epoch: 27, Train Loss: 1.59995436668396, Valid Loss: 3.7518515586853027\n",
      "Epoch: 28, Train Loss: 1.5647212266921997, Valid Loss: 3.667307138442993\n",
      "Epoch: 29, Train Loss: 1.5297446250915527, Valid Loss: 3.5825624465942383\n",
      "Epoch: 30, Train Loss: 1.4950069189071655, Valid Loss: 3.4979004859924316\n",
      "Epoch: 31, Train Loss: 1.4604955911636353, Valid Loss: 3.4134955406188965\n",
      "Epoch: 32, Train Loss: 1.4261966943740845, Valid Loss: 3.329514265060425\n",
      "Epoch: 33, Train Loss: 1.3920985460281372, Valid Loss: 3.246121883392334\n",
      "Epoch: 34, Train Loss: 1.3582011461257935, Valid Loss: 3.1633739471435547\n",
      "Epoch: 35, Train Loss: 1.3245131969451904, Valid Loss: 3.081223249435425\n",
      "Epoch: 36, Train Loss: 1.2910447120666504, Valid Loss: 2.999605178833008\n",
      "Epoch: 37, Train Loss: 1.2578130960464478, Valid Loss: 2.9184350967407227\n",
      "Epoch: 38, Train Loss: 1.2248424291610718, Valid Loss: 2.8375790119171143\n",
      "Epoch: 39, Train Loss: 1.1921472549438477, Valid Loss: 2.7569587230682373\n",
      "Epoch: 40, Train Loss: 1.1597247123718262, Valid Loss: 2.6766245365142822\n",
      "Epoch: 41, Train Loss: 1.1275713443756104, Valid Loss: 2.596633195877075\n",
      "Epoch: 42, Train Loss: 1.095699667930603, Valid Loss: 2.516948938369751\n",
      "Epoch: 43, Train Loss: 1.06412935256958, Valid Loss: 2.4375205039978027\n",
      "Epoch: 44, Train Loss: 1.032873272895813, Valid Loss: 2.3583991527557373\n",
      "Epoch: 45, Train Loss: 1.0019360780715942, Valid Loss: 2.2797462940216064\n",
      "Epoch: 46, Train Loss: 0.9713211059570312, Valid Loss: 2.201770067214966\n",
      "Epoch: 47, Train Loss: 0.9410415887832642, Valid Loss: 2.124600410461426\n",
      "Epoch: 48, Train Loss: 0.9111244678497314, Valid Loss: 2.048210382461548\n",
      "Epoch: 49, Train Loss: 0.8816010355949402, Valid Loss: 1.972469449043274\n",
      "Epoch: 50, Train Loss: 0.8524985909461975, Valid Loss: 1.8972283601760864\n",
      "Epoch: 51, Train Loss: 0.8238450884819031, Valid Loss: 1.8223527669906616\n",
      "Epoch: 52, Train Loss: 0.7956717014312744, Valid Loss: 1.7477858066558838\n",
      "Epoch: 53, Train Loss: 0.7680124640464783, Valid Loss: 1.6735763549804688\n",
      "Epoch: 54, Train Loss: 0.7409127354621887, Valid Loss: 1.5998088121414185\n",
      "Epoch: 55, Train Loss: 0.7144297957420349, Valid Loss: 1.5265731811523438\n",
      "Epoch: 56, Train Loss: 0.6886280179023743, Valid Loss: 1.4540027379989624\n",
      "Epoch: 57, Train Loss: 0.6635804176330566, Valid Loss: 1.3822510242462158\n",
      "Epoch: 58, Train Loss: 0.639373242855072, Valid Loss: 1.3114380836486816\n",
      "Epoch: 59, Train Loss: 0.6161079406738281, Valid Loss: 1.241613745689392\n",
      "Epoch: 60, Train Loss: 0.5939024090766907, Valid Loss: 1.1727670431137085\n",
      "Epoch: 61, Train Loss: 0.5728904008865356, Valid Loss: 1.1049151420593262\n",
      "Epoch: 62, Train Loss: 0.5532242655754089, Valid Loss: 1.038185715675354\n",
      "Epoch: 63, Train Loss: 0.535078763961792, Valid Loss: 0.9728388786315918\n",
      "Epoch: 64, Train Loss: 0.5186472535133362, Valid Loss: 0.9092551469802856\n",
      "Epoch: 65, Train Loss: 0.5041356086730957, Valid Loss: 0.847878634929657\n",
      "Epoch: 66, Train Loss: 0.49175184965133667, Valid Loss: 0.7891813516616821\n",
      "Epoch: 67, Train Loss: 0.48168572783470154, Valid Loss: 0.7337223887443542\n",
      "Epoch: 68, Train Loss: 0.47408345341682434, Valid Loss: 0.6821856498718262\n",
      "Epoch: 69, Train Loss: 0.46901434659957886, Valid Loss: 0.6353395581245422\n",
      "Epoch: 70, Train Loss: 0.466434121131897, Valid Loss: 0.5939378142356873\n",
      "Epoch: 71, Train Loss: 0.4661543667316437, Valid Loss: 0.5586143136024475\n",
      "Epoch: 72, Train Loss: 0.4678289294242859, Valid Loss: 0.5298045873641968\n",
      "Epoch: 73, Train Loss: 0.4709550440311432, Valid Loss: 0.5075927376747131\n",
      "Epoch: 74, Train Loss: 0.47487884759902954, Valid Loss: 0.49156180024147034\n",
      "Epoch: 75, Train Loss: 0.4788585901260376, Valid Loss: 0.4808860123157501\n",
      "Epoch: 76, Train Loss: 0.48220884799957275, Valid Loss: 0.47451454401016235\n",
      "Epoch: 77, Train Loss: 0.48443055152893066, Valid Loss: 0.47127780318260193\n",
      "Epoch: 78, Train Loss: 0.48527979850769043, Valid Loss: 0.4700687527656555\n",
      "Epoch: 79, Train Loss: 0.48476216197013855, Valid Loss: 0.4702005684375763\n",
      "Epoch: 80, Train Loss: 0.4830668270587921, Valid Loss: 0.4716622829437256\n",
      "Epoch: 81, Train Loss: 0.4804897606372833, Valid Loss: 0.47486647963523865\n",
      "Epoch: 82, Train Loss: 0.4773692786693573, Valid Loss: 0.48018401861190796\n",
      "Epoch: 83, Train Loss: 0.47404465079307556, Valid Loss: 0.4877338707447052\n",
      "Epoch: 84, Train Loss: 0.4708347022533417, Valid Loss: 0.4973898231983185\n",
      "Epoch: 85, Train Loss: 0.46800708770751953, Valid Loss: 0.5087509751319885\n",
      "Epoch: 86, Train Loss: 0.4657358229160309, Valid Loss: 0.5212223529815674\n",
      "Epoch: 87, Train Loss: 0.4640646278858185, Valid Loss: 0.5343172550201416\n",
      "Epoch: 88, Train Loss: 0.46293631196022034, Valid Loss: 0.5477215051651001\n",
      "Epoch: 89, Train Loss: 0.46226754784584045, Valid Loss: 0.5611060261726379\n",
      "Epoch: 90, Train Loss: 0.4619775414466858, Valid Loss: 0.5740886330604553\n",
      "Epoch: 91, Train Loss: 0.4619804322719574, Valid Loss: 0.5862776041030884\n",
      "Epoch: 92, Train Loss: 0.46218323707580566, Valid Loss: 0.597302258014679\n",
      "Epoch: 93, Train Loss: 0.4624927341938019, Valid Loss: 0.6068585515022278\n",
      "Epoch: 94, Train Loss: 0.4628259837627411, Valid Loss: 0.6147488951683044\n",
      "Epoch: 95, Train Loss: 0.4631183445453644, Valid Loss: 0.6208826899528503\n",
      "Epoch: 96, Train Loss: 0.46332594752311707, Valid Loss: 0.625272274017334\n",
      "Epoch: 97, Train Loss: 0.46342331171035767, Valid Loss: 0.6280074119567871\n",
      "Epoch: 98, Train Loss: 0.46340084075927734, Valid Loss: 0.6291974782943726\n",
      "Epoch: 99, Train Loss: 0.4632618725299835, Valid Loss: 0.6289463043212891\n",
      "Epoch: 100, Train Loss: 0.46301886439323425, Valid Loss: 0.627381443977356\n",
      "Epoch: 101, Train Loss: 0.46268966794013977, Valid Loss: 0.6246750950813293\n",
      "Epoch: 102, Train Loss: 0.46229562163352966, Valid Loss: 0.6210215091705322\n",
      "Epoch: 103, Train Loss: 0.4618595242500305, Valid Loss: 0.6165988445281982\n",
      "Epoch: 104, Train Loss: 0.46140554547309875, Valid Loss: 0.6115695834159851\n",
      "Epoch: 105, Train Loss: 0.4609583914279938, Valid Loss: 0.6061061024665833\n",
      "Epoch: 106, Train Loss: 0.4605405032634735, Valid Loss: 0.6003885269165039\n",
      "Epoch: 107, Train Loss: 0.4601689279079437, Valid Loss: 0.5945781469345093\n",
      "Epoch: 108, Train Loss: 0.4598536789417267, Valid Loss: 0.5888140201568604\n",
      "Epoch: 109, Train Loss: 0.45959827303886414, Valid Loss: 0.5832222104072571\n",
      "Epoch: 110, Train Loss: 0.45940104126930237, Valid Loss: 0.577907383441925\n",
      "Epoch: 111, Train Loss: 0.45925548672676086, Valid Loss: 0.5729545950889587\n",
      "Epoch: 112, Train Loss: 0.45915141701698303, Valid Loss: 0.5684491991996765\n",
      "Epoch: 113, Train Loss: 0.45907774567604065, Valid Loss: 0.5644806027412415\n",
      "Epoch: 114, Train Loss: 0.45902252197265625, Valid Loss: 0.5611159801483154\n",
      "Epoch: 115, Train Loss: 0.4589747488498688, Valid Loss: 0.5583802461624146\n",
      "Epoch: 116, Train Loss: 0.4589250087738037, Valid Loss: 0.5562686324119568\n",
      "Epoch: 117, Train Loss: 0.4588651657104492, Valid Loss: 0.5547649264335632\n",
      "Epoch: 118, Train Loss: 0.4587896764278412, Valid Loss: 0.5538405179977417\n",
      "Epoch: 119, Train Loss: 0.4586956799030304, Valid Loss: 0.5534632802009583\n",
      "Epoch: 120, Train Loss: 0.45858317613601685, Valid Loss: 0.5536009073257446\n",
      "Epoch: 121, Train Loss: 0.45845499634742737, Valid Loss: 0.5542082786560059\n",
      "Epoch: 122, Train Loss: 0.4583154320716858, Valid Loss: 0.5552229881286621\n",
      "Epoch: 123, Train Loss: 0.4581700265407562, Valid Loss: 0.55658358335495\n",
      "Epoch: 124, Train Loss: 0.45802414417266846, Valid Loss: 0.5582378506660461\n",
      "Epoch: 125, Train Loss: 0.4578815698623657, Valid Loss: 0.5601241588592529\n",
      "Epoch: 126, Train Loss: 0.45774444937705994, Valid Loss: 0.5621673464775085\n",
      "Epoch: 127, Train Loss: 0.45761412382125854, Valid Loss: 0.5642933249473572\n",
      "Epoch: 128, Train Loss: 0.45749151706695557, Valid Loss: 0.566433846950531\n",
      "Epoch: 129, Train Loss: 0.4573773741722107, Valid Loss: 0.5685251355171204\n",
      "Epoch: 130, Train Loss: 0.45727264881134033, Valid Loss: 0.5705130696296692\n",
      "Epoch: 131, Train Loss: 0.4571766257286072, Valid Loss: 0.572346568107605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132, Train Loss: 0.45708730816841125, Valid Loss: 0.5739725232124329\n",
      "Epoch: 133, Train Loss: 0.45700132846832275, Valid Loss: 0.575351357460022\n",
      "Epoch: 134, Train Loss: 0.45691564679145813, Valid Loss: 0.5764663815498352\n",
      "Epoch: 135, Train Loss: 0.4568280577659607, Valid Loss: 0.5773117542266846\n",
      "Epoch: 136, Train Loss: 0.4567383825778961, Valid Loss: 0.5778870582580566\n",
      "Epoch: 137, Train Loss: 0.4566468894481659, Valid Loss: 0.5782042741775513\n",
      "Epoch: 138, Train Loss: 0.45655396580696106, Valid Loss: 0.57828688621521\n",
      "Epoch: 139, Train Loss: 0.45645925402641296, Valid Loss: 0.5781646370887756\n",
      "Epoch: 140, Train Loss: 0.4563620090484619, Valid Loss: 0.577870786190033\n",
      "Epoch: 141, Train Loss: 0.4562624990940094, Valid Loss: 0.5774354338645935\n",
      "Epoch: 142, Train Loss: 0.45616158843040466, Valid Loss: 0.5768813490867615\n",
      "Epoch: 143, Train Loss: 0.4560604989528656, Valid Loss: 0.5762376189231873\n",
      "Epoch: 144, Train Loss: 0.45596033334732056, Valid Loss: 0.575533390045166\n",
      "Epoch: 145, Train Loss: 0.4558615982532501, Valid Loss: 0.574789822101593\n",
      "Epoch: 146, Train Loss: 0.4557642638683319, Valid Loss: 0.5740299820899963\n",
      "Epoch: 147, Train Loss: 0.45566824078559875, Valid Loss: 0.5732770562171936\n",
      "Epoch: 148, Train Loss: 0.45557430386543274, Valid Loss: 0.572551965713501\n",
      "Epoch: 149, Train Loss: 0.4554823935031891, Valid Loss: 0.5718807578086853\n",
      "Epoch: 150, Train Loss: 0.4553925693035126, Valid Loss: 0.5712846517562866\n",
      "Epoch: 151, Train Loss: 0.4553041160106659, Valid Loss: 0.570773184299469\n",
      "Epoch: 152, Train Loss: 0.4552163779735565, Valid Loss: 0.570357084274292\n",
      "Epoch: 153, Train Loss: 0.4551287889480591, Valid Loss: 0.5700430870056152\n",
      "Epoch: 154, Train Loss: 0.45504099130630493, Valid Loss: 0.5698316097259521\n",
      "Epoch: 155, Train Loss: 0.4549529552459717, Valid Loss: 0.5697203278541565\n",
      "Epoch: 156, Train Loss: 0.45486435294151306, Valid Loss: 0.5697014331817627\n",
      "Epoch: 157, Train Loss: 0.45477497577667236, Valid Loss: 0.5697652697563171\n",
      "Epoch: 158, Train Loss: 0.4546847939491272, Valid Loss: 0.5699074268341064\n",
      "Epoch: 159, Train Loss: 0.45459339022636414, Valid Loss: 0.5701150298118591\n",
      "Epoch: 160, Train Loss: 0.45450130105018616, Valid Loss: 0.5703775882720947\n",
      "Epoch: 161, Train Loss: 0.4544084072113037, Valid Loss: 0.5706855058670044\n",
      "Epoch: 162, Train Loss: 0.4543148875236511, Valid Loss: 0.5710268020629883\n",
      "Epoch: 163, Train Loss: 0.4542207717895508, Valid Loss: 0.5713930726051331\n",
      "Epoch: 164, Train Loss: 0.45412611961364746, Valid Loss: 0.5717714428901672\n",
      "Epoch: 165, Train Loss: 0.45403075218200684, Valid Loss: 0.5721473097801208\n",
      "Epoch: 166, Train Loss: 0.45393499732017517, Valid Loss: 0.5725098848342896\n",
      "Epoch: 167, Train Loss: 0.4538390040397644, Valid Loss: 0.572848379611969\n",
      "Epoch: 168, Train Loss: 0.4537433981895447, Valid Loss: 0.5731533169746399\n",
      "Epoch: 169, Train Loss: 0.4536488354206085, Valid Loss: 0.5734168887138367\n",
      "Epoch: 170, Train Loss: 0.45355600118637085, Valid Loss: 0.5736346244812012\n",
      "Epoch: 171, Train Loss: 0.45346546173095703, Valid Loss: 0.5738102793693542\n",
      "Epoch: 172, Train Loss: 0.4533776342868805, Valid Loss: 0.5739443302154541\n",
      "Epoch: 173, Train Loss: 0.4532916247844696, Valid Loss: 0.5740426778793335\n",
      "Epoch: 174, Train Loss: 0.4532071352005005, Valid Loss: 0.5741079449653625\n",
      "Epoch: 175, Train Loss: 0.45312291383743286, Valid Loss: 0.5741449594497681\n",
      "Epoch: 176, Train Loss: 0.4530380368232727, Valid Loss: 0.5741593837738037\n",
      "Epoch: 177, Train Loss: 0.45295217633247375, Valid Loss: 0.5741509199142456\n",
      "Epoch: 178, Train Loss: 0.4528653919696808, Valid Loss: 0.5741243958473206\n",
      "Epoch: 179, Train Loss: 0.45277801156044006, Valid Loss: 0.5740792751312256\n",
      "Epoch: 180, Train Loss: 0.45269063115119934, Valid Loss: 0.5740200281143188\n",
      "Epoch: 181, Train Loss: 0.45260345935821533, Valid Loss: 0.5739469528198242\n",
      "Epoch: 182, Train Loss: 0.45251694321632385, Valid Loss: 0.5738636255264282\n",
      "Epoch: 183, Train Loss: 0.4524308741092682, Valid Loss: 0.5737766027450562\n",
      "Epoch: 184, Train Loss: 0.4523452818393707, Valid Loss: 0.5736896991729736\n",
      "Epoch: 185, Train Loss: 0.4522601366043091, Valid Loss: 0.5736122727394104\n",
      "Epoch: 186, Train Loss: 0.4521752893924713, Valid Loss: 0.5735453367233276\n",
      "Epoch: 187, Train Loss: 0.45209091901779175, Valid Loss: 0.5734991431236267\n",
      "Epoch: 188, Train Loss: 0.45200687646865845, Valid Loss: 0.5734714269638062\n",
      "Epoch: 189, Train Loss: 0.4519233703613281, Valid Loss: 0.5734707117080688\n",
      "Epoch: 190, Train Loss: 0.4518403708934784, Valid Loss: 0.5734900832176208\n",
      "Epoch: 191, Train Loss: 0.4517577588558197, Valid Loss: 0.5735380053520203\n",
      "Epoch: 192, Train Loss: 0.4516757130622864, Valid Loss: 0.5736047029495239\n",
      "Epoch: 193, Train Loss: 0.45159393548965454, Valid Loss: 0.5736991167068481\n",
      "Epoch: 194, Train Loss: 0.4515123963356018, Valid Loss: 0.5738058686256409\n",
      "Epoch: 195, Train Loss: 0.4514312744140625, Valid Loss: 0.573940098285675\n",
      "Epoch: 196, Train Loss: 0.4513500928878784, Valid Loss: 0.5740753412246704\n",
      "Epoch: 197, Train Loss: 0.4512690603733063, Valid Loss: 0.5742418766021729\n",
      "Epoch: 198, Train Loss: 0.4511880576610565, Valid Loss: 0.5743837952613831\n",
      "Epoch: 199, Train Loss: 0.45110732316970825, Valid Loss: 0.5745773911476135\n",
      "Epoch: 200, Train Loss: 0.45102691650390625, Valid Loss: 0.5746874809265137\n",
      "Epoch: 201, Train Loss: 0.45094722509384155, Valid Loss: 0.574923574924469\n",
      "Epoch: 202, Train Loss: 0.4508684277534485, Valid Loss: 0.5749173164367676\n",
      "Epoch: 203, Train Loss: 0.45079177618026733, Valid Loss: 0.5752732157707214\n",
      "Epoch: 204, Train Loss: 0.4507193863391876, Valid Loss: 0.5749276876449585\n",
      "Epoch: 205, Train Loss: 0.45065125823020935, Valid Loss: 0.5755559206008911\n",
      "Epoch: 206, Train Loss: 0.450572669506073, Valid Loss: 0.5749234557151794\n",
      "Epoch: 207, Train Loss: 0.450478732585907, Valid Loss: 0.5756494998931885\n",
      "Epoch: 208, Train Loss: 0.45039957761764526, Valid Loss: 0.5756911039352417\n",
      "Epoch: 209, Train Loss: 0.45033255219459534, Valid Loss: 0.5752156972885132\n",
      "Epoch: 210, Train Loss: 0.45024749636650085, Valid Loss: 0.5758079290390015\n",
      "Epoch: 211, Train Loss: 0.4501650929450989, Valid Loss: 0.5757606029510498\n",
      "Epoch: 212, Train Loss: 0.4500967264175415, Valid Loss: 0.5753920674324036\n",
      "Epoch: 213, Train Loss: 0.45001450181007385, Valid Loss: 0.5758737921714783\n",
      "Epoch: 214, Train Loss: 0.4499349594116211, Valid Loss: 0.5758470296859741\n",
      "Epoch: 215, Train Loss: 0.44986480474472046, Valid Loss: 0.575528085231781\n",
      "Epoch: 216, Train Loss: 0.44978341460227966, Valid Loss: 0.5759370923042297\n",
      "Epoch: 217, Train Loss: 0.4497074782848358, Valid Loss: 0.5759754776954651\n",
      "Epoch: 218, Train Loss: 0.44963547587394714, Valid Loss: 0.5757036805152893\n",
      "Epoch: 219, Train Loss: 0.44955503940582275, Valid Loss: 0.5760391354560852\n",
      "Epoch: 220, Train Loss: 0.44948187470436096, Valid Loss: 0.5761505961418152\n",
      "Epoch: 221, Train Loss: 0.44940781593322754, Valid Loss: 0.5759363770484924\n",
      "Epoch: 222, Train Loss: 0.449329674243927, Valid Loss: 0.5761892795562744\n",
      "Epoch: 223, Train Loss: 0.4492574632167816, Valid Loss: 0.5763642191886902\n",
      "Epoch: 224, Train Loss: 0.4491821229457855, Valid Loss: 0.5762147307395935\n",
      "Epoch: 225, Train Loss: 0.4491061866283417, Valid Loss: 0.5763886570930481\n",
      "Epoch: 226, Train Loss: 0.449034184217453, Valid Loss: 0.5766090750694275\n",
      "Epoch: 227, Train Loss: 0.44895875453948975, Valid Loss: 0.576519787311554\n",
      "Epoch: 228, Train Loss: 0.4488846957683563, Valid Loss: 0.5766294002532959\n",
      "Epoch: 229, Train Loss: 0.4488123953342438, Valid Loss: 0.5768697261810303\n",
      "Epoch: 230, Train Loss: 0.4487374424934387, Valid Loss: 0.5768277645111084\n",
      "Epoch: 231, Train Loss: 0.44866466522216797, Valid Loss: 0.5768896341323853\n",
      "Epoch: 232, Train Loss: 0.4485921263694763, Valid Loss: 0.5771253108978271\n",
      "Epoch: 233, Train Loss: 0.4485180079936981, Valid Loss: 0.5771141648292542\n",
      "Epoch: 234, Train Loss: 0.4484458863735199, Valid Loss: 0.5771422386169434\n",
      "Epoch: 235, Train Loss: 0.4483734667301178, Valid Loss: 0.5773580074310303\n",
      "Epoch: 236, Train Loss: 0.44830021262168884, Valid Loss: 0.5773629546165466\n",
      "Epoch: 237, Train Loss: 0.44822850823402405, Valid Loss: 0.5773705840110779\n",
      "Epoch: 238, Train Loss: 0.4481562674045563, Valid Loss: 0.5775613188743591\n",
      "Epoch: 239, Train Loss: 0.448083758354187, Valid Loss: 0.5775740742683411\n",
      "Epoch: 240, Train Loss: 0.4480123519897461, Valid Loss: 0.5775758624076843\n",
      "Epoch: 241, Train Loss: 0.4479406774044037, Valid Loss: 0.5777456760406494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 242, Train Loss: 0.4478686451911926, Valid Loss: 0.5777649283409119\n",
      "Epoch: 243, Train Loss: 0.4477976858615875, Valid Loss: 0.577772319316864\n",
      "Epoch: 244, Train Loss: 0.4477263391017914, Valid Loss: 0.5779295563697815\n",
      "Epoch: 245, Train Loss: 0.4476548731327057, Valid Loss: 0.5779529809951782\n",
      "Epoch: 246, Train Loss: 0.4475841224193573, Valid Loss: 0.5779739618301392\n",
      "Epoch: 247, Train Loss: 0.44751328229904175, Valid Loss: 0.5781214237213135\n",
      "Epoch: 248, Train Loss: 0.4474424123764038, Valid Loss: 0.5781466960906982\n",
      "Epoch: 249, Train Loss: 0.4473719894886017, Valid Loss: 0.5781834125518799\n",
      "Epoch: 250, Train Loss: 0.44730162620544434, Valid Loss: 0.5783219933509827\n",
      "Epoch: 251, Train Loss: 0.44723114371299744, Valid Loss: 0.5783452987670898\n",
      "Epoch: 252, Train Loss: 0.44716110825538635, Valid Loss: 0.5784001350402832\n",
      "Epoch: 253, Train Loss: 0.44709116220474243, Valid Loss: 0.5785267353057861\n",
      "Epoch: 254, Train Loss: 0.4470210671424866, Valid Loss: 0.5785475373268127\n",
      "Epoch: 255, Train Loss: 0.446951299905777, Valid Loss: 0.5786198973655701\n",
      "Epoch: 256, Train Loss: 0.4468817710876465, Valid Loss: 0.5787312388420105\n",
      "Epoch: 257, Train Loss: 0.44681212306022644, Valid Loss: 0.5787513256072998\n",
      "Epoch: 258, Train Loss: 0.4467426538467407, Valid Loss: 0.578840434551239\n",
      "Epoch: 259, Train Loss: 0.4466734826564789, Valid Loss: 0.5789341330528259\n",
      "Epoch: 260, Train Loss: 0.4466044008731842, Valid Loss: 0.5789588689804077\n",
      "Epoch: 261, Train Loss: 0.44653522968292236, Valid Loss: 0.5790597796440125\n",
      "Epoch: 262, Train Loss: 0.4464663565158844, Valid Loss: 0.5791327953338623\n",
      "Epoch: 263, Train Loss: 0.44639769196510315, Valid Loss: 0.5791680216789246\n",
      "Epoch: 264, Train Loss: 0.44632887840270996, Valid Loss: 0.5792731642723083\n",
      "Epoch: 265, Train Loss: 0.44626036286354065, Valid Loss: 0.579325795173645\n",
      "Epoch: 266, Train Loss: 0.44619202613830566, Valid Loss: 0.5793790221214294\n",
      "Epoch: 267, Train Loss: 0.44612371921539307, Valid Loss: 0.5794768929481506\n",
      "Epoch: 268, Train Loss: 0.44605544209480286, Valid Loss: 0.5795162320137024\n",
      "Epoch: 269, Train Loss: 0.44598740339279175, Valid Loss: 0.5795894861221313\n",
      "Epoch: 270, Train Loss: 0.4459194540977478, Valid Loss: 0.5796712636947632\n",
      "Epoch: 271, Train Loss: 0.4458516538143158, Valid Loss: 0.5797096490859985\n",
      "Epoch: 272, Train Loss: 0.4457838535308838, Valid Loss: 0.5797964334487915\n",
      "Epoch: 273, Train Loss: 0.4457162618637085, Valid Loss: 0.5798567533493042\n",
      "Epoch: 274, Train Loss: 0.44564875960350037, Valid Loss: 0.579908013343811\n",
      "Epoch: 275, Train Loss: 0.445581316947937, Valid Loss: 0.5799939632415771\n",
      "Epoch: 276, Train Loss: 0.4455140233039856, Valid Loss: 0.580039918422699\n",
      "Epoch: 277, Train Loss: 0.4454468786716461, Valid Loss: 0.580108642578125\n",
      "Epoch: 278, Train Loss: 0.4453798532485962, Valid Loss: 0.5801804661750793\n",
      "Epoch: 279, Train Loss: 0.4453129172325134, Valid Loss: 0.5802260637283325\n",
      "Epoch: 280, Train Loss: 0.4452460706233978, Valid Loss: 0.5803061127662659\n",
      "Epoch: 281, Train Loss: 0.4451793432235718, Valid Loss: 0.5803594589233398\n",
      "Epoch: 282, Train Loss: 0.44511276483535767, Valid Loss: 0.580420196056366\n",
      "Epoch: 283, Train Loss: 0.44504618644714355, Valid Loss: 0.5804938673973083\n",
      "Epoch: 284, Train Loss: 0.44497981667518616, Valid Loss: 0.5805413126945496\n",
      "Epoch: 285, Train Loss: 0.44491347670555115, Valid Loss: 0.5806159377098083\n",
      "Epoch: 286, Train Loss: 0.44484731554985046, Valid Loss: 0.5806728601455688\n",
      "Epoch: 287, Train Loss: 0.44478124380111694, Valid Loss: 0.5807309150695801\n",
      "Epoch: 288, Train Loss: 0.4447151720523834, Valid Loss: 0.5808031558990479\n",
      "Epoch: 289, Train Loss: 0.444649338722229, Valid Loss: 0.5808517336845398\n",
      "Epoch: 290, Train Loss: 0.44458359479904175, Valid Loss: 0.580923855304718\n",
      "Epoch: 291, Train Loss: 0.44451797008514404, Valid Loss: 0.5809794068336487\n",
      "Epoch: 292, Train Loss: 0.4444523751735687, Valid Loss: 0.5810396671295166\n",
      "Epoch: 293, Train Loss: 0.44438689947128296, Valid Loss: 0.5811066627502441\n",
      "Epoch: 294, Train Loss: 0.4443216025829315, Valid Loss: 0.5811576843261719\n",
      "Epoch: 295, Train Loss: 0.4442562460899353, Valid Loss: 0.5812281966209412\n",
      "Epoch: 296, Train Loss: 0.4441911280155182, Valid Loss: 0.581280529499054\n",
      "Epoch: 297, Train Loss: 0.44412606954574585, Valid Loss: 0.5813446640968323\n",
      "Epoch: 298, Train Loss: 0.44406113028526306, Valid Loss: 0.5814040303230286\n",
      "Epoch: 299, Train Loss: 0.4439963400363922, Valid Loss: 0.5814599990844727\n",
      "Epoch: 300, Train Loss: 0.4439314901828766, Valid Loss: 0.5815250277519226\n",
      "Epoch: 301, Train Loss: 0.44386687874794006, Valid Loss: 0.5815755724906921\n",
      "Epoch: 302, Train Loss: 0.4438022971153259, Valid Loss: 0.5816420316696167\n",
      "Epoch: 303, Train Loss: 0.44373783469200134, Valid Loss: 0.581692636013031\n",
      "Epoch: 304, Train Loss: 0.4436735510826111, Valid Loss: 0.5817558765411377\n",
      "Epoch: 305, Train Loss: 0.4436093270778656, Valid Loss: 0.5818095803260803\n",
      "Epoch: 306, Train Loss: 0.4435451328754425, Valid Loss: 0.5818677544593811\n",
      "Epoch: 307, Train Loss: 0.44348108768463135, Valid Loss: 0.5819247961044312\n",
      "Epoch: 308, Train Loss: 0.4434170424938202, Valid Loss: 0.581978976726532\n",
      "Epoch: 309, Train Loss: 0.4433532655239105, Valid Loss: 0.5820395350456238\n",
      "Epoch: 310, Train Loss: 0.44328948855400085, Valid Loss: 0.5820898413658142\n",
      "Epoch: 311, Train Loss: 0.4432258605957031, Valid Loss: 0.5821516513824463\n",
      "Epoch: 312, Train Loss: 0.44316229224205017, Valid Loss: 0.5822004675865173\n",
      "Epoch: 313, Train Loss: 0.44309884309768677, Valid Loss: 0.5822627544403076\n",
      "Epoch: 314, Train Loss: 0.44303542375564575, Valid Loss: 0.5823104381561279\n",
      "Epoch: 315, Train Loss: 0.44297221302986145, Valid Loss: 0.5823739767074585\n",
      "Epoch: 316, Train Loss: 0.4429089426994324, Valid Loss: 0.5824189782142639\n",
      "Epoch: 317, Train Loss: 0.4428458511829376, Valid Loss: 0.5824843645095825\n",
      "Epoch: 318, Train Loss: 0.4427829086780548, Valid Loss: 0.5825257897377014\n",
      "Epoch: 319, Train Loss: 0.4427200257778168, Valid Loss: 0.5825953483581543\n",
      "Epoch: 320, Train Loss: 0.4426572024822235, Valid Loss: 0.5826295614242554\n",
      "Epoch: 321, Train Loss: 0.4425944983959198, Valid Loss: 0.5827082395553589\n",
      "Epoch: 322, Train Loss: 0.4425320029258728, Valid Loss: 0.5827277898788452\n",
      "Epoch: 323, Train Loss: 0.4424694776535034, Valid Loss: 0.5828260779380798\n",
      "Epoch: 324, Train Loss: 0.44240713119506836, Valid Loss: 0.5828151106834412\n",
      "Epoch: 325, Train Loss: 0.4423450827598572, Valid Loss: 0.582954466342926\n",
      "Epoch: 326, Train Loss: 0.44228318333625793, Valid Loss: 0.5828765630722046\n",
      "Epoch: 327, Train Loss: 0.44222187995910645, Valid Loss: 0.5831042528152466\n",
      "Epoch: 328, Train Loss: 0.4421618580818176, Valid Loss: 0.5828713774681091\n",
      "Epoch: 329, Train Loss: 0.44210389256477356, Valid Loss: 0.5832750201225281\n",
      "Epoch: 330, Train Loss: 0.44204792380332947, Valid Loss: 0.5827451944351196\n",
      "Epoch: 331, Train Loss: 0.44199156761169434, Valid Loss: 0.5834110379219055\n",
      "Epoch: 332, Train Loss: 0.4419266879558563, Valid Loss: 0.5828045606613159\n",
      "Epoch: 333, Train Loss: 0.4418541491031647, Valid Loss: 0.5834577679634094\n",
      "Epoch: 334, Train Loss: 0.44178780913352966, Valid Loss: 0.583392322063446\n",
      "Epoch: 335, Train Loss: 0.4417326748371124, Valid Loss: 0.5831577181816101\n",
      "Epoch: 336, Train Loss: 0.44167566299438477, Valid Loss: 0.5836396217346191\n",
      "Epoch: 337, Train Loss: 0.4416084289550781, Valid Loss: 0.5832980275154114\n",
      "Epoch: 338, Train Loss: 0.4415426254272461, Valid Loss: 0.5835617780685425\n",
      "Epoch: 339, Train Loss: 0.4414856433868408, Valid Loss: 0.5837395191192627\n",
      "Epoch: 340, Train Loss: 0.4414273500442505, Valid Loss: 0.5833970904350281\n",
      "Epoch: 341, Train Loss: 0.4413621127605438, Valid Loss: 0.583809494972229\n",
      "Epoch: 342, Train Loss: 0.4412991404533386, Valid Loss: 0.5837932825088501\n",
      "Epoch: 343, Train Loss: 0.4412418603897095, Valid Loss: 0.5836184620857239\n",
      "Epoch: 344, Train Loss: 0.4411816895008087, Valid Loss: 0.5839861631393433\n",
      "Epoch: 345, Train Loss: 0.4411177635192871, Valid Loss: 0.5838267207145691\n",
      "Epoch: 346, Train Loss: 0.4410572350025177, Valid Loss: 0.583878219127655\n",
      "Epoch: 347, Train Loss: 0.44099923968315125, Valid Loss: 0.5841120481491089\n",
      "Epoch: 348, Train Loss: 0.4409380555152893, Valid Loss: 0.5839053988456726\n",
      "Epoch: 349, Train Loss: 0.44087591767311096, Valid Loss: 0.584108829498291\n",
      "Epoch: 350, Train Loss: 0.4408167004585266, Valid Loss: 0.5842064023017883\n",
      "Epoch: 351, Train Loss: 0.4407579004764557, Valid Loss: 0.5840456485748291\n",
      "Epoch: 352, Train Loss: 0.440696656703949, Valid Loss: 0.5842918157577515\n",
      "Epoch: 353, Train Loss: 0.4406360983848572, Valid Loss: 0.5842923521995544\n",
      "Epoch: 354, Train Loss: 0.44057729840278625, Valid Loss: 0.5842160582542419\n",
      "Epoch: 355, Train Loss: 0.4405178725719452, Valid Loss: 0.5844558477401733\n",
      "Epoch: 356, Train Loss: 0.4404573142528534, Valid Loss: 0.5843517184257507\n",
      "Epoch: 357, Train Loss: 0.44039759039878845, Valid Loss: 0.5844327807426453\n",
      "Epoch: 358, Train Loss: 0.440339058637619, Valid Loss: 0.5845524072647095\n",
      "Epoch: 359, Train Loss: 0.44027969241142273, Valid Loss: 0.5844804048538208\n",
      "Epoch: 360, Train Loss: 0.44021978974342346, Valid Loss: 0.5845775604248047\n",
      "Epoch: 361, Train Loss: 0.4401610195636749, Valid Loss: 0.5846965909004211\n",
      "Epoch: 362, Train Loss: 0.4401029348373413, Valid Loss: 0.5845350027084351\n",
      "Epoch: 363, Train Loss: 0.4400448203086853, Valid Loss: 0.5848232507705688\n",
      "Epoch: 364, Train Loss: 0.4399873912334442, Valid Loss: 0.5846030712127686\n",
      "Epoch: 365, Train Loss: 0.43993210792541504, Valid Loss: 0.5848383903503418\n",
      "Epoch: 366, Train Loss: 0.4398786425590515, Valid Loss: 0.5846005082130432\n",
      "Epoch: 367, Train Loss: 0.43982356786727905, Valid Loss: 0.5848990082740784\n",
      "Epoch: 368, Train Loss: 0.4397639036178589, Valid Loss: 0.5845953822135925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 369, Train Loss: 0.4396968483924866, Valid Loss: 0.585075855255127\n",
      "Epoch: 370, Train Loss: 0.43963199853897095, Valid Loss: 0.584927499294281\n",
      "Epoch: 371, Train Loss: 0.43957528471946716, Valid Loss: 0.5849955081939697\n",
      "Epoch: 372, Train Loss: 0.4395223557949066, Valid Loss: 0.5851606726646423\n",
      "Epoch: 373, Train Loss: 0.4394649863243103, Valid Loss: 0.5848789215087891\n",
      "Epoch: 374, Train Loss: 0.4394015371799469, Valid Loss: 0.5852822661399841\n",
      "Epoch: 375, Train Loss: 0.43934062123298645, Valid Loss: 0.5851856470108032\n",
      "Epoch: 376, Train Loss: 0.4392853379249573, Valid Loss: 0.5851548314094543\n",
      "Epoch: 377, Train Loss: 0.4392300546169281, Valid Loss: 0.5853909850120544\n",
      "Epoch: 378, Train Loss: 0.4391701817512512, Valid Loss: 0.5851719379425049\n",
      "Epoch: 379, Train Loss: 0.4391093850135803, Valid Loss: 0.5854343771934509\n",
      "Epoch: 380, Train Loss: 0.43905243277549744, Valid Loss: 0.5854431390762329\n",
      "Epoch: 381, Train Loss: 0.43899714946746826, Valid Loss: 0.5853196382522583\n",
      "Epoch: 382, Train Loss: 0.43893909454345703, Valid Loss: 0.5855864882469177\n",
      "Epoch: 383, Train Loss: 0.43887946009635925, Valid Loss: 0.5854628086090088\n",
      "Epoch: 384, Train Loss: 0.4388218820095062, Valid Loss: 0.5855648517608643\n",
      "Epoch: 385, Train Loss: 0.438766211271286, Valid Loss: 0.585666835308075\n",
      "Epoch: 386, Train Loss: 0.4387092590332031, Valid Loss: 0.5855373740196228\n",
      "Epoch: 387, Train Loss: 0.4386507570743561, Valid Loss: 0.5857487320899963\n",
      "Epoch: 388, Train Loss: 0.4385930299758911, Valid Loss: 0.5857140421867371\n",
      "Epoch: 389, Train Loss: 0.43853694200515747, Valid Loss: 0.585712194442749\n",
      "Epoch: 390, Train Loss: 0.4384806454181671, Valid Loss: 0.5858574509620667\n",
      "Epoch: 391, Train Loss: 0.4384230971336365, Valid Loss: 0.5857737064361572\n",
      "Epoch: 392, Train Loss: 0.4383656680583954, Valid Loss: 0.585896909236908\n",
      "Epoch: 393, Train Loss: 0.4383092224597931, Valid Loss: 0.5859322547912598\n",
      "Epoch: 394, Train Loss: 0.4382532835006714, Valid Loss: 0.585889458656311\n",
      "Epoch: 395, Train Loss: 0.43819665908813477, Valid Loss: 0.586027204990387\n",
      "Epoch: 396, Train Loss: 0.4381397068500519, Valid Loss: 0.5859947800636292\n",
      "Epoch: 397, Train Loss: 0.43808305263519287, Valid Loss: 0.586048424243927\n",
      "Epoch: 398, Train Loss: 0.43802714347839355, Valid Loss: 0.5861271619796753\n",
      "Epoch: 399, Train Loss: 0.43797120451927185, Valid Loss: 0.5860779285430908\n",
      "Epoch: 400, Train Loss: 0.43791478872299194, Valid Loss: 0.5861930251121521\n",
      "Epoch: 401, Train Loss: 0.4378582835197449, Valid Loss: 0.5861942172050476\n",
      "Epoch: 402, Train Loss: 0.43780243396759033, Valid Loss: 0.5862096548080444\n",
      "Epoch: 403, Train Loss: 0.43774667382240295, Valid Loss: 0.5863072872161865\n",
      "Epoch: 404, Train Loss: 0.4376908838748932, Valid Loss: 0.5862590074539185\n",
      "Epoch: 405, Train Loss: 0.4376348853111267, Valid Loss: 0.5863620638847351\n",
      "Epoch: 406, Train Loss: 0.4375789761543274, Valid Loss: 0.586374044418335\n",
      "Epoch: 407, Train Loss: 0.43752339482307434, Valid Loss: 0.5863810181617737\n",
      "Epoch: 408, Train Loss: 0.437468022108078, Valid Loss: 0.5864803194999695\n",
      "Epoch: 409, Train Loss: 0.4374125301837921, Valid Loss: 0.5864289999008179\n",
      "Epoch: 410, Train Loss: 0.4373569190502167, Valid Loss: 0.5865373611450195\n",
      "Epoch: 411, Train Loss: 0.43730148673057556, Valid Loss: 0.5865318179130554\n",
      "Epoch: 412, Train Loss: 0.4372461438179016, Valid Loss: 0.5865623950958252\n",
      "Epoch: 413, Train Loss: 0.4371909499168396, Valid Loss: 0.5866380333900452\n",
      "Epoch: 414, Train Loss: 0.4371359348297119, Valid Loss: 0.5866003632545471\n",
      "Epoch: 415, Train Loss: 0.43708083033561707, Valid Loss: 0.5867094397544861\n",
      "Epoch: 416, Train Loss: 0.4370257556438446, Valid Loss: 0.5866784453392029\n",
      "Epoch: 417, Train Loss: 0.4369705617427826, Valid Loss: 0.5867488980293274\n",
      "Epoch: 418, Train Loss: 0.436915785074234, Valid Loss: 0.5867759585380554\n",
      "Epoch: 419, Train Loss: 0.4368610680103302, Valid Loss: 0.5867833495140076\n",
      "Epoch: 420, Train Loss: 0.436806321144104, Valid Loss: 0.5868592262268066\n",
      "Epoch: 421, Train Loss: 0.43675172328948975, Valid Loss: 0.5868381261825562\n",
      "Epoch: 422, Train Loss: 0.4366970956325531, Valid Loss: 0.5869183540344238\n",
      "Epoch: 423, Train Loss: 0.43664228916168213, Valid Loss: 0.5869141221046448\n",
      "Epoch: 424, Train Loss: 0.436587929725647, Valid Loss: 0.5869629383087158\n",
      "Epoch: 425, Train Loss: 0.4365336000919342, Valid Loss: 0.5869953632354736\n",
      "Epoch: 426, Train Loss: 0.4364791214466095, Valid Loss: 0.5870094299316406\n",
      "Epoch: 427, Train Loss: 0.4364250600337982, Valid Loss: 0.5870652794837952\n",
      "Epoch: 428, Train Loss: 0.4363706409931183, Valid Loss: 0.5870689749717712\n",
      "Epoch: 429, Train Loss: 0.43631651997566223, Valid Loss: 0.5871208310127258\n",
      "Epoch: 430, Train Loss: 0.4362623989582062, Valid Loss: 0.587140679359436\n",
      "Epoch: 431, Train Loss: 0.43620845675468445, Valid Loss: 0.5871666669845581\n",
      "Epoch: 432, Train Loss: 0.43615448474884033, Valid Loss: 0.5872163772583008\n",
      "Epoch: 433, Train Loss: 0.4361006021499634, Valid Loss: 0.5872100591659546\n",
      "Epoch: 434, Train Loss: 0.4360467493534088, Valid Loss: 0.5872902274131775\n",
      "Epoch: 435, Train Loss: 0.43599310517311096, Valid Loss: 0.5872545838356018\n",
      "Epoch: 436, Train Loss: 0.435939222574234, Valid Loss: 0.587361216545105\n",
      "Epoch: 437, Train Loss: 0.43588581681251526, Valid Loss: 0.5872972011566162\n",
      "Epoch: 438, Train Loss: 0.4358323812484741, Valid Loss: 0.5874347686767578\n",
      "Epoch: 439, Train Loss: 0.43577900528907776, Valid Loss: 0.5873300433158875\n",
      "Epoch: 440, Train Loss: 0.4357261061668396, Valid Loss: 0.5875164866447449\n",
      "Epoch: 441, Train Loss: 0.4356735348701477, Valid Loss: 0.5873337388038635\n",
      "Epoch: 442, Train Loss: 0.43562179803848267, Valid Loss: 0.5876106023788452\n",
      "Epoch: 443, Train Loss: 0.43557119369506836, Valid Loss: 0.5872767567634583\n",
      "Epoch: 444, Train Loss: 0.4355219900608063, Valid Loss: 0.5877029299736023\n",
      "Epoch: 445, Train Loss: 0.43547323346138, Valid Loss: 0.5871679782867432\n",
      "Epoch: 446, Train Loss: 0.43542200326919556, Valid Loss: 0.5877569913864136\n",
      "Epoch: 447, Train Loss: 0.43536442518234253, Valid Loss: 0.5872950553894043\n",
      "Epoch: 448, Train Loss: 0.435303658246994, Valid Loss: 0.5877300500869751\n",
      "Epoch: 449, Train Loss: 0.43524715304374695, Valid Loss: 0.5877435207366943\n",
      "Epoch: 450, Train Loss: 0.43519774079322815, Valid Loss: 0.5874646902084351\n",
      "Epoch: 451, Train Loss: 0.43514978885650635, Valid Loss: 0.587978184223175\n",
      "Epoch: 452, Train Loss: 0.4350968897342682, Valid Loss: 0.587367832660675\n",
      "Epoch: 453, Train Loss: 0.4350401759147644, Valid Loss: 0.5880197882652283\n",
      "Epoch: 454, Train Loss: 0.43498626351356506, Valid Loss: 0.5876197814941406\n",
      "Epoch: 455, Train Loss: 0.4349377453327179, Valid Loss: 0.5878839492797852\n",
      "Epoch: 456, Train Loss: 0.4348899722099304, Valid Loss: 0.5876721739768982\n",
      "Epoch: 457, Train Loss: 0.43483826518058777, Valid Loss: 0.5879571437835693\n",
      "Epoch: 458, Train Loss: 0.4347846508026123, Valid Loss: 0.5875358581542969\n",
      "Epoch: 459, Train Loss: 0.4347311854362488, Valid Loss: 0.5882421135902405\n",
      "Epoch: 460, Train Loss: 0.4346778988838196, Valid Loss: 0.5875003337860107\n",
      "Epoch: 461, Train Loss: 0.4346219003200531, Valid Loss: 0.5882552862167358\n",
      "Epoch: 462, Train Loss: 0.434565931558609, Valid Loss: 0.5879024267196655\n",
      "Epoch: 463, Train Loss: 0.4345133900642395, Valid Loss: 0.587942361831665\n",
      "Epoch: 464, Train Loss: 0.4344647228717804, Valid Loss: 0.5883100628852844\n",
      "Epoch: 465, Train Loss: 0.4344154894351959, Valid Loss: 0.587685763835907\n",
      "Epoch: 466, Train Loss: 0.4343624413013458, Valid Loss: 0.5884014964103699\n",
      "Epoch: 467, Train Loss: 0.43430715799331665, Valid Loss: 0.5879372358322144\n",
      "Epoch: 468, Train Loss: 0.4342534840106964, Valid Loss: 0.5881996750831604\n",
      "Epoch: 469, Train Loss: 0.43420252203941345, Valid Loss: 0.5883218050003052\n",
      "Epoch: 470, Train Loss: 0.4341524839401245, Valid Loss: 0.5879690051078796\n",
      "Epoch: 471, Train Loss: 0.43410125374794006, Valid Loss: 0.5884629487991333\n",
      "Epoch: 472, Train Loss: 0.43404901027679443, Valid Loss: 0.5880657434463501\n",
      "Epoch: 473, Train Loss: 0.4339965879917145, Valid Loss: 0.588374674320221\n",
      "Epoch: 474, Train Loss: 0.43394461274147034, Valid Loss: 0.5883362293243408\n",
      "Epoch: 475, Train Loss: 0.43389296531677246, Valid Loss: 0.588239848613739\n",
      "Epoch: 476, Train Loss: 0.43384185433387756, Valid Loss: 0.5884965658187866\n",
      "Epoch: 477, Train Loss: 0.4337909519672394, Valid Loss: 0.5882441997528076\n",
      "Epoch: 478, Train Loss: 0.4337400794029236, Valid Loss: 0.5885019898414612\n",
      "Epoch: 479, Train Loss: 0.4336886703968048, Valid Loss: 0.5883767604827881\n",
      "Epoch: 480, Train Loss: 0.4336368441581726, Valid Loss: 0.5884691476821899\n",
      "Epoch: 481, Train Loss: 0.43358516693115234, Valid Loss: 0.5885143280029297\n",
      "Epoch: 482, Train Loss: 0.4335341453552246, Valid Loss: 0.5884585976600647\n",
      "Epoch: 483, Train Loss: 0.4334837794303894, Valid Loss: 0.5885835289955139\n",
      "Epoch: 484, Train Loss: 0.4334332346916199, Valid Loss: 0.5884813666343689\n",
      "Epoch: 485, Train Loss: 0.4333823025226593, Valid Loss: 0.5886331796646118\n",
      "Epoch: 486, Train Loss: 0.43333104252815247, Valid Loss: 0.5885440707206726\n",
      "Epoch: 487, Train Loss: 0.43327993154525757, Valid Loss: 0.5886688828468323\n",
      "Epoch: 488, Train Loss: 0.43322911858558655, Valid Loss: 0.5886206030845642\n",
      "Epoch: 489, Train Loss: 0.43317872285842896, Valid Loss: 0.5886660218238831\n",
      "Epoch: 490, Train Loss: 0.4331284165382385, Valid Loss: 0.5887135863304138\n",
      "Epoch: 491, Train Loss: 0.4330778419971466, Valid Loss: 0.5886554718017578\n",
      "Epoch: 492, Train Loss: 0.4330272972583771, Valid Loss: 0.5888082385063171\n",
      "Epoch: 493, Train Loss: 0.43297678232192993, Valid Loss: 0.5886707305908203\n",
      "Epoch: 494, Train Loss: 0.43292632699012756, Valid Loss: 0.5888593792915344\n",
      "Epoch: 495, Train Loss: 0.43287599086761475, Valid Loss: 0.5887315273284912\n",
      "Epoch: 496, Train Loss: 0.43282535672187805, Valid Loss: 0.5888603329658508\n",
      "Epoch: 497, Train Loss: 0.43277525901794434, Valid Loss: 0.588835597038269\n",
      "Epoch: 498, Train Loss: 0.43272513151168823, Valid Loss: 0.5888416171073914\n",
      "Epoch: 499, Train Loss: 0.43267500400543213, Valid Loss: 0.5889415144920349\n",
      "Epoch: 500, Train Loss: 0.43262502551078796, Valid Loss: 0.588833212852478\n",
      "Epoch: 501, Train Loss: 0.43257513642311096, Valid Loss: 0.5890108346939087\n",
      "Epoch: 502, Train Loss: 0.4325252175331116, Valid Loss: 0.5888617634773254\n",
      "Epoch: 503, Train Loss: 0.43247517943382263, Valid Loss: 0.5890470743179321\n",
      "Epoch: 504, Train Loss: 0.43242529034614563, Valid Loss: 0.5889260768890381\n",
      "Epoch: 505, Train Loss: 0.432375431060791, Valid Loss: 0.5890640616416931\n",
      "Epoch: 506, Train Loss: 0.4323256313800812, Valid Loss: 0.5889976024627686\n",
      "Epoch: 507, Train Loss: 0.4322758913040161, Valid Loss: 0.5890772342681885\n",
      "Epoch: 508, Train Loss: 0.4322262108325958, Valid Loss: 0.5890589952468872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 509, Train Loss: 0.4321765601634979, Valid Loss: 0.5891037583351135\n",
      "Epoch: 510, Train Loss: 0.4321269690990448, Valid Loss: 0.589110791683197\n",
      "Epoch: 511, Train Loss: 0.4320774972438812, Valid Loss: 0.5891435742378235\n",
      "Epoch: 512, Train Loss: 0.4320279061794281, Valid Loss: 0.5891508460044861\n",
      "Epoch: 513, Train Loss: 0.4319784641265869, Valid Loss: 0.5891844034194946\n",
      "Epoch: 514, Train Loss: 0.43192917108535767, Valid Loss: 0.5891878008842468\n",
      "Epoch: 515, Train Loss: 0.43187981843948364, Valid Loss: 0.5892238020896912\n",
      "Epoch: 516, Train Loss: 0.43183043599128723, Valid Loss: 0.5892319083213806\n",
      "Epoch: 517, Train Loss: 0.4317813217639923, Valid Loss: 0.5892581343650818\n",
      "Epoch: 518, Train Loss: 0.4317321181297302, Valid Loss: 0.5892818570137024\n",
      "Epoch: 519, Train Loss: 0.4316829442977905, Valid Loss: 0.589281439781189\n",
      "Epoch: 520, Train Loss: 0.43163391947746277, Valid Loss: 0.5893383026123047\n",
      "Epoch: 521, Train Loss: 0.4315849244594574, Valid Loss: 0.5892975926399231\n",
      "Epoch: 522, Train Loss: 0.4315360486507416, Valid Loss: 0.589404821395874\n",
      "Epoch: 523, Train Loss: 0.43148723244667053, Valid Loss: 0.5893018245697021\n",
      "Epoch: 524, Train Loss: 0.4314383864402771, Valid Loss: 0.5894849896430969\n",
      "Epoch: 525, Train Loss: 0.43138986825942993, Valid Loss: 0.5892751216888428\n",
      "Epoch: 526, Train Loss: 0.4313417673110962, Valid Loss: 0.5895960330963135\n",
      "Epoch: 527, Train Loss: 0.4312942624092102, Valid Loss: 0.5891785025596619\n",
      "Epoch: 528, Train Loss: 0.4312479794025421, Valid Loss: 0.5897649526596069\n",
      "Epoch: 529, Train Loss: 0.4312041103839874, Valid Loss: 0.588930070400238\n",
      "Epoch: 530, Train Loss: 0.4311627149581909, Valid Loss: 0.5899704694747925\n",
      "Epoch: 531, Train Loss: 0.43112310767173767, Valid Loss: 0.5885440707206726\n",
      "Epoch: 532, Train Loss: 0.4310763478279114, Valid Loss: 0.5900681018829346\n",
      "Epoch: 533, Train Loss: 0.4310188889503479, Valid Loss: 0.588809072971344\n",
      "Epoch: 534, Train Loss: 0.4309566617012024, Valid Loss: 0.5897539258003235\n",
      "Epoch: 535, Train Loss: 0.4309062063694, Valid Loss: 0.5898202657699585\n",
      "Epoch: 536, Train Loss: 0.43086719512939453, Valid Loss: 0.5888903737068176\n",
      "Epoch: 537, Train Loss: 0.4308236241340637, Valid Loss: 0.5902009010314941\n",
      "Epoch: 538, Train Loss: 0.4307689368724823, Valid Loss: 0.5890066027641296\n",
      "Epoch: 539, Train Loss: 0.4307129383087158, Valid Loss: 0.5898627042770386\n",
      "Epoch: 540, Train Loss: 0.43066686391830444, Valid Loss: 0.5898383855819702\n",
      "Epoch: 541, Train Loss: 0.4306240379810333, Valid Loss: 0.5891937017440796\n",
      "Epoch: 542, Train Loss: 0.4305735230445862, Valid Loss: 0.5900227427482605\n",
      "Epoch: 543, Train Loss: 0.4305191934108734, Valid Loss: 0.5896060466766357\n",
      "Epoch: 544, Train Loss: 0.4304709732532501, Valid Loss: 0.5895829200744629\n",
      "Epoch: 545, Train Loss: 0.4304271340370178, Valid Loss: 0.5901100635528564\n",
      "Epoch: 546, Train Loss: 0.4303794205188751, Valid Loss: 0.5893900394439697\n",
      "Epoch: 547, Train Loss: 0.43032777309417725, Valid Loss: 0.5899314880371094\n",
      "Epoch: 548, Train Loss: 0.4302794337272644, Valid Loss: 0.5899697542190552\n",
      "Epoch: 549, Train Loss: 0.4302346408367157, Valid Loss: 0.5894573330879211\n",
      "Epoch: 550, Train Loss: 0.43018731474876404, Valid Loss: 0.5902104377746582\n",
      "Epoch: 551, Train Loss: 0.4301372766494751, Valid Loss: 0.5896364450454712\n",
      "Epoch: 552, Train Loss: 0.43008896708488464, Valid Loss: 0.5898922085762024\n",
      "Epoch: 553, Train Loss: 0.43004313111305237, Valid Loss: 0.5900500416755676\n",
      "Epoch: 554, Train Loss: 0.429996132850647, Valid Loss: 0.5896942019462585\n",
      "Epoch: 555, Train Loss: 0.4299469590187073, Valid Loss: 0.5900335311889648\n",
      "Epoch: 556, Train Loss: 0.42989858984947205, Valid Loss: 0.5900475382804871\n",
      "Epoch: 557, Train Loss: 0.4298519790172577, Valid Loss: 0.589736819267273\n",
      "Epoch: 558, Train Loss: 0.42980509996414185, Valid Loss: 0.5902485847473145\n",
      "Epoch: 559, Train Loss: 0.4297568202018738, Valid Loss: 0.5898069739341736\n",
      "Epoch: 560, Train Loss: 0.42970871925354004, Valid Loss: 0.5900754332542419\n",
      "Epoch: 561, Train Loss: 0.42966192960739136, Valid Loss: 0.5901445150375366\n",
      "Epoch: 562, Train Loss: 0.42961522936820984, Valid Loss: 0.589891791343689\n",
      "Epoch: 563, Train Loss: 0.4295676648616791, Valid Loss: 0.5902082920074463\n",
      "Epoch: 564, Train Loss: 0.42951980233192444, Valid Loss: 0.5900617837905884\n",
      "Epoch: 565, Train Loss: 0.4294728636741638, Valid Loss: 0.5900293588638306\n",
      "Epoch: 566, Train Loss: 0.42942631244659424, Valid Loss: 0.5902770757675171\n",
      "Epoch: 567, Train Loss: 0.42937931418418884, Valid Loss: 0.5899966359138489\n",
      "Epoch: 568, Train Loss: 0.4293319582939148, Valid Loss: 0.5902398824691772\n",
      "Epoch: 569, Train Loss: 0.429284930229187, Valid Loss: 0.5901989936828613\n",
      "Epoch: 570, Train Loss: 0.42923837900161743, Valid Loss: 0.5900880098342896\n",
      "Epoch: 571, Train Loss: 0.4291916787624359, Valid Loss: 0.5903370976448059\n",
      "Epoch: 572, Train Loss: 0.42914479970932007, Valid Loss: 0.5901236534118652\n",
      "Epoch: 573, Train Loss: 0.42909786105155945, Valid Loss: 0.5902809500694275\n",
      "Epoch: 574, Train Loss: 0.4290512204170227, Valid Loss: 0.5902938842773438\n",
      "Epoch: 575, Train Loss: 0.4290047287940979, Valid Loss: 0.5901891589164734\n",
      "Epoch: 576, Train Loss: 0.42895811796188354, Valid Loss: 0.5903679132461548\n",
      "Epoch: 577, Train Loss: 0.4289114773273468, Valid Loss: 0.5902620553970337\n",
      "Epoch: 578, Train Loss: 0.42886489629745483, Valid Loss: 0.5903011560440063\n",
      "Epoch: 579, Train Loss: 0.4288186728954315, Valid Loss: 0.5904190540313721\n",
      "Epoch: 580, Train Loss: 0.42877253890037537, Valid Loss: 0.590216338634491\n",
      "Epoch: 581, Train Loss: 0.42872676253318787, Valid Loss: 0.5904998183250427\n",
      "Epoch: 582, Train Loss: 0.4286811351776123, Valid Loss: 0.5902289152145386\n",
      "Epoch: 583, Train Loss: 0.4286362826824188, Valid Loss: 0.5904913544654846\n",
      "Epoch: 584, Train Loss: 0.4285925328731537, Valid Loss: 0.5902515649795532\n",
      "Epoch: 585, Train Loss: 0.4285503029823303, Valid Loss: 0.5904713273048401\n",
      "Epoch: 586, Train Loss: 0.4285086691379547, Valid Loss: 0.5901598930358887\n",
      "Epoch: 587, Train Loss: 0.4284660816192627, Valid Loss: 0.5904995799064636\n",
      "Epoch: 588, Train Loss: 0.4284181296825409, Valid Loss: 0.5901364088058472\n",
      "Epoch: 589, Train Loss: 0.42836496233940125, Valid Loss: 0.5905665755271912\n",
      "Epoch: 590, Train Loss: 0.4283112585544586, Valid Loss: 0.590431272983551\n",
      "Epoch: 591, Train Loss: 0.42826417088508606, Valid Loss: 0.5904684662818909\n",
      "Epoch: 592, Train Loss: 0.42822265625, Valid Loss: 0.5906195640563965\n",
      "Epoch: 593, Train Loss: 0.4281805455684662, Valid Loss: 0.5903278589248657\n",
      "Epoch: 594, Train Loss: 0.428133100271225, Valid Loss: 0.5906088948249817\n",
      "Epoch: 595, Train Loss: 0.4280823767185211, Valid Loss: 0.5905508995056152\n",
      "Epoch: 596, Train Loss: 0.4280346632003784, Valid Loss: 0.5904952883720398\n",
      "Epoch: 597, Train Loss: 0.4279910922050476, Valid Loss: 0.5907506942749023\n",
      "Epoch: 598, Train Loss: 0.42794764041900635, Valid Loss: 0.5904200077056885\n",
      "Epoch: 599, Train Loss: 0.4279010593891144, Valid Loss: 0.5906944274902344\n",
      "Epoch: 600, Train Loss: 0.42785272002220154, Valid Loss: 0.5906673669815063\n",
      "Epoch: 601, Train Loss: 0.42780640721321106, Valid Loss: 0.5905215740203857\n",
      "Epoch: 602, Train Loss: 0.427762508392334, Valid Loss: 0.5908703804016113\n",
      "Epoch: 603, Train Loss: 0.4277179539203644, Valid Loss: 0.5904701352119446\n",
      "Epoch: 604, Train Loss: 0.42767131328582764, Valid Loss: 0.5908144116401672\n",
      "Epoch: 605, Train Loss: 0.42762431502342224, Valid Loss: 0.5907204747200012\n",
      "Epoch: 606, Train Loss: 0.42757904529571533, Valid Loss: 0.5906158685684204\n",
      "Epoch: 607, Train Loss: 0.4275348484516144, Valid Loss: 0.5909335613250732\n",
      "Epoch: 608, Train Loss: 0.4274899363517761, Valid Loss: 0.5905446410179138\n",
      "Epoch: 609, Train Loss: 0.4274437427520752, Valid Loss: 0.5909258127212524\n",
      "Epoch: 610, Train Loss: 0.42739754915237427, Valid Loss: 0.5907309651374817\n",
      "Epoch: 611, Train Loss: 0.42735254764556885, Valid Loss: 0.5907717943191528\n",
      "Epoch: 612, Train Loss: 0.42730799317359924, Valid Loss: 0.5909194350242615\n",
      "Epoch: 613, Train Loss: 0.4272629916667938, Valid Loss: 0.5906960964202881\n",
      "Epoch: 614, Train Loss: 0.4272172152996063, Valid Loss: 0.5909639596939087\n",
      "Epoch: 615, Train Loss: 0.4271719455718994, Valid Loss: 0.5907877087593079\n",
      "Epoch: 616, Train Loss: 0.4271271824836731, Valid Loss: 0.5909038782119751\n",
      "Epoch: 617, Train Loss: 0.42708250880241394, Valid Loss: 0.5908933281898499\n",
      "Epoch: 618, Train Loss: 0.4270375072956085, Valid Loss: 0.5908835530281067\n",
      "Epoch: 619, Train Loss: 0.42699214816093445, Valid Loss: 0.5909265279769897\n",
      "Epoch: 620, Train Loss: 0.4269470274448395, Valid Loss: 0.5909470915794373\n",
      "Epoch: 621, Train Loss: 0.4269024133682251, Valid Loss: 0.5909134745597839\n",
      "Epoch: 622, Train Loss: 0.4268578588962555, Valid Loss: 0.590997040271759\n",
      "Epoch: 623, Train Loss: 0.4268130958080292, Valid Loss: 0.5909470915794373\n",
      "Epoch: 624, Train Loss: 0.426768034696579, Valid Loss: 0.5909832119941711\n",
      "Epoch: 625, Train Loss: 0.4267234206199646, Valid Loss: 0.5910411477088928\n",
      "Epoch: 626, Train Loss: 0.42667877674102783, Valid Loss: 0.5909416079521179\n",
      "Epoch: 627, Train Loss: 0.42663443088531494, Valid Loss: 0.59112149477005\n",
      "Epoch: 628, Train Loss: 0.4265897870063782, Valid Loss: 0.5909421443939209\n",
      "Epoch: 629, Train Loss: 0.4265451729297638, Valid Loss: 0.5911433696746826\n",
      "Epoch: 630, Train Loss: 0.4265005588531494, Valid Loss: 0.5909997820854187\n",
      "Epoch: 631, Train Loss: 0.42645615339279175, Valid Loss: 0.5911318063735962\n",
      "Epoch: 632, Train Loss: 0.42641180753707886, Valid Loss: 0.591061532497406\n",
      "Epoch: 633, Train Loss: 0.42636755108833313, Valid Loss: 0.5911386609077454\n",
      "Epoch: 634, Train Loss: 0.4263230860233307, Valid Loss: 0.5910829305648804\n",
      "Epoch: 635, Train Loss: 0.4262787103652954, Valid Loss: 0.5911940336227417\n",
      "Epoch: 636, Train Loss: 0.4262346029281616, Valid Loss: 0.5910634398460388\n",
      "Epoch: 637, Train Loss: 0.4261903762817383, Valid Loss: 0.5912749767303467\n",
      "Epoch: 638, Train Loss: 0.4261462986469269, Valid Loss: 0.5910305976867676\n",
      "Epoch: 639, Train Loss: 0.4261021912097931, Valid Loss: 0.5913553833961487\n",
      "Epoch: 640, Train Loss: 0.42605826258659363, Valid Loss: 0.590996503829956\n",
      "Epoch: 641, Train Loss: 0.42601460218429565, Valid Loss: 0.5914430022239685\n",
      "Epoch: 642, Train Loss: 0.4259711503982544, Valid Loss: 0.5909280776977539\n",
      "Epoch: 643, Train Loss: 0.4259282350540161, Valid Loss: 0.5915767550468445\n",
      "Epoch: 644, Train Loss: 0.425885945558548, Valid Loss: 0.5907619595527649\n",
      "Epoch: 645, Train Loss: 0.42584457993507385, Valid Loss: 0.5917931199073792\n",
      "Epoch: 646, Train Loss: 0.42580467462539673, Valid Loss: 0.5904476642608643\n",
      "Epoch: 647, Train Loss: 0.42576539516448975, Valid Loss: 0.592059850692749\n",
      "Epoch: 648, Train Loss: 0.42572593688964844, Valid Loss: 0.5901237726211548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 649, Train Loss: 0.42568185925483704, Valid Loss: 0.5921759605407715\n",
      "Epoch: 650, Train Loss: 0.4256327450275421, Valid Loss: 0.5903674960136414\n",
      "Epoch: 651, Train Loss: 0.42558038234710693, Valid Loss: 0.5918076038360596\n",
      "Epoch: 652, Train Loss: 0.42553165555000305, Valid Loss: 0.5912835597991943\n",
      "Epoch: 653, Train Loss: 0.4254891872406006, Valid Loss: 0.591007649898529\n",
      "Epoch: 654, Train Loss: 0.42545008659362793, Valid Loss: 0.5919555425643921\n",
      "Epoch: 655, Train Loss: 0.4254094064235687, Valid Loss: 0.5906069278717041\n",
      "Epoch: 656, Train Loss: 0.4253638684749603, Valid Loss: 0.5919568538665771\n",
      "Epoch: 657, Train Loss: 0.4253162741661072, Valid Loss: 0.5910804271697998\n",
      "Epoch: 658, Train Loss: 0.4252709448337555, Valid Loss: 0.5913748741149902\n",
      "Epoch: 659, Train Loss: 0.42522865533828735, Valid Loss: 0.5917701125144958\n",
      "Epoch: 660, Train Loss: 0.42518723011016846, Valid Loss: 0.590901792049408\n",
      "Epoch: 661, Train Loss: 0.4251437187194824, Valid Loss: 0.5919605493545532\n",
      "Epoch: 662, Train Loss: 0.4250987768173218, Valid Loss: 0.5911033749580383\n",
      "Epoch: 663, Train Loss: 0.425054132938385, Valid Loss: 0.5915789604187012\n",
      "Epoch: 664, Train Loss: 0.4250110983848572, Valid Loss: 0.5916503667831421\n",
      "Epoch: 665, Train Loss: 0.4249690771102905, Valid Loss: 0.5911466479301453\n",
      "Epoch: 666, Train Loss: 0.42492619156837463, Valid Loss: 0.5919224619865417\n",
      "Epoch: 667, Train Loss: 0.42488205432891846, Valid Loss: 0.5911779999732971\n",
      "Epoch: 668, Train Loss: 0.4248376488685608, Valid Loss: 0.5917315483093262\n",
      "Epoch: 669, Train Loss: 0.4247943162918091, Valid Loss: 0.5915736556053162\n",
      "Epoch: 670, Train Loss: 0.4247520864009857, Valid Loss: 0.5913821458816528\n",
      "Epoch: 671, Train Loss: 0.42470991611480713, Valid Loss: 0.5918706059455872\n",
      "Epoch: 672, Train Loss: 0.42466676235198975, Valid Loss: 0.5912818908691406\n",
      "Epoch: 673, Train Loss: 0.4246230125427246, Valid Loss: 0.591835618019104\n",
      "Epoch: 674, Train Loss: 0.42457929253578186, Valid Loss: 0.5915215015411377\n",
      "Epoch: 675, Train Loss: 0.4245363175868988, Valid Loss: 0.5915996432304382\n",
      "Epoch: 676, Train Loss: 0.4244939386844635, Valid Loss: 0.5918107032775879\n",
      "Epoch: 677, Train Loss: 0.4244515597820282, Valid Loss: 0.5914247632026672\n",
      "Epoch: 678, Train Loss: 0.4244089126586914, Valid Loss: 0.5919001698493958\n",
      "Epoch: 679, Train Loss: 0.4243658781051636, Valid Loss: 0.591498613357544\n",
      "Epoch: 680, Train Loss: 0.4243226945400238, Valid Loss: 0.5917907953262329\n",
      "Epoch: 681, Train Loss: 0.4242798089981079, Valid Loss: 0.5917237401008606\n",
      "Epoch: 682, Train Loss: 0.42423731088638306, Valid Loss: 0.5916144847869873\n",
      "Epoch: 683, Train Loss: 0.42419496178627014, Valid Loss: 0.5919000506401062\n",
      "Epoch: 684, Train Loss: 0.42415252327919006, Valid Loss: 0.5915496945381165\n",
      "Epoch: 685, Train Loss: 0.4241098463535309, Valid Loss: 0.5919314026832581\n",
      "Epoch: 686, Train Loss: 0.4240671694278717, Valid Loss: 0.5916409492492676\n",
      "Epoch: 687, Train Loss: 0.4240246117115021, Valid Loss: 0.5918349027633667\n",
      "Epoch: 688, Train Loss: 0.42398205399513245, Valid Loss: 0.591812789440155\n",
      "Epoch: 689, Train Loss: 0.4239397644996643, Valid Loss: 0.5917177200317383\n",
      "Epoch: 690, Train Loss: 0.4238974452018738, Valid Loss: 0.5919516086578369\n",
      "Epoch: 691, Train Loss: 0.4238552749156952, Valid Loss: 0.5916652679443359\n",
      "Epoch: 692, Train Loss: 0.4238131046295166, Valid Loss: 0.5919971466064453\n",
      "Epoch: 693, Train Loss: 0.4237706959247589, Valid Loss: 0.5917123556137085\n",
      "Epoch: 694, Train Loss: 0.4237282872200012, Valid Loss: 0.5919649600982666\n",
      "Epoch: 695, Train Loss: 0.42368605732917786, Valid Loss: 0.5918208360671997\n",
      "Epoch: 696, Train Loss: 0.4236440062522888, Valid Loss: 0.5918937921524048\n",
      "Epoch: 697, Train Loss: 0.42360174655914307, Valid Loss: 0.5919362306594849\n",
      "Epoch: 698, Train Loss: 0.4235597252845764, Valid Loss: 0.5918372869491577\n",
      "Epoch: 699, Train Loss: 0.42351776361465454, Valid Loss: 0.5920211672782898\n",
      "Epoch: 700, Train Loss: 0.42347580194473267, Valid Loss: 0.5918186902999878\n",
      "Epoch: 701, Train Loss: 0.42343369126319885, Valid Loss: 0.5920615196228027\n",
      "Epoch: 702, Train Loss: 0.4233919084072113, Valid Loss: 0.5918446183204651\n",
      "Epoch: 703, Train Loss: 0.42334991693496704, Valid Loss: 0.5920675992965698\n",
      "Epoch: 704, Train Loss: 0.42330801486968994, Valid Loss: 0.5918951630592346\n",
      "Epoch: 705, Train Loss: 0.42326605319976807, Valid Loss: 0.5920583009719849\n",
      "Epoch: 706, Train Loss: 0.4232242703437805, Valid Loss: 0.5919511318206787\n",
      "Epoch: 707, Train Loss: 0.42318251729011536, Valid Loss: 0.5920529961585999\n",
      "Epoch: 708, Train Loss: 0.42314085364341736, Valid Loss: 0.5919926166534424\n",
      "Epoch: 709, Train Loss: 0.423099160194397, Valid Loss: 0.5920664072036743\n",
      "Epoch: 710, Train Loss: 0.42305755615234375, Valid Loss: 0.5920095443725586\n",
      "Epoch: 711, Train Loss: 0.42301592230796814, Valid Loss: 0.5921083092689514\n",
      "Epoch: 712, Train Loss: 0.42297452688217163, Valid Loss: 0.5919936299324036\n",
      "Epoch: 713, Train Loss: 0.4229331314563751, Valid Loss: 0.5921837687492371\n",
      "Epoch: 714, Train Loss: 0.42289185523986816, Valid Loss: 0.5919333696365356\n",
      "Epoch: 715, Train Loss: 0.42285093665122986, Valid Loss: 0.5923072099685669\n",
      "Epoch: 716, Train Loss: 0.42281031608581543, Valid Loss: 0.5918037295341492\n",
      "Epoch: 717, Train Loss: 0.4227702021598816, Valid Loss: 0.5924947261810303\n",
      "Epoch: 718, Train Loss: 0.42273131012916565, Valid Loss: 0.5915541052818298\n",
      "Epoch: 719, Train Loss: 0.42269402742385864, Valid Loss: 0.5927740335464478\n",
      "Epoch: 720, Train Loss: 0.42265865206718445, Valid Loss: 0.5911204814910889\n",
      "Epoch: 721, Train Loss: 0.4226255416870117, Valid Loss: 0.593101978302002\n",
      "Epoch: 722, Train Loss: 0.42259272933006287, Valid Loss: 0.5906246900558472\n",
      "Epoch: 723, Train Loss: 0.42255571484565735, Valid Loss: 0.5932400226593018\n",
      "Epoch: 724, Train Loss: 0.4225093722343445, Valid Loss: 0.5908086895942688\n",
      "Epoch: 725, Train Loss: 0.4224552810192108, Valid Loss: 0.5928020477294922\n",
      "Epoch: 726, Train Loss: 0.4224012792110443, Valid Loss: 0.592008650302887\n",
      "Epoch: 727, Train Loss: 0.4223555624485016, Valid Loss: 0.5918721556663513\n",
      "Epoch: 728, Train Loss: 0.4223184883594513, Valid Loss: 0.592926561832428\n",
      "Epoch: 729, Train Loss: 0.4222843050956726, Valid Loss: 0.5913395881652832\n",
      "Epoch: 730, Train Loss: 0.4222460091114044, Valid Loss: 0.592877209186554\n",
      "Epoch: 731, Train Loss: 0.4222012162208557, Valid Loss: 0.5917760729789734\n",
      "Epoch: 732, Train Loss: 0.4221535623073578, Valid Loss: 0.5922977328300476\n",
      "Epoch: 733, Train Loss: 0.42210888862609863, Valid Loss: 0.592566728591919\n",
      "Epoch: 734, Train Loss: 0.4220695495605469, Valid Loss: 0.5918440818786621\n",
      "Epoch: 735, Train Loss: 0.4220328629016876, Valid Loss: 0.5927554965019226\n",
      "Epoch: 736, Train Loss: 0.42199382185935974, Valid Loss: 0.591865062713623\n",
      "Epoch: 737, Train Loss: 0.421950101852417, Valid Loss: 0.5925313234329224\n",
      "Epoch: 738, Train Loss: 0.42190495133399963, Valid Loss: 0.5922913551330566\n",
      "Epoch: 739, Train Loss: 0.42186278104782104, Valid Loss: 0.5922593474388123\n",
      "Epoch: 740, Train Loss: 0.42182445526123047, Valid Loss: 0.5925736427307129\n",
      "Epoch: 741, Train Loss: 0.4217863082885742, Valid Loss: 0.5920656323432922\n",
      "Epoch: 742, Train Loss: 0.421745240688324, Valid Loss: 0.5926647782325745\n",
      "Epoch: 743, Train Loss: 0.42170217633247375, Valid Loss: 0.5921300053596497\n",
      "Epoch: 744, Train Loss: 0.4216597378253937, Valid Loss: 0.5926020741462708\n",
      "Epoch: 745, Train Loss: 0.42161956429481506, Valid Loss: 0.592374324798584\n",
      "Epoch: 746, Train Loss: 0.42158040404319763, Valid Loss: 0.5923363566398621\n",
      "Epoch: 747, Train Loss: 0.42154037952423096, Valid Loss: 0.5926808714866638\n",
      "Epoch: 748, Train Loss: 0.42149943113327026, Valid Loss: 0.592114269733429\n",
      "Epoch: 749, Train Loss: 0.42145830392837524, Valid Loss: 0.5928349494934082\n",
      "Epoch: 750, Train Loss: 0.42141759395599365, Valid Loss: 0.5921949148178101\n",
      "Epoch: 751, Train Loss: 0.4213770627975464, Valid Loss: 0.5926394462585449\n",
      "Epoch: 752, Train Loss: 0.4213365316390991, Valid Loss: 0.5925586223602295\n",
      "Epoch: 753, Train Loss: 0.42129647731781006, Valid Loss: 0.5922865867614746\n",
      "Epoch: 754, Train Loss: 0.4212566018104553, Valid Loss: 0.5928811430931091\n",
      "Epoch: 755, Train Loss: 0.42121651768684387, Valid Loss: 0.592150092124939\n",
      "Epoch: 756, Train Loss: 0.4211759865283966, Valid Loss: 0.5928707122802734\n",
      "Epoch: 757, Train Loss: 0.42113521695137024, Valid Loss: 0.5923768877983093\n",
      "Epoch: 758, Train Loss: 0.4210946559906006, Valid Loss: 0.5925948619842529\n",
      "Epoch: 759, Train Loss: 0.42105475068092346, Valid Loss: 0.5927281379699707\n",
      "Epoch: 760, Train Loss: 0.42101508378982544, Valid Loss: 0.5923427939414978\n",
      "Epoch: 761, Train Loss: 0.42097529768943787, Valid Loss: 0.5928993225097656\n",
      "Epoch: 762, Train Loss: 0.42093509435653687, Valid Loss: 0.5923425555229187\n",
      "Epoch: 763, Train Loss: 0.42089492082595825, Valid Loss: 0.5928361415863037\n",
      "Epoch: 764, Train Loss: 0.420854777097702, Valid Loss: 0.5925292372703552\n",
      "Epoch: 765, Train Loss: 0.42081478238105774, Valid Loss: 0.5926756262779236\n",
      "Epoch: 766, Train Loss: 0.42077481746673584, Valid Loss: 0.5927168130874634\n",
      "Epoch: 767, Train Loss: 0.4207349717617035, Valid Loss: 0.5925808548927307\n",
      "Epoch: 768, Train Loss: 0.42069512605667114, Valid Loss: 0.592808723449707\n",
      "Epoch: 769, Train Loss: 0.4206554591655731, Valid Loss: 0.5925713181495667\n",
      "Epoch: 770, Train Loss: 0.4206157624721527, Valid Loss: 0.5928371548652649\n",
      "Epoch: 771, Train Loss: 0.4205760657787323, Valid Loss: 0.5925933122634888\n",
      "Epoch: 772, Train Loss: 0.4205363094806671, Valid Loss: 0.5928604602813721\n",
      "Epoch: 773, Train Loss: 0.4204964339733124, Valid Loss: 0.5926159620285034\n",
      "Epoch: 774, Train Loss: 0.42045676708221436, Valid Loss: 0.5928763151168823\n",
      "Epoch: 775, Train Loss: 0.4204171597957611, Valid Loss: 0.5926624536514282\n",
      "Epoch: 776, Train Loss: 0.42037758231163025, Valid Loss: 0.5928528904914856\n",
      "Epoch: 777, Train Loss: 0.4203379154205322, Valid Loss: 0.5927504897117615\n",
      "Epoch: 778, Train Loss: 0.42029839754104614, Valid Loss: 0.5927951335906982\n",
      "Epoch: 779, Train Loss: 0.420259028673172, Valid Loss: 0.592858076095581\n",
      "Epoch: 780, Train Loss: 0.4202194809913635, Valid Loss: 0.5927373766899109\n",
      "Epoch: 781, Train Loss: 0.42018023133277893, Valid Loss: 0.5929437875747681\n",
      "Epoch: 782, Train Loss: 0.4201408922672272, Valid Loss: 0.5927127599716187\n",
      "Epoch: 783, Train Loss: 0.42010146379470825, Valid Loss: 0.5929934978485107\n",
      "Epoch: 784, Train Loss: 0.4200621545314789, Valid Loss: 0.5927207469940186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 785, Train Loss: 0.4200229048728943, Valid Loss: 0.5930259227752686\n",
      "Epoch: 786, Train Loss: 0.41998371481895447, Valid Loss: 0.5927255153656006\n",
      "Epoch: 787, Train Loss: 0.41994455456733704, Valid Loss: 0.5930770635604858\n",
      "Epoch: 788, Train Loss: 0.41990548372268677, Valid Loss: 0.5926973819732666\n",
      "Epoch: 789, Train Loss: 0.4198664128780365, Valid Loss: 0.5931716561317444\n",
      "Epoch: 790, Train Loss: 0.41982749104499817, Valid Loss: 0.5926153063774109\n",
      "Epoch: 791, Train Loss: 0.4197887182235718, Valid Loss: 0.593320369720459\n",
      "Epoch: 792, Train Loss: 0.41975030303001404, Valid Loss: 0.5924674868583679\n",
      "Epoch: 793, Train Loss: 0.4197121858596802, Valid Loss: 0.5935338735580444\n",
      "Epoch: 794, Train Loss: 0.4196746349334717, Valid Loss: 0.5922192335128784\n",
      "Epoch: 795, Train Loss: 0.4196379482746124, Valid Loss: 0.5938404202461243\n",
      "Epoch: 796, Train Loss: 0.41960257291793823, Valid Loss: 0.5918166041374207\n",
      "Epoch: 797, Train Loss: 0.41956862807273865, Valid Loss: 0.5942478775978088\n",
      "Epoch: 798, Train Loss: 0.4195358157157898, Valid Loss: 0.591285228729248\n",
      "Epoch: 799, Train Loss: 0.4195025563240051, Valid Loss: 0.5946028232574463\n",
      "Epoch: 800, Train Loss: 0.41946524381637573, Valid Loss: 0.5910635590553284\n",
      "Epoch: 801, Train Loss: 0.4194222092628479, Valid Loss: 0.5944721102714539\n",
      "Epoch: 802, Train Loss: 0.41937363147735596, Valid Loss: 0.5918464064598083\n",
      "Epoch: 803, Train Loss: 0.4193260669708252, Valid Loss: 0.5935619473457336\n",
      "Epoch: 804, Train Loss: 0.4192831814289093, Valid Loss: 0.5932007431983948\n",
      "Epoch: 805, Train Loss: 0.41924571990966797, Valid Loss: 0.5924747586250305\n",
      "Epoch: 806, Train Loss: 0.41921138763427734, Valid Loss: 0.5940028429031372\n",
      "Epoch: 807, Train Loss: 0.41917645931243896, Valid Loss: 0.592038631439209\n",
      "Epoch: 808, Train Loss: 0.41913875937461853, Valid Loss: 0.5939574241638184\n",
      "Epoch: 809, Train Loss: 0.4190976321697235, Valid Loss: 0.592435896396637\n",
      "Epoch: 810, Train Loss: 0.4190547466278076, Valid Loss: 0.5934356451034546\n",
      "Epoch: 811, Train Loss: 0.4190126657485962, Valid Loss: 0.5931527018547058\n",
      "Epoch: 812, Train Loss: 0.4189735949039459, Valid Loss: 0.5929163098335266\n",
      "Epoch: 813, Train Loss: 0.41893741488456726, Valid Loss: 0.5935865640640259\n",
      "Epoch: 814, Train Loss: 0.41890183091163635, Valid Loss: 0.5926265120506287\n",
      "Epoch: 815, Train Loss: 0.41886433959007263, Valid Loss: 0.5937095880508423\n",
      "Epoch: 816, Train Loss: 0.4188244044780731, Valid Loss: 0.5926489233970642\n",
      "Epoch: 817, Train Loss: 0.4187834858894348, Valid Loss: 0.593651294708252\n",
      "Epoch: 818, Train Loss: 0.4187435805797577, Valid Loss: 0.5929298996925354\n",
      "Epoch: 819, Train Loss: 0.4187052249908447, Valid Loss: 0.5933614373207092\n",
      "Epoch: 820, Train Loss: 0.418667733669281, Valid Loss: 0.5933541655540466\n",
      "Epoch: 821, Train Loss: 0.4186303913593292, Valid Loss: 0.5929437279701233\n",
      "Epoch: 822, Train Loss: 0.4185926616191864, Valid Loss: 0.5937634110450745\n",
      "Epoch: 823, Train Loss: 0.4185546338558197, Valid Loss: 0.5926841497421265\n",
      "Epoch: 824, Train Loss: 0.41851624846458435, Valid Loss: 0.5939001441001892\n",
      "Epoch: 825, Train Loss: 0.4184773862361908, Valid Loss: 0.5928031206130981\n",
      "Epoch: 826, Train Loss: 0.4184384346008301, Valid Loss: 0.5936614274978638\n",
      "Epoch: 827, Train Loss: 0.4183998107910156, Valid Loss: 0.5932418704032898\n",
      "Epoch: 828, Train Loss: 0.4183616638183594, Valid Loss: 0.5932312607765198\n",
      "Epoch: 829, Train Loss: 0.41832435131073, Valid Loss: 0.5936760902404785\n",
      "Epoch: 830, Train Loss: 0.4182869791984558, Valid Loss: 0.5929335355758667\n",
      "Epoch: 831, Train Loss: 0.41824933886528015, Valid Loss: 0.5938642024993896\n",
      "Epoch: 832, Train Loss: 0.418211430311203, Valid Loss: 0.5929202437400818\n",
      "Epoch: 833, Train Loss: 0.4181734323501587, Valid Loss: 0.5938045382499695\n",
      "Epoch: 834, Train Loss: 0.41813525557518005, Valid Loss: 0.5930972099304199\n",
      "Epoch: 835, Train Loss: 0.4180973172187805, Valid Loss: 0.5936521887779236\n",
      "Epoch: 836, Train Loss: 0.41805925965309143, Valid Loss: 0.5932916402816772\n",
      "Epoch: 837, Train Loss: 0.41802114248275757, Valid Loss: 0.5935402512550354\n",
      "Epoch: 838, Train Loss: 0.4179832935333252, Valid Loss: 0.593429446220398\n",
      "Epoch: 839, Train Loss: 0.41794559359550476, Valid Loss: 0.5934730768203735\n",
      "Epoch: 840, Train Loss: 0.41790810227394104, Valid Loss: 0.5935406684875488\n",
      "Epoch: 841, Train Loss: 0.4178707003593445, Valid Loss: 0.5933974981307983\n",
      "Epoch: 842, Train Loss: 0.4178331792354584, Valid Loss: 0.5936782360076904\n",
      "Epoch: 843, Train Loss: 0.41779574751853943, Valid Loss: 0.5932908654212952\n",
      "Epoch: 844, Train Loss: 0.4177582859992981, Valid Loss: 0.5938350558280945\n",
      "Epoch: 845, Train Loss: 0.41772088408470154, Valid Loss: 0.5931843519210815\n",
      "Epoch: 846, Train Loss: 0.4176837205886841, Valid Loss: 0.5939697027206421\n",
      "Epoch: 847, Train Loss: 0.41764649748802185, Valid Loss: 0.5931070446968079\n",
      "Epoch: 848, Train Loss: 0.41760942339897156, Valid Loss: 0.5940766930580139\n",
      "Epoch: 849, Train Loss: 0.4175722897052765, Valid Loss: 0.5930387377738953\n",
      "Epoch: 850, Train Loss: 0.41753560304641724, Valid Loss: 0.5941973328590393\n",
      "Epoch: 851, Train Loss: 0.41749927401542664, Valid Loss: 0.5929142832756042\n",
      "Epoch: 852, Train Loss: 0.4174630343914032, Valid Loss: 0.5943962931632996\n",
      "Epoch: 853, Train Loss: 0.4174274206161499, Valid Loss: 0.5926675200462341\n",
      "Epoch: 854, Train Loss: 0.4173925817012787, Valid Loss: 0.5947145819664001\n",
      "Epoch: 855, Train Loss: 0.4173583984375, Valid Loss: 0.5922731161117554\n",
      "Epoch: 856, Train Loss: 0.417325496673584, Valid Loss: 0.59511798620224\n",
      "Epoch: 857, Train Loss: 0.41729238629341125, Valid Loss: 0.5918225646018982\n",
      "Epoch: 858, Train Loss: 0.41725954413414, Valid Loss: 0.5954419374465942\n",
      "Epoch: 859, Train Loss: 0.4172233045101166, Valid Loss: 0.5916452407836914\n",
      "Epoch: 860, Train Loss: 0.41718485951423645, Valid Loss: 0.5953731536865234\n",
      "Epoch: 861, Train Loss: 0.41714155673980713, Valid Loss: 0.5921642184257507\n",
      "Epoch: 862, Train Loss: 0.4170973598957062, Valid Loss: 0.5947281122207642\n",
      "Epoch: 863, Train Loss: 0.4170539975166321, Valid Loss: 0.5932356119155884\n",
      "Epoch: 864, Train Loss: 0.41701367497444153, Valid Loss: 0.5938107967376709\n",
      "Epoch: 865, Train Loss: 0.41697725653648376, Valid Loss: 0.5941886305809021\n",
      "Epoch: 866, Train Loss: 0.41694343090057373, Valid Loss: 0.5930671691894531\n",
      "Epoch: 867, Train Loss: 0.4169104993343353, Valid Loss: 0.5946954488754272\n",
      "Epoch: 868, Train Loss: 0.4168758690357208, Valid Loss: 0.5927040576934814\n",
      "Epoch: 869, Train Loss: 0.41683951020240784, Valid Loss: 0.5948322415351868\n",
      "Epoch: 870, Train Loss: 0.41680049896240234, Valid Loss: 0.5927863717079163\n",
      "Epoch: 871, Train Loss: 0.4167606234550476, Valid Loss: 0.5946503281593323\n",
      "Epoch: 872, Train Loss: 0.41672107577323914, Valid Loss: 0.5932573080062866\n",
      "Epoch: 873, Train Loss: 0.4166826605796814, Valid Loss: 0.5941545367240906\n",
      "Epoch: 874, Train Loss: 0.41664591431617737, Valid Loss: 0.5939217805862427\n",
      "Epoch: 875, Train Loss: 0.4166101813316345, Valid Loss: 0.5935306549072266\n",
      "Epoch: 876, Train Loss: 0.41657522320747375, Valid Loss: 0.594520092010498\n",
      "Epoch: 877, Train Loss: 0.4165399968624115, Valid Loss: 0.5930764675140381\n",
      "Epoch: 878, Train Loss: 0.416504442691803, Valid Loss: 0.5948262214660645\n",
      "Epoch: 879, Train Loss: 0.4164677560329437, Valid Loss: 0.5930041074752808\n",
      "Epoch: 880, Train Loss: 0.4164305627346039, Valid Loss: 0.5947654247283936\n",
      "Epoch: 881, Train Loss: 0.41639286279678345, Valid Loss: 0.5932959318161011\n",
      "Epoch: 882, Train Loss: 0.4163551330566406, Valid Loss: 0.5944534540176392\n",
      "Epoch: 883, Train Loss: 0.4163178503513336, Valid Loss: 0.5937278270721436\n",
      "Epoch: 884, Train Loss: 0.4162808954715729, Valid Loss: 0.5941068530082703\n",
      "Epoch: 885, Train Loss: 0.41624459624290466, Valid Loss: 0.5940890312194824\n",
      "Epoch: 886, Train Loss: 0.4162084460258484, Valid Loss: 0.5938528180122375\n",
      "Epoch: 887, Train Loss: 0.41617247462272644, Valid Loss: 0.5943364500999451\n",
      "Epoch: 888, Train Loss: 0.41613703966140747, Valid Loss: 0.5936702489852905\n",
      "Epoch: 889, Train Loss: 0.4161011874675751, Valid Loss: 0.5945329070091248\n",
      "Epoch: 890, Train Loss: 0.41606539487838745, Valid Loss: 0.593507707118988\n",
      "Epoch: 891, Train Loss: 0.41602975130081177, Valid Loss: 0.5947274565696716\n",
      "Epoch: 892, Train Loss: 0.4159941077232361, Valid Loss: 0.5933558344841003\n",
      "Epoch: 893, Train Loss: 0.4159587025642395, Valid Loss: 0.5949022173881531\n",
      "Epoch: 894, Train Loss: 0.4159228503704071, Valid Loss: 0.5932412147521973\n",
      "Epoch: 895, Train Loss: 0.4158875644207001, Valid Loss: 0.595037043094635\n",
      "Epoch: 896, Train Loss: 0.4158520996570587, Valid Loss: 0.5931647419929504\n",
      "Epoch: 897, Train Loss: 0.41581687331199646, Valid Loss: 0.595146894454956\n",
      "Epoch: 898, Train Loss: 0.41578155755996704, Valid Loss: 0.5930870175361633\n",
      "Epoch: 899, Train Loss: 0.4157468378543854, Valid Loss: 0.5952817797660828\n",
      "Epoch: 900, Train Loss: 0.41571182012557983, Valid Loss: 0.592958390712738\n",
      "Epoch: 901, Train Loss: 0.4156772494316101, Valid Loss: 0.5954650640487671\n",
      "Epoch: 902, Train Loss: 0.41564252972602844, Valid Loss: 0.5927948355674744\n",
      "Epoch: 903, Train Loss: 0.41560792922973633, Valid Loss: 0.5956441760063171\n",
      "Epoch: 904, Train Loss: 0.41557255387306213, Valid Loss: 0.5926888585090637\n",
      "Epoch: 905, Train Loss: 0.4155372679233551, Valid Loss: 0.5957211852073669\n",
      "Epoch: 906, Train Loss: 0.4155007302761078, Valid Loss: 0.5927554965019226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 907, Train Loss: 0.4154638648033142, Valid Loss: 0.5956167578697205\n",
      "Epoch: 908, Train Loss: 0.415426105260849, Valid Loss: 0.5930442810058594\n",
      "Epoch: 909, Train Loss: 0.41538819670677185, Valid Loss: 0.5953351855278015\n",
      "Epoch: 910, Train Loss: 0.41535013914108276, Valid Loss: 0.593483030796051\n",
      "Epoch: 911, Train Loss: 0.4153127074241638, Valid Loss: 0.5949690341949463\n",
      "Epoch: 912, Train Loss: 0.41527584195137024, Valid Loss: 0.5939410924911499\n",
      "Epoch: 913, Train Loss: 0.41523951292037964, Valid Loss: 0.5945990681648254\n",
      "Epoch: 914, Train Loss: 0.41520366072654724, Valid Loss: 0.5943530201911926\n",
      "Epoch: 915, Train Loss: 0.4151683747768402, Valid Loss: 0.5942538380622864\n",
      "Epoch: 916, Train Loss: 0.4151332974433899, Valid Loss: 0.5947180390357971\n",
      "Epoch: 917, Train Loss: 0.4150986969470978, Valid Loss: 0.5939371585845947\n",
      "Epoch: 918, Train Loss: 0.4150642454624176, Valid Loss: 0.5950486660003662\n",
      "Epoch: 919, Train Loss: 0.4150297939777374, Valid Loss: 0.5936493873596191\n",
      "Epoch: 920, Train Loss: 0.4149956703186035, Valid Loss: 0.5953534841537476\n",
      "Epoch: 921, Train Loss: 0.4149619936943054, Valid Loss: 0.5933777689933777\n",
      "Epoch: 922, Train Loss: 0.4149286448955536, Valid Loss: 0.5956516265869141\n",
      "Epoch: 923, Train Loss: 0.4148954451084137, Valid Loss: 0.5930880308151245\n",
      "Epoch: 924, Train Loss: 0.41486331820487976, Valid Loss: 0.5959710478782654\n",
      "Epoch: 925, Train Loss: 0.41483062505722046, Valid Loss: 0.5927572846412659\n",
      "Epoch: 926, Train Loss: 0.4147992432117462, Valid Loss: 0.5962958335876465\n",
      "Epoch: 927, Train Loss: 0.41476619243621826, Valid Loss: 0.5924705266952515\n",
      "Epoch: 928, Train Loss: 0.41473329067230225, Valid Loss: 0.5964973568916321\n",
      "Epoch: 929, Train Loss: 0.4146968424320221, Valid Loss: 0.5924720168113708\n",
      "Epoch: 930, Train Loss: 0.4146592915058136, Valid Loss: 0.5963567495346069\n",
      "Epoch: 931, Train Loss: 0.41461876034736633, Valid Loss: 0.5929954051971436\n",
      "Epoch: 932, Train Loss: 0.41457799077033997, Valid Loss: 0.5957725644111633\n",
      "Epoch: 933, Train Loss: 0.41453811526298523, Valid Loss: 0.5939143896102905\n",
      "Epoch: 934, Train Loss: 0.41450050473213196, Valid Loss: 0.5949345231056213\n",
      "Epoch: 935, Train Loss: 0.4144652783870697, Valid Loss: 0.594830334186554\n",
      "Epoch: 936, Train Loss: 0.41443195939064026, Valid Loss: 0.5941439270973206\n",
      "Epoch: 937, Train Loss: 0.41439956426620483, Valid Loss: 0.595503568649292\n",
      "Epoch: 938, Train Loss: 0.41436728835105896, Valid Loss: 0.5935742855072021\n",
      "Epoch: 939, Train Loss: 0.4143346846103668, Valid Loss: 0.5959098935127258\n",
      "Epoch: 940, Train Loss: 0.4143008291721344, Valid Loss: 0.5933100581169128\n",
      "Epoch: 941, Train Loss: 0.41426631808280945, Valid Loss: 0.5960365533828735\n",
      "Epoch: 942, Train Loss: 0.41423019766807556, Valid Loss: 0.5934112668037415\n",
      "Epoch: 943, Train Loss: 0.41419368982315063, Valid Loss: 0.5958558320999146\n",
      "Epoch: 944, Train Loss: 0.4141567349433899, Valid Loss: 0.5938413739204407\n",
      "Epoch: 945, Train Loss: 0.41412031650543213, Valid Loss: 0.5954453349113464\n",
      "Epoch: 946, Train Loss: 0.4140843152999878, Valid Loss: 0.5944100022315979\n",
      "Epoch: 947, Train Loss: 0.41404905915260315, Valid Loss: 0.5949813723564148\n",
      "Epoch: 948, Train Loss: 0.41401436924934387, Valid Loss: 0.594918966293335\n",
      "Epoch: 949, Train Loss: 0.41398030519485474, Valid Loss: 0.594589352607727\n",
      "Epoch: 950, Train Loss: 0.4139465391635895, Valid Loss: 0.5953090786933899\n",
      "Epoch: 951, Train Loss: 0.41391289234161377, Valid Loss: 0.5942809581756592\n",
      "Epoch: 952, Train Loss: 0.41387951374053955, Valid Loss: 0.5956177115440369\n",
      "Epoch: 953, Train Loss: 0.41384607553482056, Valid Loss: 0.5940172076225281\n",
      "Epoch: 954, Train Loss: 0.4138128459453583, Valid Loss: 0.5958942174911499\n",
      "Epoch: 955, Train Loss: 0.413779616355896, Valid Loss: 0.5937730669975281\n",
      "Epoch: 956, Train Loss: 0.4137468636035919, Valid Loss: 0.5961543917655945\n",
      "Epoch: 957, Train Loss: 0.4137139618396759, Valid Loss: 0.5935441851615906\n",
      "Epoch: 958, Train Loss: 0.4136815369129181, Valid Loss: 0.5963981747627258\n",
      "Epoch: 959, Train Loss: 0.4136486351490021, Valid Loss: 0.5933345556259155\n",
      "Epoch: 960, Train Loss: 0.4136166274547577, Valid Loss: 0.5966197848320007\n",
      "Epoch: 961, Train Loss: 0.4135836064815521, Valid Loss: 0.5931693911552429\n",
      "Epoch: 962, Train Loss: 0.41355088353157043, Valid Loss: 0.5967774987220764\n",
      "Epoch: 963, Train Loss: 0.4135165214538574, Valid Loss: 0.5931347012519836\n",
      "Epoch: 964, Train Loss: 0.4134821593761444, Valid Loss: 0.596781313419342\n",
      "Epoch: 965, Train Loss: 0.4134455621242523, Valid Loss: 0.5933442115783691\n",
      "Epoch: 966, Train Loss: 0.41340917348861694, Valid Loss: 0.5965446829795837\n",
      "Epoch: 967, Train Loss: 0.41337159276008606, Valid Loss: 0.5938306450843811\n",
      "Epoch: 968, Train Loss: 0.4133346676826477, Valid Loss: 0.5960797071456909\n",
      "Epoch: 969, Train Loss: 0.41329842805862427, Valid Loss: 0.5944727659225464\n",
      "Epoch: 970, Train Loss: 0.41326314210891724, Valid Loss: 0.5955131649971008\n",
      "Epoch: 971, Train Loss: 0.41322869062423706, Valid Loss: 0.5950916409492493\n",
      "Epoch: 972, Train Loss: 0.41319501399993896, Valid Loss: 0.5949869155883789\n",
      "Epoch: 973, Train Loss: 0.4131618142127991, Valid Loss: 0.5955983996391296\n",
      "Epoch: 974, Train Loss: 0.41312921047210693, Valid Loss: 0.5945541262626648\n",
      "Epoch: 975, Train Loss: 0.4130966067314148, Valid Loss: 0.5960049033164978\n",
      "Epoch: 976, Train Loss: 0.41306430101394653, Valid Loss: 0.5942025780677795\n",
      "Epoch: 977, Train Loss: 0.41303226351737976, Valid Loss: 0.5963537096977234\n",
      "Epoch: 978, Train Loss: 0.41300010681152344, Valid Loss: 0.5938990116119385\n",
      "Epoch: 979, Train Loss: 0.41296860575675964, Valid Loss: 0.5966744422912598\n",
      "Epoch: 980, Train Loss: 0.41293659806251526, Valid Loss: 0.5936258435249329\n",
      "Epoch: 981, Train Loss: 0.4129055440425873, Valid Loss: 0.5969657897949219\n",
      "Epoch: 982, Train Loss: 0.4128733277320862, Valid Loss: 0.5934025645256042\n",
      "Epoch: 983, Train Loss: 0.4128420948982239, Valid Loss: 0.5971838235855103\n",
      "Epoch: 984, Train Loss: 0.41280871629714966, Valid Loss: 0.5933088064193726\n",
      "Epoch: 985, Train Loss: 0.41277551651000977, Valid Loss: 0.5972395539283752\n",
      "Epoch: 986, Train Loss: 0.41273993253707886, Valid Loss: 0.5934653282165527\n",
      "Epoch: 987, Train Loss: 0.4127042889595032, Valid Loss: 0.5970393419265747\n",
      "Epoch: 988, Train Loss: 0.41266727447509766, Valid Loss: 0.5939300060272217\n",
      "Epoch: 989, Train Loss: 0.41263052821159363, Valid Loss: 0.5965718030929565\n",
      "Epoch: 990, Train Loss: 0.4125942885875702, Valid Loss: 0.5946038961410522\n",
      "Epoch: 991, Train Loss: 0.41255876421928406, Valid Loss: 0.5959573984146118\n",
      "Epoch: 992, Train Loss: 0.412524551153183, Valid Loss: 0.5952938795089722\n",
      "Epoch: 993, Train Loss: 0.4124913513660431, Valid Loss: 0.595353901386261\n",
      "Epoch: 994, Train Loss: 0.4124589264392853, Valid Loss: 0.5958768725395203\n",
      "Epoch: 995, Train Loss: 0.41242676973342896, Valid Loss: 0.5948532223701477\n",
      "Epoch: 996, Train Loss: 0.4123949408531189, Valid Loss: 0.5963379740715027\n",
      "Epoch: 997, Train Loss: 0.412363201379776, Valid Loss: 0.5944592356681824\n",
      "Epoch: 998, Train Loss: 0.41233181953430176, Valid Loss: 0.5967127084732056\n",
      "Epoch: 999, Train Loss: 0.4123004078865051, Valid Loss: 0.5941516160964966\n",
      "Epoch: 1000, Train Loss: 0.41226935386657715, Valid Loss: 0.5970282554626465\n",
      "Epoch: 1001, Train Loss: 0.4122377932071686, Valid Loss: 0.5939072966575623\n",
      "Epoch: 1002, Train Loss: 0.412206768989563, Valid Loss: 0.5972921252250671\n",
      "Epoch: 1003, Train Loss: 0.41217485070228577, Valid Loss: 0.5937354564666748\n",
      "Epoch: 1004, Train Loss: 0.4121433198451996, Valid Loss: 0.5974722504615784\n",
      "Epoch: 1005, Train Loss: 0.4121103286743164, Valid Loss: 0.5936939716339111\n",
      "Epoch: 1006, Train Loss: 0.41207751631736755, Valid Loss: 0.5974995493888855\n",
      "Epoch: 1007, Train Loss: 0.41204261779785156, Valid Loss: 0.593864381313324\n",
      "Epoch: 1008, Train Loss: 0.412008136510849, Valid Loss: 0.5973084568977356\n",
      "Epoch: 1009, Train Loss: 0.41197240352630615, Valid Loss: 0.5942727327346802\n",
      "Epoch: 1010, Train Loss: 0.41193699836730957, Valid Loss: 0.5969130992889404\n",
      "Epoch: 1011, Train Loss: 0.41190192103385925, Valid Loss: 0.5948335528373718\n",
      "Epoch: 1012, Train Loss: 0.4118673801422119, Valid Loss: 0.5964072346687317\n",
      "Epoch: 1013, Train Loss: 0.4118334650993347, Valid Loss: 0.5954135060310364\n",
      "Epoch: 1014, Train Loss: 0.4118005037307739, Valid Loss: 0.5959063172340393\n",
      "Epoch: 1015, Train Loss: 0.4117679297924042, Valid Loss: 0.5959229469299316\n",
      "Epoch: 1016, Train Loss: 0.41173574328422546, Valid Loss: 0.5954757928848267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1017, Train Loss: 0.411703884601593, Valid Loss: 0.5963500738143921\n",
      "Epoch: 1018, Train Loss: 0.4116722345352173, Valid Loss: 0.5951146483421326\n",
      "Epoch: 1019, Train Loss: 0.411641001701355, Valid Loss: 0.5967358350753784\n",
      "Epoch: 1020, Train Loss: 0.41160985827445984, Valid Loss: 0.594775378704071\n",
      "Epoch: 1021, Train Loss: 0.4115793704986572, Valid Loss: 0.5971330404281616\n",
      "Epoch: 1022, Train Loss: 0.4115491807460785, Valid Loss: 0.5943940877914429\n",
      "Epoch: 1023, Train Loss: 0.4115200936794281, Valid Loss: 0.5975939035415649\n",
      "Epoch: 1024, Train Loss: 0.41149085760116577, Valid Loss: 0.5939153432846069\n",
      "Epoch: 1025, Train Loss: 0.4114639163017273, Valid Loss: 0.5981209874153137\n",
      "Epoch: 1026, Train Loss: 0.4114357531070709, Valid Loss: 0.5933823585510254\n",
      "Epoch: 1027, Train Loss: 0.41140928864479065, Valid Loss: 0.5985966920852661\n",
      "Epoch: 1028, Train Loss: 0.4113787114620209, Valid Loss: 0.5930441617965698\n",
      "Epoch: 1029, Train Loss: 0.4113479256629944, Valid Loss: 0.598720371723175\n",
      "Epoch: 1030, Train Loss: 0.41130971908569336, Valid Loss: 0.5933601260185242\n",
      "Epoch: 1031, Train Loss: 0.4112705588340759, Valid Loss: 0.5981705784797668\n",
      "Epoch: 1032, Train Loss: 0.411228746175766, Valid Loss: 0.5944896936416626\n",
      "Epoch: 1033, Train Loss: 0.41118958592414856, Valid Loss: 0.597001850605011\n",
      "Epoch: 1034, Train Loss: 0.4111544191837311, Valid Loss: 0.5959402322769165\n",
      "Epoch: 1035, Train Loss: 0.41112303733825684, Valid Loss: 0.5956816077232361\n",
      "Epoch: 1036, Train Loss: 0.4110945761203766, Valid Loss: 0.597130298614502\n",
      "Epoch: 1037, Train Loss: 0.41106700897216797, Valid Loss: 0.5946688652038574\n",
      "Epoch: 1038, Train Loss: 0.41103866696357727, Valid Loss: 0.5978292226791382\n",
      "Epoch: 1039, Train Loss: 0.41100800037384033, Valid Loss: 0.5942370295524597\n",
      "Epoch: 1040, Train Loss: 0.41097578406333923, Valid Loss: 0.5979483723640442\n",
      "Epoch: 1041, Train Loss: 0.41094091534614563, Valid Loss: 0.5945209264755249\n",
      "Epoch: 1042, Train Loss: 0.410905659198761, Valid Loss: 0.597487211227417\n",
      "Epoch: 1043, Train Loss: 0.41087040305137634, Valid Loss: 0.5953447818756104\n",
      "Epoch: 1044, Train Loss: 0.410836398601532, Valid Loss: 0.5966970920562744\n",
      "Epoch: 1045, Train Loss: 0.41080379486083984, Valid Loss: 0.5962780117988586\n",
      "Epoch: 1046, Train Loss: 0.4107725918292999, Valid Loss: 0.5959341526031494\n",
      "Epoch: 1047, Train Loss: 0.41074225306510925, Valid Loss: 0.5970070362091064\n",
      "Epoch: 1048, Train Loss: 0.4107123911380768, Valid Loss: 0.5953838229179382\n",
      "Epoch: 1049, Train Loss: 0.4106822609901428, Valid Loss: 0.5974736213684082\n",
      "Epoch: 1050, Train Loss: 0.41065189242362976, Valid Loss: 0.595071017742157\n",
      "Epoch: 1051, Train Loss: 0.41062095761299133, Valid Loss: 0.5977104306221008\n",
      "Epoch: 1052, Train Loss: 0.4105894863605499, Valid Loss: 0.5949963927268982\n",
      "Epoch: 1053, Train Loss: 0.41055774688720703, Valid Loss: 0.597730815410614\n",
      "Epoch: 1054, Train Loss: 0.4105254113674164, Valid Loss: 0.5951414108276367\n",
      "Epoch: 1055, Train Loss: 0.41049322485923767, Valid Loss: 0.597577691078186\n",
      "Epoch: 1056, Train Loss: 0.41046053171157837, Valid Loss: 0.595421314239502\n",
      "Epoch: 1057, Train Loss: 0.41042840480804443, Valid Loss: 0.5973538756370544\n",
      "Epoch: 1058, Train Loss: 0.4103962182998657, Valid Loss: 0.5957242846488953\n",
      "Epoch: 1059, Train Loss: 0.4103641211986542, Valid Loss: 0.5971454381942749\n",
      "Epoch: 1060, Train Loss: 0.4103323817253113, Valid Loss: 0.595990002155304\n",
      "Epoch: 1061, Train Loss: 0.4103007912635803, Valid Loss: 0.5969794392585754\n",
      "Epoch: 1062, Train Loss: 0.41026929020881653, Valid Loss: 0.5962082147598267\n",
      "Epoch: 1063, Train Loss: 0.4102378785610199, Valid Loss: 0.5968548059463501\n",
      "Epoch: 1064, Train Loss: 0.4102066457271576, Valid Loss: 0.5963805317878723\n",
      "Epoch: 1065, Train Loss: 0.410175621509552, Valid Loss: 0.5967804193496704\n",
      "Epoch: 1066, Train Loss: 0.41014420986175537, Valid Loss: 0.5964916944503784\n",
      "Epoch: 1067, Train Loss: 0.4101131558418274, Valid Loss: 0.5967701077461243\n",
      "Epoch: 1068, Train Loss: 0.4100821316242218, Valid Loss: 0.5965428948402405\n",
      "Epoch: 1069, Train Loss: 0.41005101799964905, Valid Loss: 0.596807599067688\n",
      "Epoch: 1070, Train Loss: 0.41001996397972107, Valid Loss: 0.5965560078620911\n",
      "Epoch: 1071, Train Loss: 0.40998902916908264, Valid Loss: 0.5968786478042603\n",
      "Epoch: 1072, Train Loss: 0.4099583327770233, Valid Loss: 0.5965330600738525\n",
      "Epoch: 1073, Train Loss: 0.4099273085594177, Valid Loss: 0.5969974398612976\n",
      "Epoch: 1074, Train Loss: 0.409896582365036, Valid Loss: 0.5964366793632507\n",
      "Epoch: 1075, Train Loss: 0.4098661243915558, Valid Loss: 0.5972234606742859\n",
      "Epoch: 1076, Train Loss: 0.4098358154296875, Valid Loss: 0.5961830019950867\n",
      "Epoch: 1077, Train Loss: 0.40980610251426697, Valid Loss: 0.5976593494415283\n",
      "Epoch: 1078, Train Loss: 0.4097777307033539, Valid Loss: 0.5956143736839294\n",
      "Epoch: 1079, Train Loss: 0.40975192189216614, Valid Loss: 0.5985043048858643\n",
      "Epoch: 1080, Train Loss: 0.4097306430339813, Valid Loss: 0.5943752527236938\n",
      "Epoch: 1081, Train Loss: 0.40972036123275757, Valid Loss: 0.6001016497612\n",
      "Epoch: 1082, Train Loss: 0.40972164273262024, Valid Loss: 0.5919177532196045\n",
      "Epoch: 1083, Train Loss: 0.40975210070610046, Valid Loss: 0.6024131178855896\n",
      "Epoch: 1084, Train Loss: 0.4097544252872467, Valid Loss: 0.5892054438591003\n",
      "Epoch: 1085, Train Loss: 0.40973901748657227, Valid Loss: 0.6029865741729736\n",
      "Epoch: 1086, Train Loss: 0.4096127450466156, Valid Loss: 0.5921213626861572\n",
      "Epoch: 1087, Train Loss: 0.40950828790664673, Valid Loss: 0.5980940461158752\n",
      "Epoch: 1088, Train Loss: 0.40948301553726196, Valid Loss: 0.5993849039077759\n",
      "Epoch: 1089, Train Loss: 0.409506231546402, Valid Loss: 0.5925148725509644\n",
      "Epoch: 1090, Train Loss: 0.4095029830932617, Valid Loss: 0.6012722253799438\n",
      "Epoch: 1091, Train Loss: 0.40941911935806274, Valid Loss: 0.5940244197845459\n",
      "Epoch: 1092, Train Loss: 0.40934696793556213, Valid Loss: 0.5973647236824036\n",
      "Epoch: 1093, Train Loss: 0.4093380272388458, Valid Loss: 0.5992157459259033\n",
      "Epoch: 1094, Train Loss: 0.4093407690525055, Valid Loss: 0.5933290719985962\n",
      "Epoch: 1095, Train Loss: 0.4092993438243866, Valid Loss: 0.6000698804855347\n",
      "Epoch: 1096, Train Loss: 0.40923187136650085, Valid Loss: 0.5955590605735779\n",
      "Epoch: 1097, Train Loss: 0.4092019200325012, Valid Loss: 0.596160352230072\n",
      "Epoch: 1098, Train Loss: 0.40919649600982666, Valid Loss: 0.5996331572532654\n",
      "Epoch: 1099, Train Loss: 0.40916621685028076, Valid Loss: 0.5938572883605957\n",
      "Epoch: 1100, Train Loss: 0.40911561250686646, Valid Loss: 0.5990096926689148\n",
      "Epoch: 1101, Train Loss: 0.40907609462738037, Valid Loss: 0.5973496437072754\n",
      "Epoch: 1102, Train Loss: 0.40905970335006714, Valid Loss: 0.5950343012809753\n",
      "Epoch: 1103, Train Loss: 0.40903958678245544, Valid Loss: 0.5999722480773926\n",
      "Epoch: 1104, Train Loss: 0.40899577736854553, Valid Loss: 0.5952831506729126\n",
      "Epoch: 1105, Train Loss: 0.4089548885822296, Valid Loss: 0.5973786115646362\n",
      "Epoch: 1106, Train Loss: 0.4089328646659851, Valid Loss: 0.5989601016044617\n",
      "Epoch: 1107, Train Loss: 0.4089106023311615, Valid Loss: 0.5950208902359009\n",
      "Epoch: 1108, Train Loss: 0.40887510776519775, Valid Loss: 0.5990225076675415\n",
      "Epoch: 1109, Train Loss: 0.4088365137577057, Valid Loss: 0.5970384478569031\n",
      "Epoch: 1110, Train Loss: 0.4088086187839508, Valid Loss: 0.5963589549064636\n",
      "Epoch: 1111, Train Loss: 0.40878546237945557, Valid Loss: 0.5990760922431946\n",
      "Epoch: 1112, Train Loss: 0.40875476598739624, Valid Loss: 0.595874547958374\n",
      "Epoch: 1113, Train Loss: 0.4087187647819519, Valid Loss: 0.5979906916618347\n",
      "Epoch: 1114, Train Loss: 0.40868720412254333, Valid Loss: 0.597796618938446\n",
      "Epoch: 1115, Train Loss: 0.4086618423461914, Valid Loss: 0.5963254570960999\n",
      "Epoch: 1116, Train Loss: 0.4086343050003052, Valid Loss: 0.5986901521682739\n",
      "Epoch: 1117, Train Loss: 0.4086010158061981, Valid Loss: 0.596503496170044\n",
      "Epoch: 1118, Train Loss: 0.40856847167015076, Valid Loss: 0.5976850986480713\n",
      "Epoch: 1119, Train Loss: 0.4085405766963959, Valid Loss: 0.5980687141418457\n",
      "Epoch: 1120, Train Loss: 0.40851330757141113, Valid Loss: 0.5964697003364563\n",
      "Epoch: 1121, Train Loss: 0.4084833562374115, Valid Loss: 0.5986287593841553\n",
      "Epoch: 1122, Train Loss: 0.40845146775245667, Valid Loss: 0.5969364047050476\n",
      "Epoch: 1123, Train Loss: 0.408421128988266, Valid Loss: 0.5975437164306641\n",
      "Epoch: 1124, Train Loss: 0.40839314460754395, Valid Loss: 0.5983643531799316\n",
      "Epoch: 1125, Train Loss: 0.40836480259895325, Valid Loss: 0.596643328666687\n",
      "Epoch: 1126, Train Loss: 0.4083346128463745, Valid Loss: 0.5984888672828674\n",
      "Epoch: 1127, Train Loss: 0.4083038568496704, Valid Loss: 0.5973712205886841\n",
      "Epoch: 1128, Train Loss: 0.4082743525505066, Valid Loss: 0.5974559783935547\n",
      "Epoch: 1129, Train Loss: 0.4082461893558502, Valid Loss: 0.598386287689209\n",
      "Epoch: 1130, Train Loss: 0.40821757912635803, Valid Loss: 0.596961498260498\n",
      "Epoch: 1131, Train Loss: 0.4081876575946808, Valid Loss: 0.5983035564422607\n",
      "Epoch: 1132, Train Loss: 0.40815746784210205, Valid Loss: 0.5975567698478699\n",
      "Epoch: 1133, Train Loss: 0.4081282615661621, Valid Loss: 0.5976316332817078\n",
      "Epoch: 1134, Train Loss: 0.408099889755249, Valid Loss: 0.5982181429862976\n",
      "Epoch: 1135, Train Loss: 0.4080710709095001, Valid Loss: 0.5972520112991333\n",
      "Epoch: 1136, Train Loss: 0.40804168581962585, Valid Loss: 0.598339319229126\n",
      "Epoch: 1137, Train Loss: 0.4080122113227844, Valid Loss: 0.5975509285926819\n",
      "Epoch: 1138, Train Loss: 0.40798285603523254, Valid Loss: 0.5979147553443909\n",
      "Epoch: 1139, Train Loss: 0.4079541862010956, Valid Loss: 0.5981395840644836\n",
      "Epoch: 1140, Train Loss: 0.40792566537857056, Valid Loss: 0.597477376461029\n",
      "Epoch: 1141, Train Loss: 0.4078967273235321, Valid Loss: 0.5984368324279785\n",
      "Epoch: 1142, Train Loss: 0.40786758065223694, Valid Loss: 0.59759122133255\n",
      "Epoch: 1143, Train Loss: 0.4078383445739746, Valid Loss: 0.5981383919715881\n",
      "Epoch: 1144, Train Loss: 0.40780940651893616, Valid Loss: 0.5980780124664307\n",
      "Epoch: 1145, Train Loss: 0.40778088569641113, Valid Loss: 0.5977632403373718\n",
      "Epoch: 1146, Train Loss: 0.40775227546691895, Valid Loss: 0.5983895659446716\n",
      "Epoch: 1147, Train Loss: 0.407723605632782, Valid Loss: 0.5977074503898621\n",
      "Epoch: 1148, Train Loss: 0.40769466757774353, Valid Loss: 0.5983328819274902\n",
      "Epoch: 1149, Train Loss: 0.4076659381389618, Valid Loss: 0.5979334115982056\n",
      "Epoch: 1150, Train Loss: 0.4076370596885681, Valid Loss: 0.5981317758560181\n",
      "Epoch: 1151, Train Loss: 0.40760859847068787, Valid Loss: 0.5982272624969482\n",
      "Epoch: 1152, Train Loss: 0.40758010745048523, Valid Loss: 0.5979213714599609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1153, Train Loss: 0.4075515866279602, Valid Loss: 0.598432719707489\n",
      "Epoch: 1154, Train Loss: 0.40752309560775757, Valid Loss: 0.5978983044624329\n",
      "Epoch: 1155, Train Loss: 0.40749457478523254, Valid Loss: 0.5984265804290771\n",
      "Epoch: 1156, Train Loss: 0.40746599435806274, Valid Loss: 0.5980787873268127\n",
      "Epoch: 1157, Train Loss: 0.40743744373321533, Valid Loss: 0.5982590317726135\n",
      "Epoch: 1158, Train Loss: 0.40740910172462463, Valid Loss: 0.5983285903930664\n",
      "Epoch: 1159, Train Loss: 0.407380610704422, Valid Loss: 0.5981372594833374\n",
      "Epoch: 1160, Train Loss: 0.40735235810279846, Valid Loss: 0.5984752178192139\n",
      "Epoch: 1161, Train Loss: 0.40732407569885254, Valid Loss: 0.598108172416687\n",
      "Epoch: 1162, Train Loss: 0.407295823097229, Valid Loss: 0.5985326766967773\n",
      "Epoch: 1163, Train Loss: 0.4072674810886383, Valid Loss: 0.5981706976890564\n",
      "Epoch: 1164, Train Loss: 0.4072391092777252, Valid Loss: 0.5985103249549866\n",
      "Epoch: 1165, Train Loss: 0.40721094608306885, Valid Loss: 0.5982941389083862\n",
      "Epoch: 1166, Train Loss: 0.4071827232837677, Valid Loss: 0.5984299778938293\n",
      "Epoch: 1167, Train Loss: 0.40715450048446655, Valid Loss: 0.5984545350074768\n",
      "Epoch: 1168, Train Loss: 0.40712642669677734, Valid Loss: 0.5983595252037048\n",
      "Epoch: 1169, Train Loss: 0.40709835290908813, Valid Loss: 0.5985667109489441\n",
      "Epoch: 1170, Train Loss: 0.4070703685283661, Valid Loss: 0.5983373522758484\n",
      "Epoch: 1171, Train Loss: 0.40704232454299927, Valid Loss: 0.5986477136611938\n",
      "Epoch: 1172, Train Loss: 0.40701431035995483, Valid Loss: 0.598344087600708\n",
      "Epoch: 1173, Train Loss: 0.4069863557815552, Valid Loss: 0.59870845079422\n",
      "Epoch: 1174, Train Loss: 0.40695837140083313, Valid Loss: 0.5983636975288391\n",
      "Epoch: 1175, Train Loss: 0.40693041682243347, Valid Loss: 0.5987519025802612\n",
      "Epoch: 1176, Train Loss: 0.40690258145332336, Valid Loss: 0.598414957523346\n",
      "Epoch: 1177, Train Loss: 0.4068746566772461, Valid Loss: 0.5987733602523804\n",
      "Epoch: 1178, Train Loss: 0.4068469703197479, Valid Loss: 0.5984586477279663\n",
      "Epoch: 1179, Train Loss: 0.40681904554367065, Valid Loss: 0.5988175272941589\n",
      "Epoch: 1180, Train Loss: 0.40679123997688293, Valid Loss: 0.5984752178192139\n",
      "Epoch: 1181, Train Loss: 0.40676361322402954, Valid Loss: 0.5988896489143372\n",
      "Epoch: 1182, Train Loss: 0.4067358076572418, Valid Loss: 0.5984625816345215\n",
      "Epoch: 1183, Train Loss: 0.4067081809043884, Valid Loss: 0.5989874005317688\n",
      "Epoch: 1184, Train Loss: 0.4066806137561798, Valid Loss: 0.5984182953834534\n",
      "Epoch: 1185, Train Loss: 0.40665310621261597, Valid Loss: 0.5991403460502625\n",
      "Epoch: 1186, Train Loss: 0.4066256284713745, Valid Loss: 0.5982869863510132\n",
      "Epoch: 1187, Train Loss: 0.4065985083580017, Valid Loss: 0.5994022488594055\n",
      "Epoch: 1188, Train Loss: 0.4065716564655304, Valid Loss: 0.5980128645896912\n",
      "Epoch: 1189, Train Loss: 0.40654537081718445, Valid Loss: 0.5998542308807373\n",
      "Epoch: 1190, Train Loss: 0.40651974081993103, Valid Loss: 0.5974627137184143\n",
      "Epoch: 1191, Train Loss: 0.4064963459968567, Valid Loss: 0.6006632447242737\n",
      "Epoch: 1192, Train Loss: 0.4064754545688629, Valid Loss: 0.5963678956031799\n",
      "Epoch: 1193, Train Loss: 0.40646156668663025, Valid Loss: 0.60212242603302\n",
      "Epoch: 1194, Train Loss: 0.40645429491996765, Valid Loss: 0.5943290591239929\n",
      "Epoch: 1195, Train Loss: 0.4064653515815735, Valid Loss: 0.6043559908866882\n",
      "Epoch: 1196, Train Loss: 0.4064704179763794, Valid Loss: 0.5916175842285156\n",
      "Epoch: 1197, Train Loss: 0.40648379921913147, Valid Loss: 0.6060606241226196\n",
      "Epoch: 1198, Train Loss: 0.4064182937145233, Valid Loss: 0.591753363609314\n",
      "Epoch: 1199, Train Loss: 0.406333327293396, Valid Loss: 0.6036083102226257\n",
      "Epoch: 1200, Train Loss: 0.4062497615814209, Valid Loss: 0.5976927280426025\n",
      "Epoch: 1201, Train Loss: 0.4062238335609436, Valid Loss: 0.5973455905914307\n",
      "Epoch: 1202, Train Loss: 0.4062387943267822, Valid Loss: 0.6032735705375671\n",
      "Epoch: 1203, Train Loss: 0.4062332808971405, Valid Loss: 0.5937930345535278\n",
      "Epoch: 1204, Train Loss: 0.4061901271343231, Valid Loss: 0.6033428907394409\n",
      "Epoch: 1205, Train Loss: 0.40612030029296875, Valid Loss: 0.5969263315200806\n",
      "Epoch: 1206, Train Loss: 0.4060816168785095, Valid Loss: 0.5985782146453857\n",
      "Epoch: 1207, Train Loss: 0.4060775935649872, Valid Loss: 0.6019272804260254\n",
      "Epoch: 1208, Train Loss: 0.40606871247291565, Valid Loss: 0.5949757695198059\n",
      "Epoch: 1209, Train Loss: 0.4060342013835907, Valid Loss: 0.6025751233100891\n",
      "Epoch: 1210, Train Loss: 0.4059813320636749, Valid Loss: 0.5972828269004822\n",
      "Epoch: 1211, Train Loss: 0.4059469699859619, Valid Loss: 0.5986897945404053\n",
      "Epoch: 1212, Train Loss: 0.40593457221984863, Valid Loss: 0.6015457510948181\n",
      "Epoch: 1213, Train Loss: 0.40591859817504883, Valid Loss: 0.5959343910217285\n",
      "Epoch: 1214, Train Loss: 0.4058860242366791, Valid Loss: 0.6019224524497986\n",
      "Epoch: 1215, Train Loss: 0.4058437645435333, Valid Loss: 0.59806227684021\n",
      "Epoch: 1216, Train Loss: 0.4058135747909546, Valid Loss: 0.5988044142723083\n",
      "Epoch: 1217, Train Loss: 0.405796080827713, Valid Loss: 0.6013075113296509\n",
      "Epoch: 1218, Train Loss: 0.40577569603919983, Valid Loss: 0.5968765020370483\n",
      "Epoch: 1219, Train Loss: 0.4057448208332062, Valid Loss: 0.6014257073402405\n",
      "Epoch: 1220, Train Loss: 0.4057091176509857, Valid Loss: 0.5984994173049927\n",
      "Epoch: 1221, Train Loss: 0.40568041801452637, Valid Loss: 0.599075436592102\n",
      "Epoch: 1222, Train Loss: 0.40565943717956543, Valid Loss: 0.600894570350647\n",
      "Epoch: 1223, Train Loss: 0.40563687682151794, Valid Loss: 0.5974828600883484\n",
      "Epoch: 1224, Train Loss: 0.4056084454059601, Valid Loss: 0.6011526584625244\n",
      "Epoch: 1225, Train Loss: 0.4055764079093933, Valid Loss: 0.5985549092292786\n",
      "Epoch: 1226, Train Loss: 0.4055480659008026, Valid Loss: 0.5993812084197998\n",
      "Epoch: 1227, Train Loss: 0.4055243730545044, Valid Loss: 0.6005362272262573\n",
      "Epoch: 1228, Train Loss: 0.40550121665000916, Valid Loss: 0.5979653000831604\n",
      "Epoch: 1229, Train Loss: 0.4054745137691498, Valid Loss: 0.601019024848938\n",
      "Epoch: 1230, Train Loss: 0.40544506907463074, Valid Loss: 0.5986341238021851\n",
      "Epoch: 1231, Train Loss: 0.4054165482521057, Valid Loss: 0.5997893810272217\n",
      "Epoch: 1232, Train Loss: 0.40539124608039856, Valid Loss: 0.6002064347267151\n",
      "Epoch: 1233, Train Loss: 0.4053672254085541, Valid Loss: 0.5985932946205139\n",
      "Epoch: 1234, Train Loss: 0.405341774225235, Valid Loss: 0.6008772253990173\n",
      "Epoch: 1235, Train Loss: 0.4053143262863159, Valid Loss: 0.5987445712089539\n",
      "Epoch: 1236, Train Loss: 0.4052866995334625, Valid Loss: 0.6002598404884338\n",
      "Epoch: 1237, Train Loss: 0.4052600562572479, Valid Loss: 0.5997802019119263\n",
      "Epoch: 1238, Train Loss: 0.4052346348762512, Valid Loss: 0.5992532968521118\n",
      "Epoch: 1239, Train Loss: 0.40520980954170227, Valid Loss: 0.6006262898445129\n",
      "Epoch: 1240, Train Loss: 0.40518414974212646, Valid Loss: 0.5988792777061462\n",
      "Epoch: 1241, Train Loss: 0.4051573574542999, Valid Loss: 0.6005879640579224\n",
      "Epoch: 1242, Train Loss: 0.40513086318969727, Valid Loss: 0.5993798971176147\n",
      "Epoch: 1243, Train Loss: 0.40510430932044983, Valid Loss: 0.5998936295509338\n",
      "Epoch: 1244, Train Loss: 0.405078649520874, Valid Loss: 0.6002025008201599\n",
      "Epoch: 1245, Train Loss: 0.4050535559654236, Valid Loss: 0.5992981195449829\n",
      "Epoch: 1246, Train Loss: 0.4050281345844269, Valid Loss: 0.6006021499633789\n",
      "Epoch: 1247, Train Loss: 0.4050022065639496, Valid Loss: 0.599278450012207\n",
      "Epoch: 1248, Train Loss: 0.40497609972953796, Valid Loss: 0.6004436016082764\n",
      "Epoch: 1249, Train Loss: 0.40494975447654724, Valid Loss: 0.5997300148010254\n",
      "Epoch: 1250, Train Loss: 0.4049241244792938, Valid Loss: 0.6000058054924011\n",
      "Epoch: 1251, Train Loss: 0.40489858388900757, Valid Loss: 0.6002522110939026\n",
      "Epoch: 1252, Train Loss: 0.4048733711242676, Valid Loss: 0.5996420383453369\n",
      "Epoch: 1253, Train Loss: 0.4048481285572052, Valid Loss: 0.6005734801292419\n",
      "Epoch: 1254, Train Loss: 0.4048224091529846, Valid Loss: 0.5995688438415527\n",
      "Epoch: 1255, Train Loss: 0.4047967493534088, Valid Loss: 0.6005599498748779\n",
      "Epoch: 1256, Train Loss: 0.4047711193561554, Valid Loss: 0.5997884273529053\n",
      "Epoch: 1257, Train Loss: 0.4047453999519348, Valid Loss: 0.6003210544586182\n",
      "Epoch: 1258, Train Loss: 0.4047202467918396, Valid Loss: 0.600142240524292\n",
      "Epoch: 1259, Train Loss: 0.40469470620155334, Valid Loss: 0.6000547409057617\n",
      "Epoch: 1260, Train Loss: 0.4046693444252014, Valid Loss: 0.6004250049591064\n",
      "Epoch: 1261, Train Loss: 0.40464404225349426, Valid Loss: 0.5998985767364502\n",
      "Epoch: 1262, Train Loss: 0.4046187996864319, Valid Loss: 0.6005918979644775\n",
      "Epoch: 1263, Train Loss: 0.40459364652633667, Valid Loss: 0.5998777151107788\n",
      "Epoch: 1264, Train Loss: 0.40456831455230713, Valid Loss: 0.6006321310997009\n",
      "Epoch: 1265, Train Loss: 0.40454307198524475, Valid Loss: 0.5999696254730225\n",
      "Epoch: 1266, Train Loss: 0.4045177698135376, Valid Loss: 0.6005804538726807\n",
      "Epoch: 1267, Train Loss: 0.4044925570487976, Valid Loss: 0.6001334190368652\n",
      "Epoch: 1268, Train Loss: 0.4044674038887024, Valid Loss: 0.6004939675331116\n",
      "Epoch: 1269, Train Loss: 0.40444216132164, Valid Loss: 0.6002957820892334\n",
      "Epoch: 1270, Train Loss: 0.40441712737083435, Valid Loss: 0.6004185676574707\n",
      "Epoch: 1271, Train Loss: 0.40439215302467346, Valid Loss: 0.600445568561554\n",
      "Epoch: 1272, Train Loss: 0.4043671488761902, Valid Loss: 0.6003537178039551\n",
      "Epoch: 1273, Train Loss: 0.40434208512306213, Valid Loss: 0.6005788445472717\n",
      "Epoch: 1274, Train Loss: 0.4043172597885132, Valid Loss: 0.6002992391586304\n",
      "Epoch: 1275, Train Loss: 0.40429234504699707, Valid Loss: 0.6006963849067688\n",
      "Epoch: 1276, Train Loss: 0.4042675197124481, Valid Loss: 0.6002635955810547\n",
      "Epoch: 1277, Train Loss: 0.40424275398254395, Valid Loss: 0.6008098125457764\n",
      "Epoch: 1278, Train Loss: 0.4042179584503174, Valid Loss: 0.600210964679718\n",
      "Epoch: 1279, Train Loss: 0.40419313311576843, Valid Loss: 0.6009534597396851\n",
      "Epoch: 1280, Train Loss: 0.4041685163974762, Valid Loss: 0.6001170873641968\n",
      "Epoch: 1281, Train Loss: 0.40414413809776306, Valid Loss: 0.6011614203453064\n",
      "Epoch: 1282, Train Loss: 0.40411972999572754, Valid Loss: 0.5999372005462646\n",
      "Epoch: 1283, Train Loss: 0.40409550070762634, Valid Loss: 0.601478099822998\n",
      "Epoch: 1284, Train Loss: 0.40407177805900574, Valid Loss: 0.5996037125587463\n",
      "Epoch: 1285, Train Loss: 0.4040486216545105, Valid Loss: 0.6020058989524841\n",
      "Epoch: 1286, Train Loss: 0.40402647852897644, Valid Loss: 0.5989670753479004\n",
      "Epoch: 1287, Train Loss: 0.4040065407752991, Valid Loss: 0.6029143333435059\n",
      "Epoch: 1288, Train Loss: 0.4039890468120575, Valid Loss: 0.5977833271026611\n",
      "Epoch: 1289, Train Loss: 0.4039784371852875, Valid Loss: 0.604452908039093\n",
      "Epoch: 1290, Train Loss: 0.4039730727672577, Valid Loss: 0.5957425236701965\n",
      "Epoch: 1291, Train Loss: 0.4039831757545471, Valid Loss: 0.6066865921020508\n",
      "Epoch: 1292, Train Loss: 0.4039868414402008, Valid Loss: 0.5931788086891174\n",
      "Epoch: 1293, Train Loss: 0.4039990305900574, Valid Loss: 0.6084465980529785\n",
      "Epoch: 1294, Train Loss: 0.40394890308380127, Valid Loss: 0.5929872989654541\n",
      "Epoch: 1295, Train Loss: 0.4038805365562439, Valid Loss: 0.6065459251403809\n",
      "Epoch: 1296, Train Loss: 0.40379583835601807, Valid Loss: 0.5981248617172241\n",
      "Epoch: 1297, Train Loss: 0.40375256538391113, Valid Loss: 0.6006192564964294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1298, Train Loss: 0.4037531614303589, Valid Loss: 0.604292631149292\n",
      "Epoch: 1299, Train Loss: 0.40376147627830505, Valid Loss: 0.5958191752433777\n",
      "Epoch: 1300, Train Loss: 0.4037491977214813, Valid Loss: 0.6061944961547852\n",
      "Epoch: 1301, Train Loss: 0.4036940932273865, Valid Loss: 0.5967135429382324\n",
      "Epoch: 1302, Train Loss: 0.4036388397216797, Valid Loss: 0.6028182506561279\n",
      "Epoch: 1303, Train Loss: 0.4036092758178711, Valid Loss: 0.6018152832984924\n",
      "Epoch: 1304, Train Loss: 0.40360403060913086, Valid Loss: 0.5978808403015137\n",
      "Epoch: 1305, Train Loss: 0.4035986363887787, Valid Loss: 0.605007529258728\n",
      "Epoch: 1306, Train Loss: 0.40356767177581787, Valid Loss: 0.5970550775527954\n",
      "Epoch: 1307, Train Loss: 0.4035245180130005, Valid Loss: 0.6033799648284912\n",
      "Epoch: 1308, Train Loss: 0.40348827838897705, Valid Loss: 0.6007809638977051\n",
      "Epoch: 1309, Train Loss: 0.4034702479839325, Valid Loss: 0.5994565486907959\n",
      "Epoch: 1310, Train Loss: 0.40345919132232666, Valid Loss: 0.6039960384368896\n",
      "Epoch: 1311, Train Loss: 0.40343815088272095, Valid Loss: 0.598010778427124\n",
      "Epoch: 1312, Train Loss: 0.403406023979187, Valid Loss: 0.6035741567611694\n",
      "Epoch: 1313, Train Loss: 0.4033714532852173, Valid Loss: 0.6002600789070129\n",
      "Epoch: 1314, Train Loss: 0.4033462107181549, Valid Loss: 0.6007464528083801\n",
      "Epoch: 1315, Train Loss: 0.4033290147781372, Valid Loss: 0.6030594706535339\n",
      "Epoch: 1316, Train Loss: 0.4033111333847046, Valid Loss: 0.5988605618476868\n",
      "Epoch: 1317, Train Loss: 0.40328606963157654, Valid Loss: 0.6035522222518921\n",
      "Epoch: 1318, Train Loss: 0.4032556116580963, Valid Loss: 0.5998085141181946\n",
      "Epoch: 1319, Train Loss: 0.4032275974750519, Valid Loss: 0.6016780734062195\n",
      "Epoch: 1320, Train Loss: 0.4032052457332611, Valid Loss: 0.6021186709403992\n",
      "Epoch: 1321, Train Loss: 0.40318581461906433, Valid Loss: 0.5997154712677002\n",
      "Epoch: 1322, Train Loss: 0.4031647741794586, Valid Loss: 0.6032410264015198\n",
      "Epoch: 1323, Train Loss: 0.40313920378685, Valid Loss: 0.5997081995010376\n",
      "Epoch: 1324, Train Loss: 0.4031125009059906, Valid Loss: 0.6024174690246582\n",
      "Epoch: 1325, Train Loss: 0.4030868411064148, Valid Loss: 0.6012606620788574\n",
      "Epoch: 1326, Train Loss: 0.40306413173675537, Valid Loss: 0.6008553504943848\n",
      "Epoch: 1327, Train Loss: 0.40304306149482727, Valid Loss: 0.6026614308357239\n",
      "Epoch: 1328, Train Loss: 0.4030209481716156, Valid Loss: 0.6001057624816895\n",
      "Epoch: 1329, Train Loss: 0.4029971957206726, Valid Loss: 0.6028636693954468\n",
      "Epoch: 1330, Train Loss: 0.4029720723628998, Valid Loss: 0.6006315350532532\n",
      "Epoch: 1331, Train Loss: 0.40294739603996277, Valid Loss: 0.6019793152809143\n",
      "Epoch: 1332, Train Loss: 0.4029237926006317, Valid Loss: 0.6018180251121521\n",
      "Epoch: 1333, Train Loss: 0.4029017388820648, Valid Loss: 0.6009335517883301\n",
      "Epoch: 1334, Train Loss: 0.402879536151886, Valid Loss: 0.6026417016983032\n",
      "Epoch: 1335, Train Loss: 0.40285682678222656, Valid Loss: 0.6005712747573853\n",
      "Epoch: 1336, Train Loss: 0.4028332233428955, Valid Loss: 0.6026097536087036\n",
      "Epoch: 1337, Train Loss: 0.40280935168266296, Valid Loss: 0.6010343432426453\n",
      "Epoch: 1338, Train Loss: 0.4027855396270752, Valid Loss: 0.6019884943962097\n",
      "Epoch: 1339, Train Loss: 0.4027624726295471, Valid Loss: 0.6018251180648804\n",
      "Epoch: 1340, Train Loss: 0.4027397930622101, Valid Loss: 0.6013205051422119\n",
      "Epoch: 1341, Train Loss: 0.4027174115180969, Valid Loss: 0.6024244427680969\n",
      "Epoch: 1342, Train Loss: 0.40269485116004944, Valid Loss: 0.6010093092918396\n",
      "Epoch: 1343, Train Loss: 0.40267208218574524, Valid Loss: 0.6025993227958679\n",
      "Epoch: 1344, Train Loss: 0.4026488661766052, Valid Loss: 0.6011567115783691\n",
      "Epoch: 1345, Train Loss: 0.40262559056282043, Valid Loss: 0.6023622155189514\n",
      "Epoch: 1346, Train Loss: 0.40260255336761475, Valid Loss: 0.6016074419021606\n",
      "Epoch: 1347, Train Loss: 0.40257948637008667, Valid Loss: 0.6019520163536072\n",
      "Epoch: 1348, Train Loss: 0.4025568962097168, Valid Loss: 0.6020910143852234\n",
      "Epoch: 1349, Train Loss: 0.4025343358516693, Valid Loss: 0.6016033291816711\n",
      "Epoch: 1350, Train Loss: 0.40251192450523376, Valid Loss: 0.6024281978607178\n",
      "Epoch: 1351, Train Loss: 0.40248948335647583, Valid Loss: 0.6014241576194763\n",
      "Epoch: 1352, Train Loss: 0.40246692299842834, Valid Loss: 0.6025779247283936\n",
      "Epoch: 1353, Train Loss: 0.4024443030357361, Valid Loss: 0.6014347076416016\n",
      "Epoch: 1354, Train Loss: 0.4024216830730438, Valid Loss: 0.6025545597076416\n",
      "Epoch: 1355, Train Loss: 0.40239909291267395, Valid Loss: 0.6015937328338623\n",
      "Epoch: 1356, Train Loss: 0.4023765027523041, Valid Loss: 0.602430522441864\n",
      "Epoch: 1357, Train Loss: 0.4023539423942566, Valid Loss: 0.6018142104148865\n",
      "Epoch: 1358, Train Loss: 0.4023314118385315, Valid Loss: 0.6022944450378418\n",
      "Epoch: 1359, Train Loss: 0.40230897068977356, Valid Loss: 0.6020215153694153\n",
      "Epoch: 1360, Train Loss: 0.402286559343338, Valid Loss: 0.6021826863288879\n",
      "Epoch: 1361, Train Loss: 0.40226423740386963, Valid Loss: 0.6022047996520996\n",
      "Epoch: 1362, Train Loss: 0.40224167704582214, Valid Loss: 0.6020892858505249\n",
      "Epoch: 1363, Train Loss: 0.4022196829319, Valid Loss: 0.6023643016815186\n",
      "Epoch: 1364, Train Loss: 0.40219756960868835, Valid Loss: 0.6020250916481018\n",
      "Epoch: 1365, Train Loss: 0.40217530727386475, Valid Loss: 0.602492094039917\n",
      "Epoch: 1366, Train Loss: 0.4021531045436859, Valid Loss: 0.6019738912582397\n",
      "Epoch: 1367, Train Loss: 0.4021311402320862, Valid Loss: 0.6026248931884766\n",
      "Epoch: 1368, Train Loss: 0.40210890769958496, Valid Loss: 0.6018961071968079\n",
      "Epoch: 1369, Train Loss: 0.4020870327949524, Valid Loss: 0.602800726890564\n",
      "Epoch: 1370, Train Loss: 0.402065247297287, Valid Loss: 0.6017565131187439\n",
      "Epoch: 1371, Train Loss: 0.4020434021949768, Valid Loss: 0.6030524969100952\n",
      "Epoch: 1372, Train Loss: 0.4020218849182129, Valid Loss: 0.601516842842102\n",
      "Epoch: 1373, Train Loss: 0.4020005166530609, Valid Loss: 0.6034486889839172\n",
      "Epoch: 1374, Train Loss: 0.40197983384132385, Valid Loss: 0.6010738611221313\n",
      "Epoch: 1375, Train Loss: 0.4019600749015808, Valid Loss: 0.6041080951690674\n",
      "Epoch: 1376, Train Loss: 0.40194153785705566, Valid Loss: 0.6002613306045532\n",
      "Epoch: 1377, Train Loss: 0.4019259512424469, Valid Loss: 0.6052374839782715\n",
      "Epoch: 1378, Train Loss: 0.40191391110420227, Valid Loss: 0.5987901091575623\n",
      "Epoch: 1379, Train Loss: 0.40191030502319336, Valid Loss: 0.6070982217788696\n",
      "Epoch: 1380, Train Loss: 0.40191197395324707, Valid Loss: 0.5963868498802185\n",
      "Epoch: 1381, Train Loss: 0.4019314646720886, Valid Loss: 0.6096378564834595\n",
      "Epoch: 1382, Train Loss: 0.4019368886947632, Valid Loss: 0.5937337279319763\n",
      "Epoch: 1383, Train Loss: 0.4019453525543213, Valid Loss: 0.6111986637115479\n",
      "Epoch: 1384, Train Loss: 0.40188267827033997, Valid Loss: 0.5943209528923035\n",
      "Epoch: 1385, Train Loss: 0.4018051326274872, Valid Loss: 0.6083143353462219\n",
      "Epoch: 1386, Train Loss: 0.40172749757766724, Valid Loss: 0.6004489064216614\n",
      "Epoch: 1387, Train Loss: 0.4016973078250885, Valid Loss: 0.6015960574150085\n",
      "Epoch: 1388, Train Loss: 0.4017079472541809, Valid Loss: 0.6068806648254395\n",
      "Epoch: 1389, Train Loss: 0.40171754360198975, Valid Loss: 0.5967786312103271\n",
      "Epoch: 1390, Train Loss: 0.40170174837112427, Valid Loss: 0.6084694862365723\n",
      "Epoch: 1391, Train Loss: 0.40164485573768616, Valid Loss: 0.5982488393783569\n",
      "Epoch: 1392, Train Loss: 0.4015927016735077, Valid Loss: 0.6044226288795471\n",
      "Epoch: 1393, Train Loss: 0.4015686810016632, Valid Loss: 0.6039000749588013\n",
      "Epoch: 1394, Train Loss: 0.4015679359436035, Valid Loss: 0.5991459488868713\n",
      "Epoch: 1395, Train Loss: 0.4015648663043976, Valid Loss: 0.6072080135345459\n",
      "Epoch: 1396, Train Loss: 0.40153560042381287, Valid Loss: 0.5984399914741516\n",
      "Epoch: 1397, Train Loss: 0.40149444341659546, Valid Loss: 0.6053627729415894\n",
      "Epoch: 1398, Train Loss: 0.401460200548172, Valid Loss: 0.6024553179740906\n",
      "Epoch: 1399, Train Loss: 0.4014439880847931, Valid Loss: 0.6011841297149658\n",
      "Epoch: 1400, Train Loss: 0.4014362394809723, Valid Loss: 0.6059598922729492\n",
      "Epoch: 1401, Train Loss: 0.401419073343277, Valid Loss: 0.5994551777839661\n",
      "Epoch: 1402, Train Loss: 0.4013904333114624, Valid Loss: 0.6057185530662537\n",
      "Epoch: 1403, Train Loss: 0.40135765075683594, Valid Loss: 0.6016432046890259\n",
      "Epoch: 1404, Train Loss: 0.40133363008499146, Valid Loss: 0.6027354598045349\n",
      "Epoch: 1405, Train Loss: 0.40131819248199463, Valid Loss: 0.6047604084014893\n",
      "Epoch: 1406, Train Loss: 0.4013034701347351, Valid Loss: 0.6004279255867004\n",
      "Epoch: 1407, Train Loss: 0.4012831151485443, Valid Loss: 0.6055877804756165\n",
      "Epoch: 1408, Train Loss: 0.4012560248374939, Valid Loss: 0.6011253595352173\n",
      "Epoch: 1409, Train Loss: 0.4012294113636017, Valid Loss: 0.6037840843200684\n",
      "Epoch: 1410, Train Loss: 0.40120813250541687, Valid Loss: 0.6035716533660889\n",
      "Epoch: 1411, Train Loss: 0.40119078755378723, Valid Loss: 0.6015673279762268\n",
      "Epoch: 1412, Train Loss: 0.40117350220680237, Valid Loss: 0.6050564050674438\n",
      "Epoch: 1413, Train Loss: 0.4011519253253937, Valid Loss: 0.6011742353439331\n",
      "Epoch: 1414, Train Loss: 0.40112829208374023, Valid Loss: 0.6045728325843811\n",
      "Epoch: 1415, Train Loss: 0.4011043608188629, Valid Loss: 0.6025760173797607\n",
      "Epoch: 1416, Train Loss: 0.40108320116996765, Valid Loss: 0.6029715538024902\n",
      "Epoch: 1417, Train Loss: 0.4010641872882843, Valid Loss: 0.6042187809944153\n",
      "Epoch: 1418, Train Loss: 0.4010455310344696, Valid Loss: 0.6018306612968445\n",
      "Epoch: 1419, Train Loss: 0.4010254144668579, Valid Loss: 0.6048144698143005\n",
      "Epoch: 1420, Train Loss: 0.40100347995758057, Valid Loss: 0.6020346283912659\n",
      "Epoch: 1421, Train Loss: 0.4009810984134674, Valid Loss: 0.6040957570075989\n",
      "Epoch: 1422, Train Loss: 0.40095949172973633, Valid Loss: 0.6031804084777832\n",
      "Epoch: 1423, Train Loss: 0.40093934535980225, Valid Loss: 0.6029226183891296\n",
      "Epoch: 1424, Train Loss: 0.40091994404792786, Valid Loss: 0.6042280197143555\n",
      "Epoch: 1425, Train Loss: 0.40090030431747437, Valid Loss: 0.602277934551239\n",
      "Epoch: 1426, Train Loss: 0.4008799195289612, Valid Loss: 0.6045024991035461\n",
      "Epoch: 1427, Train Loss: 0.4008587896823883, Valid Loss: 0.602461040019989\n",
      "Epoch: 1428, Train Loss: 0.4008376896381378, Valid Loss: 0.6040611863136292\n",
      "Epoch: 1429, Train Loss: 0.40081673860549927, Valid Loss: 0.6032072305679321\n",
      "Epoch: 1430, Train Loss: 0.40079623460769653, Valid Loss: 0.6033401489257812\n",
      "Epoch: 1431, Train Loss: 0.40077638626098633, Valid Loss: 0.6039746403694153\n",
      "Epoch: 1432, Train Loss: 0.4007565975189209, Valid Loss: 0.6028201580047607\n",
      "Epoch: 1433, Train Loss: 0.400736540555954, Valid Loss: 0.6043513417243958\n",
      "Epoch: 1434, Train Loss: 0.40071651339530945, Valid Loss: 0.6027740240097046\n",
      "Epoch: 1435, Train Loss: 0.40069615840911865, Valid Loss: 0.6042786240577698\n",
      "Epoch: 1436, Train Loss: 0.40067553520202637, Valid Loss: 0.6030911207199097\n",
      "Epoch: 1437, Train Loss: 0.40065497159957886, Valid Loss: 0.6039330363273621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1438, Train Loss: 0.4006350636482239, Valid Loss: 0.6035474538803101\n",
      "Epoch: 1439, Train Loss: 0.40061482787132263, Valid Loss: 0.6035383939743042\n",
      "Epoch: 1440, Train Loss: 0.4005950093269348, Valid Loss: 0.6039777398109436\n",
      "Epoch: 1441, Train Loss: 0.4005751609802246, Valid Loss: 0.603240966796875\n",
      "Epoch: 1442, Train Loss: 0.40055525302886963, Valid Loss: 0.6042386889457703\n",
      "Epoch: 1443, Train Loss: 0.4005354940891266, Valid Loss: 0.6031394600868225\n",
      "Epoch: 1444, Train Loss: 0.40051549673080444, Valid Loss: 0.6043208837509155\n",
      "Epoch: 1445, Train Loss: 0.40049564838409424, Valid Loss: 0.6032083630561829\n",
      "Epoch: 1446, Train Loss: 0.4004756212234497, Valid Loss: 0.604279637336731\n",
      "Epoch: 1447, Train Loss: 0.4004555940628052, Valid Loss: 0.603364884853363\n",
      "Epoch: 1448, Train Loss: 0.400436133146286, Valid Loss: 0.6041769981384277\n",
      "Epoch: 1449, Train Loss: 0.40041589736938477, Valid Loss: 0.6035676598548889\n",
      "Epoch: 1450, Train Loss: 0.40039607882499695, Valid Loss: 0.6040490865707397\n",
      "Epoch: 1451, Train Loss: 0.4003763496875763, Valid Loss: 0.6037715077400208\n",
      "Epoch: 1452, Train Loss: 0.4003565013408661, Valid Loss: 0.6039295196533203\n",
      "Epoch: 1453, Train Loss: 0.40033695101737976, Valid Loss: 0.6039438843727112\n",
      "Epoch: 1454, Train Loss: 0.40031737089157104, Valid Loss: 0.6038414239883423\n",
      "Epoch: 1455, Train Loss: 0.40029779076576233, Valid Loss: 0.6040939092636108\n",
      "Epoch: 1456, Train Loss: 0.400278240442276, Valid Loss: 0.6037591099739075\n",
      "Epoch: 1457, Train Loss: 0.4002586007118225, Valid Loss: 0.6042385697364807\n",
      "Epoch: 1458, Train Loss: 0.40023934841156006, Valid Loss: 0.6036731600761414\n",
      "Epoch: 1459, Train Loss: 0.4002199172973633, Valid Loss: 0.604404091835022\n",
      "Epoch: 1460, Train Loss: 0.4002005457878113, Valid Loss: 0.6035645008087158\n",
      "Epoch: 1461, Train Loss: 0.40018120408058167, Valid Loss: 0.6046083569526672\n",
      "Epoch: 1462, Train Loss: 0.4001620411872864, Valid Loss: 0.6033923625946045\n",
      "Epoch: 1463, Train Loss: 0.400143027305603, Valid Loss: 0.6049104928970337\n",
      "Epoch: 1464, Train Loss: 0.40012434124946594, Valid Loss: 0.6030838489532471\n",
      "Epoch: 1465, Train Loss: 0.4001059830188751, Valid Loss: 0.6053911447525024\n",
      "Epoch: 1466, Train Loss: 0.4000883102416992, Valid Loss: 0.6025316119194031\n",
      "Epoch: 1467, Train Loss: 0.40007176995277405, Valid Loss: 0.6061834692955017\n",
      "Epoch: 1468, Train Loss: 0.40005674958229065, Valid Loss: 0.6015426516532898\n",
      "Epoch: 1469, Train Loss: 0.4000455141067505, Valid Loss: 0.6075183749198914\n",
      "Epoch: 1470, Train Loss: 0.40003833174705505, Valid Loss: 0.5998046398162842\n",
      "Epoch: 1471, Train Loss: 0.4000413119792938, Valid Loss: 0.6096802949905396\n",
      "Epoch: 1472, Train Loss: 0.4000496566295624, Valid Loss: 0.5970710515975952\n",
      "Epoch: 1473, Train Loss: 0.4000770151615143, Valid Loss: 0.6124992966651917\n",
      "Epoch: 1474, Train Loss: 0.4000837504863739, Valid Loss: 0.5943383574485779\n",
      "Epoch: 1475, Train Loss: 0.40008944272994995, Valid Loss: 0.6139040589332581\n",
      "Epoch: 1476, Train Loss: 0.40001896023750305, Valid Loss: 0.5955144166946411\n",
      "Epoch: 1477, Train Loss: 0.39993637800216675, Valid Loss: 0.6102343201637268\n",
      "Epoch: 1478, Train Loss: 0.39986294507980347, Valid Loss: 0.6024456024169922\n",
      "Epoch: 1479, Train Loss: 0.3998417854309082, Valid Loss: 0.602769136428833\n",
      "Epoch: 1480, Train Loss: 0.39985978603363037, Valid Loss: 0.6092951893806458\n",
      "Epoch: 1481, Train Loss: 0.3998715281486511, Valid Loss: 0.5977530479431152\n",
      "Epoch: 1482, Train Loss: 0.3998551070690155, Valid Loss: 0.6107607483863831\n",
      "Epoch: 1483, Train Loss: 0.39979788661003113, Valid Loss: 0.599600076675415\n",
      "Epoch: 1484, Train Loss: 0.399747371673584, Valid Loss: 0.6061566472053528\n",
      "Epoch: 1485, Train Loss: 0.39972659945487976, Valid Loss: 0.6057938933372498\n",
      "Epoch: 1486, Train Loss: 0.3997296690940857, Valid Loss: 0.6004878878593445\n",
      "Epoch: 1487, Train Loss: 0.39973023533821106, Valid Loss: 0.6093525886535645\n",
      "Epoch: 1488, Train Loss: 0.3997035324573517, Valid Loss: 0.5997229218482971\n",
      "Epoch: 1489, Train Loss: 0.3996645510196686, Valid Loss: 0.6074195504188538\n",
      "Epoch: 1490, Train Loss: 0.3996311128139496, Valid Loss: 0.6039658188819885\n",
      "Epoch: 1491, Train Loss: 0.39961671829223633, Valid Loss: 0.6029366850852966\n",
      "Epoch: 1492, Train Loss: 0.39961206912994385, Valid Loss: 0.6078735589981079\n",
      "Epoch: 1493, Train Loss: 0.3995991051197052, Valid Loss: 0.6008263230323792\n",
      "Epoch: 1494, Train Loss: 0.39957407116889954, Valid Loss: 0.6078349947929382\n",
      "Epoch: 1495, Train Loss: 0.3995433449745178, Valid Loss: 0.6029479503631592\n",
      "Epoch: 1496, Train Loss: 0.39951959252357483, Valid Loss: 0.6046611666679382\n",
      "Epoch: 1497, Train Loss: 0.3995060324668884, Valid Loss: 0.6064102649688721\n",
      "Epoch: 1498, Train Loss: 0.3994949460029602, Valid Loss: 0.6019604206085205\n",
      "Epoch: 1499, Train Loss: 0.3994784653186798, Valid Loss: 0.6075414419174194\n",
      "Epoch: 1500, Train Loss: 0.3994544744491577, Valid Loss: 0.6024188995361328\n",
      "Epoch: 1501, Train Loss: 0.3994297683238983, Valid Loss: 0.6058071255683899\n",
      "Epoch: 1502, Train Loss: 0.39940962195396423, Valid Loss: 0.604993999004364\n",
      "Epoch: 1503, Train Loss: 0.3993943929672241, Valid Loss: 0.6033833026885986\n",
      "Epoch: 1504, Train Loss: 0.39938005805015564, Valid Loss: 0.606814980506897\n",
      "Epoch: 1505, Train Loss: 0.39936280250549316, Valid Loss: 0.6026232242584229\n",
      "Epoch: 1506, Train Loss: 0.3993419408798218, Valid Loss: 0.606602668762207\n",
      "Epoch: 1507, Train Loss: 0.39932000637054443, Valid Loss: 0.6039215326309204\n",
      "Epoch: 1508, Train Loss: 0.39930057525634766, Valid Loss: 0.6049490571022034\n",
      "Epoch: 1509, Train Loss: 0.3992835283279419, Valid Loss: 0.605769157409668\n",
      "Epoch: 1510, Train Loss: 0.3992677330970764, Valid Loss: 0.6034983396530151\n",
      "Epoch: 1511, Train Loss: 0.39925089478492737, Valid Loss: 0.6066180467605591\n",
      "Epoch: 1512, Train Loss: 0.3992319107055664, Valid Loss: 0.603473424911499\n",
      "Epoch: 1513, Train Loss: 0.3992120623588562, Valid Loss: 0.6060396432876587\n",
      "Epoch: 1514, Train Loss: 0.3991926312446594, Valid Loss: 0.6045728921890259\n",
      "Epoch: 1515, Train Loss: 0.39917439222335815, Valid Loss: 0.6047907471656799\n",
      "Epoch: 1516, Train Loss: 0.39915740489959717, Valid Loss: 0.605757474899292\n",
      "Epoch: 1517, Train Loss: 0.3991406559944153, Valid Loss: 0.6039440631866455\n",
      "Epoch: 1518, Train Loss: 0.3991231918334961, Valid Loss: 0.6062681078910828\n",
      "Epoch: 1519, Train Loss: 0.39910489320755005, Valid Loss: 0.6039551496505737\n",
      "Epoch: 1520, Train Loss: 0.39908620715141296, Valid Loss: 0.605934739112854\n",
      "Epoch: 1521, Train Loss: 0.39906758069992065, Valid Loss: 0.6046662926673889\n",
      "Epoch: 1522, Train Loss: 0.3990496098995209, Valid Loss: 0.605170488357544\n",
      "Epoch: 1523, Train Loss: 0.3990321755409241, Valid Loss: 0.6055362224578857\n",
      "Epoch: 1524, Train Loss: 0.3990148603916168, Valid Loss: 0.6045320630073547\n",
      "Epoch: 1525, Train Loss: 0.39899763464927673, Valid Loss: 0.6060378551483154\n",
      "Epoch: 1526, Train Loss: 0.39898011088371277, Valid Loss: 0.6043403744697571\n",
      "Epoch: 1527, Train Loss: 0.39896222949028015, Valid Loss: 0.6060447096824646\n",
      "Epoch: 1528, Train Loss: 0.39894434809684753, Valid Loss: 0.6046090126037598\n",
      "Epoch: 1529, Train Loss: 0.3989262878894806, Valid Loss: 0.6056945323944092\n",
      "Epoch: 1530, Train Loss: 0.3989085257053375, Valid Loss: 0.6051069498062134\n",
      "Epoch: 1531, Train Loss: 0.3988908529281616, Valid Loss: 0.6052225232124329\n",
      "Epoch: 1532, Train Loss: 0.3988737165927887, Valid Loss: 0.6055922508239746\n",
      "Epoch: 1533, Train Loss: 0.3988564610481262, Valid Loss: 0.6048775315284729\n",
      "Epoch: 1534, Train Loss: 0.3988391160964966, Valid Loss: 0.6059006452560425\n",
      "Epoch: 1535, Train Loss: 0.39882171154022217, Valid Loss: 0.604752242565155\n",
      "Epoch: 1536, Train Loss: 0.39880433678627014, Valid Loss: 0.605992317199707\n",
      "Epoch: 1537, Train Loss: 0.3987870514392853, Valid Loss: 0.6048154234886169\n",
      "Epoch: 1538, Train Loss: 0.3987694978713989, Valid Loss: 0.6059361100196838\n",
      "Epoch: 1539, Train Loss: 0.3987520933151245, Valid Loss: 0.605009138584137\n",
      "Epoch: 1540, Train Loss: 0.3987347483634949, Valid Loss: 0.6057847738265991\n",
      "Epoch: 1541, Train Loss: 0.39871740341186523, Valid Loss: 0.6052512526512146\n",
      "Epoch: 1542, Train Loss: 0.3987002372741699, Valid Loss: 0.6056024432182312\n",
      "Epoch: 1543, Train Loss: 0.3986828029155731, Valid Loss: 0.6054846048355103\n",
      "Epoch: 1544, Train Loss: 0.3986656963825226, Valid Loss: 0.6054558753967285\n",
      "Epoch: 1545, Train Loss: 0.39864853024482727, Valid Loss: 0.605675458908081\n",
      "Epoch: 1546, Train Loss: 0.39863160252571106, Valid Loss: 0.6053352355957031\n",
      "Epoch: 1547, Train Loss: 0.39861440658569336, Valid Loss: 0.6058375835418701\n",
      "Epoch: 1548, Train Loss: 0.3985973000526428, Valid Loss: 0.6052401661872864\n",
      "Epoch: 1549, Train Loss: 0.39858031272888184, Valid Loss: 0.6059895753860474\n",
      "Epoch: 1550, Train Loss: 0.3985634744167328, Valid Loss: 0.605161726474762\n",
      "Epoch: 1551, Train Loss: 0.3985465168952942, Valid Loss: 0.6061336994171143\n",
      "Epoch: 1552, Train Loss: 0.39852967858314514, Valid Loss: 0.6050723791122437\n",
      "Epoch: 1553, Train Loss: 0.3985128402709961, Valid Loss: 0.606309175491333\n",
      "Epoch: 1554, Train Loss: 0.3984960615634918, Valid Loss: 0.6049396991729736\n",
      "Epoch: 1555, Train Loss: 0.3984791934490204, Valid Loss: 0.6065519452095032\n",
      "Epoch: 1556, Train Loss: 0.3984629213809967, Valid Loss: 0.6047084331512451\n",
      "Epoch: 1557, Train Loss: 0.39844679832458496, Valid Loss: 0.6069139838218689\n",
      "Epoch: 1558, Train Loss: 0.39843079447746277, Valid Loss: 0.6043121218681335\n",
      "Epoch: 1559, Train Loss: 0.3984154760837555, Valid Loss: 0.6074889898300171\n",
      "Epoch: 1560, Train Loss: 0.3984011709690094, Valid Loss: 0.6036291718482971\n",
      "Epoch: 1561, Train Loss: 0.39838817715644836, Valid Loss: 0.6084283590316772\n",
      "Epoch: 1562, Train Loss: 0.3983772397041321, Valid Loss: 0.6024497747421265\n",
      "Epoch: 1563, Train Loss: 0.3983706533908844, Valid Loss: 0.6099498867988586\n",
      "Epoch: 1564, Train Loss: 0.3983679711818695, Valid Loss: 0.6005347967147827\n",
      "Epoch: 1565, Train Loss: 0.3983757793903351, Valid Loss: 0.6122215390205383\n",
      "Epoch: 1566, Train Loss: 0.39838528633117676, Valid Loss: 0.597861111164093\n",
      "Epoch: 1567, Train Loss: 0.3984090983867645, Valid Loss: 0.6148095726966858\n",
      "Epoch: 1568, Train Loss: 0.3984069228172302, Valid Loss: 0.5957522988319397\n",
      "Epoch: 1569, Train Loss: 0.39839836955070496, Valid Loss: 0.6155194640159607\n",
      "Epoch: 1570, Train Loss: 0.3983312249183655, Valid Loss: 0.5976011753082275\n",
      "Epoch: 1571, Train Loss: 0.39826008677482605, Valid Loss: 0.6115447878837585\n",
      "Epoch: 1572, Train Loss: 0.398201584815979, Valid Loss: 0.6041510105133057\n",
      "Epoch: 1573, Train Loss: 0.3981829285621643, Valid Loss: 0.6045582890510559\n",
      "Epoch: 1574, Train Loss: 0.39819440245628357, Valid Loss: 0.6105260252952576\n",
      "Epoch: 1575, Train Loss: 0.39820560812950134, Valid Loss: 0.5996376276016235\n",
      "Epoch: 1576, Train Loss: 0.3981994390487671, Valid Loss: 0.612511157989502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1577, Train Loss: 0.39815863966941833, Valid Loss: 0.6003803014755249\n",
      "Epoch: 1578, Train Loss: 0.39811304211616516, Valid Loss: 0.6091539859771729\n",
      "Epoch: 1579, Train Loss: 0.3980814218521118, Valid Loss: 0.6056306958198547\n",
      "Epoch: 1580, Train Loss: 0.39807257056236267, Valid Loss: 0.6037516593933105\n",
      "Epoch: 1581, Train Loss: 0.39807456731796265, Valid Loss: 0.610107958316803\n",
      "Epoch: 1582, Train Loss: 0.3980676531791687, Valid Loss: 0.6011782288551331\n",
      "Epoch: 1583, Train Loss: 0.39804643392562866, Valid Loss: 0.6104403138160706\n",
      "Epoch: 1584, Train Loss: 0.39801377058029175, Valid Loss: 0.6032138466835022\n",
      "Epoch: 1585, Train Loss: 0.3979855477809906, Valid Loss: 0.6071850061416626\n",
      "Epoch: 1586, Train Loss: 0.3979699909687042, Valid Loss: 0.6073251962661743\n",
      "Epoch: 1587, Train Loss: 0.3979629576206207, Valid Loss: 0.603588879108429\n",
      "Epoch: 1588, Train Loss: 0.3979547917842865, Valid Loss: 0.6097321510314941\n",
      "Epoch: 1589, Train Loss: 0.3979378044605255, Valid Loss: 0.602764904499054\n",
      "Epoch: 1590, Train Loss: 0.39791473746299744, Valid Loss: 0.6088878512382507\n",
      "Epoch: 1591, Train Loss: 0.39789071679115295, Valid Loss: 0.6049641966819763\n",
      "Epoch: 1592, Train Loss: 0.3978722095489502, Valid Loss: 0.6060752272605896\n",
      "Epoch: 1593, Train Loss: 0.3978595435619354, Valid Loss: 0.6077449321746826\n",
      "Epoch: 1594, Train Loss: 0.39784854650497437, Valid Loss: 0.6039126515388489\n",
      "Epoch: 1595, Train Loss: 0.3978351354598999, Valid Loss: 0.6088998913764954\n",
      "Epoch: 1596, Train Loss: 0.39781710505485535, Valid Loss: 0.6039294004440308\n",
      "Epoch: 1597, Train Loss: 0.39779701828956604, Valid Loss: 0.608014702796936\n",
      "Epoch: 1598, Train Loss: 0.39777782559394836, Valid Loss: 0.605680525302887\n",
      "Epoch: 1599, Train Loss: 0.39776137471199036, Valid Loss: 0.6060975193977356\n",
      "Epoch: 1600, Train Loss: 0.39774757623672485, Valid Loss: 0.6076087355613708\n",
      "Epoch: 1601, Train Loss: 0.3977341651916504, Valid Loss: 0.6047074794769287\n",
      "Epoch: 1602, Train Loss: 0.3977195620536804, Valid Loss: 0.6084081530570984\n",
      "Epoch: 1603, Train Loss: 0.3977029025554657, Valid Loss: 0.6047088503837585\n",
      "Epoch: 1604, Train Loss: 0.3976854383945465, Valid Loss: 0.6078360676765442\n",
      "Epoch: 1605, Train Loss: 0.39766794443130493, Valid Loss: 0.6057859659194946\n",
      "Epoch: 1606, Train Loss: 0.3976515829563141, Valid Loss: 0.606580913066864\n",
      "Epoch: 1607, Train Loss: 0.3976363241672516, Valid Loss: 0.6070729494094849\n",
      "Epoch: 1608, Train Loss: 0.3976218104362488, Valid Loss: 0.6055123805999756\n",
      "Epoch: 1609, Train Loss: 0.39760732650756836, Valid Loss: 0.6078524589538574\n",
      "Epoch: 1610, Train Loss: 0.39759206771850586, Valid Loss: 0.605170726776123\n",
      "Epoch: 1611, Train Loss: 0.3975759744644165, Valid Loss: 0.6078550815582275\n",
      "Epoch: 1612, Train Loss: 0.3975597023963928, Valid Loss: 0.6055880784988403\n",
      "Epoch: 1613, Train Loss: 0.3975433111190796, Valid Loss: 0.6072779297828674\n",
      "Epoch: 1614, Train Loss: 0.3975275754928589, Valid Loss: 0.6063932776451111\n",
      "Epoch: 1615, Train Loss: 0.3975121080875397, Valid Loss: 0.6065468788146973\n",
      "Epoch: 1616, Train Loss: 0.39749690890312195, Valid Loss: 0.6071515083312988\n",
      "Epoch: 1617, Train Loss: 0.39748209714889526, Valid Loss: 0.6059908270835876\n",
      "Epoch: 1618, Train Loss: 0.39746713638305664, Valid Loss: 0.6075987815856934\n",
      "Epoch: 1619, Train Loss: 0.39745187759399414, Valid Loss: 0.6057806015014648\n",
      "Epoch: 1620, Train Loss: 0.39743658900260925, Valid Loss: 0.6076788306236267\n",
      "Epoch: 1621, Train Loss: 0.3974211513996124, Valid Loss: 0.6059121489524841\n",
      "Epoch: 1622, Train Loss: 0.3974055349826813, Valid Loss: 0.6074719429016113\n",
      "Epoch: 1623, Train Loss: 0.3973899483680725, Valid Loss: 0.6062564253807068\n",
      "Epoch: 1624, Train Loss: 0.3973746597766876, Valid Loss: 0.6071311831474304\n",
      "Epoch: 1625, Train Loss: 0.39735934138298035, Valid Loss: 0.6066609025001526\n",
      "Epoch: 1626, Train Loss: 0.39734408259391785, Valid Loss: 0.6068000197410583\n",
      "Epoch: 1627, Train Loss: 0.39732906222343445, Valid Loss: 0.6070330739021301\n",
      "Epoch: 1628, Train Loss: 0.3973141610622406, Valid Loss: 0.6065343022346497\n",
      "Epoch: 1629, Train Loss: 0.3972991406917572, Valid Loss: 0.607320249080658\n",
      "Epoch: 1630, Train Loss: 0.3972841799259186, Valid Loss: 0.606360912322998\n",
      "Epoch: 1631, Train Loss: 0.39726927876472473, Valid Loss: 0.6075162291526794\n",
      "Epoch: 1632, Train Loss: 0.39725446701049805, Valid Loss: 0.6062655448913574\n",
      "Epoch: 1633, Train Loss: 0.3972395062446594, Valid Loss: 0.6076509952545166\n",
      "Epoch: 1634, Train Loss: 0.3972247838973999, Valid Loss: 0.6062082052230835\n",
      "Epoch: 1635, Train Loss: 0.39720970392227173, Valid Loss: 0.607753574848175\n",
      "Epoch: 1636, Train Loss: 0.3971948027610779, Valid Loss: 0.606156587600708\n",
      "Epoch: 1637, Train Loss: 0.39718031883239746, Valid Loss: 0.6078639030456543\n",
      "Epoch: 1638, Train Loss: 0.3971654772758484, Valid Loss: 0.6060823798179626\n",
      "Epoch: 1639, Train Loss: 0.3971507251262665, Valid Loss: 0.6080216765403748\n",
      "Epoch: 1640, Train Loss: 0.3971360921859741, Valid Loss: 0.605939507484436\n",
      "Epoch: 1641, Train Loss: 0.39712169766426086, Valid Loss: 0.6082656979560852\n",
      "Epoch: 1642, Train Loss: 0.39710766077041626, Valid Loss: 0.6056913137435913\n",
      "Epoch: 1643, Train Loss: 0.3970939815044403, Valid Loss: 0.6086494326591492\n",
      "Epoch: 1644, Train Loss: 0.39708003401756287, Valid Loss: 0.6052601337432861\n",
      "Epoch: 1645, Train Loss: 0.39706704020500183, Valid Loss: 0.6092665195465088\n",
      "Epoch: 1646, Train Loss: 0.3970552682876587, Valid Loss: 0.6045382022857666\n",
      "Epoch: 1647, Train Loss: 0.3970448076725006, Valid Loss: 0.6102241277694702\n",
      "Epoch: 1648, Train Loss: 0.3970358967781067, Valid Loss: 0.6033741235733032\n",
      "Epoch: 1649, Train Loss: 0.397031307220459, Valid Loss: 0.6116878986358643\n",
      "Epoch: 1650, Train Loss: 0.39702892303466797, Valid Loss: 0.601611316204071\n",
      "Epoch: 1651, Train Loss: 0.3970344662666321, Valid Loss: 0.6137160658836365\n",
      "Epoch: 1652, Train Loss: 0.3970396816730499, Valid Loss: 0.5993540287017822\n",
      "Epoch: 1653, Train Loss: 0.3970543444156647, Valid Loss: 0.6158664226531982\n",
      "Epoch: 1654, Train Loss: 0.3970496654510498, Valid Loss: 0.597678005695343\n",
      "Epoch: 1655, Train Loss: 0.39704200625419617, Valid Loss: 0.6165051460266113\n",
      "Epoch: 1656, Train Loss: 0.3969949781894684, Valid Loss: 0.5989241600036621\n",
      "Epoch: 1657, Train Loss: 0.3969425857067108, Valid Loss: 0.6135942339897156\n",
      "Epoch: 1658, Train Loss: 0.396888792514801, Valid Loss: 0.6039431095123291\n",
      "Epoch: 1659, Train Loss: 0.39685776829719543, Valid Loss: 0.6078600287437439\n",
      "Epoch: 1660, Train Loss: 0.3968513607978821, Valid Loss: 0.6097851395606995\n",
      "Epoch: 1661, Train Loss: 0.39685794711112976, Valid Loss: 0.6027060747146606\n",
      "Epoch: 1662, Train Loss: 0.3968641459941864, Valid Loss: 0.6131426095962524\n",
      "Epoch: 1663, Train Loss: 0.3968515694141388, Valid Loss: 0.6010509729385376\n",
      "Epoch: 1664, Train Loss: 0.39682626724243164, Valid Loss: 0.6125722527503967\n",
      "Epoch: 1665, Train Loss: 0.39679035544395447, Valid Loss: 0.6036401987075806\n",
      "Epoch: 1666, Train Loss: 0.3967607915401459, Valid Loss: 0.6088497042655945\n",
      "Epoch: 1667, Train Loss: 0.39674440026283264, Valid Loss: 0.6081042289733887\n",
      "Epoch: 1668, Train Loss: 0.3967384099960327, Valid Loss: 0.6048510074615479\n",
      "Epoch: 1669, Train Loss: 0.3967357277870178, Valid Loss: 0.6112384796142578\n",
      "Epoch: 1670, Train Loss: 0.39672648906707764, Valid Loss: 0.6031489968299866\n",
      "Epoch: 1671, Train Loss: 0.396709680557251, Valid Loss: 0.6115082502365112\n",
      "Epoch: 1672, Train Loss: 0.39668571949005127, Valid Loss: 0.6044749617576599\n",
      "Epoch: 1673, Train Loss: 0.39666271209716797, Valid Loss: 0.6092210412025452\n",
      "Epoch: 1674, Train Loss: 0.39664486050605774, Valid Loss: 0.6074631214141846\n",
      "Epoch: 1675, Train Loss: 0.3966331481933594, Valid Loss: 0.6062508225440979\n",
      "Epoch: 1676, Train Loss: 0.3966244161128998, Valid Loss: 0.6099060773849487\n",
      "Epoch: 1677, Train Loss: 0.39661478996276855, Valid Loss: 0.6045682430267334\n",
      "Epoch: 1678, Train Loss: 0.3966016471385956, Valid Loss: 0.6105608940124512\n",
      "Epoch: 1679, Train Loss: 0.3965846300125122, Valid Loss: 0.6048856973648071\n",
      "Epoch: 1680, Train Loss: 0.39656615257263184, Valid Loss: 0.6094915270805359\n",
      "Epoch: 1681, Train Loss: 0.396548867225647, Valid Loss: 0.6066243648529053\n",
      "Epoch: 1682, Train Loss: 0.3965335190296173, Valid Loss: 0.6076116561889648\n",
      "Epoch: 1683, Train Loss: 0.39652079343795776, Valid Loss: 0.6085735559463501\n",
      "Epoch: 1684, Train Loss: 0.39650920033454895, Valid Loss: 0.6060714721679688\n",
      "Epoch: 1685, Train Loss: 0.39649736881256104, Valid Loss: 0.6097192168235779\n",
      "Epoch: 1686, Train Loss: 0.3964843451976776, Valid Loss: 0.6055700778961182\n",
      "Epoch: 1687, Train Loss: 0.3964698314666748, Valid Loss: 0.609722912311554\n",
      "Epoch: 1688, Train Loss: 0.3964541554450989, Valid Loss: 0.6061205267906189\n",
      "Epoch: 1689, Train Loss: 0.39643850922584534, Valid Loss: 0.6088809370994568\n",
      "Epoch: 1690, Train Loss: 0.3964236378669739, Valid Loss: 0.6072381138801575\n",
      "Epoch: 1691, Train Loss: 0.3964095711708069, Valid Loss: 0.6077297925949097\n",
      "Epoch: 1692, Train Loss: 0.3963961899280548, Valid Loss: 0.608359694480896\n",
      "Epoch: 1693, Train Loss: 0.3963835537433624, Valid Loss: 0.6067911386489868\n",
      "Epoch: 1694, Train Loss: 0.39637085795402527, Valid Loss: 0.6090915203094482\n",
      "Epoch: 1695, Train Loss: 0.39635777473449707, Valid Loss: 0.6063658595085144\n",
      "Epoch: 1696, Train Loss: 0.396344393491745, Valid Loss: 0.6093108057975769\n",
      "Epoch: 1697, Train Loss: 0.39633041620254517, Valid Loss: 0.6064541339874268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1698, Train Loss: 0.3963163197040558, Valid Loss: 0.6091098189353943\n",
      "Epoch: 1699, Train Loss: 0.3963020443916321, Valid Loss: 0.6068904995918274\n",
      "Epoch: 1700, Train Loss: 0.3962880074977875, Valid Loss: 0.6086622476577759\n",
      "Epoch: 1701, Train Loss: 0.39627400040626526, Valid Loss: 0.6074787378311157\n",
      "Epoch: 1702, Train Loss: 0.3962603211402893, Valid Loss: 0.6081289649009705\n",
      "Epoch: 1703, Train Loss: 0.3962468206882477, Valid Loss: 0.6080383062362671\n",
      "Epoch: 1704, Train Loss: 0.3962336480617523, Valid Loss: 0.6076652407646179\n",
      "Epoch: 1705, Train Loss: 0.3962205946445465, Valid Loss: 0.6084773540496826\n",
      "Epoch: 1706, Train Loss: 0.3962072730064392, Valid Loss: 0.6073297262191772\n",
      "Epoch: 1707, Train Loss: 0.396194189786911, Valid Loss: 0.6087949275970459\n",
      "Epoch: 1708, Train Loss: 0.3961811363697052, Valid Loss: 0.6071046590805054\n",
      "Epoch: 1709, Train Loss: 0.3961680233478546, Valid Loss: 0.6090238690376282\n",
      "Epoch: 1710, Train Loss: 0.3961550295352936, Valid Loss: 0.6069579720497131\n",
      "Epoch: 1711, Train Loss: 0.3961418569087982, Valid Loss: 0.6092026233673096\n",
      "Epoch: 1712, Train Loss: 0.39612895250320435, Valid Loss: 0.6068530082702637\n",
      "Epoch: 1713, Train Loss: 0.39611586928367615, Valid Loss: 0.6093788146972656\n",
      "Epoch: 1714, Train Loss: 0.3961029052734375, Valid Loss: 0.606728196144104\n",
      "Epoch: 1715, Train Loss: 0.39609014987945557, Valid Loss: 0.6095963716506958\n",
      "Epoch: 1716, Train Loss: 0.3960774838924408, Valid Loss: 0.6065300107002258\n",
      "Epoch: 1717, Train Loss: 0.39606502652168274, Valid Loss: 0.6099053025245667\n",
      "Epoch: 1718, Train Loss: 0.3960527181625366, Valid Loss: 0.6062026619911194\n",
      "Epoch: 1719, Train Loss: 0.39604097604751587, Valid Loss: 0.6103612780570984\n",
      "Epoch: 1720, Train Loss: 0.3960297703742981, Valid Loss: 0.6056721210479736\n",
      "Epoch: 1721, Train Loss: 0.39601925015449524, Valid Loss: 0.6110616326332092\n",
      "Epoch: 1722, Train Loss: 0.39600980281829834, Valid Loss: 0.6048400402069092\n",
      "Epoch: 1723, Train Loss: 0.39600247144699097, Valid Loss: 0.6121072769165039\n",
      "Epoch: 1724, Train Loss: 0.39599621295928955, Valid Loss: 0.6036173701286316\n",
      "Epoch: 1725, Train Loss: 0.39599427580833435, Valid Loss: 0.6135637164115906\n",
      "Epoch: 1726, Train Loss: 0.39599278569221497, Valid Loss: 0.6019690036773682\n",
      "Epoch: 1727, Train Loss: 0.395997554063797, Valid Loss: 0.6153393983840942\n",
      "Epoch: 1728, Train Loss: 0.3959980010986328, Valid Loss: 0.600230872631073\n",
      "Epoch: 1729, Train Loss: 0.39600270986557007, Valid Loss: 0.6167972683906555\n",
      "Epoch: 1730, Train Loss: 0.3959885537624359, Valid Loss: 0.5994973182678223\n",
      "Epoch: 1731, Train Loss: 0.39597082138061523, Valid Loss: 0.6165714859962463\n",
      "Epoch: 1732, Train Loss: 0.3959302306175232, Valid Loss: 0.6012800335884094\n",
      "Epoch: 1733, Train Loss: 0.3958894908428192, Valid Loss: 0.6136284470558167\n",
      "Epoch: 1734, Train Loss: 0.3958519399166107, Valid Loss: 0.6055371761322021\n",
      "Epoch: 1735, Train Loss: 0.3958284258842468, Valid Loss: 0.608943521976471\n",
      "Epoch: 1736, Train Loss: 0.39581942558288574, Valid Loss: 0.6101577877998352\n",
      "Epoch: 1737, Train Loss: 0.3958192467689514, Valid Loss: 0.6047657132148743\n",
      "Epoch: 1738, Train Loss: 0.395820677280426, Valid Loss: 0.6131650805473328\n",
      "Epoch: 1739, Train Loss: 0.39581480622291565, Valid Loss: 0.602837085723877\n",
      "Epoch: 1740, Train Loss: 0.39580196142196655, Valid Loss: 0.6136584281921387\n",
      "Epoch: 1741, Train Loss: 0.3957788050174713, Valid Loss: 0.6037706136703491\n",
      "Epoch: 1742, Train Loss: 0.3957538902759552, Valid Loss: 0.6117528080940247\n",
      "Epoch: 1743, Train Loss: 0.3957308530807495, Valid Loss: 0.606701672077179\n",
      "Epoch: 1744, Train Loss: 0.39571431279182434, Valid Loss: 0.6086791753768921\n",
      "Epoch: 1745, Train Loss: 0.3957040011882782, Valid Loss: 0.6098678112030029\n",
      "Epoch: 1746, Train Loss: 0.39569708704948425, Valid Loss: 0.6060454845428467\n",
      "Epoch: 1747, Train Loss: 0.39569076895713806, Valid Loss: 0.6118574738502502\n",
      "Epoch: 1748, Train Loss: 0.3956807255744934, Valid Loss: 0.6049253940582275\n",
      "Epoch: 1749, Train Loss: 0.39566749334335327, Valid Loss: 0.6120815277099609\n",
      "Epoch: 1750, Train Loss: 0.3956507444381714, Valid Loss: 0.6055409908294678\n",
      "Epoch: 1751, Train Loss: 0.39563313126564026, Valid Loss: 0.6108080744743347\n",
      "Epoch: 1752, Train Loss: 0.39561644196510315, Valid Loss: 0.6072798371315002\n",
      "Epoch: 1753, Train Loss: 0.3956020474433899, Valid Loss: 0.6089032292366028\n",
      "Epoch: 1754, Train Loss: 0.3955899178981781, Valid Loss: 0.6091844439506531\n",
      "Epoch: 1755, Train Loss: 0.39557942748069763, Valid Loss: 0.6072391867637634\n",
      "Epoch: 1756, Train Loss: 0.3955696225166321, Valid Loss: 0.6105697751045227\n",
      "Epoch: 1757, Train Loss: 0.3955591022968292, Valid Loss: 0.6063327789306641\n",
      "Epoch: 1758, Train Loss: 0.39554768800735474, Valid Loss: 0.6111240983009338\n",
      "Epoch: 1759, Train Loss: 0.395534873008728, Valid Loss: 0.606316089630127\n",
      "Epoch: 1760, Train Loss: 0.3955213725566864, Valid Loss: 0.610859751701355\n",
      "Epoch: 1761, Train Loss: 0.3955070674419403, Valid Loss: 0.6069725751876831\n",
      "Epoch: 1762, Train Loss: 0.3954932391643524, Valid Loss: 0.6100710034370422\n",
      "Epoch: 1763, Train Loss: 0.39547964930534363, Valid Loss: 0.6079398989677429\n",
      "Epoch: 1764, Train Loss: 0.3954666256904602, Valid Loss: 0.6091042160987854\n",
      "Epoch: 1765, Train Loss: 0.3954543173313141, Valid Loss: 0.6089129447937012\n",
      "Epoch: 1766, Train Loss: 0.39544254541397095, Valid Loss: 0.6082355380058289\n",
      "Epoch: 1767, Train Loss: 0.39543092250823975, Valid Loss: 0.609685480594635\n",
      "Epoch: 1768, Train Loss: 0.3954193890094757, Valid Loss: 0.6076231598854065\n",
      "Epoch: 1769, Train Loss: 0.39540818333625793, Valid Loss: 0.6101931929588318\n",
      "Epoch: 1770, Train Loss: 0.39539650082588196, Valid Loss: 0.6072849035263062\n",
      "Epoch: 1771, Train Loss: 0.39538487792015076, Valid Loss: 0.6104783415794373\n",
      "Epoch: 1772, Train Loss: 0.39537298679351807, Valid Loss: 0.6071654558181763\n",
      "Epoch: 1773, Train Loss: 0.3953610360622406, Valid Loss: 0.6105960607528687\n",
      "Epoch: 1774, Train Loss: 0.39534905552864075, Valid Loss: 0.607191264629364\n",
      "Epoch: 1775, Train Loss: 0.39533692598342896, Valid Loss: 0.6106112003326416\n",
      "Epoch: 1776, Train Loss: 0.3953249454498291, Valid Loss: 0.607272207736969\n",
      "Epoch: 1777, Train Loss: 0.39531269669532776, Valid Loss: 0.610588014125824\n",
      "Epoch: 1778, Train Loss: 0.39530083537101746, Valid Loss: 0.6073251366615295\n",
      "Epoch: 1779, Train Loss: 0.3952889144420624, Valid Loss: 0.6105924844741821\n",
      "Epoch: 1780, Train Loss: 0.3952770531177521, Valid Loss: 0.6073182821273804\n",
      "Epoch: 1781, Train Loss: 0.3952654302120209, Valid Loss: 0.6106716990470886\n",
      "Epoch: 1782, Train Loss: 0.39525362849235535, Valid Loss: 0.6072257161140442\n",
      "Epoch: 1783, Train Loss: 0.3952423334121704, Valid Loss: 0.610869824886322\n",
      "Epoch: 1784, Train Loss: 0.39523106813430786, Valid Loss: 0.606989324092865\n",
      "Epoch: 1785, Train Loss: 0.39522024989128113, Valid Loss: 0.61124587059021\n",
      "Epoch: 1786, Train Loss: 0.39521005749702454, Valid Loss: 0.6065582036972046\n",
      "Epoch: 1787, Train Loss: 0.39520063996315, Valid Loss: 0.6118626594543457\n",
      "Epoch: 1788, Train Loss: 0.3951915502548218, Valid Loss: 0.6058438420295715\n",
      "Epoch: 1789, Train Loss: 0.3951842784881592, Valid Loss: 0.6128023266792297\n",
      "Epoch: 1790, Train Loss: 0.395177960395813, Valid Loss: 0.6047456860542297\n",
      "Epoch: 1791, Train Loss: 0.3951754868030548, Valid Loss: 0.6141419410705566\n",
      "Epoch: 1792, Train Loss: 0.3951735198497772, Valid Loss: 0.6032123565673828\n",
      "Epoch: 1793, Train Loss: 0.3951772451400757, Valid Loss: 0.6158571243286133\n",
      "Epoch: 1794, Train Loss: 0.39517900347709656, Valid Loss: 0.6014220714569092\n",
      "Epoch: 1795, Train Loss: 0.39518624544143677, Valid Loss: 0.6175389289855957\n",
      "Epoch: 1796, Train Loss: 0.3951813578605652, Valid Loss: 0.6001458168029785\n",
      "Epoch: 1797, Train Loss: 0.39517536759376526, Valid Loss: 0.6181119680404663\n",
      "Epoch: 1798, Train Loss: 0.3951461911201477, Valid Loss: 0.6008285284042358\n",
      "Epoch: 1799, Train Loss: 0.39511239528656006, Valid Loss: 0.6162462830543518\n",
      "Epoch: 1800, Train Loss: 0.39507031440734863, Valid Loss: 0.6042426824569702\n",
      "Epoch: 1801, Train Loss: 0.3950367271900177, Valid Loss: 0.6120136976242065\n",
      "Epoch: 1802, Train Loss: 0.3950165808200836, Valid Loss: 0.6090261340141296\n",
      "Epoch: 1803, Train Loss: 0.39500972628593445, Valid Loss: 0.6073117256164551\n",
      "Epoch: 1804, Train Loss: 0.39501044154167175, Valid Loss: 0.6129656434059143\n",
      "Epoch: 1805, Train Loss: 0.3950119614601135, Valid Loss: 0.6041815876960754\n",
      "Epoch: 1806, Train Loss: 0.39500901103019714, Valid Loss: 0.6147419810295105\n",
      "Epoch: 1807, Train Loss: 0.39499521255493164, Valid Loss: 0.6036984920501709\n",
      "Epoch: 1808, Train Loss: 0.394975870847702, Valid Loss: 0.614005982875824\n",
      "Epoch: 1809, Train Loss: 0.39495179057121277, Valid Loss: 0.6057388186454773\n",
      "Epoch: 1810, Train Loss: 0.39493024349212646, Valid Loss: 0.6113914847373962\n",
      "Epoch: 1811, Train Loss: 0.39491403102874756, Valid Loss: 0.6089580655097961\n",
      "Epoch: 1812, Train Loss: 0.3949039876461029, Valid Loss: 0.6083379983901978\n",
      "Epoch: 1813, Train Loss: 0.3948977291584015, Valid Loss: 0.6117364764213562\n",
      "Epoch: 1814, Train Loss: 0.3948921263217926, Valid Loss: 0.606220006942749\n",
      "Epoch: 1815, Train Loss: 0.39488479495048523, Valid Loss: 0.6130560040473938\n",
      "Epoch: 1816, Train Loss: 0.39487341046333313, Valid Loss: 0.6057358384132385\n",
      "Epoch: 1817, Train Loss: 0.3948594033718109, Valid Loss: 0.6127193570137024\n",
      "Epoch: 1818, Train Loss: 0.3948434591293335, Valid Loss: 0.6067531704902649\n",
      "Epoch: 1819, Train Loss: 0.3948276937007904, Valid Loss: 0.6112234592437744\n",
      "Epoch: 1820, Train Loss: 0.3948134779930115, Valid Loss: 0.6085689663887024\n",
      "Epoch: 1821, Train Loss: 0.39480122923851013, Valid Loss: 0.6093814969062805\n",
      "Epoch: 1822, Train Loss: 0.39479124546051025, Valid Loss: 0.6103677153587341\n",
      "Epoch: 1823, Train Loss: 0.39478209614753723, Valid Loss: 0.6079025864601135\n",
      "Epoch: 1824, Train Loss: 0.3947727382183075, Valid Loss: 0.6115926504135132\n",
      "Epoch: 1825, Train Loss: 0.3947635293006897, Valid Loss: 0.6071557998657227\n",
      "Epoch: 1826, Train Loss: 0.394753098487854, Valid Loss: 0.6120209097862244\n",
      "Epoch: 1827, Train Loss: 0.39474156498908997, Valid Loss: 0.6071828603744507\n",
      "Epoch: 1828, Train Loss: 0.39472922682762146, Valid Loss: 0.6117393970489502\n",
      "Epoch: 1829, Train Loss: 0.3947167992591858, Valid Loss: 0.6077720522880554\n",
      "Epoch: 1830, Train Loss: 0.3947039544582367, Valid Loss: 0.6110094785690308\n",
      "Epoch: 1831, Train Loss: 0.3946918547153473, Valid Loss: 0.6086534261703491\n",
      "Epoch: 1832, Train Loss: 0.3946799337863922, Valid Loss: 0.6101216077804565\n",
      "Epoch: 1833, Train Loss: 0.39466866850852966, Valid Loss: 0.6095472574234009\n",
      "Epoch: 1834, Train Loss: 0.39465782046318054, Valid Loss: 0.6093217730522156\n",
      "Epoch: 1835, Train Loss: 0.3946472704410553, Valid Loss: 0.6102995872497559\n",
      "Epoch: 1836, Train Loss: 0.39463692903518677, Valid Loss: 0.6087090373039246\n",
      "Epoch: 1837, Train Loss: 0.39462655782699585, Valid Loss: 0.6108503937721252\n",
      "Epoch: 1838, Train Loss: 0.3946162760257721, Valid Loss: 0.6083133220672607\n",
      "Epoch: 1839, Train Loss: 0.3946060836315155, Valid Loss: 0.6112294793128967\n",
      "Epoch: 1840, Train Loss: 0.39459553360939026, Valid Loss: 0.6080783605575562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1841, Train Loss: 0.3945849537849426, Valid Loss: 0.6114818453788757\n",
      "Epoch: 1842, Train Loss: 0.39457452297210693, Valid Loss: 0.6079394817352295\n",
      "Epoch: 1843, Train Loss: 0.3945639431476593, Valid Loss: 0.6116544008255005\n",
      "Epoch: 1844, Train Loss: 0.3945533335208893, Valid Loss: 0.6078148484230042\n",
      "Epoch: 1845, Train Loss: 0.3945431411266327, Valid Loss: 0.6118261218070984\n",
      "Epoch: 1846, Train Loss: 0.39453285932540894, Valid Loss: 0.6076536774635315\n",
      "Epoch: 1847, Train Loss: 0.3945227563381195, Valid Loss: 0.6120629906654358\n",
      "Epoch: 1848, Train Loss: 0.39451277256011963, Valid Loss: 0.6073981523513794\n",
      "Epoch: 1849, Train Loss: 0.39450332522392273, Valid Loss: 0.612418532371521\n",
      "Epoch: 1850, Train Loss: 0.39449387788772583, Valid Loss: 0.6070001721382141\n",
      "Epoch: 1851, Train Loss: 0.3944852948188782, Valid Loss: 0.6129569411277771\n",
      "Epoch: 1852, Train Loss: 0.39447706937789917, Valid Loss: 0.6063984632492065\n",
      "Epoch: 1853, Train Loss: 0.3944702446460724, Valid Loss: 0.6137340664863586\n",
      "Epoch: 1854, Train Loss: 0.39446374773979187, Valid Loss: 0.6055306792259216\n",
      "Epoch: 1855, Train Loss: 0.3944593369960785, Valid Loss: 0.6147851943969727\n",
      "Epoch: 1856, Train Loss: 0.3944557309150696, Valid Loss: 0.6043737530708313\n",
      "Epoch: 1857, Train Loss: 0.3944551348686218, Valid Loss: 0.6160790920257568\n",
      "Epoch: 1858, Train Loss: 0.39445292949676514, Valid Loss: 0.6030727624893188\n",
      "Epoch: 1859, Train Loss: 0.39445430040359497, Valid Loss: 0.617340624332428\n",
      "Epoch: 1860, Train Loss: 0.3944488763809204, Valid Loss: 0.6020700931549072\n",
      "Epoch: 1861, Train Loss: 0.39444419741630554, Valid Loss: 0.6179618835449219\n",
      "Epoch: 1862, Train Loss: 0.3944269120693207, Valid Loss: 0.6021657586097717\n",
      "Epoch: 1863, Train Loss: 0.39440739154815674, Valid Loss: 0.617138683795929\n",
      "Epoch: 1864, Train Loss: 0.3943782150745392, Valid Loss: 0.6040241122245789\n",
      "Epoch: 1865, Train Loss: 0.3943503201007843, Valid Loss: 0.6145703196525574\n",
      "Epoch: 1866, Train Loss: 0.39432492852211, Valid Loss: 0.6072918176651001\n",
      "Epoch: 1867, Train Loss: 0.3943067789077759, Valid Loss: 0.6110472083091736\n",
      "Epoch: 1868, Train Loss: 0.3942958116531372, Valid Loss: 0.6107536554336548\n",
      "Epoch: 1869, Train Loss: 0.39429032802581787, Valid Loss: 0.6078310608863831\n",
      "Epoch: 1870, Train Loss: 0.394287645816803, Valid Loss: 0.6133738160133362\n",
      "Epoch: 1871, Train Loss: 0.394284188747406, Valid Loss: 0.6057976484298706\n",
      "Epoch: 1872, Train Loss: 0.3942791819572449, Valid Loss: 0.6146923899650574\n",
      "Epoch: 1873, Train Loss: 0.3942692279815674, Valid Loss: 0.6052815914154053\n",
      "Epoch: 1874, Train Loss: 0.3942568600177765, Valid Loss: 0.6146000027656555\n",
      "Epoch: 1875, Train Loss: 0.39424073696136475, Valid Loss: 0.6061913967132568\n",
      "Epoch: 1876, Train Loss: 0.39422407746315, Valid Loss: 0.6133092641830444\n",
      "Epoch: 1877, Train Loss: 0.3942078649997711, Valid Loss: 0.6080341935157776\n",
      "Epoch: 1878, Train Loss: 0.3941938281059265, Valid Loss: 0.6113671660423279\n",
      "Epoch: 1879, Train Loss: 0.39418208599090576, Valid Loss: 0.6100822687149048\n",
      "Epoch: 1880, Train Loss: 0.3941725194454193, Valid Loss: 0.6094411015510559\n",
      "Epoch: 1881, Train Loss: 0.39416420459747314, Valid Loss: 0.6117495894432068\n",
      "Epoch: 1882, Train Loss: 0.39415669441223145, Valid Loss: 0.6080251932144165\n",
      "Epoch: 1883, Train Loss: 0.39414915442466736, Valid Loss: 0.6127945184707642\n",
      "Epoch: 1884, Train Loss: 0.39414069056510925, Valid Loss: 0.6072863936424255\n",
      "Epoch: 1885, Train Loss: 0.39413154125213623, Valid Loss: 0.6132329702377319\n",
      "Epoch: 1886, Train Loss: 0.39412108063697815, Valid Loss: 0.607196033000946\n",
      "Epoch: 1887, Train Loss: 0.3941105008125305, Valid Loss: 0.6131540536880493\n",
      "Epoch: 1888, Train Loss: 0.39409878849983215, Valid Loss: 0.6076177954673767\n",
      "Epoch: 1889, Train Loss: 0.3940871059894562, Valid Loss: 0.6126929521560669\n",
      "Epoch: 1890, Train Loss: 0.39407530426979065, Valid Loss: 0.6083230376243591\n",
      "Epoch: 1891, Train Loss: 0.3940637409687042, Valid Loss: 0.6120090484619141\n",
      "Epoch: 1892, Train Loss: 0.3940524160861969, Valid Loss: 0.6091064214706421\n",
      "Epoch: 1893, Train Loss: 0.394041508436203, Valid Loss: 0.6112697720527649\n",
      "Epoch: 1894, Train Loss: 0.3940310776233673, Valid Loss: 0.6098197102546692\n",
      "Epoch: 1895, Train Loss: 0.394020676612854, Valid Loss: 0.610605776309967\n",
      "Epoch: 1896, Train Loss: 0.39401066303253174, Valid Loss: 0.61041659116745\n",
      "Epoch: 1897, Train Loss: 0.3940007984638214, Valid Loss: 0.6100751757621765\n",
      "Epoch: 1898, Train Loss: 0.3939911127090454, Valid Loss: 0.6109129190444946\n",
      "Epoch: 1899, Train Loss: 0.3939817547798157, Valid Loss: 0.6096591949462891\n",
      "Epoch: 1900, Train Loss: 0.39397186040878296, Valid Loss: 0.6113556027412415\n",
      "Epoch: 1901, Train Loss: 0.3939625024795532, Valid Loss: 0.6093186140060425\n",
      "Epoch: 1902, Train Loss: 0.3939531445503235, Valid Loss: 0.611781656742096\n",
      "Epoch: 1903, Train Loss: 0.39394399523735046, Valid Loss: 0.6089613437652588\n",
      "Epoch: 1904, Train Loss: 0.3939349353313446, Valid Loss: 0.6122555732727051\n",
      "Epoch: 1905, Train Loss: 0.39392635226249695, Valid Loss: 0.6084937453269958\n",
      "Epoch: 1906, Train Loss: 0.3939180374145508, Valid Loss: 0.6128587126731873\n",
      "Epoch: 1907, Train Loss: 0.3939101994037628, Valid Loss: 0.607818067073822\n",
      "Epoch: 1908, Train Loss: 0.3939034640789032, Valid Loss: 0.6136942505836487\n",
      "Epoch: 1909, Train Loss: 0.39389780163764954, Valid Loss: 0.6068251132965088\n",
      "Epoch: 1910, Train Loss: 0.39389440417289734, Valid Loss: 0.6149085760116577\n",
      "Epoch: 1911, Train Loss: 0.39389240741729736, Valid Loss: 0.6053699851036072\n",
      "Epoch: 1912, Train Loss: 0.39389514923095703, Valid Loss: 0.616631031036377\n",
      "Epoch: 1913, Train Loss: 0.3938991129398346, Valid Loss: 0.6034153699874878\n",
      "Epoch: 1914, Train Loss: 0.393910676240921, Valid Loss: 0.6187757253646851\n",
      "Epoch: 1915, Train Loss: 0.3939180076122284, Valid Loss: 0.6012741923332214\n",
      "Epoch: 1916, Train Loss: 0.39393094182014465, Valid Loss: 0.6206743121147156\n",
      "Epoch: 1917, Train Loss: 0.3939230442047119, Valid Loss: 0.6001726388931274\n",
      "Epoch: 1918, Train Loss: 0.39391013979911804, Valid Loss: 0.6206842660903931\n",
      "Epoch: 1919, Train Loss: 0.3938687741756439, Valid Loss: 0.6019859313964844\n",
      "Epoch: 1920, Train Loss: 0.3938252031803131, Valid Loss: 0.6173384189605713\n",
      "Epoch: 1921, Train Loss: 0.3937830924987793, Valid Loss: 0.6069473624229431\n",
      "Epoch: 1922, Train Loss: 0.3937581777572632, Valid Loss: 0.611659049987793\n",
      "Epoch: 1923, Train Loss: 0.3937515914440155, Valid Loss: 0.6125923991203308\n",
      "Epoch: 1924, Train Loss: 0.39375707507133484, Valid Loss: 0.6064968705177307\n",
      "Epoch: 1925, Train Loss: 0.39376530051231384, Valid Loss: 0.6163473725318909\n",
      "Epoch: 1926, Train Loss: 0.3937648832798004, Valid Loss: 0.604086697101593\n",
      "Epoch: 1927, Train Loss: 0.39375531673431396, Valid Loss: 0.6169983148574829\n",
      "Epoch: 1928, Train Loss: 0.3937325179576874, Valid Loss: 0.6052212119102478\n",
      "Epoch: 1929, Train Loss: 0.3937074840068817, Valid Loss: 0.6146335601806641\n",
      "Epoch: 1930, Train Loss: 0.39368554949760437, Valid Loss: 0.6088584661483765\n",
      "Epoch: 1931, Train Loss: 0.3936719298362732, Valid Loss: 0.6107876300811768\n",
      "Epoch: 1932, Train Loss: 0.39366647601127625, Valid Loss: 0.6127228140830994\n",
      "Epoch: 1933, Train Loss: 0.39366480708122253, Valid Loss: 0.6075922846794128\n",
      "Epoch: 1934, Train Loss: 0.39366230368614197, Valid Loss: 0.6149631142616272\n",
      "Epoch: 1935, Train Loss: 0.3936549723148346, Valid Loss: 0.6064824461936951\n",
      "Epoch: 1936, Train Loss: 0.3936430811882019, Valid Loss: 0.6148889064788818\n",
      "Epoch: 1937, Train Loss: 0.39362722635269165, Valid Loss: 0.6075947284698486\n",
      "Epoch: 1938, Train Loss: 0.39361143112182617, Valid Loss: 0.6129977703094482\n",
      "Epoch: 1939, Train Loss: 0.39359787106513977, Valid Loss: 0.6099379658699036\n",
      "Epoch: 1940, Train Loss: 0.3935878574848175, Valid Loss: 0.6105307936668396\n",
      "Epoch: 1941, Train Loss: 0.3935805857181549, Valid Loss: 0.6122528314590454\n",
      "Epoch: 1942, Train Loss: 0.39357441663742065, Valid Loss: 0.6086807250976562\n",
      "Epoch: 1943, Train Loss: 0.39356791973114014, Valid Loss: 0.6136382818222046\n",
      "Epoch: 1944, Train Loss: 0.39355966448783875, Valid Loss: 0.6080559492111206\n",
      "Epoch: 1945, Train Loss: 0.39354977011680603, Valid Loss: 0.613760232925415\n",
      "Epoch: 1946, Train Loss: 0.3935382664203644, Valid Loss: 0.6085996031761169\n",
      "Epoch: 1947, Train Loss: 0.39352652430534363, Valid Loss: 0.6128566265106201\n",
      "Epoch: 1948, Train Loss: 0.3935151994228363, Valid Loss: 0.6098427176475525\n",
      "Epoch: 1949, Train Loss: 0.3935047686100006, Valid Loss: 0.6114997863769531\n",
      "Epoch: 1950, Train Loss: 0.3934954106807709, Valid Loss: 0.6112164258956909\n",
      "Epoch: 1951, Train Loss: 0.393486887216568, Valid Loss: 0.6102436184883118\n",
      "Epoch: 1952, Train Loss: 0.393478661775589, Valid Loss: 0.6122785806655884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1953, Train Loss: 0.39347100257873535, Valid Loss: 0.6094512343406677\n",
      "Epoch: 1954, Train Loss: 0.39346227049827576, Valid Loss: 0.612847626209259\n",
      "Epoch: 1955, Train Loss: 0.39345329999923706, Valid Loss: 0.6091808080673218\n",
      "Epoch: 1956, Train Loss: 0.393444299697876, Valid Loss: 0.612949550151825\n",
      "Epoch: 1957, Train Loss: 0.39343467354774475, Valid Loss: 0.6093582510948181\n",
      "Epoch: 1958, Train Loss: 0.39342501759529114, Valid Loss: 0.6126841306686401\n",
      "Epoch: 1959, Train Loss: 0.39341530203819275, Valid Loss: 0.6098310947418213\n",
      "Epoch: 1960, Train Loss: 0.3934055268764496, Valid Loss: 0.6122161149978638\n",
      "Epoch: 1961, Train Loss: 0.3933960199356079, Valid Loss: 0.6104070544242859\n",
      "Epoch: 1962, Train Loss: 0.39338672161102295, Valid Loss: 0.6116949319839478\n",
      "Epoch: 1963, Train Loss: 0.3933775722980499, Valid Loss: 0.6109431982040405\n",
      "Epoch: 1964, Train Loss: 0.3933682441711426, Valid Loss: 0.611203134059906\n",
      "Epoch: 1965, Train Loss: 0.39335930347442627, Valid Loss: 0.6114081740379333\n",
      "Epoch: 1966, Train Loss: 0.39335060119628906, Valid Loss: 0.610801637172699\n",
      "Epoch: 1967, Train Loss: 0.39334166049957275, Valid Loss: 0.6117960810661316\n",
      "Epoch: 1968, Train Loss: 0.39333322644233704, Valid Loss: 0.6105015873908997\n",
      "Epoch: 1969, Train Loss: 0.39332443475723267, Valid Loss: 0.6121281981468201\n",
      "Epoch: 1970, Train Loss: 0.39331549406051636, Valid Loss: 0.6102551221847534\n",
      "Epoch: 1971, Train Loss: 0.39330726861953735, Valid Loss: 0.6124300360679626\n",
      "Epoch: 1972, Train Loss: 0.3932987451553345, Valid Loss: 0.610011100769043\n",
      "Epoch: 1973, Train Loss: 0.3932904005050659, Valid Loss: 0.6127521991729736\n",
      "Epoch: 1974, Train Loss: 0.3932822644710541, Valid Loss: 0.6097155213356018\n",
      "Epoch: 1975, Train Loss: 0.39327389001846313, Valid Loss: 0.6131430864334106\n",
      "Epoch: 1976, Train Loss: 0.3932660222053528, Valid Loss: 0.6093010902404785\n",
      "Epoch: 1977, Train Loss: 0.39325857162475586, Valid Loss: 0.6136813163757324\n",
      "Epoch: 1978, Train Loss: 0.3932516574859619, Valid Loss: 0.6086680293083191\n",
      "Epoch: 1979, Train Loss: 0.393245667219162, Valid Loss: 0.6144947409629822\n",
      "Epoch: 1980, Train Loss: 0.3932405114173889, Valid Loss: 0.6077154874801636\n",
      "Epoch: 1981, Train Loss: 0.39323756098747253, Valid Loss: 0.6156862378120422\n",
      "Epoch: 1982, Train Loss: 0.3932359218597412, Valid Loss: 0.6063095331192017\n",
      "Epoch: 1983, Train Loss: 0.39323851466178894, Valid Loss: 0.6173862814903259\n",
      "Epoch: 1984, Train Loss: 0.39324286580085754, Valid Loss: 0.6043747067451477\n",
      "Epoch: 1985, Train Loss: 0.39325445890426636, Valid Loss: 0.6195593476295471\n",
      "Epoch: 1986, Train Loss: 0.3932628333568573, Valid Loss: 0.6021528244018555\n",
      "Epoch: 1987, Train Loss: 0.3932776153087616, Valid Loss: 0.6216371655464172\n",
      "Epoch: 1988, Train Loss: 0.3932751715183258, Valid Loss: 0.6007173657417297\n",
      "Epoch: 1989, Train Loss: 0.39326947927474976, Valid Loss: 0.6220988631248474\n",
      "Epoch: 1990, Train Loss: 0.3932346999645233, Valid Loss: 0.6019198894500732\n",
      "Epoch: 1991, Train Loss: 0.39319488406181335, Valid Loss: 0.6193161606788635\n",
      "Epoch: 1992, Train Loss: 0.3931499421596527, Valid Loss: 0.6064656972885132\n",
      "Epoch: 1993, Train Loss: 0.3931189477443695, Valid Loss: 0.6137998104095459\n",
      "Epoch: 1994, Train Loss: 0.3931058645248413, Valid Loss: 0.6123008131980896\n",
      "Epoch: 1995, Train Loss: 0.39310765266418457, Valid Loss: 0.6082282662391663\n",
      "Epoch: 1996, Train Loss: 0.3931170105934143, Valid Loss: 0.6166905164718628\n",
      "Epoch: 1997, Train Loss: 0.39312171936035156, Valid Loss: 0.6050382852554321\n",
      "Epoch: 1998, Train Loss: 0.3931190073490143, Valid Loss: 0.6181666851043701\n",
      "Epoch: 1999, Train Loss: 0.39310207962989807, Valid Loss: 0.6053155660629272\n",
      "Epoch: 2000, Train Loss: 0.39307984709739685, Valid Loss: 0.6165022850036621\n",
      "Epoch: 2001, Train Loss: 0.3930559456348419, Valid Loss: 0.6084789037704468\n",
      "Epoch: 2002, Train Loss: 0.3930385410785675, Valid Loss: 0.6128329634666443\n",
      "Epoch: 2003, Train Loss: 0.3930295407772064, Valid Loss: 0.6125133633613586\n",
      "Epoch: 2004, Train Loss: 0.39302676916122437, Valid Loss: 0.6092178225517273\n",
      "Epoch: 2005, Train Loss: 0.39302608370780945, Valid Loss: 0.6153738498687744\n",
      "Epoch: 2006, Train Loss: 0.39302271604537964, Valid Loss: 0.607344388961792\n",
      "Epoch: 2007, Train Loss: 0.3930153548717499, Valid Loss: 0.6160652041435242\n",
      "Epoch: 2008, Train Loss: 0.3930025100708008, Valid Loss: 0.6077473163604736\n",
      "Epoch: 2009, Train Loss: 0.39298802614212036, Valid Loss: 0.6147241592407227\n",
      "Epoch: 2010, Train Loss: 0.3929738998413086, Valid Loss: 0.6097717881202698\n",
      "Epoch: 2011, Train Loss: 0.39296209812164307, Valid Loss: 0.6123653054237366\n",
      "Epoch: 2012, Train Loss: 0.3929535746574402, Valid Loss: 0.6122223138809204\n",
      "Epoch: 2013, Train Loss: 0.3929472863674164, Valid Loss: 0.6101983785629272\n",
      "Epoch: 2014, Train Loss: 0.3929421603679657, Valid Loss: 0.6140614151954651\n",
      "Epoch: 2015, Train Loss: 0.39293622970581055, Valid Loss: 0.6090190410614014\n",
      "Epoch: 2016, Train Loss: 0.3929290175437927, Valid Loss: 0.614754855632782\n",
      "Epoch: 2017, Train Loss: 0.3929198086261749, Valid Loss: 0.6090171933174133\n",
      "Epoch: 2018, Train Loss: 0.3929097056388855, Valid Loss: 0.6143125295639038\n",
      "Epoch: 2019, Train Loss: 0.3928990364074707, Valid Loss: 0.6099249720573425\n",
      "Epoch: 2020, Train Loss: 0.39288872480392456, Valid Loss: 0.6131352186203003\n",
      "Epoch: 2021, Train Loss: 0.39287903904914856, Valid Loss: 0.6112573146820068\n",
      "Epoch: 2022, Train Loss: 0.3928704857826233, Valid Loss: 0.6117911338806152\n",
      "Epoch: 2023, Train Loss: 0.39286258816719055, Valid Loss: 0.6125180125236511\n",
      "Epoch: 2024, Train Loss: 0.39285531640052795, Valid Loss: 0.6107378602027893\n",
      "Epoch: 2025, Train Loss: 0.3928481936454773, Valid Loss: 0.6134002804756165\n",
      "Epoch: 2026, Train Loss: 0.39284077286720276, Valid Loss: 0.6101524829864502\n",
      "Epoch: 2027, Train Loss: 0.3928332030773163, Valid Loss: 0.6138232350349426\n",
      "Epoch: 2028, Train Loss: 0.392825186252594, Valid Loss: 0.6100290417671204\n",
      "Epoch: 2029, Train Loss: 0.3928167223930359, Valid Loss: 0.6138270497322083\n",
      "Epoch: 2030, Train Loss: 0.3928079903125763, Valid Loss: 0.6102540493011475\n",
      "Epoch: 2031, Train Loss: 0.39279940724372864, Valid Loss: 0.6135480999946594\n",
      "Epoch: 2032, Train Loss: 0.39279061555862427, Valid Loss: 0.6106888055801392\n",
      "Epoch: 2033, Train Loss: 0.3927818834781647, Valid Loss: 0.6131115555763245\n",
      "Epoch: 2034, Train Loss: 0.39277365803718567, Valid Loss: 0.6111921668052673\n",
      "Epoch: 2035, Train Loss: 0.39276495575904846, Valid Loss: 0.612636387348175\n",
      "Epoch: 2036, Train Loss: 0.3927568197250366, Valid Loss: 0.6116722226142883\n",
      "Epoch: 2037, Train Loss: 0.39274856448173523, Valid Loss: 0.612211287021637\n",
      "Epoch: 2038, Train Loss: 0.39274051785469055, Valid Loss: 0.6120836734771729\n",
      "Epoch: 2039, Train Loss: 0.3927328586578369, Valid Loss: 0.6118760108947754\n",
      "Epoch: 2040, Train Loss: 0.3927247226238251, Valid Loss: 0.6124458909034729\n",
      "Epoch: 2041, Train Loss: 0.39271676540374756, Valid Loss: 0.6116178035736084\n",
      "Epoch: 2042, Train Loss: 0.39270877838134766, Valid Loss: 0.6127526760101318\n",
      "Epoch: 2043, Train Loss: 0.39270102977752686, Valid Loss: 0.6113976836204529\n",
      "Epoch: 2044, Train Loss: 0.3926932215690613, Valid Loss: 0.6130290031433105\n",
      "Epoch: 2045, Train Loss: 0.3926854431629181, Valid Loss: 0.6111549139022827\n",
      "Epoch: 2046, Train Loss: 0.392677903175354, Valid Loss: 0.6133437156677246\n",
      "Epoch: 2047, Train Loss: 0.39267048239707947, Valid Loss: 0.6108397841453552\n",
      "Epoch: 2048, Train Loss: 0.3926631212234497, Valid Loss: 0.6137524247169495\n",
      "Epoch: 2049, Train Loss: 0.3926560878753662, Valid Loss: 0.6103904247283936\n",
      "Epoch: 2050, Train Loss: 0.3926495909690857, Valid Loss: 0.6143450140953064\n",
      "Epoch: 2051, Train Loss: 0.39264318346977234, Valid Loss: 0.6097021102905273\n",
      "Epoch: 2052, Train Loss: 0.39263859391212463, Valid Loss: 0.6152433753013611\n",
      "Epoch: 2053, Train Loss: 0.3926343023777008, Valid Loss: 0.6086417436599731\n",
      "Epoch: 2054, Train Loss: 0.3926328122615814, Valid Loss: 0.6166031956672668\n",
      "Epoch: 2055, Train Loss: 0.3926331698894501, Valid Loss: 0.6070209741592407\n",
      "Epoch: 2056, Train Loss: 0.39263880252838135, Valid Loss: 0.6186047792434692\n",
      "Epoch: 2057, Train Loss: 0.39264729619026184, Valid Loss: 0.6046714782714844\n",
      "Epoch: 2058, Train Loss: 0.3926653563976288, Valid Loss: 0.6213036179542542\n",
      "Epoch: 2059, Train Loss: 0.39268168807029724, Valid Loss: 0.6018233299255371\n",
      "Epoch: 2060, Train Loss: 0.3927072584629059, Valid Loss: 0.6240251064300537\n",
      "Epoch: 2061, Train Loss: 0.3927097022533417, Valid Loss: 0.5998662710189819\n",
      "Epoch: 2062, Train Loss: 0.3927063047885895, Valid Loss: 0.6246872544288635\n",
      "Epoch: 2063, Train Loss: 0.3926607370376587, Valid Loss: 0.601444661617279\n",
      "Epoch: 2064, Train Loss: 0.3926084637641907, Valid Loss: 0.6209344267845154\n",
      "Epoch: 2065, Train Loss: 0.39255291223526, Valid Loss: 0.6075000762939453\n",
      "Epoch: 2066, Train Loss: 0.3925219178199768, Valid Loss: 0.6136980652809143\n",
      "Epoch: 2067, Train Loss: 0.392518550157547, Valid Loss: 0.6148384809494019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2068, Train Loss: 0.3925330638885498, Valid Loss: 0.607019305229187\n",
      "Epoch: 2069, Train Loss: 0.3925504684448242, Valid Loss: 0.6195661425590515\n",
      "Epoch: 2070, Train Loss: 0.3925522267818451, Valid Loss: 0.6042667627334595\n",
      "Epoch: 2071, Train Loss: 0.392538845539093, Valid Loss: 0.619815468788147\n",
      "Epoch: 2072, Train Loss: 0.3925086557865143, Valid Loss: 0.6065073013305664\n",
      "Epoch: 2073, Train Loss: 0.3924793601036072, Valid Loss: 0.6159723401069641\n",
      "Epoch: 2074, Train Loss: 0.3924601376056671, Valid Loss: 0.6117578744888306\n",
      "Epoch: 2075, Train Loss: 0.3924553096294403, Valid Loss: 0.61077481508255\n",
      "Epoch: 2076, Train Loss: 0.3924591839313507, Valid Loss: 0.6163997054100037\n",
      "Epoch: 2077, Train Loss: 0.39246222376823425, Valid Loss: 0.6074385643005371\n",
      "Epoch: 2078, Train Loss: 0.3924587368965149, Valid Loss: 0.6179782152175903\n",
      "Epoch: 2079, Train Loss: 0.39244505763053894, Valid Loss: 0.6076465845108032\n",
      "Epoch: 2080, Train Loss: 0.3924272656440735, Valid Loss: 0.6161781549453735\n",
      "Epoch: 2081, Train Loss: 0.3924102783203125, Valid Loss: 0.6106457114219666\n",
      "Epoch: 2082, Train Loss: 0.3923993408679962, Valid Loss: 0.6126569509506226\n",
      "Epoch: 2083, Train Loss: 0.3923940658569336, Valid Loss: 0.6141110062599182\n",
      "Epoch: 2084, Train Loss: 0.39239203929901123, Valid Loss: 0.609714150428772\n",
      "Epoch: 2085, Train Loss: 0.3923893868923187, Valid Loss: 0.6161273717880249\n",
      "Epoch: 2086, Train Loss: 0.39238297939300537, Valid Loss: 0.6088314652442932\n",
      "Epoch: 2087, Train Loss: 0.3923732042312622, Valid Loss: 0.6160389184951782\n",
      "Epoch: 2088, Train Loss: 0.39236098527908325, Valid Loss: 0.6100769639015198\n",
      "Epoch: 2089, Train Loss: 0.3923492133617401, Valid Loss: 0.6142805218696594\n",
      "Epoch: 2090, Train Loss: 0.3923396170139313, Valid Loss: 0.6123388409614563\n",
      "Epoch: 2091, Train Loss: 0.3923324942588806, Valid Loss: 0.6120433211326599\n",
      "Epoch: 2092, Train Loss: 0.3923272490501404, Valid Loss: 0.6143086552619934\n",
      "Epoch: 2093, Train Loss: 0.3923220932483673, Valid Loss: 0.610486626625061\n",
      "Epoch: 2094, Train Loss: 0.3923160433769226, Valid Loss: 0.6152350306510925\n",
      "Epoch: 2095, Train Loss: 0.3923085629940033, Valid Loss: 0.6101942658424377\n",
      "Epoch: 2096, Train Loss: 0.3923000991344452, Valid Loss: 0.614976167678833\n",
      "Epoch: 2097, Train Loss: 0.3922906517982483, Valid Loss: 0.6110125780105591\n",
      "Epoch: 2098, Train Loss: 0.3922818899154663, Valid Loss: 0.6139167547225952\n",
      "Epoch: 2099, Train Loss: 0.3922733962535858, Valid Loss: 0.6123340725898743\n",
      "Epoch: 2100, Train Loss: 0.39226582646369934, Valid Loss: 0.6126692295074463\n",
      "Epoch: 2101, Train Loss: 0.39225897192955017, Valid Loss: 0.6135578751564026\n",
      "Epoch: 2102, Train Loss: 0.3922525644302368, Valid Loss: 0.6116983890533447\n",
      "Epoch: 2103, Train Loss: 0.3922457993030548, Valid Loss: 0.6143366098403931\n",
      "Epoch: 2104, Train Loss: 0.39223921298980713, Valid Loss: 0.6112427115440369\n",
      "Epoch: 2105, Train Loss: 0.3922320008277893, Valid Loss: 0.6145487427711487\n",
      "Epoch: 2106, Train Loss: 0.3922244608402252, Valid Loss: 0.6113302111625671\n",
      "Epoch: 2107, Train Loss: 0.3922167122364044, Valid Loss: 0.6142964959144592\n",
      "Epoch: 2108, Train Loss: 0.3922088146209717, Valid Loss: 0.611788272857666\n",
      "Epoch: 2109, Train Loss: 0.3922012150287628, Valid Loss: 0.6137663125991821\n",
      "Epoch: 2110, Train Loss: 0.3921934962272644, Valid Loss: 0.61241614818573\n",
      "Epoch: 2111, Train Loss: 0.3921859860420227, Valid Loss: 0.6131705641746521\n",
      "Epoch: 2112, Train Loss: 0.3921789824962616, Valid Loss: 0.6130344867706299\n",
      "Epoch: 2113, Train Loss: 0.39217159152030945, Valid Loss: 0.6126757860183716\n",
      "Epoch: 2114, Train Loss: 0.3921646475791931, Valid Loss: 0.6135344505310059\n",
      "Epoch: 2115, Train Loss: 0.39215776324272156, Valid Loss: 0.6123254895210266\n",
      "Epoch: 2116, Train Loss: 0.39215075969696045, Valid Loss: 0.6138815879821777\n",
      "Epoch: 2117, Train Loss: 0.3921438455581665, Valid Loss: 0.6120939254760742\n",
      "Epoch: 2118, Train Loss: 0.39213693141937256, Valid Loss: 0.6140921711921692\n",
      "Epoch: 2119, Train Loss: 0.39212992787361145, Valid Loss: 0.6119604706764221\n",
      "Epoch: 2120, Train Loss: 0.39212286472320557, Valid Loss: 0.6142212152481079\n",
      "Epoch: 2121, Train Loss: 0.3921160399913788, Valid Loss: 0.6118989586830139\n",
      "Epoch: 2122, Train Loss: 0.39210909605026245, Valid Loss: 0.6143175363540649\n",
      "Epoch: 2123, Train Loss: 0.39210188388824463, Valid Loss: 0.6118617057800293\n",
      "Epoch: 2124, Train Loss: 0.3920948803424835, Valid Loss: 0.6144173741340637\n",
      "Epoch: 2125, Train Loss: 0.3920881152153015, Valid Loss: 0.6118108630180359\n",
      "Epoch: 2126, Train Loss: 0.392081081867218, Valid Loss: 0.6145487427711487\n",
      "Epoch: 2127, Train Loss: 0.39207443594932556, Valid Loss: 0.6116942763328552\n",
      "Epoch: 2128, Train Loss: 0.39206767082214355, Valid Loss: 0.6147642731666565\n",
      "Epoch: 2129, Train Loss: 0.3920610845088959, Valid Loss: 0.6114704608917236\n",
      "Epoch: 2130, Train Loss: 0.3920547366142273, Valid Loss: 0.6151055693626404\n",
      "Epoch: 2131, Train Loss: 0.39204853773117065, Valid Loss: 0.6110923290252686\n",
      "Epoch: 2132, Train Loss: 0.3920429050922394, Valid Loss: 0.6156348586082458\n",
      "Epoch: 2133, Train Loss: 0.39203760027885437, Valid Loss: 0.6104767322540283\n",
      "Epoch: 2134, Train Loss: 0.3920333981513977, Valid Loss: 0.6164588928222656\n",
      "Epoch: 2135, Train Loss: 0.3920299708843231, Valid Loss: 0.6094972491264343\n",
      "Epoch: 2136, Train Loss: 0.3920285105705261, Valid Loss: 0.6177163124084473\n",
      "Epoch: 2137, Train Loss: 0.39202889800071716, Valid Loss: 0.6080133318901062\n",
      "Epoch: 2138, Train Loss: 0.39203357696533203, Valid Loss: 0.6195369958877563\n",
      "Epoch: 2139, Train Loss: 0.3920396864414215, Valid Loss: 0.6059243679046631\n",
      "Epoch: 2140, Train Loss: 0.3920537233352661, Valid Loss: 0.6219313144683838\n",
      "Epoch: 2141, Train Loss: 0.3920658230781555, Valid Loss: 0.6034325957298279\n",
      "Epoch: 2142, Train Loss: 0.39208564162254333, Valid Loss: 0.6243752241134644\n",
      "Epoch: 2143, Train Loss: 0.3920893669128418, Valid Loss: 0.6015573740005493\n",
      "Epoch: 2144, Train Loss: 0.39209115505218506, Valid Loss: 0.6253252625465393\n",
      "Epoch: 2145, Train Loss: 0.3920615017414093, Valid Loss: 0.6022989153862\n",
      "Epoch: 2146, Train Loss: 0.3920242190361023, Valid Loss: 0.6228264570236206\n",
      "Epoch: 2147, Train Loss: 0.3919753134250641, Valid Loss: 0.6068277955055237\n",
      "Epoch: 2148, Train Loss: 0.3919384777545929, Valid Loss: 0.6169613003730774\n",
      "Epoch: 2149, Train Loss: 0.39192068576812744, Valid Loss: 0.6133177280426025\n",
      "Epoch: 2150, Train Loss: 0.3919212222099304, Valid Loss: 0.6105557084083557\n",
      "Epoch: 2151, Train Loss: 0.39193278551101685, Valid Loss: 0.618611216545105\n",
      "Epoch: 2152, Train Loss: 0.3919430077075958, Valid Loss: 0.6065008044242859\n",
      "Epoch: 2153, Train Loss: 0.3919464647769928, Valid Loss: 0.6208168864250183\n",
      "Epoch: 2154, Train Loss: 0.39193394780158997, Valid Loss: 0.6062381267547607\n",
      "Epoch: 2155, Train Loss: 0.391913503408432, Valid Loss: 0.6194375157356262\n",
      "Epoch: 2156, Train Loss: 0.3918888568878174, Valid Loss: 0.6094375848770142\n",
      "Epoch: 2157, Train Loss: 0.3918699026107788, Valid Loss: 0.6154888272285461\n",
      "Epoch: 2158, Train Loss: 0.3918600082397461, Valid Loss: 0.6139770746231079\n",
      "Epoch: 2159, Train Loss: 0.39185839891433716, Valid Loss: 0.6112469434738159\n",
      "Epoch: 2160, Train Loss: 0.3918604552745819, Valid Loss: 0.6174375414848328\n",
      "Epoch: 2161, Train Loss: 0.39186033606529236, Valid Loss: 0.608807384967804\n",
      "Epoch: 2162, Train Loss: 0.39185622334480286, Valid Loss: 0.6185031533241272\n",
      "Epoch: 2163, Train Loss: 0.3918454945087433, Valid Loss: 0.6090073585510254\n",
      "Epoch: 2164, Train Loss: 0.39183226227760315, Valid Loss: 0.6171872615814209\n",
      "Epoch: 2165, Train Loss: 0.3918186128139496, Valid Loss: 0.6112341284751892\n",
      "Epoch: 2166, Train Loss: 0.3918076455593109, Valid Loss: 0.6145561337471008\n",
      "Epoch: 2167, Train Loss: 0.39180031418800354, Valid Loss: 0.6140576004981995\n",
      "Epoch: 2168, Train Loss: 0.39179590344429016, Valid Loss: 0.6120285987854004\n",
      "Epoch: 2169, Train Loss: 0.391792893409729, Valid Loss: 0.6161988377571106\n",
      "Epoch: 2170, Train Loss: 0.3917890191078186, Valid Loss: 0.6106153726577759\n",
      "Epoch: 2171, Train Loss: 0.39178380370140076, Valid Loss: 0.6170055866241455\n",
      "Epoch: 2172, Train Loss: 0.3917762041091919, Valid Loss: 0.610606849193573\n",
      "Epoch: 2173, Train Loss: 0.3917672634124756, Valid Loss: 0.6164616942405701\n",
      "Epoch: 2174, Train Loss: 0.39175790548324585, Valid Loss: 0.611702024936676\n",
      "Epoch: 2175, Train Loss: 0.3917490541934967, Valid Loss: 0.6150468587875366\n",
      "Epoch: 2176, Train Loss: 0.3917410969734192, Valid Loss: 0.6132739186286926\n",
      "Epoch: 2177, Train Loss: 0.3917345404624939, Valid Loss: 0.6134784817695618\n",
      "Epoch: 2178, Train Loss: 0.3917287588119507, Valid Loss: 0.6147163510322571\n",
      "Epoch: 2179, Train Loss: 0.3917233645915985, Valid Loss: 0.6123147010803223\n",
      "Epoch: 2180, Train Loss: 0.3917180001735687, Valid Loss: 0.6156558990478516\n",
      "Epoch: 2181, Train Loss: 0.39171236753463745, Valid Loss: 0.6117817163467407\n",
      "Epoch: 2182, Train Loss: 0.39170628786087036, Valid Loss: 0.615993082523346\n",
      "Epoch: 2183, Train Loss: 0.39169955253601074, Valid Loss: 0.6118292808532715\n",
      "Epoch: 2184, Train Loss: 0.39169251918792725, Valid Loss: 0.6157986521720886\n",
      "Epoch: 2185, Train Loss: 0.3916851878166199, Valid Loss: 0.6122707724571228\n",
      "Epoch: 2186, Train Loss: 0.3916778862476349, Valid Loss: 0.6152698397636414\n",
      "Epoch: 2187, Train Loss: 0.39167076349258423, Valid Loss: 0.6129066348075867\n",
      "Epoch: 2188, Train Loss: 0.39166387915611267, Valid Loss: 0.6146122813224792\n",
      "Epoch: 2189, Train Loss: 0.3916570842266083, Valid Loss: 0.6135907173156738\n",
      "Epoch: 2190, Train Loss: 0.39165061712265015, Valid Loss: 0.6140040755271912\n",
      "Epoch: 2191, Train Loss: 0.39164426922798157, Valid Loss: 0.6142006516456604\n",
      "Epoch: 2192, Train Loss: 0.3916378915309906, Valid Loss: 0.6135297417640686\n",
      "Epoch: 2193, Train Loss: 0.39163199067115784, Valid Loss: 0.6146699786186218\n",
      "Epoch: 2194, Train Loss: 0.39162564277648926, Valid Loss: 0.6131856441497803\n",
      "Epoch: 2195, Train Loss: 0.3916196823120117, Valid Loss: 0.6150215268135071\n",
      "Epoch: 2196, Train Loss: 0.39161357283592224, Valid Loss: 0.6129367351531982\n",
      "Epoch: 2197, Train Loss: 0.39160746335983276, Valid Loss: 0.6152942776679993\n",
      "Epoch: 2198, Train Loss: 0.3916012942790985, Valid Loss: 0.6127517819404602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2199, Train Loss: 0.39159536361694336, Valid Loss: 0.6155369281768799\n",
      "Epoch: 2200, Train Loss: 0.3915894329547882, Valid Loss: 0.6125588417053223\n",
      "Epoch: 2201, Train Loss: 0.3915834128856659, Valid Loss: 0.615790843963623\n",
      "Epoch: 2202, Train Loss: 0.3915775418281555, Valid Loss: 0.6123148798942566\n",
      "Epoch: 2203, Train Loss: 0.391571968793869, Valid Loss: 0.6161145567893982\n",
      "Epoch: 2204, Train Loss: 0.3915664255619049, Valid Loss: 0.6119722723960876\n",
      "Epoch: 2205, Train Loss: 0.39156123995780945, Valid Loss: 0.616585373878479\n",
      "Epoch: 2206, Train Loss: 0.39155638217926025, Valid Loss: 0.6114575862884521\n",
      "Epoch: 2207, Train Loss: 0.3915521204471588, Valid Loss: 0.6172857880592346\n",
      "Epoch: 2208, Train Loss: 0.3915485441684723, Valid Loss: 0.6106715202331543\n",
      "Epoch: 2209, Train Loss: 0.39154621958732605, Valid Loss: 0.6183095574378967\n",
      "Epoch: 2210, Train Loss: 0.3915449380874634, Valid Loss: 0.6095101237297058\n",
      "Epoch: 2211, Train Loss: 0.39154624938964844, Valid Loss: 0.6197470426559448\n",
      "Epoch: 2212, Train Loss: 0.39154893159866333, Valid Loss: 0.6078757047653198\n",
      "Epoch: 2213, Train Loss: 0.39155638217926025, Valid Loss: 0.6216621398925781\n",
      "Epoch: 2214, Train Loss: 0.3915640115737915, Valid Loss: 0.6058000326156616\n",
      "Epoch: 2215, Train Loss: 0.39157772064208984, Valid Loss: 0.623862087726593\n",
      "Epoch: 2216, Train Loss: 0.39158570766448975, Valid Loss: 0.6037757396697998\n",
      "Epoch: 2217, Train Loss: 0.3915965259075165, Valid Loss: 0.6255414485931396\n",
      "Epoch: 2218, Train Loss: 0.39158856868743896, Valid Loss: 0.6030102372169495\n",
      "Epoch: 2219, Train Loss: 0.3915759027004242, Valid Loss: 0.6252046227455139\n",
      "Epoch: 2220, Train Loss: 0.3915412127971649, Valid Loss: 0.6050077080726624\n",
      "Epoch: 2221, Train Loss: 0.3915053606033325, Valid Loss: 0.6217572093009949\n",
      "Epoch: 2222, Train Loss: 0.3914702236652374, Valid Loss: 0.6098077297210693\n",
      "Epoch: 2223, Train Loss: 0.39144790172576904, Valid Loss: 0.6161997318267822\n",
      "Epoch: 2224, Train Loss: 0.3914399743080139, Valid Loss: 0.6153852939605713\n",
      "Epoch: 2225, Train Loss: 0.3914431631565094, Valid Loss: 0.6109659075737\n",
      "Epoch: 2226, Train Loss: 0.39145132899284363, Valid Loss: 0.6195642948150635\n",
      "Epoch: 2227, Train Loss: 0.3914571702480316, Valid Loss: 0.6079211235046387\n",
      "Epoch: 2228, Train Loss: 0.3914574682712555, Valid Loss: 0.621253252029419\n",
      "Epoch: 2229, Train Loss: 0.391447514295578, Valid Loss: 0.6078053116798401\n",
      "Epoch: 2230, Train Loss: 0.3914322555065155, Valid Loss: 0.6202114224433899\n",
      "Epoch: 2231, Train Loss: 0.3914129137992859, Valid Loss: 0.6102725863456726\n",
      "Epoch: 2232, Train Loss: 0.39139652252197266, Valid Loss: 0.6171145439147949\n",
      "Epoch: 2233, Train Loss: 0.3913852870464325, Valid Loss: 0.6139161586761475\n",
      "Epoch: 2234, Train Loss: 0.3913800120353699, Valid Loss: 0.6135043501853943\n",
      "Epoch: 2235, Train Loss: 0.3913787305355072, Valid Loss: 0.6170855760574341\n",
      "Epoch: 2236, Train Loss: 0.3913784325122833, Valid Loss: 0.6109020113945007\n",
      "Epoch: 2237, Train Loss: 0.3913770616054535, Valid Loss: 0.6187742352485657\n",
      "Epoch: 2238, Train Loss: 0.39137259125709534, Valid Loss: 0.6100722551345825\n",
      "Epoch: 2239, Train Loss: 0.39136505126953125, Valid Loss: 0.618776261806488\n",
      "Epoch: 2240, Train Loss: 0.3913549780845642, Valid Loss: 0.6109308004379272\n",
      "Epoch: 2241, Train Loss: 0.39134451746940613, Valid Loss: 0.6174409985542297\n",
      "Epoch: 2242, Train Loss: 0.39133450388908386, Valid Loss: 0.612824559211731\n",
      "Epoch: 2243, Train Loss: 0.39132609963417053, Valid Loss: 0.6154741048812866\n",
      "Epoch: 2244, Train Loss: 0.3913196921348572, Valid Loss: 0.6149100065231323\n",
      "Epoch: 2245, Train Loss: 0.39131492376327515, Valid Loss: 0.6136143207550049\n",
      "Epoch: 2246, Train Loss: 0.3913109302520752, Valid Loss: 0.616538941860199\n",
      "Epoch: 2247, Train Loss: 0.3913068473339081, Valid Loss: 0.6123660206794739\n",
      "Epoch: 2248, Train Loss: 0.3913026452064514, Valid Loss: 0.6174117922782898\n",
      "Epoch: 2249, Train Loss: 0.3912973403930664, Valid Loss: 0.6118946671485901\n",
      "Epoch: 2250, Train Loss: 0.39129137992858887, Valid Loss: 0.6175318956375122\n",
      "Epoch: 2251, Train Loss: 0.39128467440605164, Valid Loss: 0.612127959728241\n",
      "Epoch: 2252, Train Loss: 0.39127734303474426, Valid Loss: 0.617091178894043\n",
      "Epoch: 2253, Train Loss: 0.39127033948898315, Valid Loss: 0.6128473877906799\n",
      "Epoch: 2254, Train Loss: 0.39126330614089966, Valid Loss: 0.6163350343704224\n",
      "Epoch: 2255, Train Loss: 0.3912566006183624, Valid Loss: 0.6137726306915283\n",
      "Epoch: 2256, Train Loss: 0.39125001430511475, Valid Loss: 0.6155019998550415\n",
      "Epoch: 2257, Train Loss: 0.39124399423599243, Valid Loss: 0.6146581172943115\n",
      "Epoch: 2258, Train Loss: 0.39123815298080444, Valid Loss: 0.6147339344024658\n",
      "Epoch: 2259, Train Loss: 0.39123260974884033, Valid Loss: 0.6153825521469116\n",
      "Epoch: 2260, Train Loss: 0.3912270665168762, Valid Loss: 0.6141284108161926\n",
      "Epoch: 2261, Train Loss: 0.3912217617034912, Valid Loss: 0.6159306168556213\n",
      "Epoch: 2262, Train Loss: 0.39121654629707336, Valid Loss: 0.613678514957428\n",
      "Epoch: 2263, Train Loss: 0.3912111520767212, Valid Loss: 0.6163511276245117\n",
      "Epoch: 2264, Train Loss: 0.391205757856369, Valid Loss: 0.6133643984794617\n",
      "Epoch: 2265, Train Loss: 0.3912006914615631, Valid Loss: 0.6166994571685791\n",
      "Epoch: 2266, Train Loss: 0.3911953866481781, Valid Loss: 0.6131265759468079\n",
      "Epoch: 2267, Train Loss: 0.3911900520324707, Valid Loss: 0.6170166730880737\n",
      "Epoch: 2268, Train Loss: 0.3911849856376648, Valid Loss: 0.6128897666931152\n",
      "Epoch: 2269, Train Loss: 0.3911799490451813, Valid Loss: 0.6173532009124756\n",
      "Epoch: 2270, Train Loss: 0.39117491245269775, Valid Loss: 0.6125690340995789\n",
      "Epoch: 2271, Train Loss: 0.391170471906662, Valid Loss: 0.617779016494751\n",
      "Epoch: 2272, Train Loss: 0.39116615056991577, Valid Loss: 0.6120957136154175\n",
      "Epoch: 2273, Train Loss: 0.391162246465683, Valid Loss: 0.6183732748031616\n",
      "Epoch: 2274, Train Loss: 0.39115890860557556, Valid Loss: 0.6114299297332764\n",
      "Epoch: 2275, Train Loss: 0.3911561965942383, Valid Loss: 0.619223952293396\n",
      "Epoch: 2276, Train Loss: 0.39115479588508606, Valid Loss: 0.6104865670204163\n",
      "Epoch: 2277, Train Loss: 0.391154944896698, Valid Loss: 0.6204080581665039\n",
      "Epoch: 2278, Train Loss: 0.39115583896636963, Valid Loss: 0.6091814637184143\n",
      "Epoch: 2279, Train Loss: 0.39115992188453674, Valid Loss: 0.6219635605812073\n",
      "Epoch: 2280, Train Loss: 0.39116379618644714, Valid Loss: 0.6075380444526672\n",
      "Epoch: 2281, Train Loss: 0.39117223024368286, Valid Loss: 0.6237621903419495\n",
      "Epoch: 2282, Train Loss: 0.3911772668361664, Valid Loss: 0.6058266162872314\n",
      "Epoch: 2283, Train Loss: 0.39118602871894836, Valid Loss: 0.6253395676612854\n",
      "Epoch: 2284, Train Loss: 0.3911835551261902, Valid Loss: 0.6047952175140381\n",
      "Epoch: 2285, Train Loss: 0.3911799192428589, Valid Loss: 0.6256915330886841\n",
      "Epoch: 2286, Train Loss: 0.3911606967449188, Valid Loss: 0.6055523157119751\n",
      "Epoch: 2287, Train Loss: 0.3911377489566803, Valid Loss: 0.6238490343093872\n",
      "Epoch: 2288, Train Loss: 0.3911076784133911, Valid Loss: 0.6085976958274841\n",
      "Epoch: 2289, Train Loss: 0.39108195900917053, Valid Loss: 0.6199332475662231\n",
      "Epoch: 2290, Train Loss: 0.3910626471042633, Valid Loss: 0.6130563616752625\n",
      "Epoch: 2291, Train Loss: 0.391052782535553, Valid Loss: 0.6153084635734558\n",
      "Epoch: 2292, Train Loss: 0.39105090498924255, Valid Loss: 0.6173373460769653\n",
      "Epoch: 2293, Train Loss: 0.39105352759361267, Valid Loss: 0.6115410327911377\n",
      "Epoch: 2294, Train Loss: 0.3910580277442932, Valid Loss: 0.6203012466430664\n",
      "Epoch: 2295, Train Loss: 0.39105960726737976, Valid Loss: 0.6095156669616699\n",
      "Epoch: 2296, Train Loss: 0.3910578489303589, Valid Loss: 0.6214907169342041\n",
      "Epoch: 2297, Train Loss: 0.3910501003265381, Valid Loss: 0.6094607710838318\n",
      "Epoch: 2298, Train Loss: 0.39103925228118896, Valid Loss: 0.620820939540863\n",
      "Epoch: 2299, Train Loss: 0.3910258114337921, Valid Loss: 0.6110970377922058\n",
      "Epoch: 2300, Train Loss: 0.39101260900497437, Valid Loss: 0.6186914443969727\n",
      "Epoch: 2301, Train Loss: 0.39100104570388794, Valid Loss: 0.6136501431465149\n",
      "Epoch: 2302, Train Loss: 0.39099329710006714, Valid Loss: 0.6159883737564087\n",
      "Epoch: 2303, Train Loss: 0.390988290309906, Valid Loss: 0.6162161231040955\n",
      "Epoch: 2304, Train Loss: 0.39098525047302246, Valid Loss: 0.6136268377304077\n",
      "Epoch: 2305, Train Loss: 0.3909832835197449, Valid Loss: 0.6181644201278687\n",
      "Epoch: 2306, Train Loss: 0.3909810781478882, Valid Loss: 0.6121475696563721\n",
      "Epoch: 2307, Train Loss: 0.39097800850868225, Valid Loss: 0.6192276477813721\n",
      "Epoch: 2308, Train Loss: 0.3909734785556793, Valid Loss: 0.6116694808006287\n",
      "Epoch: 2309, Train Loss: 0.39096808433532715, Valid Loss: 0.6194019317626953\n",
      "Epoch: 2310, Train Loss: 0.39096108078956604, Valid Loss: 0.6120458841323853\n",
      "Epoch: 2311, Train Loss: 0.3909536302089691, Valid Loss: 0.6188297867774963\n",
      "Epoch: 2312, Train Loss: 0.39094579219818115, Valid Loss: 0.612977921962738\n",
      "Epoch: 2313, Train Loss: 0.3909379839897156, Valid Loss: 0.6177830696105957\n",
      "Epoch: 2314, Train Loss: 0.39093104004859924, Valid Loss: 0.6141458749771118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2315, Train Loss: 0.3909245431423187, Valid Loss: 0.6165883541107178\n",
      "Epoch: 2316, Train Loss: 0.39091864228248596, Valid Loss: 0.6152981519699097\n",
      "Epoch: 2317, Train Loss: 0.39091330766677856, Valid Loss: 0.6155097484588623\n",
      "Epoch: 2318, Train Loss: 0.39090844988822937, Valid Loss: 0.6163066029548645\n",
      "Epoch: 2319, Train Loss: 0.3909035921096802, Valid Loss: 0.6146603226661682\n",
      "Epoch: 2320, Train Loss: 0.3908992111682892, Valid Loss: 0.6171191334724426\n",
      "Epoch: 2321, Train Loss: 0.3908945322036743, Valid Loss: 0.6140545010566711\n",
      "Epoch: 2322, Train Loss: 0.3908903896808624, Valid Loss: 0.6177366375923157\n",
      "Epoch: 2323, Train Loss: 0.39088574051856995, Valid Loss: 0.6136261820793152\n",
      "Epoch: 2324, Train Loss: 0.3908814489841461, Valid Loss: 0.6182018518447876\n",
      "Epoch: 2325, Train Loss: 0.390876829624176, Valid Loss: 0.6132748126983643\n",
      "Epoch: 2326, Train Loss: 0.3908725082874298, Valid Loss: 0.6185961365699768\n",
      "Epoch: 2327, Train Loss: 0.3908681571483612, Valid Loss: 0.6129214763641357\n",
      "Epoch: 2328, Train Loss: 0.39086413383483887, Valid Loss: 0.6189976334571838\n",
      "Epoch: 2329, Train Loss: 0.39086011052131653, Valid Loss: 0.6125028729438782\n",
      "Epoch: 2330, Train Loss: 0.3908563554286957, Valid Loss: 0.6195042729377747\n",
      "Epoch: 2331, Train Loss: 0.3908531367778778, Valid Loss: 0.6119725704193115\n",
      "Epoch: 2332, Train Loss: 0.3908505141735077, Valid Loss: 0.6201773881912231\n",
      "Epoch: 2333, Train Loss: 0.3908481299877167, Valid Loss: 0.6112832427024841\n",
      "Epoch: 2334, Train Loss: 0.39084720611572266, Valid Loss: 0.6210582256317139\n",
      "Epoch: 2335, Train Loss: 0.3908458948135376, Valid Loss: 0.6103889346122742\n",
      "Epoch: 2336, Train Loss: 0.3908466696739197, Valid Loss: 0.6221373081207275\n",
      "Epoch: 2337, Train Loss: 0.3908471465110779, Valid Loss: 0.6093006134033203\n",
      "Epoch: 2338, Train Loss: 0.39084991812705994, Valid Loss: 0.6233375668525696\n",
      "Epoch: 2339, Train Loss: 0.39085066318511963, Valid Loss: 0.6081604957580566\n",
      "Epoch: 2340, Train Loss: 0.390853613615036, Valid Loss: 0.6244308948516846\n",
      "Epoch: 2341, Train Loss: 0.3908519148826599, Valid Loss: 0.6073277592658997\n",
      "Epoch: 2342, Train Loss: 0.3908507227897644, Valid Loss: 0.6249755620956421\n",
      "Epoch: 2343, Train Loss: 0.39084184169769287, Valid Loss: 0.6073294281959534\n",
      "Epoch: 2344, Train Loss: 0.3908321261405945, Valid Loss: 0.6244547367095947\n",
      "Epoch: 2345, Train Loss: 0.3908155560493469, Valid Loss: 0.6085979342460632\n",
      "Epoch: 2346, Train Loss: 0.3907986879348755, Valid Loss: 0.6225917339324951\n",
      "Epoch: 2347, Train Loss: 0.3907800316810608, Valid Loss: 0.6110824942588806\n",
      "Epoch: 2348, Train Loss: 0.39076483249664307, Valid Loss: 0.6197265386581421\n",
      "Epoch: 2349, Train Loss: 0.3907526433467865, Valid Loss: 0.6141400933265686\n",
      "Epoch: 2350, Train Loss: 0.39074456691741943, Valid Loss: 0.616664469242096\n",
      "Epoch: 2351, Train Loss: 0.3907397389411926, Valid Loss: 0.6170164346694946\n",
      "Epoch: 2352, Train Loss: 0.3907375931739807, Valid Loss: 0.6140863299369812\n",
      "Epoch: 2353, Train Loss: 0.3907369077205658, Valid Loss: 0.6192601919174194\n",
      "Epoch: 2354, Train Loss: 0.3907364308834076, Valid Loss: 0.6123275756835938\n",
      "Epoch: 2355, Train Loss: 0.39073556661605835, Valid Loss: 0.6206810474395752\n",
      "Epoch: 2356, Train Loss: 0.39073312282562256, Valid Loss: 0.6114580035209656\n",
      "Epoch: 2357, Train Loss: 0.3907295763492584, Valid Loss: 0.6212490200996399\n",
      "Epoch: 2358, Train Loss: 0.39072373509407043, Valid Loss: 0.6113990545272827\n",
      "Epoch: 2359, Train Loss: 0.39071762561798096, Valid Loss: 0.621027946472168\n",
      "Epoch: 2360, Train Loss: 0.39070966839790344, Valid Loss: 0.6120038032531738\n",
      "Epoch: 2361, Train Loss: 0.39070194959640503, Valid Loss: 0.6202053427696228\n",
      "Epoch: 2362, Train Loss: 0.3906936049461365, Valid Loss: 0.6130333542823792\n",
      "Epoch: 2363, Train Loss: 0.3906858563423157, Valid Loss: 0.6190682053565979\n",
      "Epoch: 2364, Train Loss: 0.3906784653663635, Valid Loss: 0.614250659942627\n",
      "Epoch: 2365, Train Loss: 0.3906717300415039, Valid Loss: 0.6178799271583557\n",
      "Epoch: 2366, Train Loss: 0.3906656503677368, Valid Loss: 0.6154385209083557\n",
      "Epoch: 2367, Train Loss: 0.39066028594970703, Valid Loss: 0.616838276386261\n",
      "Epoch: 2368, Train Loss: 0.39065515995025635, Valid Loss: 0.6164740324020386\n",
      "Epoch: 2369, Train Loss: 0.3906504511833191, Valid Loss: 0.6159817576408386\n",
      "Epoch: 2370, Train Loss: 0.3906460702419281, Valid Loss: 0.6173337697982788\n",
      "Epoch: 2371, Train Loss: 0.39064186811447144, Valid Loss: 0.615283191204071\n",
      "Epoch: 2372, Train Loss: 0.3906376361846924, Valid Loss: 0.6180311441421509\n",
      "Epoch: 2373, Train Loss: 0.39063355326652527, Valid Loss: 0.6147016286849976\n",
      "Epoch: 2374, Train Loss: 0.3906297981739044, Valid Loss: 0.6186386942863464\n",
      "Epoch: 2375, Train Loss: 0.390625923871994, Valid Loss: 0.6141493320465088\n",
      "Epoch: 2376, Train Loss: 0.3906223773956299, Valid Loss: 0.6192432045936584\n",
      "Epoch: 2377, Train Loss: 0.3906190097332001, Valid Loss: 0.6135671734809875\n",
      "Epoch: 2378, Train Loss: 0.39061638712882996, Valid Loss: 0.6199427843093872\n",
      "Epoch: 2379, Train Loss: 0.3906137943267822, Valid Loss: 0.6128436923027039\n",
      "Epoch: 2380, Train Loss: 0.3906124234199524, Valid Loss: 0.6208550333976746\n",
      "Epoch: 2381, Train Loss: 0.3906113803386688, Valid Loss: 0.6118667125701904\n",
      "Epoch: 2382, Train Loss: 0.39061224460601807, Valid Loss: 0.6220763921737671\n",
      "Epoch: 2383, Train Loss: 0.39061397314071655, Valid Loss: 0.6105496883392334\n",
      "Epoch: 2384, Train Loss: 0.39061838388442993, Valid Loss: 0.6236401796340942\n",
      "Epoch: 2385, Train Loss: 0.3906230330467224, Valid Loss: 0.6089038252830505\n",
      "Epoch: 2386, Train Loss: 0.39063191413879395, Valid Loss: 0.6254489421844482\n",
      "Epoch: 2387, Train Loss: 0.3906378746032715, Valid Loss: 0.6071682572364807\n",
      "Epoch: 2388, Train Loss: 0.39064711332321167, Valid Loss: 0.6270753145217896\n",
      "Epoch: 2389, Train Loss: 0.39064690470695496, Valid Loss: 0.6060305833816528\n",
      "Epoch: 2390, Train Loss: 0.39064621925354004, Valid Loss: 0.6276312470436096\n",
      "Epoch: 2391, Train Loss: 0.3906301259994507, Valid Loss: 0.6065183877944946\n",
      "Epoch: 2392, Train Loss: 0.39061060547828674, Valid Loss: 0.6261137127876282\n",
      "Epoch: 2393, Train Loss: 0.3905821442604065, Valid Loss: 0.6092607378959656\n",
      "Epoch: 2394, Train Loss: 0.3905561566352844, Valid Loss: 0.6224166750907898\n",
      "Epoch: 2395, Train Loss: 0.3905350863933563, Valid Loss: 0.6136239767074585\n",
      "Epoch: 2396, Train Loss: 0.3905227780342102, Valid Loss: 0.6177420616149902\n",
      "Epoch: 2397, Train Loss: 0.3905186355113983, Valid Loss: 0.6181012392044067\n",
      "Epoch: 2398, Train Loss: 0.39052051305770874, Valid Loss: 0.6136721968650818\n",
      "Epoch: 2399, Train Loss: 0.39052531123161316, Valid Loss: 0.6214465498924255\n",
      "Epoch: 2400, Train Loss: 0.3905290365219116, Valid Loss: 0.6112067699432373\n",
      "Epoch: 2401, Train Loss: 0.39053013920783997, Valid Loss: 0.6230961084365845\n",
      "Epoch: 2402, Train Loss: 0.39052584767341614, Valid Loss: 0.6106691956520081\n",
      "Epoch: 2403, Train Loss: 0.39051827788352966, Valid Loss: 0.6228969693183899\n",
      "Epoch: 2404, Train Loss: 0.3905063569545746, Valid Loss: 0.6118949055671692\n",
      "Epoch: 2405, Train Loss: 0.39049383997917175, Valid Loss: 0.621112585067749\n",
      "Epoch: 2406, Train Loss: 0.3904820680618286, Valid Loss: 0.6142374277114868\n",
      "Epoch: 2407, Train Loss: 0.39047300815582275, Valid Loss: 0.618497908115387\n",
      "Epoch: 2408, Train Loss: 0.39046671986579895, Valid Loss: 0.6168422698974609\n",
      "Epoch: 2409, Train Loss: 0.39046305418014526, Valid Loss: 0.6159782409667969\n",
      "Epoch: 2410, Train Loss: 0.39046090841293335, Valid Loss: 0.6190242171287537\n",
      "Epoch: 2411, Train Loss: 0.39045950770378113, Valid Loss: 0.6141906380653381\n",
      "Epoch: 2412, Train Loss: 0.39045795798301697, Valid Loss: 0.620456337928772\n",
      "Epoch: 2413, Train Loss: 0.39045509696006775, Valid Loss: 0.6133214831352234\n",
      "Epoch: 2414, Train Loss: 0.39045169949531555, Valid Loss: 0.6210430264472961\n",
      "Epoch: 2415, Train Loss: 0.3904467821121216, Valid Loss: 0.6133080124855042\n",
      "Epoch: 2416, Train Loss: 0.3904411494731903, Valid Loss: 0.6208368539810181\n",
      "Epoch: 2417, Train Loss: 0.3904346227645874, Valid Loss: 0.6139211058616638\n",
      "Epoch: 2418, Train Loss: 0.39042794704437256, Valid Loss: 0.6200553178787231\n",
      "Epoch: 2419, Train Loss: 0.39042121171951294, Valid Loss: 0.6148825287818909\n",
      "Epoch: 2420, Train Loss: 0.39041492342948914, Valid Loss: 0.6190062761306763\n",
      "Epoch: 2421, Train Loss: 0.39040908217430115, Valid Loss: 0.6159455180168152\n",
      "Epoch: 2422, Train Loss: 0.3904038369655609, Valid Loss: 0.6179746389389038\n",
      "Epoch: 2423, Train Loss: 0.3903990685939789, Valid Loss: 0.6169407367706299\n",
      "Epoch: 2424, Train Loss: 0.3903942108154297, Valid Loss: 0.6171232461929321\n",
      "Epoch: 2425, Train Loss: 0.3903903067111969, Valid Loss: 0.6177992820739746\n",
      "Epoch: 2426, Train Loss: 0.3903861343860626, Valid Loss: 0.6164588928222656\n",
      "Epoch: 2427, Train Loss: 0.3903822898864746, Valid Loss: 0.6185021996498108\n",
      "Epoch: 2428, Train Loss: 0.39037850499153137, Valid Loss: 0.6159297823905945\n",
      "Epoch: 2429, Train Loss: 0.39037466049194336, Valid Loss: 0.619066059589386\n",
      "Epoch: 2430, Train Loss: 0.3903708755970001, Valid Loss: 0.6154690384864807\n",
      "Epoch: 2431, Train Loss: 0.3903672993183136, Valid Loss: 0.6195552349090576\n",
      "Epoch: 2432, Train Loss: 0.39036375284194946, Valid Loss: 0.6150166988372803\n",
      "Epoch: 2433, Train Loss: 0.3903605341911316, Valid Loss: 0.62006014585495\n",
      "Epoch: 2434, Train Loss: 0.39035719633102417, Valid Loss: 0.6145081520080566\n",
      "Epoch: 2435, Train Loss: 0.3903544843196869, Valid Loss: 0.6206873059272766\n",
      "Epoch: 2436, Train Loss: 0.3903521001338959, Valid Loss: 0.6138653755187988\n",
      "Epoch: 2437, Train Loss: 0.3903503715991974, Valid Loss: 0.6215146780014038\n",
      "Epoch: 2438, Train Loss: 0.39034950733184814, Valid Loss: 0.612993061542511\n",
      "Epoch: 2439, Train Loss: 0.3903500735759735, Valid Loss: 0.6226311326026917\n",
      "Epoch: 2440, Train Loss: 0.3903512954711914, Valid Loss: 0.6117929816246033\n",
      "Epoch: 2441, Train Loss: 0.3903549611568451, Valid Loss: 0.6240845322608948\n",
      "Epoch: 2442, Train Loss: 0.3903590142726898, Valid Loss: 0.6102513670921326\n",
      "Epoch: 2443, Train Loss: 0.3903663754463196, Valid Loss: 0.6258227825164795\n",
      "Epoch: 2444, Train Loss: 0.3903728127479553, Valid Loss: 0.608519971370697\n",
      "Epoch: 2445, Train Loss: 0.39038217067718506, Valid Loss: 0.6275544762611389\n",
      "Epoch: 2446, Train Loss: 0.3903849720954895, Valid Loss: 0.6071202754974365\n",
      "Epoch: 2447, Train Loss: 0.3903883993625641, Valid Loss: 0.6285455226898193\n",
      "Epoch: 2448, Train Loss: 0.3903787136077881, Valid Loss: 0.6069741249084473\n",
      "Epoch: 2449, Train Loss: 0.3903658092021942, Valid Loss: 0.6277945041656494\n",
      "Epoch: 2450, Train Loss: 0.39034104347229004, Valid Loss: 0.6089251637458801\n",
      "Epoch: 2451, Train Loss: 0.39031609892845154, Valid Loss: 0.6248170137405396\n",
      "Epoch: 2452, Train Loss: 0.3902912437915802, Valid Loss: 0.6127994060516357\n",
      "Epoch: 2453, Train Loss: 0.39027366042137146, Valid Loss: 0.6203850507736206\n",
      "Epoch: 2454, Train Loss: 0.39026403427124023, Valid Loss: 0.6173145174980164\n",
      "Epoch: 2455, Train Loss: 0.39026159048080444, Valid Loss: 0.6160468459129333\n",
      "Epoch: 2456, Train Loss: 0.3902643620967865, Valid Loss: 0.6210935711860657\n",
      "Epoch: 2457, Train Loss: 0.39026856422424316, Valid Loss: 0.6129778027534485\n",
      "Epoch: 2458, Train Loss: 0.3902720510959625, Valid Loss: 0.6234092712402344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2459, Train Loss: 0.3902723789215088, Valid Loss: 0.6116768717765808\n",
      "Epoch: 2460, Train Loss: 0.3902689218521118, Valid Loss: 0.6239952445030212\n",
      "Epoch: 2461, Train Loss: 0.39026111364364624, Valid Loss: 0.6121178269386292\n",
      "Epoch: 2462, Train Loss: 0.3902513384819031, Valid Loss: 0.6229627728462219\n",
      "Epoch: 2463, Train Loss: 0.39023974537849426, Valid Loss: 0.6138589382171631\n",
      "Epoch: 2464, Train Loss: 0.39022913575172424, Valid Loss: 0.620846688747406\n",
      "Epoch: 2465, Train Loss: 0.390220046043396, Valid Loss: 0.6161884665489197\n",
      "Epoch: 2466, Train Loss: 0.3902137875556946, Valid Loss: 0.6184256672859192\n",
      "Epoch: 2467, Train Loss: 0.3902096152305603, Valid Loss: 0.618451714515686\n",
      "Epoch: 2468, Train Loss: 0.39020705223083496, Valid Loss: 0.616372287273407\n",
      "Epoch: 2469, Train Loss: 0.39020559191703796, Valid Loss: 0.6202274560928345\n",
      "Epoch: 2470, Train Loss: 0.3902040719985962, Valid Loss: 0.6150178909301758\n",
      "Epoch: 2471, Train Loss: 0.3902021646499634, Valid Loss: 0.6213590502738953\n",
      "Epoch: 2472, Train Loss: 0.3901994824409485, Valid Loss: 0.6143864989280701\n",
      "Epoch: 2473, Train Loss: 0.39019593596458435, Valid Loss: 0.6218123435974121\n",
      "Epoch: 2474, Train Loss: 0.39019152522087097, Valid Loss: 0.6143818497657776\n",
      "Epoch: 2475, Train Loss: 0.39018625020980835, Valid Loss: 0.6216415762901306\n",
      "Epoch: 2476, Train Loss: 0.3901805877685547, Valid Loss: 0.6148334741592407\n",
      "Epoch: 2477, Train Loss: 0.3901749551296234, Valid Loss: 0.6210310459136963\n",
      "Epoch: 2478, Train Loss: 0.39016881585121155, Valid Loss: 0.6155652403831482\n",
      "Epoch: 2479, Train Loss: 0.3901633322238922, Valid Loss: 0.6202177405357361\n",
      "Epoch: 2480, Train Loss: 0.39015787839889526, Valid Loss: 0.616425096988678\n",
      "Epoch: 2481, Train Loss: 0.39015311002731323, Valid Loss: 0.6194183826446533\n",
      "Epoch: 2482, Train Loss: 0.3901483118534088, Valid Loss: 0.6172619462013245\n",
      "Epoch: 2483, Train Loss: 0.3901437819004059, Valid Loss: 0.6187469959259033\n",
      "Epoch: 2484, Train Loss: 0.3901395797729492, Valid Loss: 0.6179834604263306\n",
      "Epoch: 2485, Train Loss: 0.39013543725013733, Valid Loss: 0.6181950569152832\n",
      "Epoch: 2486, Train Loss: 0.3901313841342926, Valid Loss: 0.61856609582901\n",
      "Epoch: 2487, Train Loss: 0.3901275098323822, Valid Loss: 0.617738664150238\n",
      "Epoch: 2488, Train Loss: 0.3901236355304718, Valid Loss: 0.6190193295478821\n",
      "Epoch: 2489, Train Loss: 0.3901198208332062, Valid Loss: 0.617368221282959\n",
      "Epoch: 2490, Train Loss: 0.39011603593826294, Valid Loss: 0.6194062829017639\n",
      "Epoch: 2491, Train Loss: 0.39011281728744507, Valid Loss: 0.6170241832733154\n",
      "Epoch: 2492, Train Loss: 0.390109121799469, Valid Loss: 0.619828999042511\n",
      "Epoch: 2493, Train Loss: 0.39010584354400635, Valid Loss: 0.6166234016418457\n",
      "Epoch: 2494, Train Loss: 0.3901028335094452, Valid Loss: 0.6203786730766296\n",
      "Epoch: 2495, Train Loss: 0.39010000228881836, Valid Loss: 0.6160613894462585\n",
      "Epoch: 2496, Train Loss: 0.3900981545448303, Valid Loss: 0.6211602687835693\n",
      "Epoch: 2497, Train Loss: 0.390097051858902, Valid Loss: 0.6151896119117737\n",
      "Epoch: 2498, Train Loss: 0.39009732007980347, Valid Loss: 0.6223224401473999\n",
      "Epoch: 2499, Train Loss: 0.39009931683540344, Valid Loss: 0.6138302087783813\n",
      "Epoch: 2500, Train Loss: 0.39010390639305115, Valid Loss: 0.6240680813789368\n",
      "Epoch: 2501, Train Loss: 0.39011144638061523, Valid Loss: 0.6117767095565796\n",
      "Epoch: 2502, Train Loss: 0.3901234567165375, Valid Loss: 0.6265875101089478\n",
      "Epoch: 2503, Train Loss: 0.3901382386684418, Valid Loss: 0.608962893486023\n",
      "Epoch: 2504, Train Loss: 0.390160471200943, Valid Loss: 0.6297792196273804\n",
      "Epoch: 2505, Train Loss: 0.39017927646636963, Valid Loss: 0.6058392524719238\n",
      "Epoch: 2506, Train Loss: 0.39020463824272156, Valid Loss: 0.632670521736145\n",
      "Epoch: 2507, Train Loss: 0.39020755887031555, Valid Loss: 0.6039961576461792\n",
      "Epoch: 2508, Train Loss: 0.39020299911499023, Valid Loss: 0.6330386400222778\n",
      "Epoch: 2509, Train Loss: 0.39016225934028625, Valid Loss: 0.605914294719696\n",
      "Epoch: 2510, Train Loss: 0.3901143968105316, Valid Loss: 0.6287968754768372\n",
      "Epoch: 2511, Train Loss: 0.3900637626647949, Valid Loss: 0.6122905015945435\n",
      "Epoch: 2512, Train Loss: 0.39003312587738037, Valid Loss: 0.6210522055625916\n",
      "Epoch: 2513, Train Loss: 0.39002725481987, Valid Loss: 0.6201943159103394\n",
      "Epoch: 2514, Train Loss: 0.3900395333766937, Valid Loss: 0.6136797070503235\n",
      "Epoch: 2515, Train Loss: 0.3900579810142517, Valid Loss: 0.625922679901123\n",
      "Epoch: 2516, Train Loss: 0.3900690972805023, Valid Loss: 0.6098870038986206\n",
      "Epoch: 2517, Train Loss: 0.3900701403617859, Valid Loss: 0.6275232434272766\n",
      "Epoch: 2518, Train Loss: 0.3900547921657562, Valid Loss: 0.6107795238494873\n",
      "Epoch: 2519, Train Loss: 0.39003339409828186, Valid Loss: 0.6248940825462341\n",
      "Epoch: 2520, Train Loss: 0.3900114595890045, Valid Loss: 0.6152155995368958\n",
      "Epoch: 2521, Train Loss: 0.3899972140789032, Valid Loss: 0.6198806166648865\n",
      "Epoch: 2522, Train Loss: 0.3899928033351898, Valid Loss: 0.6203413009643555\n",
      "Epoch: 2523, Train Loss: 0.3899957537651062, Valid Loss: 0.6153429746627808\n",
      "Epoch: 2524, Train Loss: 0.3900016248226166, Valid Loss: 0.6236488819122314\n",
      "Epoch: 2525, Train Loss: 0.39000415802001953, Valid Loss: 0.6132001280784607\n",
      "Epoch: 2526, Train Loss: 0.39000168442726135, Valid Loss: 0.6242787837982178\n",
      "Epoch: 2527, Train Loss: 0.38999220728874207, Valid Loss: 0.6138997673988342\n",
      "Epoch: 2528, Train Loss: 0.38997986912727356, Valid Loss: 0.6225878000259399\n",
      "Epoch: 2529, Train Loss: 0.38996824622154236, Valid Loss: 0.6166180372238159\n",
      "Epoch: 2530, Train Loss: 0.3899606466293335, Valid Loss: 0.6196973919868469\n",
      "Epoch: 2531, Train Loss: 0.3899571895599365, Valid Loss: 0.6197578310966492\n",
      "Epoch: 2532, Train Loss: 0.3899567425251007, Valid Loss: 0.61698317527771\n",
      "Epoch: 2533, Train Loss: 0.389957070350647, Valid Loss: 0.6219671368598938\n",
      "Epoch: 2534, Train Loss: 0.3899555802345276, Valid Loss: 0.6154322624206543\n",
      "Epoch: 2535, Train Loss: 0.3899526000022888, Valid Loss: 0.62270188331604\n",
      "Epoch: 2536, Train Loss: 0.3899473249912262, Valid Loss: 0.6154285669326782\n",
      "Epoch: 2537, Train Loss: 0.38994070887565613, Valid Loss: 0.6220279335975647\n",
      "Epoch: 2538, Train Loss: 0.3899337649345398, Valid Loss: 0.6167445182800293\n",
      "Epoch: 2539, Train Loss: 0.38992804288864136, Valid Loss: 0.620421826839447\n",
      "Epoch: 2540, Train Loss: 0.3899231255054474, Valid Loss: 0.6186860799789429\n",
      "Epoch: 2541, Train Loss: 0.3899194300174713, Valid Loss: 0.6186110973358154\n",
      "Epoch: 2542, Train Loss: 0.3899165987968445, Valid Loss: 0.6204437017440796\n",
      "Epoch: 2543, Train Loss: 0.389914333820343, Valid Loss: 0.6172393560409546\n",
      "Epoch: 2544, Train Loss: 0.38991206884384155, Valid Loss: 0.6214926242828369\n",
      "Epoch: 2545, Train Loss: 0.38990896940231323, Valid Loss: 0.6166529655456543\n",
      "Epoch: 2546, Train Loss: 0.3899053931236267, Valid Loss: 0.6216968894004822\n",
      "Epoch: 2547, Train Loss: 0.3899010121822357, Valid Loss: 0.61684650182724\n",
      "Epoch: 2548, Train Loss: 0.3898964822292328, Valid Loss: 0.6212503910064697\n",
      "Epoch: 2549, Train Loss: 0.3898918926715851, Valid Loss: 0.6175756454467773\n",
      "Epoch: 2550, Train Loss: 0.38988742232322693, Valid Loss: 0.6204677820205688\n",
      "Epoch: 2551, Train Loss: 0.3898831307888031, Valid Loss: 0.6185004115104675\n",
      "Epoch: 2552, Train Loss: 0.3898790776729584, Valid Loss: 0.6196629405021667\n",
      "Epoch: 2553, Train Loss: 0.3898753225803375, Valid Loss: 0.6193344593048096\n",
      "Epoch: 2554, Train Loss: 0.38987165689468384, Valid Loss: 0.6190077066421509\n",
      "Epoch: 2555, Train Loss: 0.3898680508136749, Valid Loss: 0.6199488043785095\n",
      "Epoch: 2556, Train Loss: 0.38986462354660034, Valid Loss: 0.6185570955276489\n",
      "Epoch: 2557, Train Loss: 0.38986143469810486, Valid Loss: 0.6203362941741943\n",
      "Epoch: 2558, Train Loss: 0.3898578882217407, Valid Loss: 0.6183018684387207\n",
      "Epoch: 2559, Train Loss: 0.38985469937324524, Valid Loss: 0.6205852031707764\n",
      "Epoch: 2560, Train Loss: 0.3898516297340393, Valid Loss: 0.618161141872406\n",
      "Epoch: 2561, Train Loss: 0.38984808325767517, Valid Loss: 0.6207793951034546\n",
      "Epoch: 2562, Train Loss: 0.38984477519989014, Valid Loss: 0.6180613040924072\n",
      "Epoch: 2563, Train Loss: 0.3898414075374603, Valid Loss: 0.6209696531295776\n",
      "Epoch: 2564, Train Loss: 0.3898380398750305, Valid Loss: 0.6179335713386536\n",
      "Epoch: 2565, Train Loss: 0.38983485102653503, Valid Loss: 0.6212082505226135\n",
      "Epoch: 2566, Train Loss: 0.38983145356178284, Valid Loss: 0.617719829082489\n",
      "Epoch: 2567, Train Loss: 0.38982847332954407, Valid Loss: 0.621525228023529\n",
      "Epoch: 2568, Train Loss: 0.38982534408569336, Valid Loss: 0.6174132823944092\n",
      "Epoch: 2569, Train Loss: 0.38982269167900085, Valid Loss: 0.6219450831413269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2570, Train Loss: 0.3898201584815979, Valid Loss: 0.6169770956039429\n",
      "Epoch: 2571, Train Loss: 0.389818012714386, Valid Loss: 0.6225359439849854\n",
      "Epoch: 2572, Train Loss: 0.3898162245750427, Valid Loss: 0.6163466572761536\n",
      "Epoch: 2573, Train Loss: 0.3898153603076935, Valid Loss: 0.6233749985694885\n",
      "Epoch: 2574, Train Loss: 0.38981568813323975, Valid Loss: 0.6154336929321289\n",
      "Epoch: 2575, Train Loss: 0.3898165822029114, Valid Loss: 0.624558687210083\n",
      "Epoch: 2576, Train Loss: 0.38981902599334717, Valid Loss: 0.6141183972358704\n",
      "Epoch: 2577, Train Loss: 0.38982442021369934, Valid Loss: 0.626177966594696\n",
      "Epoch: 2578, Train Loss: 0.3898307979106903, Valid Loss: 0.6123467087745667\n",
      "Epoch: 2579, Train Loss: 0.38984087109565735, Valid Loss: 0.628253698348999\n",
      "Epoch: 2580, Train Loss: 0.38985082507133484, Valid Loss: 0.6101902723312378\n",
      "Epoch: 2581, Train Loss: 0.3898646831512451, Valid Loss: 0.630540132522583\n",
      "Epoch: 2582, Train Loss: 0.3898724913597107, Valid Loss: 0.6081982254981995\n",
      "Epoch: 2583, Train Loss: 0.38988226652145386, Valid Loss: 0.6321559548377991\n",
      "Epoch: 2584, Train Loss: 0.3898763060569763, Valid Loss: 0.6075093746185303\n",
      "Epoch: 2585, Train Loss: 0.3898662030696869, Valid Loss: 0.6317675709724426\n",
      "Epoch: 2586, Train Loss: 0.38983869552612305, Valid Loss: 0.6093825101852417\n",
      "Epoch: 2587, Train Loss: 0.3898089826107025, Valid Loss: 0.628477931022644\n",
      "Epoch: 2588, Train Loss: 0.38977813720703125, Valid Loss: 0.6139085292816162\n",
      "Epoch: 2589, Train Loss: 0.3897559642791748, Valid Loss: 0.6231073141098022\n",
      "Epoch: 2590, Train Loss: 0.38974541425704956, Valid Loss: 0.6194561123847961\n",
      "Epoch: 2591, Train Loss: 0.38974496722221375, Valid Loss: 0.6177449226379395\n",
      "Epoch: 2592, Train Loss: 0.3897511065006256, Valid Loss: 0.6240888237953186\n",
      "Epoch: 2593, Train Loss: 0.3897586166858673, Valid Loss: 0.6140993237495422\n",
      "Epoch: 2594, Train Loss: 0.3897646963596344, Valid Loss: 0.6266754865646362\n",
      "Epoch: 2595, Train Loss: 0.3897648751735687, Valid Loss: 0.6128861904144287\n",
      "Epoch: 2596, Train Loss: 0.38976073265075684, Valid Loss: 0.6268894076347351\n",
      "Epoch: 2597, Train Loss: 0.3897506594657898, Valid Loss: 0.6139849424362183\n",
      "Epoch: 2598, Train Loss: 0.389738529920578, Valid Loss: 0.6250244975090027\n",
      "Epoch: 2599, Train Loss: 0.38972586393356323, Valid Loss: 0.616611659526825\n",
      "Epoch: 2600, Train Loss: 0.38971537351608276, Valid Loss: 0.6220406293869019\n",
      "Epoch: 2601, Train Loss: 0.3897083103656769, Valid Loss: 0.6196329593658447\n",
      "Epoch: 2602, Train Loss: 0.38970521092414856, Valid Loss: 0.6191062927246094\n",
      "Epoch: 2603, Train Loss: 0.38970452547073364, Valid Loss: 0.6221770644187927\n",
      "Epoch: 2604, Train Loss: 0.38970550894737244, Valid Loss: 0.6169936656951904\n",
      "Epoch: 2605, Train Loss: 0.389706015586853, Valid Loss: 0.6238274574279785\n",
      "Epoch: 2606, Train Loss: 0.38970550894737244, Valid Loss: 0.6160051226615906\n",
      "Epoch: 2607, Train Loss: 0.3897028863430023, Valid Loss: 0.6244704723358154\n",
      "Epoch: 2608, Train Loss: 0.38969847559928894, Valid Loss: 0.6160510182380676\n",
      "Epoch: 2609, Train Loss: 0.3896927535533905, Valid Loss: 0.624155580997467\n",
      "Epoch: 2610, Train Loss: 0.3896864652633667, Valid Loss: 0.6168811917304993\n",
      "Epoch: 2611, Train Loss: 0.38968023657798767, Valid Loss: 0.623072624206543\n",
      "Epoch: 2612, Train Loss: 0.3896743357181549, Valid Loss: 0.6181885600090027\n",
      "Epoch: 2613, Train Loss: 0.3896693289279938, Valid Loss: 0.6215970516204834\n",
      "Epoch: 2614, Train Loss: 0.3896651566028595, Valid Loss: 0.6196690797805786\n",
      "Epoch: 2615, Train Loss: 0.38966161012649536, Valid Loss: 0.6201429963111877\n",
      "Epoch: 2616, Train Loss: 0.389658659696579, Valid Loss: 0.621078610420227\n",
      "Epoch: 2617, Train Loss: 0.38965627551078796, Valid Loss: 0.6189720630645752\n",
      "Epoch: 2618, Train Loss: 0.3896539807319641, Valid Loss: 0.6222057938575745\n",
      "Epoch: 2619, Train Loss: 0.3896520137786865, Valid Loss: 0.618191659450531\n",
      "Epoch: 2620, Train Loss: 0.3896495997905731, Valid Loss: 0.6229424476623535\n",
      "Epoch: 2621, Train Loss: 0.3896472454071045, Valid Loss: 0.6177443861961365\n",
      "Epoch: 2622, Train Loss: 0.38964447379112244, Valid Loss: 0.6233099699020386\n",
      "Epoch: 2623, Train Loss: 0.38964176177978516, Valid Loss: 0.6175488829612732\n",
      "Epoch: 2624, Train Loss: 0.3896385431289673, Valid Loss: 0.6234349608421326\n",
      "Epoch: 2625, Train Loss: 0.38963577151298523, Valid Loss: 0.6175058484077454\n",
      "Epoch: 2626, Train Loss: 0.38963285088539124, Valid Loss: 0.6234792470932007\n",
      "Epoch: 2627, Train Loss: 0.38962990045547485, Valid Loss: 0.6175070405006409\n",
      "Epoch: 2628, Train Loss: 0.38962724804878235, Valid Loss: 0.6235847473144531\n",
      "Epoch: 2629, Train Loss: 0.389624685049057, Valid Loss: 0.6174406409263611\n",
      "Epoch: 2630, Train Loss: 0.3896220028400421, Valid Loss: 0.6238459348678589\n",
      "Epoch: 2631, Train Loss: 0.38962000608444214, Valid Loss: 0.617204487323761\n",
      "Epoch: 2632, Train Loss: 0.38961753249168396, Valid Loss: 0.6242822408676147\n",
      "Epoch: 2633, Train Loss: 0.38961613178253174, Valid Loss: 0.6167497634887695\n",
      "Epoch: 2634, Train Loss: 0.38961461186408997, Valid Loss: 0.6248958110809326\n",
      "Epoch: 2635, Train Loss: 0.38961365818977356, Valid Loss: 0.6160669922828674\n",
      "Epoch: 2636, Train Loss: 0.389613538980484, Valid Loss: 0.6257368922233582\n",
      "Epoch: 2637, Train Loss: 0.38961371779441833, Valid Loss: 0.6151494383811951\n",
      "Epoch: 2638, Train Loss: 0.389615535736084, Valid Loss: 0.6268233060836792\n",
      "Epoch: 2639, Train Loss: 0.3896174728870392, Valid Loss: 0.614040195941925\n",
      "Epoch: 2640, Train Loss: 0.3896213173866272, Valid Loss: 0.6281155347824097\n",
      "Epoch: 2641, Train Loss: 0.3896249532699585, Valid Loss: 0.6127985119819641\n",
      "Epoch: 2642, Train Loss: 0.3896307945251465, Valid Loss: 0.629472553730011\n",
      "Epoch: 2643, Train Loss: 0.389634370803833, Valid Loss: 0.6116194128990173\n",
      "Epoch: 2644, Train Loss: 0.3896391987800598, Valid Loss: 0.6305669546127319\n",
      "Epoch: 2645, Train Loss: 0.3896387219429016, Valid Loss: 0.6109076142311096\n",
      "Epoch: 2646, Train Loss: 0.38963744044303894, Valid Loss: 0.6309095621109009\n",
      "Epoch: 2647, Train Loss: 0.3896280527114868, Valid Loss: 0.6112188100814819\n",
      "Epoch: 2648, Train Loss: 0.38961684703826904, Valid Loss: 0.6299770474433899\n",
      "Epoch: 2649, Train Loss: 0.38959962129592896, Valid Loss: 0.612910807132721\n",
      "Epoch: 2650, Train Loss: 0.38958263397216797, Valid Loss: 0.627623438835144\n",
      "Epoch: 2651, Train Loss: 0.38956552743911743, Valid Loss: 0.6158239245414734\n",
      "Epoch: 2652, Train Loss: 0.38955211639404297, Valid Loss: 0.6243448257446289\n",
      "Epoch: 2653, Train Loss: 0.38954296708106995, Valid Loss: 0.6192410588264465\n",
      "Epoch: 2654, Train Loss: 0.38953787088394165, Valid Loss: 0.6209924221038818\n",
      "Epoch: 2655, Train Loss: 0.38953617215156555, Valid Loss: 0.6223763823509216\n",
      "Epoch: 2656, Train Loss: 0.38953688740730286, Valid Loss: 0.6182720065116882\n",
      "Epoch: 2657, Train Loss: 0.3895387649536133, Valid Loss: 0.6247352957725525\n",
      "Epoch: 2658, Train Loss: 0.389540433883667, Valid Loss: 0.6164882183074951\n",
      "Epoch: 2659, Train Loss: 0.38954147696495056, Valid Loss: 0.6261593103408813\n",
      "Epoch: 2660, Train Loss: 0.3895408511161804, Valid Loss: 0.6156620979309082\n",
      "Epoch: 2661, Train Loss: 0.38953912258148193, Valid Loss: 0.6266452670097351\n",
      "Epoch: 2662, Train Loss: 0.3895353078842163, Valid Loss: 0.6156926155090332\n",
      "Epoch: 2663, Train Loss: 0.38953062891960144, Valid Loss: 0.6263062953948975\n",
      "Epoch: 2664, Train Loss: 0.38952451944351196, Valid Loss: 0.6163767576217651\n",
      "Epoch: 2665, Train Loss: 0.3895184397697449, Valid Loss: 0.6254268288612366\n",
      "Epoch: 2666, Train Loss: 0.38951218128204346, Valid Loss: 0.6174525618553162\n",
      "Epoch: 2667, Train Loss: 0.38950586318969727, Valid Loss: 0.6242858171463013\n",
      "Epoch: 2668, Train Loss: 0.3894999921321869, Valid Loss: 0.6186859607696533\n",
      "Epoch: 2669, Train Loss: 0.38949525356292725, Valid Loss: 0.6231141090393066\n",
      "Epoch: 2670, Train Loss: 0.38949063420295715, Valid Loss: 0.619898796081543\n",
      "Epoch: 2671, Train Loss: 0.38948675990104675, Valid Loss: 0.6220541000366211\n",
      "Epoch: 2672, Train Loss: 0.3894832730293274, Valid Loss: 0.6209625601768494\n",
      "Epoch: 2673, Train Loss: 0.38948044180870056, Valid Loss: 0.6211647987365723\n",
      "Epoch: 2674, Train Loss: 0.3894776403903961, Valid Loss: 0.621844470500946\n",
      "Epoch: 2675, Train Loss: 0.3894750773906708, Valid Loss: 0.6204217672348022\n",
      "Epoch: 2676, Train Loss: 0.3894726037979126, Valid Loss: 0.6225816607475281\n",
      "Epoch: 2677, Train Loss: 0.38947051763534546, Valid Loss: 0.6197906136512756\n",
      "Epoch: 2678, Train Loss: 0.3894684314727783, Valid Loss: 0.6232554912567139\n",
      "Epoch: 2679, Train Loss: 0.38946613669395447, Valid Loss: 0.6191904544830322\n",
      "Epoch: 2680, Train Loss: 0.38946494460105896, Valid Loss: 0.6239599585533142\n",
      "Epoch: 2681, Train Loss: 0.3894635736942291, Valid Loss: 0.6185324788093567\n",
      "Epoch: 2682, Train Loss: 0.3894626796245575, Valid Loss: 0.6247709393501282\n",
      "Epoch: 2683, Train Loss: 0.38946232199668884, Valid Loss: 0.6176990270614624\n",
      "Epoch: 2684, Train Loss: 0.3894628882408142, Valid Loss: 0.6258253455162048\n",
      "Epoch: 2685, Train Loss: 0.3894646167755127, Valid Loss: 0.6165620684623718\n",
      "Epoch: 2686, Train Loss: 0.3894680142402649, Valid Loss: 0.6272304058074951\n",
      "Epoch: 2687, Train Loss: 0.389473021030426, Valid Loss: 0.6150216460227966\n",
      "Epoch: 2688, Train Loss: 0.3894805312156677, Valid Loss: 0.6290901899337769\n",
      "Epoch: 2689, Train Loss: 0.3894895613193512, Valid Loss: 0.6130281090736389\n",
      "Epoch: 2690, Train Loss: 0.3895024061203003, Valid Loss: 0.6313619017601013\n",
      "Epoch: 2691, Train Loss: 0.38951367139816284, Valid Loss: 0.6108091473579407\n",
      "Epoch: 2692, Train Loss: 0.3895283341407776, Valid Loss: 0.6335852146148682\n",
      "Epoch: 2693, Train Loss: 0.3895343840122223, Valid Loss: 0.6090964078903198\n",
      "Epoch: 2694, Train Loss: 0.38953909277915955, Valid Loss: 0.6346839070320129\n",
      "Epoch: 2695, Train Loss: 0.38952577114105225, Valid Loss: 0.6091887950897217\n",
      "Epoch: 2696, Train Loss: 0.389507532119751, Valid Loss: 0.6332760453224182\n",
      "Epoch: 2697, Train Loss: 0.3894754946231842, Valid Loss: 0.6121110916137695\n",
      "Epoch: 2698, Train Loss: 0.3894445300102234, Valid Loss: 0.6289877891540527\n",
      "Epoch: 2699, Train Loss: 0.38941848278045654, Valid Loss: 0.6173269152641296\n",
      "Epoch: 2700, Train Loss: 0.38940393924713135, Valid Loss: 0.6232315897941589\n",
      "Epoch: 2701, Train Loss: 0.38940054178237915, Valid Loss: 0.6229397654533386\n",
      "Epoch: 2702, Train Loss: 0.3894055485725403, Valid Loss: 0.6181015968322754\n",
      "Epoch: 2703, Train Loss: 0.3894144296646118, Valid Loss: 0.6272045373916626\n",
      "Epoch: 2704, Train Loss: 0.3894219994544983, Valid Loss: 0.6150373816490173\n",
      "Epoch: 2705, Train Loss: 0.38942620158195496, Valid Loss: 0.6291685700416565\n",
      "Epoch: 2706, Train Loss: 0.38942334055900574, Valid Loss: 0.6145417094230652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2707, Train Loss: 0.38941630721092224, Valid Loss: 0.6286575198173523\n",
      "Epoch: 2708, Train Loss: 0.38940465450286865, Valid Loss: 0.6162642240524292\n",
      "Epoch: 2709, Train Loss: 0.38939258456230164, Valid Loss: 0.6262368559837341\n",
      "Epoch: 2710, Train Loss: 0.3893815279006958, Valid Loss: 0.6192018985748291\n",
      "Epoch: 2711, Train Loss: 0.3893735110759735, Valid Loss: 0.6230667233467102\n",
      "Epoch: 2712, Train Loss: 0.38936883211135864, Valid Loss: 0.622225284576416\n",
      "Epoch: 2713, Train Loss: 0.3893674314022064, Valid Loss: 0.6202791333198547\n",
      "Epoch: 2714, Train Loss: 0.38936808705329895, Valid Loss: 0.6245782375335693\n",
      "Epoch: 2715, Train Loss: 0.3893691897392273, Valid Loss: 0.6184917688369751\n",
      "Epoch: 2716, Train Loss: 0.3893699049949646, Valid Loss: 0.6259522438049316\n",
      "Epoch: 2717, Train Loss: 0.38936933875083923, Valid Loss: 0.617825984954834\n",
      "Epoch: 2718, Train Loss: 0.38936662673950195, Valid Loss: 0.6263045072555542\n",
      "Epoch: 2719, Train Loss: 0.3893624246120453, Valid Loss: 0.6180795431137085\n",
      "Epoch: 2720, Train Loss: 0.3893570899963379, Valid Loss: 0.6257924437522888\n",
      "Epoch: 2721, Train Loss: 0.38935109972953796, Valid Loss: 0.618966281414032\n",
      "Epoch: 2722, Train Loss: 0.38934558629989624, Valid Loss: 0.624686598777771\n",
      "Epoch: 2723, Train Loss: 0.38934090733528137, Valid Loss: 0.6202142834663391\n",
      "Epoch: 2724, Train Loss: 0.3893362879753113, Valid Loss: 0.6233305931091309\n",
      "Epoch: 2725, Train Loss: 0.38933297991752625, Valid Loss: 0.6215965747833252\n",
      "Epoch: 2726, Train Loss: 0.38933029770851135, Valid Loss: 0.6220318078994751\n",
      "Epoch: 2727, Train Loss: 0.38932791352272034, Valid Loss: 0.6228999495506287\n",
      "Epoch: 2728, Train Loss: 0.3893258571624756, Valid Loss: 0.6209626197814941\n",
      "Epoch: 2729, Train Loss: 0.3893240988254547, Valid Loss: 0.623975396156311\n",
      "Epoch: 2730, Train Loss: 0.3893224000930786, Valid Loss: 0.6201698780059814\n",
      "Epoch: 2731, Train Loss: 0.38932061195373535, Valid Loss: 0.6247265338897705\n",
      "Epoch: 2732, Train Loss: 0.3893187344074249, Valid Loss: 0.6196373105049133\n",
      "Epoch: 2733, Train Loss: 0.38931673765182495, Valid Loss: 0.6251954436302185\n",
      "Epoch: 2734, Train Loss: 0.3893146812915802, Valid Loss: 0.6193013787269592\n",
      "Epoch: 2735, Train Loss: 0.38931265473365784, Valid Loss: 0.6254712343215942\n",
      "Epoch: 2736, Train Loss: 0.38931041955947876, Valid Loss: 0.6191295385360718\n",
      "Epoch: 2737, Train Loss: 0.38930827379226685, Valid Loss: 0.6256746649742126\n",
      "Epoch: 2738, Train Loss: 0.38930657505989075, Valid Loss: 0.619006335735321\n",
      "Epoch: 2739, Train Loss: 0.3893044590950012, Valid Loss: 0.6259340643882751\n",
      "Epoch: 2740, Train Loss: 0.3893028497695923, Valid Loss: 0.6188160181045532\n",
      "Epoch: 2741, Train Loss: 0.3893013000488281, Valid Loss: 0.6262894868850708\n",
      "Epoch: 2742, Train Loss: 0.38930025696754456, Valid Loss: 0.6184669733047485\n",
      "Epoch: 2743, Train Loss: 0.38929980993270874, Valid Loss: 0.6268154382705688\n",
      "Epoch: 2744, Train Loss: 0.389299601316452, Valid Loss: 0.6178785562515259\n",
      "Epoch: 2745, Train Loss: 0.38930004835128784, Valid Loss: 0.6275880336761475\n",
      "Epoch: 2746, Train Loss: 0.3893009126186371, Valid Loss: 0.6170351505279541\n",
      "Epoch: 2747, Train Loss: 0.389302521944046, Valid Loss: 0.628643810749054\n",
      "Epoch: 2748, Train Loss: 0.38930439949035645, Valid Loss: 0.6159294247627258\n",
      "Epoch: 2749, Train Loss: 0.3893081247806549, Valid Loss: 0.6299539804458618\n",
      "Epoch: 2750, Train Loss: 0.38931146264076233, Valid Loss: 0.6146462559700012\n",
      "Epoch: 2751, Train Loss: 0.38931673765182495, Valid Loss: 0.6313321590423584\n",
      "Epoch: 2752, Train Loss: 0.3893200755119324, Valid Loss: 0.6134400963783264\n",
      "Epoch: 2753, Train Loss: 0.3893249034881592, Valid Loss: 0.6324511170387268\n",
      "Epoch: 2754, Train Loss: 0.3893249034881592, Valid Loss: 0.6126796007156372\n",
      "Epoch: 2755, Train Loss: 0.38932496309280396, Valid Loss: 0.6328714489936829\n",
      "Epoch: 2756, Train Loss: 0.3893178701400757, Valid Loss: 0.6128630042076111\n",
      "Epoch: 2757, Train Loss: 0.3893093168735504, Valid Loss: 0.6321241855621338\n",
      "Epoch: 2758, Train Loss: 0.38929519057273865, Valid Loss: 0.6143157482147217\n",
      "Epoch: 2759, Train Loss: 0.38928067684173584, Valid Loss: 0.6300801038742065\n",
      "Epoch: 2760, Train Loss: 0.38926512002944946, Valid Loss: 0.6169175505638123\n",
      "Epoch: 2761, Train Loss: 0.3892519772052765, Valid Loss: 0.6271204948425293\n",
      "Epoch: 2762, Train Loss: 0.38924139738082886, Valid Loss: 0.620060384273529\n",
      "Epoch: 2763, Train Loss: 0.38923418521881104, Valid Loss: 0.6240115165710449\n",
      "Epoch: 2764, Train Loss: 0.3892301023006439, Valid Loss: 0.623007595539093\n",
      "Epoch: 2765, Train Loss: 0.38922855257987976, Valid Loss: 0.6213878393173218\n",
      "Epoch: 2766, Train Loss: 0.38922935724258423, Valid Loss: 0.6253378987312317\n",
      "Epoch: 2767, Train Loss: 0.389230340719223, Valid Loss: 0.6195010542869568\n",
      "Epoch: 2768, Train Loss: 0.38923192024230957, Valid Loss: 0.6269505023956299\n",
      "Epoch: 2769, Train Loss: 0.3892325758934021, Valid Loss: 0.6183488368988037\n",
      "Epoch: 2770, Train Loss: 0.38923323154449463, Valid Loss: 0.62789386510849\n",
      "Epoch: 2771, Train Loss: 0.3892323076725006, Valid Loss: 0.6178064942359924\n",
      "Epoch: 2772, Train Loss: 0.38923096656799316, Valid Loss: 0.6282666921615601\n",
      "Epoch: 2773, Train Loss: 0.389227956533432, Valid Loss: 0.617755115032196\n",
      "Epoch: 2774, Train Loss: 0.3892243206501007, Valid Loss: 0.6281612515449524\n",
      "Epoch: 2775, Train Loss: 0.389219731092453, Valid Loss: 0.6181042790412903\n",
      "Epoch: 2776, Train Loss: 0.38921523094177246, Valid Loss: 0.6276904940605164\n",
      "Epoch: 2777, Train Loss: 0.38920989632606506, Valid Loss: 0.6187560558319092\n",
      "Epoch: 2778, Train Loss: 0.3892053961753845, Valid Loss: 0.6269896030426025\n",
      "Epoch: 2779, Train Loss: 0.38920047879219055, Valid Loss: 0.6195915937423706\n",
      "Epoch: 2780, Train Loss: 0.3891960084438324, Valid Loss: 0.6261776089668274\n",
      "Epoch: 2781, Train Loss: 0.3891923427581787, Valid Loss: 0.6204949021339417\n",
      "Epoch: 2782, Train Loss: 0.38918831944465637, Valid Loss: 0.6253603100776672\n",
      "Epoch: 2783, Train Loss: 0.38918501138687134, Valid Loss: 0.6213405132293701\n",
      "Epoch: 2784, Train Loss: 0.38918155431747437, Valid Loss: 0.6246384978294373\n",
      "Epoch: 2785, Train Loss: 0.3891782760620117, Valid Loss: 0.6220643520355225\n",
      "Epoch: 2786, Train Loss: 0.3891756236553192, Valid Loss: 0.6240749359130859\n",
      "Epoch: 2787, Train Loss: 0.3891730308532715, Valid Loss: 0.6226100325584412\n",
      "Epoch: 2788, Train Loss: 0.3891703486442566, Valid Loss: 0.6236826181411743\n",
      "Epoch: 2789, Train Loss: 0.38916802406311035, Valid Loss: 0.6230040192604065\n",
      "Epoch: 2790, Train Loss: 0.389165461063385, Valid Loss: 0.6234287023544312\n",
      "Epoch: 2791, Train Loss: 0.38916289806365967, Valid Loss: 0.6232717037200928\n",
      "Epoch: 2792, Train Loss: 0.38916051387786865, Valid Loss: 0.623282790184021\n",
      "Epoch: 2793, Train Loss: 0.3891580104827881, Valid Loss: 0.6234455108642578\n",
      "Epoch: 2794, Train Loss: 0.38915562629699707, Valid Loss: 0.6232120394706726\n",
      "Epoch: 2795, Train Loss: 0.38915321230888367, Valid Loss: 0.6235695481300354\n",
      "Epoch: 2796, Train Loss: 0.38915079832077026, Valid Loss: 0.623185396194458\n",
      "Epoch: 2797, Train Loss: 0.3891482949256897, Valid Loss: 0.6236582398414612\n",
      "Epoch: 2798, Train Loss: 0.38914576172828674, Valid Loss: 0.6231757402420044\n",
      "Epoch: 2799, Train Loss: 0.3891434967517853, Valid Loss: 0.6237489581108093\n",
      "Epoch: 2800, Train Loss: 0.38914117217063904, Valid Loss: 0.623135507106781\n",
      "Epoch: 2801, Train Loss: 0.3891385793685913, Valid Loss: 0.6238876581192017\n",
      "Epoch: 2802, Train Loss: 0.38913631439208984, Valid Loss: 0.623043954372406\n",
      "Epoch: 2803, Train Loss: 0.38913413882255554, Valid Loss: 0.6241057515144348\n",
      "Epoch: 2804, Train Loss: 0.389132022857666, Valid Loss: 0.6228338479995728\n",
      "Epoch: 2805, Train Loss: 0.38912972807884216, Valid Loss: 0.6244711875915527\n",
      "Epoch: 2806, Train Loss: 0.38912805914878845, Valid Loss: 0.622427225112915\n",
      "Epoch: 2807, Train Loss: 0.3891262412071228, Valid Loss: 0.6250944137573242\n",
      "Epoch: 2808, Train Loss: 0.38912537693977356, Valid Loss: 0.621677815914154\n",
      "Epoch: 2809, Train Loss: 0.38912591338157654, Valid Loss: 0.6261910796165466\n",
      "Epoch: 2810, Train Loss: 0.3891284763813019, Valid Loss: 0.6202792525291443\n",
      "Epoch: 2811, Train Loss: 0.3891349136829376, Valid Loss: 0.6282011866569519\n",
      "Epoch: 2812, Train Loss: 0.38914886116981506, Valid Loss: 0.6176581382751465\n",
      "Epoch: 2813, Train Loss: 0.3891725242137909, Valid Loss: 0.6318888068199158\n",
      "Epoch: 2814, Train Loss: 0.3892126679420471, Valid Loss: 0.6129292249679565\n",
      "Epoch: 2815, Train Loss: 0.38926804065704346, Valid Loss: 0.6382108926773071\n",
      "Epoch: 2816, Train Loss: 0.38933655619621277, Valid Loss: 0.6057359576225281\n",
      "Epoch: 2817, Train Loss: 0.3894365429878235, Valid Loss: 0.6461407542228699\n",
      "Epoch: 2818, Train Loss: 0.38950327038764954, Valid Loss: 0.5990597009658813\n",
      "Epoch: 2819, Train Loss: 0.3895532488822937, Valid Loss: 0.649698793888092\n",
      "Epoch: 2820, Train Loss: 0.38943761587142944, Valid Loss: 0.6018689870834351\n",
      "Epoch: 2821, Train Loss: 0.3892620801925659, Valid Loss: 0.6393759846687317\n",
      "Epoch: 2822, Train Loss: 0.3891110420227051, Valid Loss: 0.6185453534126282\n",
      "Epoch: 2823, Train Loss: 0.3891076445579529, Valid Loss: 0.6192548871040344\n",
      "Epoch: 2824, Train Loss: 0.3892055153846741, Valid Loss: 0.6364374756813049\n",
      "Epoch: 2825, Train Loss: 0.38927769660949707, Valid Loss: 0.6065759062767029\n",
      "Epoch: 2826, Train Loss: 0.38927486538887024, Valid Loss: 0.640778124332428\n",
      "Epoch: 2827, Train Loss: 0.3891824185848236, Valid Loss: 0.6113333702087402\n",
      "Epoch: 2828, Train Loss: 0.3891031742095947, Valid Loss: 0.6284942626953125\n",
      "Epoch: 2829, Train Loss: 0.38909921050071716, Valid Loss: 0.6276096105575562\n",
      "Epoch: 2830, Train Loss: 0.38913580775260925, Valid Loss: 0.6147400140762329\n",
      "Epoch: 2831, Train Loss: 0.38916298747062683, Valid Loss: 0.6357458233833313\n",
      "Epoch: 2832, Train Loss: 0.38915392756462097, Valid Loss: 0.6136478185653687\n",
      "Epoch: 2833, Train Loss: 0.38911792635917664, Valid Loss: 0.6305933594703674\n",
      "Epoch: 2834, Train Loss: 0.389077365398407, Valid Loss: 0.6228612661361694\n",
      "Epoch: 2835, Train Loss: 0.3890754282474518, Valid Loss: 0.6197885274887085\n",
      "Epoch: 2836, Train Loss: 0.3891022801399231, Valid Loss: 0.6308530569076538\n",
      "Epoch: 2837, Train Loss: 0.38912007212638855, Valid Loss: 0.6156966686248779\n",
      "Epoch: 2838, Train Loss: 0.38910073041915894, Valid Loss: 0.6313912272453308\n",
      "Epoch: 2839, Train Loss: 0.3890642523765564, Valid Loss: 0.619976818561554\n",
      "Epoch: 2840, Train Loss: 0.3890530467033386, Valid Loss: 0.6235166788101196\n",
      "Epoch: 2841, Train Loss: 0.38906967639923096, Valid Loss: 0.6285557746887207\n",
      "Epoch: 2842, Train Loss: 0.38907718658447266, Valid Loss: 0.6182438731193542\n",
      "Epoch: 2843, Train Loss: 0.3890708088874817, Valid Loss: 0.6301767826080322\n",
      "Epoch: 2844, Train Loss: 0.38905850052833557, Valid Loss: 0.6194297671318054\n",
      "Epoch: 2845, Train Loss: 0.3890463709831238, Valid Loss: 0.6260002851486206\n",
      "Epoch: 2846, Train Loss: 0.38904139399528503, Valid Loss: 0.6254021525382996\n",
      "Epoch: 2847, Train Loss: 0.38904523849487305, Valid Loss: 0.6202355027198792\n",
      "Epoch: 2848, Train Loss: 0.38905012607574463, Valid Loss: 0.6290733218193054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2849, Train Loss: 0.38904696702957153, Valid Loss: 0.619483470916748\n",
      "Epoch: 2850, Train Loss: 0.3890353739261627, Valid Loss: 0.6273786425590515\n",
      "Epoch: 2851, Train Loss: 0.3890259265899658, Valid Loss: 0.6236246228218079\n",
      "Epoch: 2852, Train Loss: 0.38902726769447327, Valid Loss: 0.6224018335342407\n",
      "Epoch: 2853, Train Loss: 0.38903021812438965, Valid Loss: 0.6277464032173157\n",
      "Epoch: 2854, Train Loss: 0.3890288174152374, Valid Loss: 0.6206212043762207\n",
      "Epoch: 2855, Train Loss: 0.38902395963668823, Valid Loss: 0.6273566484451294\n",
      "Epoch: 2856, Train Loss: 0.3890184462070465, Valid Loss: 0.6225114464759827\n",
      "Epoch: 2857, Train Loss: 0.3890145719051361, Valid Loss: 0.6245157122612\n",
      "Epoch: 2858, Train Loss: 0.38901254534721375, Valid Loss: 0.6256992220878601\n",
      "Epoch: 2859, Train Loss: 0.38901177048683167, Valid Loss: 0.6220722794532776\n",
      "Epoch: 2860, Train Loss: 0.3890116512775421, Valid Loss: 0.6269516348838806\n",
      "Epoch: 2861, Train Loss: 0.3890092074871063, Valid Loss: 0.6221703886985779\n",
      "Epoch: 2862, Train Loss: 0.38900426030158997, Valid Loss: 0.6259795427322388\n",
      "Epoch: 2863, Train Loss: 0.38899996876716614, Valid Loss: 0.6241073608398438\n",
      "Epoch: 2864, Train Loss: 0.3889981508255005, Valid Loss: 0.6237470507621765\n",
      "Epoch: 2865, Train Loss: 0.38899776339530945, Valid Loss: 0.6259104013442993\n",
      "Epoch: 2866, Train Loss: 0.388996422290802, Valid Loss: 0.6228138208389282\n",
      "Epoch: 2867, Train Loss: 0.38899365067481995, Valid Loss: 0.6263324022293091\n",
      "Epoch: 2868, Train Loss: 0.3889903426170349, Valid Loss: 0.6229868531227112\n",
      "Epoch: 2869, Train Loss: 0.3889877498149872, Valid Loss: 0.6254266500473022\n",
      "Epoch: 2870, Train Loss: 0.388985276222229, Valid Loss: 0.6246861815452576\n",
      "Epoch: 2871, Train Loss: 0.3889833688735962, Valid Loss: 0.6238324642181396\n",
      "Epoch: 2872, Train Loss: 0.38898158073425293, Valid Loss: 0.6259341835975647\n",
      "Epoch: 2873, Train Loss: 0.388979971408844, Valid Loss: 0.6231762170791626\n",
      "Epoch: 2874, Train Loss: 0.38897770643234253, Valid Loss: 0.6260942220687866\n",
      "Epoch: 2875, Train Loss: 0.3889749050140381, Valid Loss: 0.6237440705299377\n",
      "Epoch: 2876, Train Loss: 0.3889721632003784, Valid Loss: 0.6250001788139343\n",
      "Epoch: 2877, Train Loss: 0.3889700174331665, Valid Loss: 0.6249801516532898\n",
      "Epoch: 2878, Train Loss: 0.3889686167240143, Valid Loss: 0.6240452527999878\n",
      "Epoch: 2879, Train Loss: 0.3889665901660919, Valid Loss: 0.6257664561271667\n",
      "Epoch: 2880, Train Loss: 0.3889644742012024, Valid Loss: 0.6236720085144043\n",
      "Epoch: 2881, Train Loss: 0.38896244764328003, Valid Loss: 0.6257758140563965\n",
      "Epoch: 2882, Train Loss: 0.3889597952365875, Valid Loss: 0.6242736577987671\n",
      "Epoch: 2883, Train Loss: 0.38895753026008606, Valid Loss: 0.6250637769699097\n",
      "Epoch: 2884, Train Loss: 0.3889552354812622, Valid Loss: 0.6249895095825195\n",
      "Epoch: 2885, Train Loss: 0.3889535367488861, Valid Loss: 0.6245291233062744\n",
      "Epoch: 2886, Train Loss: 0.38895121216773987, Valid Loss: 0.6254639625549316\n",
      "Epoch: 2887, Train Loss: 0.38894951343536377, Valid Loss: 0.6242648959159851\n",
      "Epoch: 2888, Train Loss: 0.38894742727279663, Valid Loss: 0.6255507469177246\n",
      "Epoch: 2889, Train Loss: 0.38894546031951904, Valid Loss: 0.6244234442710876\n",
      "Epoch: 2890, Train Loss: 0.38894325494766235, Valid Loss: 0.6253905296325684\n",
      "Epoch: 2891, Train Loss: 0.3889410197734833, Valid Loss: 0.6247614622116089\n",
      "Epoch: 2892, Train Loss: 0.3889389932155609, Valid Loss: 0.6250474452972412\n",
      "Epoch: 2893, Train Loss: 0.38893720507621765, Valid Loss: 0.625207245349884\n",
      "Epoch: 2894, Train Loss: 0.38893502950668335, Valid Loss: 0.6247642040252686\n",
      "Epoch: 2895, Train Loss: 0.3889329135417938, Valid Loss: 0.6254941821098328\n",
      "Epoch: 2896, Train Loss: 0.388931006193161, Valid Loss: 0.6245958805084229\n",
      "Epoch: 2897, Train Loss: 0.38892892003059387, Valid Loss: 0.6256327629089355\n",
      "Epoch: 2898, Train Loss: 0.3889268636703491, Valid Loss: 0.6246911883354187\n",
      "Epoch: 2899, Train Loss: 0.38892480731010437, Valid Loss: 0.6254749894142151\n",
      "Epoch: 2900, Train Loss: 0.38892287015914917, Valid Loss: 0.6249858140945435\n",
      "Epoch: 2901, Train Loss: 0.38892078399658203, Valid Loss: 0.6252010464668274\n",
      "Epoch: 2902, Train Loss: 0.38891899585723877, Valid Loss: 0.6253654360771179\n",
      "Epoch: 2903, Train Loss: 0.38891661167144775, Valid Loss: 0.6249499917030334\n",
      "Epoch: 2904, Train Loss: 0.3889148235321045, Valid Loss: 0.6255760192871094\n",
      "Epoch: 2905, Train Loss: 0.3889128267765045, Valid Loss: 0.6249108910560608\n",
      "Epoch: 2906, Train Loss: 0.38891077041625977, Valid Loss: 0.6256442666053772\n",
      "Epoch: 2907, Train Loss: 0.38890892267227173, Valid Loss: 0.6249765753746033\n",
      "Epoch: 2908, Train Loss: 0.3889065682888031, Valid Loss: 0.6255678534507751\n",
      "Epoch: 2909, Train Loss: 0.38890478014945984, Valid Loss: 0.6251794099807739\n",
      "Epoch: 2910, Train Loss: 0.3889029324054718, Valid Loss: 0.6254597902297974\n",
      "Epoch: 2911, Train Loss: 0.3889008164405823, Valid Loss: 0.6253195405006409\n",
      "Epoch: 2912, Train Loss: 0.3888987898826599, Valid Loss: 0.6254033446311951\n",
      "Epoch: 2913, Train Loss: 0.3888969123363495, Valid Loss: 0.6254581212997437\n",
      "Epoch: 2914, Train Loss: 0.3888949453830719, Valid Loss: 0.625364363193512\n",
      "Epoch: 2915, Train Loss: 0.3888930082321167, Valid Loss: 0.6255386471748352\n",
      "Epoch: 2916, Train Loss: 0.38889098167419434, Valid Loss: 0.6253583431243896\n",
      "Epoch: 2917, Train Loss: 0.38888922333717346, Valid Loss: 0.625629186630249\n",
      "Epoch: 2918, Train Loss: 0.3888871967792511, Valid Loss: 0.625342607498169\n",
      "Epoch: 2919, Train Loss: 0.38888517022132874, Valid Loss: 0.625694751739502\n",
      "Epoch: 2920, Train Loss: 0.3888833224773407, Valid Loss: 0.6253563165664673\n",
      "Epoch: 2921, Train Loss: 0.38888126611709595, Valid Loss: 0.6257714033126831\n",
      "Epoch: 2922, Train Loss: 0.3888793885707855, Valid Loss: 0.6253575682640076\n",
      "Epoch: 2923, Train Loss: 0.38887688517570496, Valid Loss: 0.6258206367492676\n",
      "Epoch: 2924, Train Loss: 0.3888753652572632, Valid Loss: 0.6254092454910278\n",
      "Epoch: 2925, Train Loss: 0.38887345790863037, Valid Loss: 0.6258371472358704\n",
      "Epoch: 2926, Train Loss: 0.38887155055999756, Valid Loss: 0.6254639625549316\n",
      "Epoch: 2927, Train Loss: 0.3888698220252991, Valid Loss: 0.6258431673049927\n",
      "Epoch: 2928, Train Loss: 0.3888678252696991, Valid Loss: 0.6255305409431458\n",
      "Epoch: 2929, Train Loss: 0.38886597752571106, Valid Loss: 0.6258518099784851\n",
      "Epoch: 2930, Train Loss: 0.38886404037475586, Valid Loss: 0.6255882382392883\n",
      "Epoch: 2931, Train Loss: 0.3888622522354126, Valid Loss: 0.6258724331855774\n",
      "Epoch: 2932, Train Loss: 0.3888600766658783, Valid Loss: 0.6256270408630371\n",
      "Epoch: 2933, Train Loss: 0.3888583481311798, Valid Loss: 0.6259351372718811\n",
      "Epoch: 2934, Train Loss: 0.38885632157325745, Valid Loss: 0.6256265044212341\n",
      "Epoch: 2935, Train Loss: 0.3888545632362366, Valid Loss: 0.6260198950767517\n",
      "Epoch: 2936, Train Loss: 0.3888530433177948, Valid Loss: 0.6255996227264404\n",
      "Epoch: 2937, Train Loss: 0.38885077834129333, Valid Loss: 0.6261327862739563\n",
      "Epoch: 2938, Train Loss: 0.3888486921787262, Valid Loss: 0.625529408454895\n",
      "Epoch: 2939, Train Loss: 0.38884711265563965, Valid Loss: 0.6262994408607483\n",
      "Epoch: 2940, Train Loss: 0.388845294713974, Valid Loss: 0.6254061460494995\n",
      "Epoch: 2941, Train Loss: 0.3888435959815979, Valid Loss: 0.6265442967414856\n",
      "Epoch: 2942, Train Loss: 0.3888418972492218, Valid Loss: 0.6251787543296814\n",
      "Epoch: 2943, Train Loss: 0.38884037733078003, Valid Loss: 0.6269135475158691\n",
      "Epoch: 2944, Train Loss: 0.3888389468193054, Valid Loss: 0.6247985363006592\n",
      "Epoch: 2945, Train Loss: 0.38883790373802185, Valid Loss: 0.6274911761283875\n",
      "Epoch: 2946, Train Loss: 0.38883739709854126, Valid Loss: 0.624107837677002\n",
      "Epoch: 2947, Train Loss: 0.38883814215660095, Valid Loss: 0.6285097002983093\n",
      "Epoch: 2948, Train Loss: 0.38884076476097107, Valid Loss: 0.6228452920913696\n",
      "Epoch: 2949, Train Loss: 0.3888463079929352, Valid Loss: 0.630292534828186\n",
      "Epoch: 2950, Train Loss: 0.38885733485221863, Valid Loss: 0.6205810904502869\n",
      "Epoch: 2951, Train Loss: 0.3888755142688751, Valid Loss: 0.6334524750709534\n",
      "Epoch: 2952, Train Loss: 0.3889048099517822, Valid Loss: 0.6166571378707886\n",
      "Epoch: 2953, Train Loss: 0.388945072889328, Valid Loss: 0.6386576294898987\n",
      "Epoch: 2954, Train Loss: 0.38899320363998413, Valid Loss: 0.6107784509658813\n",
      "Epoch: 2955, Train Loss: 0.3890579342842102, Valid Loss: 0.6453573107719421\n",
      "Epoch: 2956, Train Loss: 0.3891087472438812, Valid Loss: 0.6046876311302185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2957, Train Loss: 0.38915953040122986, Valid Loss: 0.6496840715408325\n",
      "Epoch: 2958, Train Loss: 0.3891143798828125, Valid Loss: 0.6043321490287781\n",
      "Epoch: 2959, Train Loss: 0.3890237808227539, Valid Loss: 0.6447837352752686\n",
      "Epoch: 2960, Train Loss: 0.3888933062553406, Valid Loss: 0.6148577332496643\n",
      "Epoch: 2961, Train Loss: 0.38881707191467285, Valid Loss: 0.6297719478607178\n",
      "Epoch: 2962, Train Loss: 0.38882073760032654, Valid Loss: 0.6305431127548218\n",
      "Epoch: 2963, Train Loss: 0.38887467980384827, Valid Loss: 0.6156272292137146\n",
      "Epoch: 2964, Train Loss: 0.38892996311187744, Valid Loss: 0.6403186321258545\n",
      "Epoch: 2965, Train Loss: 0.38893646001815796, Valid Loss: 0.6113116145133972\n",
      "Epoch: 2966, Train Loss: 0.3889060914516449, Valid Loss: 0.6388536691665649\n",
      "Epoch: 2967, Train Loss: 0.38885173201560974, Valid Loss: 0.6185572743415833\n",
      "Epoch: 2968, Train Loss: 0.38881027698516846, Valid Loss: 0.6287674903869629\n",
      "Epoch: 2969, Train Loss: 0.38880228996276855, Valid Loss: 0.6296328902244568\n",
      "Epoch: 2970, Train Loss: 0.38882461190223694, Valid Loss: 0.6191442608833313\n",
      "Epoch: 2971, Train Loss: 0.388853520154953, Valid Loss: 0.6357805728912354\n",
      "Epoch: 2972, Train Loss: 0.3888581395149231, Valid Loss: 0.6170491576194763\n",
      "Epoch: 2973, Train Loss: 0.388832688331604, Valid Loss: 0.6339602470397949\n",
      "Epoch: 2974, Train Loss: 0.3887985646724701, Valid Loss: 0.6218138337135315\n",
      "Epoch: 2975, Train Loss: 0.388783723115921, Valid Loss: 0.6267584562301636\n",
      "Epoch: 2976, Train Loss: 0.38879165053367615, Valid Loss: 0.6294235587120056\n",
      "Epoch: 2977, Train Loss: 0.38880687952041626, Valid Loss: 0.6209167242050171\n",
      "Epoch: 2978, Train Loss: 0.3888120651245117, Valid Loss: 0.6335127353668213\n",
      "Epoch: 2979, Train Loss: 0.3888034522533417, Valid Loss: 0.6198187470436096\n",
      "Epoch: 2980, Train Loss: 0.3887898027896881, Valid Loss: 0.6314749717712402\n",
      "Epoch: 2981, Train Loss: 0.38877806067466736, Valid Loss: 0.6242676377296448\n",
      "Epoch: 2982, Train Loss: 0.38877299427986145, Valid Loss: 0.6259257793426514\n",
      "Epoch: 2983, Train Loss: 0.3887757956981659, Valid Loss: 0.6295737624168396\n",
      "Epoch: 2984, Train Loss: 0.3887816369533539, Valid Loss: 0.6216309070587158\n",
      "Epoch: 2985, Train Loss: 0.3887843191623688, Valid Loss: 0.6319761276245117\n",
      "Epoch: 2986, Train Loss: 0.3887786865234375, Valid Loss: 0.6217983961105347\n",
      "Epoch: 2987, Train Loss: 0.38876885175704956, Valid Loss: 0.6298694014549255\n",
      "Epoch: 2988, Train Loss: 0.38876137137413025, Valid Loss: 0.6254689693450928\n",
      "Epoch: 2989, Train Loss: 0.3887597620487213, Valid Loss: 0.6257838606834412\n",
      "Epoch: 2990, Train Loss: 0.38876163959503174, Valid Loss: 0.6293280720710754\n",
      "Epoch: 2991, Train Loss: 0.3887631893157959, Valid Loss: 0.6230950355529785\n",
      "Epoch: 2992, Train Loss: 0.38876208662986755, Valid Loss: 0.6303812265396118\n",
      "Epoch: 2993, Train Loss: 0.3887585997581482, Valid Loss: 0.6235439777374268\n",
      "Epoch: 2994, Train Loss: 0.38875412940979004, Valid Loss: 0.628896176815033\n",
      "Epoch: 2995, Train Loss: 0.38875025510787964, Valid Loss: 0.6258181929588318\n",
      "Epoch: 2996, Train Loss: 0.3887472450733185, Valid Loss: 0.6264595985412598\n",
      "Epoch: 2997, Train Loss: 0.38874635100364685, Valid Loss: 0.6281750202178955\n",
      "Epoch: 2998, Train Loss: 0.3887460231781006, Valid Loss: 0.6248255372047424\n",
      "Epoch: 2999, Train Loss: 0.38874614238739014, Valid Loss: 0.6291984915733337\n",
      "Epoch: 3000, Train Loss: 0.3887442648410797, Valid Loss: 0.6245675683021545\n",
      "Epoch: 3001, Train Loss: 0.388741672039032, Valid Loss: 0.6288444399833679\n",
      "Epoch: 3002, Train Loss: 0.38873791694641113, Valid Loss: 0.6255396604537964\n",
      "Epoch: 3003, Train Loss: 0.38873520493507385, Valid Loss: 0.6275127530097961\n",
      "Epoch: 3004, Train Loss: 0.3887336552143097, Valid Loss: 0.627016544342041\n",
      "Epoch: 3005, Train Loss: 0.38873255252838135, Valid Loss: 0.6261904835700989\n",
      "Epoch: 3006, Train Loss: 0.38873159885406494, Valid Loss: 0.6282796263694763\n",
      "Epoch: 3007, Train Loss: 0.38873031735420227, Valid Loss: 0.6253588199615479\n",
      "Epoch: 3008, Train Loss: 0.38872867822647095, Valid Loss: 0.6287557482719421\n",
      "Epoch: 3009, Train Loss: 0.3887266516685486, Valid Loss: 0.625454843044281\n",
      "Epoch: 3010, Train Loss: 0.38872453570365906, Valid Loss: 0.6283432245254517\n",
      "Epoch: 3011, Train Loss: 0.38872218132019043, Valid Loss: 0.6262701153755188\n",
      "Epoch: 3012, Train Loss: 0.3887200355529785, Valid Loss: 0.6273406744003296\n",
      "Epoch: 3013, Train Loss: 0.38871851563453674, Valid Loss: 0.627373993396759\n",
      "Epoch: 3014, Train Loss: 0.3887169361114502, Valid Loss: 0.6264147162437439\n",
      "Epoch: 3015, Train Loss: 0.388715922832489, Valid Loss: 0.6281500458717346\n",
      "Epoch: 3016, Train Loss: 0.3887144923210144, Valid Loss: 0.6259563565254211\n",
      "Epoch: 3017, Train Loss: 0.38871288299560547, Valid Loss: 0.6284034848213196\n",
      "Epoch: 3018, Train Loss: 0.38871124386787415, Valid Loss: 0.6260988712310791\n",
      "Epoch: 3019, Train Loss: 0.388709157705307, Valid Loss: 0.6281165480613708\n",
      "Epoch: 3020, Train Loss: 0.3887075185775757, Valid Loss: 0.6266172528266907\n",
      "Epoch: 3021, Train Loss: 0.3887057602405548, Valid Loss: 0.6276078224182129\n",
      "Epoch: 3022, Train Loss: 0.3887040913105011, Valid Loss: 0.6272140741348267\n",
      "Epoch: 3023, Train Loss: 0.38870248198509216, Valid Loss: 0.6271163821220398\n",
      "Epoch: 3024, Train Loss: 0.38870078325271606, Valid Loss: 0.6276649236679077\n",
      "Epoch: 3025, Train Loss: 0.3886992037296295, Valid Loss: 0.6268361210823059\n",
      "Epoch: 3026, Train Loss: 0.3886978030204773, Valid Loss: 0.6279349327087402\n",
      "Epoch: 3027, Train Loss: 0.38869619369506836, Valid Loss: 0.6267220377922058\n",
      "Epoch: 3028, Train Loss: 0.38869476318359375, Valid Loss: 0.6280577182769775\n",
      "Epoch: 3029, Train Loss: 0.38869309425354004, Valid Loss: 0.6267427802085876\n",
      "Epoch: 3030, Train Loss: 0.3886914551258087, Valid Loss: 0.6280839443206787\n",
      "Epoch: 3031, Train Loss: 0.38869011402130127, Valid Loss: 0.6268168091773987\n",
      "Epoch: 3032, Train Loss: 0.3886881172657013, Valid Loss: 0.6280359625816345\n",
      "Epoch: 3033, Train Loss: 0.38868653774261475, Valid Loss: 0.6269620656967163\n",
      "Epoch: 3034, Train Loss: 0.38868486881256104, Valid Loss: 0.6279449462890625\n",
      "Epoch: 3035, Train Loss: 0.3886832594871521, Valid Loss: 0.6271436810493469\n",
      "Epoch: 3036, Train Loss: 0.38868167996406555, Valid Loss: 0.6278077363967896\n",
      "Epoch: 3037, Train Loss: 0.38867995142936707, Valid Loss: 0.6273891925811768\n",
      "Epoch: 3038, Train Loss: 0.38867834210395813, Valid Loss: 0.6276475787162781\n",
      "Epoch: 3039, Train Loss: 0.38867685198783875, Valid Loss: 0.6276132464408875\n",
      "Epoch: 3040, Train Loss: 0.3886752724647522, Valid Loss: 0.6274974942207336\n",
      "Epoch: 3041, Train Loss: 0.38867366313934326, Valid Loss: 0.6278257369995117\n",
      "Epoch: 3042, Train Loss: 0.38867226243019104, Valid Loss: 0.6273812055587769\n",
      "Epoch: 3043, Train Loss: 0.3886709213256836, Valid Loss: 0.6279726624488831\n",
      "Epoch: 3044, Train Loss: 0.3886692225933075, Valid Loss: 0.6273283958435059\n",
      "Epoch: 3045, Train Loss: 0.3886679410934448, Valid Loss: 0.6280958652496338\n",
      "Epoch: 3046, Train Loss: 0.38866618275642395, Valid Loss: 0.6272885203361511\n",
      "Epoch: 3047, Train Loss: 0.3886643648147583, Valid Loss: 0.6281981468200684\n",
      "Epoch: 3048, Train Loss: 0.38866329193115234, Valid Loss: 0.6272649765014648\n",
      "Epoch: 3049, Train Loss: 0.38866156339645386, Valid Loss: 0.6283179521560669\n",
      "Epoch: 3050, Train Loss: 0.3886603116989136, Valid Loss: 0.6271789073944092\n",
      "Epoch: 3051, Train Loss: 0.3886588215827942, Valid Loss: 0.6285267472267151\n",
      "Epoch: 3052, Train Loss: 0.38865718245506287, Valid Loss: 0.6269856095314026\n",
      "Epoch: 3053, Train Loss: 0.38865628838539124, Valid Loss: 0.6288542151451111\n",
      "Epoch: 3054, Train Loss: 0.3886551558971405, Valid Loss: 0.6266568899154663\n",
      "Epoch: 3055, Train Loss: 0.3886541426181793, Valid Loss: 0.6293549537658691\n",
      "Epoch: 3056, Train Loss: 0.38865384459495544, Valid Loss: 0.6260972023010254\n",
      "Epoch: 3057, Train Loss: 0.3886539340019226, Valid Loss: 0.6301730871200562\n",
      "Epoch: 3058, Train Loss: 0.38865530490875244, Valid Loss: 0.6251318454742432\n",
      "Epoch: 3059, Train Loss: 0.38865742087364197, Valid Loss: 0.631507933139801\n",
      "Epoch: 3060, Train Loss: 0.38866251707077026, Valid Loss: 0.6235321164131165\n",
      "Epoch: 3061, Train Loss: 0.3886711597442627, Valid Loss: 0.6336813569068909\n",
      "Epoch: 3062, Train Loss: 0.38868555426597595, Valid Loss: 0.6208877563476562\n",
      "Epoch: 3063, Train Loss: 0.38870736956596375, Valid Loss: 0.637185275554657\n",
      "Epoch: 3064, Train Loss: 0.38873806595802307, Valid Loss: 0.6168029308319092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3065, Train Loss: 0.3887787163257599, Valid Loss: 0.6422688364982605\n",
      "Epoch: 3066, Train Loss: 0.38882237672805786, Valid Loss: 0.6114975810050964\n",
      "Epoch: 3067, Train Loss: 0.3888748288154602, Valid Loss: 0.6477511525154114\n",
      "Epoch: 3068, Train Loss: 0.38890042901039124, Valid Loss: 0.6072948575019836\n",
      "Epoch: 3069, Train Loss: 0.3889116048812866, Valid Loss: 0.6496884822845459\n",
      "Epoch: 3070, Train Loss: 0.38885167241096497, Valid Loss: 0.6091583967208862\n",
      "Epoch: 3071, Train Loss: 0.3887682557106018, Valid Loss: 0.6433426141738892\n",
      "Epoch: 3072, Train Loss: 0.3886764645576477, Valid Loss: 0.6193590760231018\n",
      "Epoch: 3073, Train Loss: 0.38862958550453186, Valid Loss: 0.630262017250061\n",
      "Epoch: 3074, Train Loss: 0.3886367678642273, Valid Loss: 0.6323657035827637\n",
      "Epoch: 3075, Train Loss: 0.38867732882499695, Valid Loss: 0.6186650991439819\n",
      "Epoch: 3076, Train Loss: 0.38871967792510986, Valid Loss: 0.640724778175354\n",
      "Epoch: 3077, Train Loss: 0.3887309730052948, Valid Loss: 0.614572286605835\n",
      "Epoch: 3078, Train Loss: 0.38871505856513977, Valid Loss: 0.6405486464500427\n",
      "Epoch: 3079, Train Loss: 0.3886759877204895, Valid Loss: 0.6194156408309937\n",
      "Epoch: 3080, Train Loss: 0.3886384963989258, Valid Loss: 0.6329973936080933\n",
      "Epoch: 3081, Train Loss: 0.38861969113349915, Valid Loss: 0.6284868717193604\n",
      "Epoch: 3082, Train Loss: 0.38862383365631104, Valid Loss: 0.6241304874420166\n",
      "Epoch: 3083, Train Loss: 0.38864320516586304, Valid Loss: 0.6352462768554688\n",
      "Epoch: 3084, Train Loss: 0.3886599540710449, Valid Loss: 0.6198034882545471\n",
      "Epoch: 3085, Train Loss: 0.38866278529167175, Valid Loss: 0.6366856098175049\n",
      "Epoch: 3086, Train Loss: 0.38864752650260925, Valid Loss: 0.6211684942245483\n",
      "Epoch: 3087, Train Loss: 0.38862428069114685, Valid Loss: 0.6331419944763184\n",
      "Epoch: 3088, Train Loss: 0.3886074125766754, Valid Loss: 0.626343846321106\n",
      "Epoch: 3089, Train Loss: 0.3886048495769501, Valid Loss: 0.6275256276130676\n",
      "Epoch: 3090, Train Loss: 0.3886130750179291, Valid Loss: 0.6319040656089783\n",
      "Epoch: 3091, Train Loss: 0.38862207531929016, Valid Loss: 0.6232983469963074\n",
      "Epoch: 3092, Train Loss: 0.38862407207489014, Valid Loss: 0.6344769597053528\n",
      "Epoch: 3093, Train Loss: 0.3886185884475708, Valid Loss: 0.6225946545600891\n",
      "Epoch: 3094, Train Loss: 0.388609915971756, Valid Loss: 0.6330599188804626\n",
      "Epoch: 3095, Train Loss: 0.38860082626342773, Valid Loss: 0.6254850029945374\n",
      "Epoch: 3096, Train Loss: 0.38859495520591736, Valid Loss: 0.6293588280677795\n",
      "Epoch: 3097, Train Loss: 0.38859397172927856, Valid Loss: 0.6296542286872864\n",
      "Epoch: 3098, Train Loss: 0.3885963559150696, Valid Loss: 0.625693678855896\n",
      "Epoch: 3099, Train Loss: 0.3885990083217621, Valid Loss: 0.6326132416725159\n",
      "Epoch: 3100, Train Loss: 0.38859978318214417, Valid Loss: 0.6241648197174072\n",
      "Epoch: 3101, Train Loss: 0.3885972499847412, Valid Loss: 0.6327722668647766\n",
      "Epoch: 3102, Train Loss: 0.3885916769504547, Valid Loss: 0.6252902746200562\n",
      "Epoch: 3103, Train Loss: 0.3885861933231354, Valid Loss: 0.6305907964706421\n",
      "Epoch: 3104, Train Loss: 0.38858282566070557, Valid Loss: 0.6280635595321655\n",
      "Epoch: 3105, Train Loss: 0.38858160376548767, Valid Loss: 0.6278064846992493\n",
      "Epoch: 3106, Train Loss: 0.3885820508003235, Valid Loss: 0.6305548548698425\n",
      "Epoch: 3107, Train Loss: 0.38858237862586975, Valid Loss: 0.6261300444602966\n",
      "Epoch: 3108, Train Loss: 0.38858193159103394, Valid Loss: 0.6316030621528625\n",
      "Epoch: 3109, Train Loss: 0.3885805904865265, Valid Loss: 0.6260070204734802\n",
      "Epoch: 3110, Train Loss: 0.3885783851146698, Valid Loss: 0.6311337351799011\n",
      "Epoch: 3111, Train Loss: 0.38857561349868774, Valid Loss: 0.6270086765289307\n",
      "Epoch: 3112, Train Loss: 0.3885727822780609, Valid Loss: 0.6298637986183167\n",
      "Epoch: 3113, Train Loss: 0.3885703980922699, Valid Loss: 0.6284052133560181\n",
      "Epoch: 3114, Train Loss: 0.3885689675807953, Valid Loss: 0.6285297274589539\n",
      "Epoch: 3115, Train Loss: 0.38856780529022217, Valid Loss: 0.6296350955963135\n",
      "Epoch: 3116, Train Loss: 0.38856738805770874, Valid Loss: 0.6276503801345825\n",
      "Epoch: 3117, Train Loss: 0.3885668218135834, Valid Loss: 0.6303585171699524\n",
      "Epoch: 3118, Train Loss: 0.3885657787322998, Valid Loss: 0.6273062229156494\n",
      "Epoch: 3119, Train Loss: 0.3885642886161804, Valid Loss: 0.6305550932884216\n",
      "Epoch: 3120, Train Loss: 0.38856273889541626, Valid Loss: 0.6274237036705017\n",
      "Epoch: 3121, Train Loss: 0.38856062293052673, Valid Loss: 0.6303254961967468\n",
      "Epoch: 3122, Train Loss: 0.3885587751865387, Valid Loss: 0.6278448700904846\n",
      "Epoch: 3123, Train Loss: 0.388557106256485, Valid Loss: 0.6298185586929321\n",
      "Epoch: 3124, Train Loss: 0.38855576515197754, Valid Loss: 0.628521203994751\n",
      "Epoch: 3125, Train Loss: 0.38855430483818054, Valid Loss: 0.629151463508606\n",
      "Epoch: 3126, Train Loss: 0.38855284452438354, Valid Loss: 0.629263162612915\n",
      "Epoch: 3127, Train Loss: 0.3885514736175537, Valid Loss: 0.6285393238067627\n",
      "Epoch: 3128, Train Loss: 0.38855046033859253, Valid Loss: 0.629874587059021\n",
      "Epoch: 3129, Train Loss: 0.38854923844337463, Valid Loss: 0.6281290650367737\n",
      "Epoch: 3130, Train Loss: 0.3885481655597687, Valid Loss: 0.6302210092544556\n",
      "Epoch: 3131, Train Loss: 0.388546884059906, Valid Loss: 0.6279696226119995\n",
      "Epoch: 3132, Train Loss: 0.38854578137397766, Valid Loss: 0.6303389668464661\n",
      "Epoch: 3133, Train Loss: 0.3885442912578583, Valid Loss: 0.6280388832092285\n",
      "Epoch: 3134, Train Loss: 0.3885428011417389, Valid Loss: 0.6302516460418701\n",
      "Epoch: 3135, Train Loss: 0.38854116201400757, Valid Loss: 0.6282538771629333\n",
      "Epoch: 3136, Train Loss: 0.3885398805141449, Valid Loss: 0.6300889849662781\n",
      "Epoch: 3137, Train Loss: 0.3885385990142822, Valid Loss: 0.6284990906715393\n",
      "Epoch: 3138, Train Loss: 0.3885374367237091, Valid Loss: 0.6299241185188293\n",
      "Epoch: 3139, Train Loss: 0.38853541016578674, Valid Loss: 0.6287034153938293\n",
      "Epoch: 3140, Train Loss: 0.38853469491004944, Valid Loss: 0.6298406720161438\n",
      "Epoch: 3141, Train Loss: 0.38853341341018677, Valid Loss: 0.6288142800331116\n",
      "Epoch: 3142, Train Loss: 0.38853201270103455, Valid Loss: 0.6298290491104126\n",
      "Epoch: 3143, Train Loss: 0.3885307312011719, Valid Loss: 0.6288673877716064\n",
      "Epoch: 3144, Train Loss: 0.388528972864151, Valid Loss: 0.6298789978027344\n",
      "Epoch: 3145, Train Loss: 0.3885279893875122, Valid Loss: 0.6288567185401917\n",
      "Epoch: 3146, Train Loss: 0.3885270953178406, Valid Loss: 0.6299935579299927\n",
      "Epoch: 3147, Train Loss: 0.3885258138179779, Valid Loss: 0.6288028955459595\n",
      "Epoch: 3148, Train Loss: 0.3885243237018585, Valid Loss: 0.6301427483558655\n",
      "Epoch: 3149, Train Loss: 0.3885232210159302, Valid Loss: 0.628703773021698\n",
      "Epoch: 3150, Train Loss: 0.3885217607021332, Valid Loss: 0.6303397417068481\n",
      "Epoch: 3151, Train Loss: 0.3885209560394287, Valid Loss: 0.6285508871078491\n",
      "Epoch: 3152, Train Loss: 0.38851994276046753, Valid Loss: 0.630607008934021\n",
      "Epoch: 3153, Train Loss: 0.3885191082954407, Valid Loss: 0.6282800436019897\n",
      "Epoch: 3154, Train Loss: 0.3885180950164795, Valid Loss: 0.6310502886772156\n",
      "Epoch: 3155, Train Loss: 0.3885182738304138, Valid Loss: 0.6277906894683838\n",
      "Epoch: 3156, Train Loss: 0.38851821422576904, Valid Loss: 0.6317712068557739\n",
      "Epoch: 3157, Train Loss: 0.38851937651634216, Valid Loss: 0.6269360780715942\n",
      "Epoch: 3158, Train Loss: 0.3885219395160675, Valid Loss: 0.6329942941665649\n",
      "Epoch: 3159, Train Loss: 0.38852640986442566, Valid Loss: 0.6254571676254272\n",
      "Epoch: 3160, Train Loss: 0.3885348439216614, Valid Loss: 0.6350426077842712\n",
      "Epoch: 3161, Train Loss: 0.3885486125946045, Valid Loss: 0.6229428648948669\n",
      "Epoch: 3162, Train Loss: 0.3885694742202759, Valid Loss: 0.638444721698761\n",
      "Epoch: 3163, Train Loss: 0.3885996341705322, Valid Loss: 0.6189234256744385\n",
      "Epoch: 3164, Train Loss: 0.38863950967788696, Valid Loss: 0.6435777544975281\n",
      "Epoch: 3165, Train Loss: 0.3886847496032715, Valid Loss: 0.6134170293807983\n",
      "Epoch: 3166, Train Loss: 0.3887402415275574, Valid Loss: 0.6495500802993774\n",
      "Epoch: 3167, Train Loss: 0.3887762427330017, Valid Loss: 0.6084116101264954\n",
      "Epoch: 3168, Train Loss: 0.3888035714626312, Valid Loss: 0.6526258587837219\n",
      "Epoch: 3169, Train Loss: 0.38875871896743774, Valid Loss: 0.6089480519294739\n",
      "Epoch: 3170, Train Loss: 0.3886811435222626, Valid Loss: 0.6475082635879517\n",
      "Epoch: 3171, Train Loss: 0.3885759115219116, Valid Loss: 0.6184781193733215\n",
      "Epoch: 3172, Train Loss: 0.388507604598999, Valid Loss: 0.6343061327934265\n",
      "Epoch: 3173, Train Loss: 0.3884984850883484, Valid Loss: 0.6322830319404602\n",
      "Epoch: 3174, Train Loss: 0.3885363042354584, Valid Loss: 0.6213138699531555\n",
      "Epoch: 3175, Train Loss: 0.3885856568813324, Valid Loss: 0.6422759890556335\n",
      "Epoch: 3176, Train Loss: 0.38860762119293213, Valid Loss: 0.6155698895454407\n",
      "Epoch: 3177, Train Loss: 0.3885989189147949, Valid Loss: 0.6434495449066162\n",
      "Epoch: 3178, Train Loss: 0.38855913281440735, Valid Loss: 0.6196141242980957\n",
      "Epoch: 3179, Train Loss: 0.38851892948150635, Valid Loss: 0.6360211968421936\n",
      "Epoch: 3180, Train Loss: 0.38849496841430664, Valid Loss: 0.6292373538017273\n",
      "Epoch: 3181, Train Loss: 0.388494610786438, Valid Loss: 0.6262819170951843\n",
      "Epoch: 3182, Train Loss: 0.38851162791252136, Valid Loss: 0.6368463039398193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3183, Train Loss: 0.38853079080581665, Valid Loss: 0.6211693286895752\n",
      "Epoch: 3184, Train Loss: 0.38853877782821655, Valid Loss: 0.6387603878974915\n",
      "Epoch: 3185, Train Loss: 0.3885270059108734, Valid Loss: 0.6223737597465515\n",
      "Epoch: 3186, Train Loss: 0.3885030746459961, Valid Loss: 0.6353864073753357\n",
      "Epoch: 3187, Train Loss: 0.388482928276062, Valid Loss: 0.6275229454040527\n",
      "Epoch: 3188, Train Loss: 0.3884768486022949, Valid Loss: 0.6295071244239807\n",
      "Epoch: 3189, Train Loss: 0.3884848654270172, Valid Loss: 0.6333475112915039\n",
      "Epoch: 3190, Train Loss: 0.38849616050720215, Valid Loss: 0.6250001192092896\n",
      "Epoch: 3191, Train Loss: 0.38850051164627075, Valid Loss: 0.6362941861152649\n",
      "Epoch: 3192, Train Loss: 0.3884948492050171, Valid Loss: 0.623974084854126\n",
      "Epoch: 3193, Train Loss: 0.38848504424095154, Valid Loss: 0.6349892020225525\n",
      "Epoch: 3194, Train Loss: 0.388475626707077, Valid Loss: 0.6269032955169678\n",
      "Epoch: 3195, Train Loss: 0.3884706497192383, Valid Loss: 0.6312445998191833\n",
      "Epoch: 3196, Train Loss: 0.388469398021698, Valid Loss: 0.631199836730957\n",
      "Epoch: 3197, Train Loss: 0.3884715139865875, Valid Loss: 0.6273816823959351\n",
      "Epoch: 3198, Train Loss: 0.38847464323043823, Valid Loss: 0.634310245513916\n",
      "Epoch: 3199, Train Loss: 0.3884757161140442, Valid Loss: 0.625704824924469\n",
      "Epoch: 3200, Train Loss: 0.3884734511375427, Valid Loss: 0.6345767378807068\n",
      "Epoch: 3201, Train Loss: 0.3884681165218353, Valid Loss: 0.6267402172088623\n",
      "Epoch: 3202, Train Loss: 0.3884623944759369, Valid Loss: 0.6323478817939758\n",
      "Epoch: 3203, Train Loss: 0.3884592652320862, Valid Loss: 0.6297365427017212\n",
      "Epoch: 3204, Train Loss: 0.3884584307670593, Valid Loss: 0.6293083429336548\n",
      "Epoch: 3205, Train Loss: 0.38845962285995483, Valid Loss: 0.6324693560600281\n",
      "Epoch: 3206, Train Loss: 0.38846027851104736, Valid Loss: 0.6274805665016174\n",
      "Epoch: 3207, Train Loss: 0.3884599804878235, Valid Loss: 0.6335180401802063\n",
      "Epoch: 3208, Train Loss: 0.3884583115577698, Valid Loss: 0.6275160312652588\n",
      "Epoch: 3209, Train Loss: 0.38845571875572205, Valid Loss: 0.6327658891677856\n",
      "Epoch: 3210, Train Loss: 0.3884533941745758, Valid Loss: 0.6287832856178284\n",
      "Epoch: 3211, Train Loss: 0.38845106959342957, Valid Loss: 0.6312665343284607\n",
      "Epoch: 3212, Train Loss: 0.38844940066337585, Valid Loss: 0.6303925514221191\n",
      "Epoch: 3213, Train Loss: 0.38844794034957886, Valid Loss: 0.6297820210456848\n",
      "Epoch: 3214, Train Loss: 0.3884471356868744, Valid Loss: 0.6316680312156677\n",
      "Epoch: 3215, Train Loss: 0.3884468078613281, Valid Loss: 0.6289622783660889\n",
      "Epoch: 3216, Train Loss: 0.3884466588497162, Valid Loss: 0.6322806477546692\n",
      "Epoch: 3217, Train Loss: 0.3884456157684326, Valid Loss: 0.6288055181503296\n",
      "Epoch: 3218, Train Loss: 0.3884446620941162, Valid Loss: 0.6322082281112671\n",
      "Epoch: 3219, Train Loss: 0.3884425759315491, Valid Loss: 0.6291813850402832\n",
      "Epoch: 3220, Train Loss: 0.38844066858291626, Valid Loss: 0.6317625641822815\n",
      "Epoch: 3221, Train Loss: 0.3884391188621521, Valid Loss: 0.6297610998153687\n",
      "Epoch: 3222, Train Loss: 0.3884378671646118, Valid Loss: 0.6311323642730713\n",
      "Epoch: 3223, Train Loss: 0.3884366750717163, Valid Loss: 0.6305144429206848\n",
      "Epoch: 3224, Train Loss: 0.3884354531764984, Valid Loss: 0.6304513812065125\n",
      "Epoch: 3225, Train Loss: 0.38843464851379395, Valid Loss: 0.63126540184021\n",
      "Epoch: 3226, Train Loss: 0.3884338140487671, Valid Loss: 0.6298444271087646\n",
      "Epoch: 3227, Train Loss: 0.38843271136283875, Valid Loss: 0.6318264007568359\n",
      "Epoch: 3228, Train Loss: 0.3884319067001343, Valid Loss: 0.6295297741889954\n",
      "Epoch: 3229, Train Loss: 0.3884309232234955, Valid Loss: 0.6320402026176453\n",
      "Epoch: 3230, Train Loss: 0.3884296119213104, Valid Loss: 0.6295181512832642\n",
      "Epoch: 3231, Train Loss: 0.3884284794330597, Valid Loss: 0.6319663524627686\n",
      "Epoch: 3232, Train Loss: 0.3884272575378418, Valid Loss: 0.6297813653945923\n",
      "Epoch: 3233, Train Loss: 0.3884260952472687, Valid Loss: 0.6317098140716553\n",
      "Epoch: 3234, Train Loss: 0.38842466473579407, Valid Loss: 0.6301671862602234\n",
      "Epoch: 3235, Train Loss: 0.3884235918521881, Valid Loss: 0.6313701868057251\n",
      "Epoch: 3236, Train Loss: 0.3884224593639374, Valid Loss: 0.6305918097496033\n",
      "Epoch: 3237, Train Loss: 0.38842132687568665, Valid Loss: 0.6310662627220154\n",
      "Epoch: 3238, Train Loss: 0.388420045375824, Valid Loss: 0.6308865547180176\n",
      "Epoch: 3239, Train Loss: 0.3884192407131195, Valid Loss: 0.6308943033218384\n",
      "Epoch: 3240, Train Loss: 0.38841792941093445, Valid Loss: 0.6310777068138123\n",
      "Epoch: 3241, Train Loss: 0.38841700553894043, Valid Loss: 0.6308102607727051\n",
      "Epoch: 3242, Train Loss: 0.38841602206230164, Valid Loss: 0.6311987638473511\n",
      "Epoch: 3243, Train Loss: 0.3884149491786957, Valid Loss: 0.6307819485664368\n",
      "Epoch: 3244, Train Loss: 0.38841378688812256, Valid Loss: 0.6313024163246155\n",
      "Epoch: 3245, Train Loss: 0.3884128928184509, Valid Loss: 0.6307516694068909\n",
      "Epoch: 3246, Train Loss: 0.38841187953948975, Valid Loss: 0.6314237713813782\n",
      "Epoch: 3247, Train Loss: 0.388410747051239, Valid Loss: 0.6306827664375305\n",
      "Epoch: 3248, Train Loss: 0.3884097933769226, Valid Loss: 0.631594717502594\n",
      "Epoch: 3249, Train Loss: 0.38840875029563904, Valid Loss: 0.6305452585220337\n",
      "Epoch: 3250, Train Loss: 0.38840794563293457, Valid Loss: 0.6318406462669373\n",
      "Epoch: 3251, Train Loss: 0.38840702176094055, Valid Loss: 0.630312979221344\n",
      "Epoch: 3252, Train Loss: 0.38840630650520325, Valid Loss: 0.6322066783905029\n",
      "Epoch: 3253, Train Loss: 0.3884056806564331, Valid Loss: 0.629953145980835\n",
      "Epoch: 3254, Train Loss: 0.3884049355983734, Valid Loss: 0.6327261328697205\n",
      "Epoch: 3255, Train Loss: 0.388404905796051, Valid Loss: 0.6294004321098328\n",
      "Epoch: 3256, Train Loss: 0.3884051442146301, Valid Loss: 0.633500337600708\n",
      "Epoch: 3257, Train Loss: 0.3884061872959137, Valid Loss: 0.6285251379013062\n",
      "Epoch: 3258, Train Loss: 0.38840848207473755, Valid Loss: 0.6346906423568726\n",
      "Epoch: 3259, Train Loss: 0.3884126543998718, Valid Loss: 0.6270989179611206\n",
      "Epoch: 3260, Train Loss: 0.3884198069572449, Valid Loss: 0.6366317272186279\n",
      "Epoch: 3261, Train Loss: 0.3884316384792328, Valid Loss: 0.6247683763504028\n",
      "Epoch: 3262, Train Loss: 0.38845017552375793, Valid Loss: 0.6397609710693359\n",
      "Epoch: 3263, Train Loss: 0.3884780704975128, Valid Loss: 0.6210669875144958\n",
      "Epoch: 3264, Train Loss: 0.3885161280632019, Valid Loss: 0.6445571780204773\n",
      "Epoch: 3265, Train Loss: 0.3885616362094879, Valid Loss: 0.6158486604690552\n",
      "Epoch: 3266, Train Loss: 0.38861557841300964, Valid Loss: 0.6505212187767029\n",
      "Epoch: 3267, Train Loss: 0.38865575194358826, Valid Loss: 0.6105547547340393\n",
      "Epoch: 3268, Train Loss: 0.38869020342826843, Valid Loss: 0.654456615447998\n",
      "Epoch: 3269, Train Loss: 0.3886643350124359, Valid Loss: 0.6096515655517578\n",
      "Epoch: 3270, Train Loss: 0.38860589265823364, Valid Loss: 0.6510923504829407\n",
      "Epoch: 3271, Train Loss: 0.3885045647621155, Valid Loss: 0.6175000071525574\n",
      "Epoch: 3272, Train Loss: 0.38842111825942993, Valid Loss: 0.6390937566757202\n",
      "Epoch: 3273, Train Loss: 0.38838517665863037, Valid Loss: 0.630989670753479\n",
      "Epoch: 3274, Train Loss: 0.3884049355983734, Valid Loss: 0.6253721714019775\n",
      "Epoch: 3275, Train Loss: 0.3884539306163788, Valid Loss: 0.6423794627189636\n",
      "Epoch: 3276, Train Loss: 0.38849180936813354, Valid Loss: 0.6176126003265381\n",
      "Epoch: 3277, Train Loss: 0.38850027322769165, Valid Loss: 0.6459841728210449\n",
      "Epoch: 3278, Train Loss: 0.38847029209136963, Valid Loss: 0.6192190051078796\n",
      "Epoch: 3279, Train Loss: 0.3884289264678955, Valid Loss: 0.6403186917304993\n",
      "Epoch: 3280, Train Loss: 0.3883954882621765, Valid Loss: 0.6281412243843079\n",
      "Epoch: 3281, Train Loss: 0.3883835971355438, Valid Loss: 0.6303128004074097\n",
      "Epoch: 3282, Train Loss: 0.3883930444717407, Valid Loss: 0.6369603872299194\n",
      "Epoch: 3283, Train Loss: 0.38841232657432556, Valid Loss: 0.6233993768692017\n",
      "Epoch: 3284, Train Loss: 0.3884275257587433, Valid Loss: 0.6405884027481079\n",
      "Epoch: 3285, Train Loss: 0.38842785358428955, Valid Loss: 0.6230090856552124\n",
      "Epoch: 3286, Train Loss: 0.3884124159812927, Valid Loss: 0.6386891007423401\n",
      "Epoch: 3287, Train Loss: 0.38838985562324524, Valid Loss: 0.6272629499435425\n",
      "Epoch: 3288, Train Loss: 0.3883732557296753, Valid Loss: 0.6332486271858215\n",
      "Epoch: 3289, Train Loss: 0.38837096095085144, Valid Loss: 0.6330318450927734\n",
      "Epoch: 3290, Train Loss: 0.38838016986846924, Valid Loss: 0.6280078887939453\n",
      "Epoch: 3291, Train Loss: 0.38839077949523926, Valid Loss: 0.6372055411338806\n",
      "Epoch: 3292, Train Loss: 0.3883940577507019, Valid Loss: 0.6255284547805786\n",
      "Epoch: 3293, Train Loss: 0.3883882164955139, Valid Loss: 0.6375859975814819\n",
      "Epoch: 3294, Train Loss: 0.3883778750896454, Valid Loss: 0.6269375681877136\n",
      "Epoch: 3295, Train Loss: 0.3883693516254425, Valid Loss: 0.6348485350608826\n",
      "Epoch: 3296, Train Loss: 0.3883647620677948, Valid Loss: 0.6308326125144958\n",
      "Epoch: 3297, Train Loss: 0.388364315032959, Valid Loss: 0.6308824419975281\n",
      "Epoch: 3298, Train Loss: 0.38836660981178284, Valid Loss: 0.6345902681350708\n",
      "Epoch: 3299, Train Loss: 0.3883694112300873, Valid Loss: 0.627993106842041\n",
      "Epoch: 3300, Train Loss: 0.38837045431137085, Valid Loss: 0.6363259553909302\n",
      "Epoch: 3301, Train Loss: 0.3883688747882843, Valid Loss: 0.6274515986442566\n",
      "Epoch: 3302, Train Loss: 0.3883645236492157, Valid Loss: 0.6355345249176025\n",
      "Epoch: 3303, Train Loss: 0.38835951685905457, Valid Loss: 0.6294017434120178\n",
      "Epoch: 3304, Train Loss: 0.38835570216178894, Valid Loss: 0.6329658627510071\n",
      "Epoch: 3305, Train Loss: 0.3883543014526367, Valid Loss: 0.632436215877533\n",
      "Epoch: 3306, Train Loss: 0.38835492730140686, Valid Loss: 0.6302669048309326\n",
      "Epoch: 3307, Train Loss: 0.3883560299873352, Valid Loss: 0.634625256061554\n",
      "Epoch: 3308, Train Loss: 0.38835620880126953, Valid Loss: 0.6290316581726074\n",
      "Epoch: 3309, Train Loss: 0.388355553150177, Valid Loss: 0.6350024342536926\n",
      "Epoch: 3310, Train Loss: 0.388353556394577, Valid Loss: 0.6294108033180237\n",
      "Epoch: 3311, Train Loss: 0.38835152983665466, Valid Loss: 0.6340700387954712\n",
      "Epoch: 3312, Train Loss: 0.3883492946624756, Valid Loss: 0.6307600140571594\n",
      "Epoch: 3313, Train Loss: 0.38834741711616516, Valid Loss: 0.632683515548706\n",
      "Epoch: 3314, Train Loss: 0.3883461654186249, Valid Loss: 0.6322152614593506\n",
      "Epoch: 3315, Train Loss: 0.3883451819419861, Valid Loss: 0.6314565539360046\n",
      "Epoch: 3316, Train Loss: 0.38834473490715027, Valid Loss: 0.6332992315292358\n",
      "Epoch: 3317, Train Loss: 0.3883442282676697, Valid Loss: 0.6307523846626282\n",
      "Epoch: 3318, Train Loss: 0.3883439302444458, Valid Loss: 0.6337436437606812\n",
      "Epoch: 3319, Train Loss: 0.3883433938026428, Valid Loss: 0.6306285858154297\n",
      "Epoch: 3320, Train Loss: 0.3883421719074249, Valid Loss: 0.6337247490882874\n",
      "Epoch: 3321, Train Loss: 0.3883408308029175, Valid Loss: 0.6308798789978027\n",
      "Epoch: 3322, Train Loss: 0.3883390426635742, Valid Loss: 0.6334591507911682\n",
      "Epoch: 3323, Train Loss: 0.38833796977996826, Valid Loss: 0.6313070058822632\n",
      "Epoch: 3324, Train Loss: 0.38833683729171753, Valid Loss: 0.6330339908599854\n",
      "Epoch: 3325, Train Loss: 0.38833582401275635, Valid Loss: 0.6318992972373962\n",
      "Epoch: 3326, Train Loss: 0.388334721326828, Valid Loss: 0.6324464678764343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3327, Train Loss: 0.3883340060710907, Valid Loss: 0.6325556039810181\n",
      "Epoch: 3328, Train Loss: 0.3883332908153534, Valid Loss: 0.6318586468696594\n",
      "Epoch: 3329, Train Loss: 0.38833245635032654, Valid Loss: 0.6331419348716736\n",
      "Epoch: 3330, Train Loss: 0.38833191990852356, Valid Loss: 0.631437361240387\n",
      "Epoch: 3331, Train Loss: 0.38833093643188477, Valid Loss: 0.6335195302963257\n",
      "Epoch: 3332, Train Loss: 0.38833022117614746, Valid Loss: 0.6312565803527832\n",
      "Epoch: 3333, Train Loss: 0.3883292078971863, Valid Loss: 0.633681058883667\n",
      "Epoch: 3334, Train Loss: 0.38832855224609375, Valid Loss: 0.6312653422355652\n",
      "Epoch: 3335, Train Loss: 0.38832759857177734, Valid Loss: 0.6336603760719299\n",
      "Epoch: 3336, Train Loss: 0.3883264660835266, Valid Loss: 0.6314175128936768\n",
      "Epoch: 3337, Train Loss: 0.388325572013855, Valid Loss: 0.6335229873657227\n",
      "Epoch: 3338, Train Loss: 0.38832464814186096, Valid Loss: 0.6316478848457336\n",
      "Epoch: 3339, Train Loss: 0.3883238136768341, Valid Loss: 0.6333777904510498\n",
      "Epoch: 3340, Train Loss: 0.38832318782806396, Valid Loss: 0.6318107843399048\n",
      "Epoch: 3341, Train Loss: 0.3883218765258789, Valid Loss: 0.6333466172218323\n",
      "Epoch: 3342, Train Loss: 0.3883211314678192, Valid Loss: 0.6318661570549011\n",
      "Epoch: 3343, Train Loss: 0.3883201479911804, Valid Loss: 0.6334154605865479\n",
      "Epoch: 3344, Train Loss: 0.3883194327354431, Valid Loss: 0.6318151950836182\n",
      "Epoch: 3345, Train Loss: 0.38831856846809387, Valid Loss: 0.6335704326629639\n",
      "Epoch: 3346, Train Loss: 0.3883177638053894, Valid Loss: 0.6317079663276672\n",
      "Epoch: 3347, Train Loss: 0.3883170485496521, Valid Loss: 0.6337810754776001\n",
      "Epoch: 3348, Train Loss: 0.38831645250320435, Valid Loss: 0.631511926651001\n",
      "Epoch: 3349, Train Loss: 0.38831546902656555, Valid Loss: 0.634107232093811\n",
      "Epoch: 3350, Train Loss: 0.3883152902126312, Valid Loss: 0.6312011480331421\n",
      "Epoch: 3351, Train Loss: 0.3883148431777954, Valid Loss: 0.6345555782318115\n",
      "Epoch: 3352, Train Loss: 0.388314813375473, Valid Loss: 0.6307364106178284\n",
      "Epoch: 3353, Train Loss: 0.3883152902126312, Valid Loss: 0.6352246999740601\n",
      "Epoch: 3354, Train Loss: 0.3883163034915924, Valid Loss: 0.6299754977226257\n",
      "Epoch: 3355, Train Loss: 0.38831841945648193, Valid Loss: 0.6362879872322083\n",
      "Epoch: 3356, Train Loss: 0.38832223415374756, Valid Loss: 0.6287076473236084\n",
      "Epoch: 3357, Train Loss: 0.38832852244377136, Valid Loss: 0.6380333304405212\n",
      "Epoch: 3358, Train Loss: 0.3883382976055145, Valid Loss: 0.626616358757019\n",
      "Epoch: 3359, Train Loss: 0.3883534371852875, Valid Loss: 0.6408169269561768\n",
      "Epoch: 3360, Train Loss: 0.38837575912475586, Valid Loss: 0.6233651041984558\n",
      "Epoch: 3361, Train Loss: 0.38840651512145996, Valid Loss: 0.6450231075286865\n",
      "Epoch: 3362, Train Loss: 0.38844504952430725, Valid Loss: 0.6187465786933899\n",
      "Epoch: 3363, Train Loss: 0.388491153717041, Valid Loss: 0.6504519581794739\n",
      "Epoch: 3364, Train Loss: 0.38853153586387634, Valid Loss: 0.6136698126792908\n",
      "Epoch: 3365, Train Loss: 0.38857007026672363, Valid Loss: 0.6548770666122437\n",
      "Epoch: 3366, Train Loss: 0.38856685161590576, Valid Loss: 0.6114218235015869\n",
      "Epoch: 3367, Train Loss: 0.3885378837585449, Valid Loss: 0.6538415551185608\n",
      "Epoch: 3368, Train Loss: 0.3884587585926056, Valid Loss: 0.6163786053657532\n",
      "Epoch: 3369, Train Loss: 0.38837558031082153, Valid Loss: 0.6447207927703857\n",
      "Epoch: 3370, Train Loss: 0.3883133828639984, Valid Loss: 0.6278864145278931\n",
      "Epoch: 3371, Train Loss: 0.38829776644706726, Valid Loss: 0.6317242980003357\n",
      "Epoch: 3372, Train Loss: 0.3883223831653595, Valid Loss: 0.6397737264633179\n",
      "Epoch: 3373, Train Loss: 0.38836318254470825, Valid Loss: 0.6220150589942932\n",
      "Epoch: 3374, Train Loss: 0.38839539885520935, Valid Loss: 0.6464623808860779\n",
      "Epoch: 3375, Train Loss: 0.38839665055274963, Valid Loss: 0.6195769309997559\n",
      "Epoch: 3376, Train Loss: 0.3883747458457947, Valid Loss: 0.6451148390769958\n",
      "Epoch: 3377, Train Loss: 0.38833773136138916, Valid Loss: 0.6249030232429504\n",
      "Epoch: 3378, Train Loss: 0.3883076608181, Valid Loss: 0.6373018622398376\n",
      "Epoch: 3379, Train Loss: 0.38829493522644043, Valid Loss: 0.6335959434509277\n",
      "Epoch: 3380, Train Loss: 0.3883000314235687, Valid Loss: 0.6287969350814819\n",
      "Epoch: 3381, Train Loss: 0.3883156180381775, Valid Loss: 0.6399682760238647\n",
      "Epoch: 3382, Train Loss: 0.3883304297924042, Valid Loss: 0.624747097492218\n",
      "Epoch: 3383, Train Loss: 0.3883362412452698, Valid Loss: 0.6416993737220764\n",
      "Epoch: 3384, Train Loss: 0.38832879066467285, Valid Loss: 0.625783383846283\n",
      "Epoch: 3385, Train Loss: 0.38831162452697754, Valid Loss: 0.6390535831451416\n",
      "Epoch: 3386, Train Loss: 0.3882940113544464, Valid Loss: 0.6299985647201538\n",
      "Epoch: 3387, Train Loss: 0.3882845938205719, Valid Loss: 0.6339874267578125\n",
      "Epoch: 3388, Train Loss: 0.38828572630882263, Valid Loss: 0.6349716186523438\n",
      "Epoch: 3389, Train Loss: 0.3882940113544464, Valid Loss: 0.6294435262680054\n",
      "Epoch: 3390, Train Loss: 0.3883019685745239, Valid Loss: 0.6384798288345337\n",
      "Epoch: 3391, Train Loss: 0.38830459117889404, Valid Loss: 0.6274054646492004\n",
      "Epoch: 3392, Train Loss: 0.3883005976676941, Valid Loss: 0.6390712261199951\n",
      "Epoch: 3393, Train Loss: 0.3882928788661957, Valid Loss: 0.6284973621368408\n",
      "Epoch: 3394, Train Loss: 0.3882855176925659, Valid Loss: 0.636969804763794\n",
      "Epoch: 3395, Train Loss: 0.38828009366989136, Valid Loss: 0.631644606590271\n",
      "Epoch: 3396, Train Loss: 0.3882780075073242, Valid Loss: 0.6334424018859863\n",
      "Epoch: 3397, Train Loss: 0.38827866315841675, Valid Loss: 0.6350381970405579\n",
      "Epoch: 3398, Train Loss: 0.3882811367511749, Valid Loss: 0.6303760409355164\n",
      "Epoch: 3399, Train Loss: 0.3882836699485779, Valid Loss: 0.6373350620269775\n",
      "Epoch: 3400, Train Loss: 0.3882843255996704, Valid Loss: 0.6290384531021118\n",
      "Epoch: 3401, Train Loss: 0.38828253746032715, Valid Loss: 0.637739896774292\n",
      "Epoch: 3402, Train Loss: 0.3882793188095093, Valid Loss: 0.6298676133155823\n",
      "Epoch: 3403, Train Loss: 0.3882753849029541, Valid Loss: 0.6362633109092712\n",
      "Epoch: 3404, Train Loss: 0.38827165961265564, Valid Loss: 0.6320787668228149\n",
      "Epoch: 3405, Train Loss: 0.3882700204849243, Valid Loss: 0.6338363885879517\n",
      "Epoch: 3406, Train Loss: 0.3882695734500885, Valid Loss: 0.6343719959259033\n",
      "Epoch: 3407, Train Loss: 0.38826999068260193, Valid Loss: 0.6318479776382446\n",
      "Epoch: 3408, Train Loss: 0.3882704973220825, Valid Loss: 0.6358574032783508\n",
      "Epoch: 3409, Train Loss: 0.3882707357406616, Valid Loss: 0.6309685707092285\n",
      "Epoch: 3410, Train Loss: 0.38827037811279297, Valid Loss: 0.6363410353660583\n",
      "Epoch: 3411, Train Loss: 0.38826945424079895, Valid Loss: 0.6311004757881165\n",
      "Epoch: 3412, Train Loss: 0.3882678151130676, Valid Loss: 0.6360136270523071\n",
      "Epoch: 3413, Train Loss: 0.38826656341552734, Valid Loss: 0.6318173408508301\n",
      "Epoch: 3414, Train Loss: 0.38826489448547363, Valid Loss: 0.6351333856582642\n",
      "Epoch: 3415, Train Loss: 0.3882634937763214, Valid Loss: 0.6327779293060303\n",
      "Epoch: 3416, Train Loss: 0.3882617950439453, Valid Loss: 0.6341722011566162\n",
      "Epoch: 3417, Train Loss: 0.38826075196266174, Valid Loss: 0.6337027549743652\n",
      "Epoch: 3418, Train Loss: 0.38825997710227966, Valid Loss: 0.6334128379821777\n",
      "Epoch: 3419, Train Loss: 0.388259619474411, Valid Loss: 0.6344556212425232\n",
      "Epoch: 3420, Train Loss: 0.38825929164886475, Valid Loss: 0.6329070329666138\n",
      "Epoch: 3421, Train Loss: 0.38825884461402893, Valid Loss: 0.6350030303001404\n",
      "Epoch: 3422, Train Loss: 0.3882584273815155, Valid Loss: 0.6325318217277527\n",
      "Epoch: 3423, Train Loss: 0.38825783133506775, Valid Loss: 0.6353400945663452\n",
      "Epoch: 3424, Train Loss: 0.38825687766075134, Valid Loss: 0.6322996020317078\n",
      "Epoch: 3425, Train Loss: 0.3882565200328827, Valid Loss: 0.6355013847351074\n",
      "Epoch: 3426, Train Loss: 0.3882555663585663, Valid Loss: 0.632270336151123\n",
      "Epoch: 3427, Train Loss: 0.38825473189353943, Valid Loss: 0.6355159282684326\n",
      "Epoch: 3428, Train Loss: 0.3882540762424469, Valid Loss: 0.6324173212051392\n",
      "Epoch: 3429, Train Loss: 0.3882528841495514, Valid Loss: 0.635427713394165\n",
      "Epoch: 3430, Train Loss: 0.3882521092891693, Valid Loss: 0.632626473903656\n",
      "Epoch: 3431, Train Loss: 0.3882511854171753, Valid Loss: 0.63527911901474\n",
      "Epoch: 3432, Train Loss: 0.3882506489753723, Valid Loss: 0.6328372955322266\n",
      "Epoch: 3433, Train Loss: 0.3882496654987335, Valid Loss: 0.6351075172424316\n",
      "Epoch: 3434, Train Loss: 0.3882487416267395, Valid Loss: 0.6330236196517944\n",
      "Epoch: 3435, Train Loss: 0.38824793696403503, Valid Loss: 0.6350158452987671\n",
      "Epoch: 3436, Train Loss: 0.3882474899291992, Valid Loss: 0.6331514120101929\n",
      "Epoch: 3437, Train Loss: 0.38824665546417236, Valid Loss: 0.6350257396697998\n",
      "Epoch: 3438, Train Loss: 0.3882460296154022, Valid Loss: 0.6331655383110046\n",
      "Epoch: 3439, Train Loss: 0.38824528455734253, Valid Loss: 0.6351770758628845\n",
      "Epoch: 3440, Train Loss: 0.3882448375225067, Valid Loss: 0.6330003142356873\n",
      "Epoch: 3441, Train Loss: 0.38824453949928284, Valid Loss: 0.6354838013648987\n",
      "Epoch: 3442, Train Loss: 0.38824406266212463, Valid Loss: 0.6326636672019958\n",
      "Epoch: 3443, Train Loss: 0.3882439136505127, Valid Loss: 0.6359628438949585\n",
      "Epoch: 3444, Train Loss: 0.3882441222667694, Valid Loss: 0.632144570350647\n",
      "Epoch: 3445, Train Loss: 0.38824453949928284, Valid Loss: 0.636696457862854\n",
      "Epoch: 3446, Train Loss: 0.3882456421852112, Valid Loss: 0.6313280463218689\n",
      "Epoch: 3447, Train Loss: 0.38824784755706787, Valid Loss: 0.637825608253479\n",
      "Epoch: 3448, Train Loss: 0.3882514238357544, Valid Loss: 0.6300216913223267\n",
      "Epoch: 3449, Train Loss: 0.3882571756839752, Valid Loss: 0.639559805393219\n",
      "Epoch: 3450, Train Loss: 0.38826650381088257, Valid Loss: 0.627973198890686\n",
      "Epoch: 3451, Train Loss: 0.3882809579372406, Valid Loss: 0.6422490477561951\n",
      "Epoch: 3452, Train Loss: 0.3883019685745239, Valid Loss: 0.6248335242271423\n",
      "Epoch: 3453, Train Loss: 0.38833171129226685, Valid Loss: 0.6463056206703186\n",
      "Epoch: 3454, Train Loss: 0.38837018609046936, Valid Loss: 0.6203696727752686\n",
      "Epoch: 3455, Train Loss: 0.3884167969226837, Valid Loss: 0.6516637206077576\n",
      "Epoch: 3456, Train Loss: 0.3884601294994354, Valid Loss: 0.6152707934379578\n",
      "Epoch: 3457, Train Loss: 0.3885013461112976, Valid Loss: 0.6564224362373352\n",
      "Epoch: 3458, Train Loss: 0.38850510120391846, Valid Loss: 0.6124727129936218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3459, Train Loss: 0.38848474621772766, Valid Loss: 0.6561845541000366\n",
      "Epoch: 3460, Train Loss: 0.38841307163238525, Valid Loss: 0.6164361238479614\n",
      "Epoch: 3461, Train Loss: 0.38833123445510864, Valid Loss: 0.6479464769363403\n",
      "Epoch: 3462, Train Loss: 0.3882603347301483, Valid Loss: 0.6274179220199585\n",
      "Epoch: 3463, Train Loss: 0.38823002576828003, Valid Loss: 0.6349951028823853\n",
      "Epoch: 3464, Train Loss: 0.3882439434528351, Valid Loss: 0.639706015586853\n",
      "Epoch: 3465, Train Loss: 0.38828346133232117, Valid Loss: 0.6243674755096436\n",
      "Epoch: 3466, Train Loss: 0.38832297921180725, Valid Loss: 0.6476075649261475\n",
      "Epoch: 3467, Train Loss: 0.38833382725715637, Valid Loss: 0.6205365061759949\n",
      "Epoch: 3468, Train Loss: 0.38831791281700134, Valid Loss: 0.647655725479126\n",
      "Epoch: 3469, Train Loss: 0.3882814645767212, Valid Loss: 0.6247297525405884\n",
      "Epoch: 3470, Train Loss: 0.3882472813129425, Valid Loss: 0.6403598189353943\n",
      "Epoch: 3471, Train Loss: 0.3882288634777069, Valid Loss: 0.6335639357566833\n",
      "Epoch: 3472, Train Loss: 0.38822993636131287, Valid Loss: 0.6312577128410339\n",
      "Epoch: 3473, Train Loss: 0.3882441818714142, Valid Loss: 0.6408694386482239\n",
      "Epoch: 3474, Train Loss: 0.38825953006744385, Valid Loss: 0.6261742115020752\n",
      "Epoch: 3475, Train Loss: 0.38826820254325867, Valid Loss: 0.6433970928192139\n",
      "Epoch: 3476, Train Loss: 0.38826480507850647, Valid Loss: 0.6266162991523743\n",
      "Epoch: 3477, Train Loss: 0.388251930475235, Valid Loss: 0.6412525773048401\n",
      "Epoch: 3478, Train Loss: 0.38823455572128296, Valid Loss: 0.6305942535400391\n",
      "Epoch: 3479, Train Loss: 0.3882214426994324, Valid Loss: 0.6362823247909546\n",
      "Epoch: 3480, Train Loss: 0.38821783661842346, Valid Loss: 0.6355172991752625\n",
      "Epoch: 3481, Train Loss: 0.3882232904434204, Valid Loss: 0.6314906477928162\n",
      "Epoch: 3482, Train Loss: 0.3882323205471039, Valid Loss: 0.6393945813179016\n",
      "Epoch: 3483, Train Loss: 0.38823819160461426, Valid Loss: 0.6290320158004761\n",
      "Epoch: 3484, Train Loss: 0.3882378935813904, Valid Loss: 0.6405893564224243\n",
      "Epoch: 3485, Train Loss: 0.3882315456867218, Valid Loss: 0.6295642256736755\n",
      "Epoch: 3486, Train Loss: 0.3882233202457428, Valid Loss: 0.6389830708503723\n",
      "Epoch: 3487, Train Loss: 0.38821664452552795, Valid Loss: 0.6322997808456421\n",
      "Epoch: 3488, Train Loss: 0.38821303844451904, Valid Loss: 0.6357078552246094\n",
      "Epoch: 3489, Train Loss: 0.3882128894329071, Valid Loss: 0.6355178356170654\n",
      "Epoch: 3490, Train Loss: 0.38821500539779663, Valid Loss: 0.6325775384902954\n",
      "Epoch: 3491, Train Loss: 0.3882175087928772, Valid Loss: 0.6381126046180725\n",
      "Epoch: 3492, Train Loss: 0.38821902871131897, Valid Loss: 0.6307770013809204\n",
      "Epoch: 3493, Train Loss: 0.38821902871131897, Valid Loss: 0.6392226219177246\n",
      "Epoch: 3494, Train Loss: 0.3882167935371399, Valid Loss: 0.6308303475379944\n",
      "Epoch: 3495, Train Loss: 0.3882136046886444, Valid Loss: 0.6384220719337463\n",
      "Epoch: 3496, Train Loss: 0.388209730386734, Valid Loss: 0.6325738430023193\n",
      "Epoch: 3497, Train Loss: 0.38820675015449524, Valid Loss: 0.6361631751060486\n",
      "Epoch: 3498, Train Loss: 0.3882052004337311, Valid Loss: 0.6349019408226013\n",
      "Epoch: 3499, Train Loss: 0.3882054090499878, Valid Loss: 0.633866548538208\n",
      "Epoch: 3500, Train Loss: 0.3882059156894684, Valid Loss: 0.6368271112442017\n",
      "Epoch: 3501, Train Loss: 0.38820672035217285, Valid Loss: 0.6325828433036804\n",
      "Epoch: 3502, Train Loss: 0.38820692896842957, Valid Loss: 0.63773512840271\n",
      "Epoch: 3503, Train Loss: 0.3882063627243042, Valid Loss: 0.632364809513092\n",
      "Epoch: 3504, Train Loss: 0.388205349445343, Valid Loss: 0.6376672983169556\n",
      "Epoch: 3505, Train Loss: 0.388203889131546, Valid Loss: 0.6328914165496826\n",
      "Epoch: 3506, Train Loss: 0.38820257782936096, Valid Loss: 0.6368663311004639\n",
      "Epoch: 3507, Train Loss: 0.38820114731788635, Valid Loss: 0.6338063478469849\n",
      "Epoch: 3508, Train Loss: 0.38819971680641174, Valid Loss: 0.6358525156974792\n",
      "Epoch: 3509, Train Loss: 0.38819828629493713, Valid Loss: 0.6348253488540649\n",
      "Epoch: 3510, Train Loss: 0.3881978988647461, Valid Loss: 0.6350656151771545\n",
      "Epoch: 3511, Train Loss: 0.38819730281829834, Valid Loss: 0.6356125473976135\n",
      "Epoch: 3512, Train Loss: 0.38819676637649536, Valid Loss: 0.6345711350440979\n",
      "Epoch: 3513, Train Loss: 0.3881966769695282, Valid Loss: 0.6361095309257507\n",
      "Epoch: 3514, Train Loss: 0.38819628953933716, Valid Loss: 0.6342198848724365\n",
      "Epoch: 3515, Train Loss: 0.38819611072540283, Valid Loss: 0.6364319324493408\n",
      "Epoch: 3516, Train Loss: 0.3881954848766327, Valid Loss: 0.6339102387428284\n",
      "Epoch: 3517, Train Loss: 0.3881949186325073, Valid Loss: 0.6367141008377075\n",
      "Epoch: 3518, Train Loss: 0.38819459080696106, Valid Loss: 0.6337398290634155\n",
      "Epoch: 3519, Train Loss: 0.38819387555122375, Valid Loss: 0.6369211673736572\n",
      "Epoch: 3520, Train Loss: 0.38819339871406555, Valid Loss: 0.633726954460144\n",
      "Epoch: 3521, Train Loss: 0.38819247484207153, Valid Loss: 0.6369822025299072\n",
      "Epoch: 3522, Train Loss: 0.388191819190979, Valid Loss: 0.6337825655937195\n",
      "Epoch: 3523, Train Loss: 0.3881911039352417, Valid Loss: 0.6369621157646179\n",
      "Epoch: 3524, Train Loss: 0.3881905674934387, Valid Loss: 0.6338415741920471\n",
      "Epoch: 3525, Train Loss: 0.3881896436214447, Valid Loss: 0.6369062662124634\n",
      "Epoch: 3526, Train Loss: 0.3881891965866089, Valid Loss: 0.6339303851127625\n",
      "Epoch: 3527, Train Loss: 0.3881886303424835, Valid Loss: 0.6369121670722961\n",
      "Epoch: 3528, Train Loss: 0.3881881535053253, Valid Loss: 0.6340014934539795\n",
      "Epoch: 3529, Train Loss: 0.3881879448890686, Valid Loss: 0.6369999647140503\n",
      "Epoch: 3530, Train Loss: 0.38818734884262085, Valid Loss: 0.6339240074157715\n",
      "Epoch: 3531, Train Loss: 0.3881871998310089, Valid Loss: 0.6372376084327698\n",
      "Epoch: 3532, Train Loss: 0.3881871700286865, Valid Loss: 0.6336420178413391\n",
      "Epoch: 3533, Train Loss: 0.3881872296333313, Valid Loss: 0.6376748085021973\n",
      "Epoch: 3534, Train Loss: 0.3881876766681671, Valid Loss: 0.6331073641777039\n",
      "Epoch: 3535, Train Loss: 0.3881886303424835, Valid Loss: 0.6384238600730896\n",
      "Epoch: 3536, Train Loss: 0.3881900906562805, Valid Loss: 0.6322634220123291\n",
      "Epoch: 3537, Train Loss: 0.3881930112838745, Valid Loss: 0.6395984292030334\n",
      "Epoch: 3538, Train Loss: 0.3881970942020416, Valid Loss: 0.6309443116188049\n",
      "Epoch: 3539, Train Loss: 0.3882032036781311, Valid Loss: 0.6413543224334717\n",
      "Epoch: 3540, Train Loss: 0.38821253180503845, Valid Loss: 0.6289043426513672\n",
      "Epoch: 3541, Train Loss: 0.38822606205940247, Valid Loss: 0.6439813375473022\n",
      "Epoch: 3542, Train Loss: 0.388245165348053, Valid Loss: 0.6258947849273682\n",
      "Epoch: 3543, Train Loss: 0.38827112317085266, Valid Loss: 0.6477329730987549\n",
      "Epoch: 3544, Train Loss: 0.3883034884929657, Valid Loss: 0.6218780279159546\n",
      "Epoch: 3545, Train Loss: 0.3883422911167145, Valid Loss: 0.6524064540863037\n",
      "Epoch: 3546, Train Loss: 0.3883773386478424, Valid Loss: 0.617572546005249\n",
      "Epoch: 3547, Train Loss: 0.38840940594673157, Valid Loss: 0.6563594341278076\n",
      "Epoch: 3548, Train Loss: 0.38841232657432556, Valid Loss: 0.615304708480835\n",
      "Epoch: 3549, Train Loss: 0.3883962333202362, Valid Loss: 0.6562222242355347\n",
      "Epoch: 3550, Train Loss: 0.38834065198898315, Valid Loss: 0.6183924674987793\n",
      "Epoch: 3551, Train Loss: 0.38827580213546753, Valid Loss: 0.6496001482009888\n",
      "Epoch: 3552, Train Loss: 0.38821372389793396, Valid Loss: 0.6273306012153625\n",
      "Epoch: 3553, Train Loss: 0.3881785571575165, Valid Loss: 0.6387243866920471\n",
      "Epoch: 3554, Train Loss: 0.388175368309021, Valid Loss: 0.6380962133407593\n",
      "Epoch: 3555, Train Loss: 0.38819754123687744, Valid Loss: 0.6288300156593323\n",
      "Epoch: 3556, Train Loss: 0.3882296681404114, Valid Loss: 0.6461653709411621\n",
      "Epoch: 3557, Train Loss: 0.388252317905426, Valid Loss: 0.6236383318901062\n",
      "Epoch: 3558, Train Loss: 0.38825803995132446, Valid Loss: 0.6486858129501343\n",
      "Epoch: 3559, Train Loss: 0.388240784406662, Valid Loss: 0.6245369911193848\n",
      "Epoch: 3560, Train Loss: 0.3882136344909668, Valid Loss: 0.6449235677719116\n",
      "Epoch: 3561, Train Loss: 0.3881869912147522, Valid Loss: 0.6304562091827393\n",
      "Epoch: 3562, Train Loss: 0.38817206025123596, Valid Loss: 0.6375721096992493\n",
      "Epoch: 3563, Train Loss: 0.3881702721118927, Valid Loss: 0.63764888048172\n",
      "Epoch: 3564, Train Loss: 0.3881780505180359, Valid Loss: 0.6311049461364746\n",
      "Epoch: 3565, Train Loss: 0.38818949460983276, Valid Loss: 0.6425776481628418\n",
      "Epoch: 3566, Train Loss: 0.38819876313209534, Valid Loss: 0.6283004283905029\n",
      "Epoch: 3567, Train Loss: 0.38820138573646545, Valid Loss: 0.643781840801239\n",
      "Epoch: 3568, Train Loss: 0.38819658756256104, Valid Loss: 0.6291664242744446\n",
      "Epoch: 3569, Train Loss: 0.38818588852882385, Valid Loss: 0.6416088342666626\n",
      "Epoch: 3570, Train Loss: 0.3881743252277374, Valid Loss: 0.6323242783546448\n",
      "Epoch: 3571, Train Loss: 0.38816553354263306, Valid Loss: 0.63767409324646\n",
      "Epoch: 3572, Train Loss: 0.38816237449645996, Valid Loss: 0.6361939907073975\n",
      "Epoch: 3573, Train Loss: 0.38816410303115845, Valid Loss: 0.6339936256408691\n",
      "Epoch: 3574, Train Loss: 0.3881690204143524, Valid Loss: 0.6394434571266174\n",
      "Epoch: 3575, Train Loss: 0.38817328214645386, Valid Loss: 0.6317805647850037\n",
      "Epoch: 3576, Train Loss: 0.3881758749485016, Valid Loss: 0.6410394906997681\n",
      "Epoch: 3577, Train Loss: 0.3881751000881195, Valid Loss: 0.6313308477401733\n",
      "Epoch: 3578, Train Loss: 0.38817164301872253, Valid Loss: 0.6406745910644531\n",
      "Epoch: 3579, Train Loss: 0.3881668746471405, Valid Loss: 0.6324005722999573\n",
      "Epoch: 3580, Train Loss: 0.388161838054657, Valid Loss: 0.6389349102973938\n",
      "Epoch: 3581, Train Loss: 0.38815876841545105, Valid Loss: 0.6343702077865601\n",
      "Epoch: 3582, Train Loss: 0.38815686106681824, Valid Loss: 0.6367775797843933\n",
      "Epoch: 3583, Train Loss: 0.3881564140319824, Valid Loss: 0.6366642713546753\n",
      "Epoch: 3584, Train Loss: 0.3881572484970093, Valid Loss: 0.634792685508728\n",
      "Epoch: 3585, Train Loss: 0.3881583511829376, Valid Loss: 0.638578474521637\n",
      "Epoch: 3586, Train Loss: 0.3881593346595764, Valid Loss: 0.6333897113800049\n",
      "Epoch: 3587, Train Loss: 0.388159841299057, Valid Loss: 0.6395769715309143\n",
      "Epoch: 3588, Train Loss: 0.3881595730781555, Valid Loss: 0.6328721642494202\n",
      "Epoch: 3589, Train Loss: 0.38815873861312866, Valid Loss: 0.6395817399024963\n",
      "Epoch: 3590, Train Loss: 0.38815706968307495, Valid Loss: 0.6332817673683167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3591, Train Loss: 0.38815540075302124, Valid Loss: 0.6388751268386841\n",
      "Epoch: 3592, Train Loss: 0.3881535232067108, Valid Loss: 0.6343265771865845\n",
      "Epoch: 3593, Train Loss: 0.38815227150917053, Valid Loss: 0.6378753185272217\n",
      "Epoch: 3594, Train Loss: 0.3881506025791168, Valid Loss: 0.6354792714118958\n",
      "Epoch: 3595, Train Loss: 0.38815003633499146, Valid Loss: 0.6368498802185059\n",
      "Epoch: 3596, Train Loss: 0.3881489932537079, Valid Loss: 0.6364506483078003\n",
      "Epoch: 3597, Train Loss: 0.3881484568119049, Valid Loss: 0.6359857320785522\n",
      "Epoch: 3598, Train Loss: 0.3881482183933258, Valid Loss: 0.6371890306472778\n",
      "Epoch: 3599, Train Loss: 0.3881479799747467, Valid Loss: 0.6353978514671326\n",
      "Epoch: 3600, Train Loss: 0.38814792037010193, Valid Loss: 0.6377384662628174\n",
      "Epoch: 3601, Train Loss: 0.38814765214920044, Valid Loss: 0.6350834369659424\n",
      "Epoch: 3602, Train Loss: 0.3881475329399109, Valid Loss: 0.6380966901779175\n",
      "Epoch: 3603, Train Loss: 0.3881474435329437, Valid Loss: 0.6348928213119507\n",
      "Epoch: 3604, Train Loss: 0.38814711570739746, Valid Loss: 0.6383376121520996\n",
      "Epoch: 3605, Train Loss: 0.3881469666957855, Valid Loss: 0.6346909403800964\n",
      "Epoch: 3606, Train Loss: 0.3881468176841736, Valid Loss: 0.6385720372200012\n",
      "Epoch: 3607, Train Loss: 0.38814666867256165, Valid Loss: 0.6344408392906189\n",
      "Epoch: 3608, Train Loss: 0.38814663887023926, Valid Loss: 0.6389203071594238\n",
      "Epoch: 3609, Train Loss: 0.38814666867256165, Valid Loss: 0.634120762348175\n",
      "Epoch: 3610, Train Loss: 0.3881468176841736, Valid Loss: 0.6394032835960388\n",
      "Epoch: 3611, Train Loss: 0.3881472647190094, Valid Loss: 0.6336790323257446\n",
      "Epoch: 3612, Train Loss: 0.38814812898635864, Valid Loss: 0.640018105506897\n",
      "Epoch: 3613, Train Loss: 0.3881493806838989, Valid Loss: 0.6330206990242004\n",
      "Epoch: 3614, Train Loss: 0.3881511986255646, Valid Loss: 0.640868067741394\n",
      "Epoch: 3615, Train Loss: 0.38815394043922424, Valid Loss: 0.6320423483848572\n",
      "Epoch: 3616, Train Loss: 0.3881577253341675, Valid Loss: 0.6421129107475281\n",
      "Epoch: 3617, Train Loss: 0.3881630599498749, Valid Loss: 0.6306482553482056\n",
      "Epoch: 3618, Train Loss: 0.3881705403327942, Valid Loss: 0.6439056396484375\n",
      "Epoch: 3619, Train Loss: 0.38818055391311646, Valid Loss: 0.6287002563476562\n",
      "Epoch: 3620, Train Loss: 0.3881939947605133, Valid Loss: 0.6463350653648376\n",
      "Epoch: 3621, Train Loss: 0.3882107436656952, Valid Loss: 0.6261200904846191\n",
      "Epoch: 3622, Train Loss: 0.3882313668727875, Valid Loss: 0.6493892669677734\n",
      "Epoch: 3623, Train Loss: 0.388253390789032, Valid Loss: 0.6230629086494446\n",
      "Epoch: 3624, Train Loss: 0.3882780969142914, Valid Loss: 0.6526435017585754\n",
      "Epoch: 3625, Train Loss: 0.3882947564125061, Valid Loss: 0.6203357577323914\n",
      "Epoch: 3626, Train Loss: 0.3883071839809418, Valid Loss: 0.6547601222991943\n",
      "Epoch: 3627, Train Loss: 0.38830041885375977, Valid Loss: 0.6195924282073975\n",
      "Epoch: 3628, Train Loss: 0.3882830739021301, Valid Loss: 0.6537623405456543\n",
      "Epoch: 3629, Train Loss: 0.3882465660572052, Valid Loss: 0.622482180595398\n",
      "Epoch: 3630, Train Loss: 0.3882070481777191, Valid Loss: 0.6487217545509338\n",
      "Epoch: 3631, Train Loss: 0.3881686329841614, Valid Loss: 0.6288514137268066\n",
      "Epoch: 3632, Train Loss: 0.3881422281265259, Valid Loss: 0.6411374807357788\n",
      "Epoch: 3633, Train Loss: 0.388131320476532, Valid Loss: 0.6364825367927551\n",
      "Epoch: 3634, Train Loss: 0.3881356716156006, Valid Loss: 0.6337926983833313\n",
      "Epoch: 3635, Train Loss: 0.388150155544281, Valid Loss: 0.6430086493492126\n",
      "Epoch: 3636, Train Loss: 0.38816702365875244, Valid Loss: 0.6286911964416504\n",
      "Epoch: 3637, Train Loss: 0.38818037509918213, Valid Loss: 0.6467973589897156\n",
      "Epoch: 3638, Train Loss: 0.3881838619709015, Valid Loss: 0.6268136501312256\n",
      "Epoch: 3639, Train Loss: 0.388180136680603, Valid Loss: 0.6469830274581909\n",
      "Epoch: 3640, Train Loss: 0.388168603181839, Valid Loss: 0.6283637881278992\n",
      "Epoch: 3641, Train Loss: 0.388154536485672, Valid Loss: 0.6439797282218933\n",
      "Epoch: 3642, Train Loss: 0.3881411552429199, Valid Loss: 0.6322673559188843\n",
      "Epoch: 3643, Train Loss: 0.388131707906723, Valid Loss: 0.6395225524902344\n",
      "Epoch: 3644, Train Loss: 0.3881272077560425, Valid Loss: 0.6366822123527527\n",
      "Epoch: 3645, Train Loss: 0.3881269693374634, Valid Loss: 0.6355293393135071\n",
      "Epoch: 3646, Train Loss: 0.38812997937202454, Valid Loss: 0.6401535272598267\n",
      "Epoch: 3647, Train Loss: 0.3881341218948364, Valid Loss: 0.6328895092010498\n",
      "Epoch: 3648, Train Loss: 0.3881380259990692, Valid Loss: 0.6421657800674438\n",
      "Epoch: 3649, Train Loss: 0.38814085721969604, Valid Loss: 0.6317154765129089\n",
      "Epoch: 3650, Train Loss: 0.3881419003009796, Valid Loss: 0.6427345275878906\n",
      "Epoch: 3651, Train Loss: 0.3881409466266632, Valid Loss: 0.6318269371986389\n",
      "Epoch: 3652, Train Loss: 0.3881380558013916, Valid Loss: 0.642124354839325\n",
      "Epoch: 3653, Train Loss: 0.38813385367393494, Valid Loss: 0.6329429149627686\n",
      "Epoch: 3654, Train Loss: 0.3881290555000305, Valid Loss: 0.6407582759857178\n",
      "Epoch: 3655, Train Loss: 0.38812515139579773, Valid Loss: 0.6345778703689575\n",
      "Epoch: 3656, Train Loss: 0.3881220519542694, Valid Loss: 0.6390870809555054\n",
      "Epoch: 3657, Train Loss: 0.3881201148033142, Valid Loss: 0.6362440586090088\n",
      "Epoch: 3658, Train Loss: 0.38811925053596497, Valid Loss: 0.6375383138656616\n",
      "Epoch: 3659, Train Loss: 0.38811877369880676, Valid Loss: 0.6377103328704834\n",
      "Epoch: 3660, Train Loss: 0.3881196975708008, Valid Loss: 0.6362307071685791\n",
      "Epoch: 3661, Train Loss: 0.3881199359893799, Valid Loss: 0.6389622688293457\n",
      "Epoch: 3662, Train Loss: 0.3881206810474396, Valid Loss: 0.6351712346076965\n",
      "Epoch: 3663, Train Loss: 0.3881213068962097, Valid Loss: 0.6400052905082703\n",
      "Epoch: 3664, Train Loss: 0.38812169432640076, Valid Loss: 0.6343675255775452\n",
      "Epoch: 3665, Train Loss: 0.3881221413612366, Valid Loss: 0.6407171487808228\n",
      "Epoch: 3666, Train Loss: 0.38812217116355896, Valid Loss: 0.6338635683059692\n",
      "Epoch: 3667, Train Loss: 0.3881223499774933, Valid Loss: 0.641122579574585\n",
      "Epoch: 3668, Train Loss: 0.38812246918678284, Valid Loss: 0.6336357593536377\n",
      "Epoch: 3669, Train Loss: 0.38812240958213806, Valid Loss: 0.6413300037384033\n",
      "Epoch: 3670, Train Loss: 0.3881223499774933, Valid Loss: 0.6335268616676331\n",
      "Epoch: 3671, Train Loss: 0.38812220096588135, Valid Loss: 0.6415066719055176\n",
      "Epoch: 3672, Train Loss: 0.3881220519542694, Valid Loss: 0.633421003818512\n",
      "Epoch: 3673, Train Loss: 0.3881221115589142, Valid Loss: 0.6417199969291687\n",
      "Epoch: 3674, Train Loss: 0.38812288641929626, Valid Loss: 0.6332288384437561\n",
      "Epoch: 3675, Train Loss: 0.3881230652332306, Valid Loss: 0.6420043706893921\n",
      "Epoch: 3676, Train Loss: 0.38812386989593506, Valid Loss: 0.6329391002655029\n",
      "Epoch: 3677, Train Loss: 0.3881252110004425, Valid Loss: 0.6424655914306641\n",
      "Epoch: 3678, Train Loss: 0.3881269693374634, Valid Loss: 0.6324264407157898\n",
      "Epoch: 3679, Train Loss: 0.3881295323371887, Valid Loss: 0.6432331800460815\n",
      "Epoch: 3680, Train Loss: 0.38813287019729614, Valid Loss: 0.631567120552063\n",
      "Epoch: 3681, Train Loss: 0.3881373107433319, Valid Loss: 0.6443893909454346\n",
      "Epoch: 3682, Train Loss: 0.3881428837776184, Valid Loss: 0.6303176879882812\n",
      "Epoch: 3683, Train Loss: 0.38814932107925415, Valid Loss: 0.6459393501281738\n",
      "Epoch: 3684, Train Loss: 0.38815778493881226, Valid Loss: 0.6286569237709045\n",
      "Epoch: 3685, Train Loss: 0.388168066740036, Valid Loss: 0.6478882431983948\n",
      "Epoch: 3686, Train Loss: 0.3881789445877075, Valid Loss: 0.6267008781433105\n",
      "Epoch: 3687, Train Loss: 0.38819199800491333, Valid Loss: 0.6500476002693176\n",
      "Epoch: 3688, Train Loss: 0.3882034420967102, Valid Loss: 0.6247314810752869\n",
      "Epoch: 3689, Train Loss: 0.38821515440940857, Valid Loss: 0.6519331336021423\n",
      "Epoch: 3690, Train Loss: 0.38822078704833984, Valid Loss: 0.6233830451965332\n",
      "Epoch: 3691, Train Loss: 0.38822320103645325, Valid Loss: 0.6527089476585388\n",
      "Epoch: 3692, Train Loss: 0.38821524381637573, Valid Loss: 0.6235322952270508\n",
      "Epoch: 3693, Train Loss: 0.388202428817749, Valid Loss: 0.6514744758605957\n",
      "Epoch: 3694, Train Loss: 0.3881806433200836, Valid Loss: 0.6258346438407898\n",
      "Epoch: 3695, Train Loss: 0.3881576955318451, Valid Loss: 0.6480024456977844\n",
      "Epoch: 3696, Train Loss: 0.3881346881389618, Valid Loss: 0.6300547122955322\n",
      "Epoch: 3697, Train Loss: 0.3881164789199829, Valid Loss: 0.6430795788764954\n",
      "Epoch: 3698, Train Loss: 0.3881050646305084, Valid Loss: 0.635108232498169\n",
      "Epoch: 3699, Train Loss: 0.3881009817123413, Valid Loss: 0.6380559206008911\n",
      "Epoch: 3700, Train Loss: 0.38810253143310547, Valid Loss: 0.6398137807846069\n",
      "Epoch: 3701, Train Loss: 0.3881082236766815, Valid Loss: 0.6339528560638428\n",
      "Epoch: 3702, Train Loss: 0.3881155848503113, Valid Loss: 0.6433516144752502\n",
      "Epoch: 3703, Train Loss: 0.38812291622161865, Valid Loss: 0.6312621235847473\n",
      "Epoch: 3704, Train Loss: 0.38812828063964844, Valid Loss: 0.645376980304718\n",
      "Epoch: 3705, Train Loss: 0.38813090324401855, Valid Loss: 0.6301273107528687\n",
      "Epoch: 3706, Train Loss: 0.3881312906742096, Valid Loss: 0.6458227038383484\n",
      "Epoch: 3707, Train Loss: 0.38812872767448425, Valid Loss: 0.6304239630699158\n",
      "Epoch: 3708, Train Loss: 0.38812461495399475, Valid Loss: 0.6449688076972961\n",
      "Epoch: 3709, Train Loss: 0.388119101524353, Valid Loss: 0.631791889667511\n",
      "Epoch: 3710, Train Loss: 0.38811352849006653, Valid Loss: 0.6433089375495911\n",
      "Epoch: 3711, Train Loss: 0.3881080746650696, Valid Loss: 0.6336974501609802\n",
      "Epoch: 3712, Train Loss: 0.38810333609580994, Valid Loss: 0.6413459777832031\n",
      "Epoch: 3713, Train Loss: 0.38809970021247864, Valid Loss: 0.6356778144836426\n",
      "Epoch: 3714, Train Loss: 0.38809704780578613, Valid Loss: 0.6394818425178528\n",
      "Epoch: 3715, Train Loss: 0.3880951404571533, Valid Loss: 0.6374602317810059\n",
      "Epoch: 3716, Train Loss: 0.388094037771225, Valid Loss: 0.6378918886184692\n",
      "Epoch: 3717, Train Loss: 0.3880937695503235, Valid Loss: 0.6389216780662537\n",
      "Epoch: 3718, Train Loss: 0.3880939185619354, Valid Loss: 0.6366797089576721\n",
      "Epoch: 3719, Train Loss: 0.3880944848060608, Valid Loss: 0.6400299072265625\n",
      "Epoch: 3720, Train Loss: 0.3880954086780548, Valid Loss: 0.6358008980751038\n",
      "Epoch: 3721, Train Loss: 0.3880962133407593, Valid Loss: 0.6408484578132629\n",
      "Epoch: 3722, Train Loss: 0.38809719681739807, Valid Loss: 0.6351309418678284\n",
      "Epoch: 3723, Train Loss: 0.3880983889102936, Valid Loss: 0.6415424942970276\n",
      "Epoch: 3724, Train Loss: 0.3880995810031891, Valid Loss: 0.634518563747406\n",
      "Epoch: 3725, Train Loss: 0.3881009519100189, Valid Loss: 0.6422651410102844\n",
      "Epoch: 3726, Train Loss: 0.38810276985168457, Valid Loss: 0.633808970451355\n",
      "Epoch: 3727, Train Loss: 0.3881045877933502, Valid Loss: 0.6431361436843872\n",
      "Epoch: 3728, Train Loss: 0.3881070017814636, Valid Loss: 0.6329329609870911\n",
      "Epoch: 3729, Train Loss: 0.38811010122299194, Valid Loss: 0.6442068219184875\n",
      "Epoch: 3730, Train Loss: 0.38811376690864563, Valid Loss: 0.6318240165710449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3731, Train Loss: 0.38811856508255005, Valid Loss: 0.6455309391021729\n",
      "Epoch: 3732, Train Loss: 0.3881244659423828, Valid Loss: 0.6304396986961365\n",
      "Epoch: 3733, Train Loss: 0.38813161849975586, Valid Loss: 0.6471554040908813\n",
      "Epoch: 3734, Train Loss: 0.3881400525569916, Valid Loss: 0.6287810206413269\n",
      "Epoch: 3735, Train Loss: 0.38815027475357056, Valid Loss: 0.6490570306777954\n",
      "Epoch: 3736, Train Loss: 0.3881606459617615, Valid Loss: 0.6269328594207764\n",
      "Epoch: 3737, Train Loss: 0.38817286491394043, Valid Loss: 0.6510303020477295\n",
      "Epoch: 3738, Train Loss: 0.3881835341453552, Valid Loss: 0.6252164244651794\n",
      "Epoch: 3739, Train Loss: 0.38819336891174316, Valid Loss: 0.6526022553443909\n",
      "Epoch: 3740, Train Loss: 0.38819754123687744, Valid Loss: 0.6242170929908752\n",
      "Epoch: 3741, Train Loss: 0.3881980776786804, Valid Loss: 0.653042197227478\n",
      "Epoch: 3742, Train Loss: 0.38818827271461487, Valid Loss: 0.6246665120124817\n",
      "Epoch: 3743, Train Loss: 0.3881738483905792, Valid Loss: 0.651573896408081\n",
      "Epoch: 3744, Train Loss: 0.3881525695323944, Valid Loss: 0.6270968317985535\n",
      "Epoch: 3745, Train Loss: 0.38813120126724243, Valid Loss: 0.6480880975723267\n",
      "Epoch: 3746, Train Loss: 0.388111412525177, Valid Loss: 0.6311951279640198\n",
      "Epoch: 3747, Train Loss: 0.388095885515213, Valid Loss: 0.643393874168396\n",
      "Epoch: 3748, Train Loss: 0.38808557391166687, Valid Loss: 0.6359558701515198\n",
      "Epoch: 3749, Train Loss: 0.38808128237724304, Valid Loss: 0.6387209892272949\n",
      "Epoch: 3750, Train Loss: 0.388082355260849, Valid Loss: 0.6402786374092102\n",
      "Epoch: 3751, Train Loss: 0.38808682560920715, Valid Loss: 0.63496333360672\n",
      "Epoch: 3752, Train Loss: 0.3880940079689026, Valid Loss: 0.6435536742210388\n",
      "Epoch: 3753, Train Loss: 0.38810059428215027, Valid Loss: 0.63242506980896\n",
      "Epoch: 3754, Train Loss: 0.3881058394908905, Valid Loss: 0.6455649733543396\n",
      "Epoch: 3755, Train Loss: 0.38810911774635315, Valid Loss: 0.6311216354370117\n",
      "Epoch: 3756, Train Loss: 0.3881104290485382, Valid Loss: 0.6463435292243958\n",
      "Epoch: 3757, Train Loss: 0.3881092965602875, Valid Loss: 0.630981981754303\n",
      "Epoch: 3758, Train Loss: 0.38810673356056213, Valid Loss: 0.6459846496582031\n",
      "Epoch: 3759, Train Loss: 0.3881019353866577, Valid Loss: 0.6318920850753784\n",
      "Epoch: 3760, Train Loss: 0.38809677958488464, Valid Loss: 0.6446957588195801\n",
      "Epoch: 3761, Train Loss: 0.38809192180633545, Valid Loss: 0.6335260272026062\n",
      "Epoch: 3762, Train Loss: 0.3880871832370758, Valid Loss: 0.6429133415222168\n",
      "Epoch: 3763, Train Loss: 0.38808345794677734, Valid Loss: 0.6354042291641235\n",
      "Epoch: 3764, Train Loss: 0.3880801498889923, Valid Loss: 0.6411197781562805\n",
      "Epoch: 3765, Train Loss: 0.3880775272846222, Valid Loss: 0.6371096968650818\n",
      "Epoch: 3766, Train Loss: 0.38807618618011475, Valid Loss: 0.6396300196647644\n",
      "Epoch: 3767, Train Loss: 0.3880749046802521, Valid Loss: 0.6384662985801697\n",
      "Epoch: 3768, Train Loss: 0.38807418942451477, Valid Loss: 0.6384881734848022\n",
      "Epoch: 3769, Train Loss: 0.38807395100593567, Valid Loss: 0.6395280361175537\n",
      "Epoch: 3770, Train Loss: 0.38807371258735657, Valid Loss: 0.6375960111618042\n",
      "Epoch: 3771, Train Loss: 0.38807404041290283, Valid Loss: 0.6403672695159912\n",
      "Epoch: 3772, Train Loss: 0.38807404041290283, Valid Loss: 0.6368906497955322\n",
      "Epoch: 3773, Train Loss: 0.38807442784309387, Valid Loss: 0.6410654187202454\n",
      "Epoch: 3774, Train Loss: 0.3880748450756073, Valid Loss: 0.6363121867179871\n",
      "Epoch: 3775, Train Loss: 0.38807570934295654, Valid Loss: 0.6416916847229004\n",
      "Epoch: 3776, Train Loss: 0.3880768120288849, Valid Loss: 0.6357558369636536\n",
      "Epoch: 3777, Train Loss: 0.3880780339241028, Valid Loss: 0.6423726081848145\n",
      "Epoch: 3778, Train Loss: 0.38808009028434753, Valid Loss: 0.6350605487823486\n",
      "Epoch: 3779, Train Loss: 0.3880825638771057, Valid Loss: 0.6432963609695435\n",
      "Epoch: 3780, Train Loss: 0.3880860507488251, Valid Loss: 0.6340517997741699\n",
      "Epoch: 3781, Train Loss: 0.3880906403064728, Valid Loss: 0.64459627866745\n",
      "Epoch: 3782, Train Loss: 0.38809677958488464, Valid Loss: 0.6326115727424622\n",
      "Epoch: 3783, Train Loss: 0.38810479640960693, Valid Loss: 0.6464176774024963\n",
      "Epoch: 3784, Train Loss: 0.38811567425727844, Valid Loss: 0.630624532699585\n",
      "Epoch: 3785, Train Loss: 0.38812878727912903, Valid Loss: 0.6488620638847351\n",
      "Epoch: 3786, Train Loss: 0.3881451189517975, Valid Loss: 0.628059983253479\n",
      "Epoch: 3787, Train Loss: 0.3881639242172241, Valid Loss: 0.6518559455871582\n",
      "Epoch: 3788, Train Loss: 0.3881837725639343, Valid Loss: 0.625113844871521\n",
      "Epoch: 3789, Train Loss: 0.3882046043872833, Valid Loss: 0.6549525260925293\n",
      "Epoch: 3790, Train Loss: 0.38821929693222046, Valid Loss: 0.6225293874740601\n",
      "Epoch: 3791, Train Loss: 0.38823041319847107, Valid Loss: 0.6569323539733887\n",
      "Epoch: 3792, Train Loss: 0.38822561502456665, Valid Loss: 0.621751606464386\n",
      "Epoch: 3793, Train Loss: 0.3882129490375519, Valid Loss: 0.6561751365661621\n",
      "Epoch: 3794, Train Loss: 0.3881842792034149, Valid Loss: 0.6241605281829834\n",
      "Epoch: 3795, Train Loss: 0.38815078139305115, Valid Loss: 0.651871919631958\n",
      "Epoch: 3796, Train Loss: 0.3881143033504486, Valid Loss: 0.6297050714492798\n",
      "Epoch: 3797, Train Loss: 0.3880850374698639, Valid Loss: 0.6450794339179993\n",
      "Epoch: 3798, Train Loss: 0.3880673050880432, Valid Loss: 0.6367732286453247\n",
      "Epoch: 3799, Train Loss: 0.38806432485580444, Valid Loss: 0.6379266977310181\n",
      "Epoch: 3800, Train Loss: 0.3880730867385864, Valid Loss: 0.6434584259986877\n",
      "Epoch: 3801, Train Loss: 0.3880876302719116, Valid Loss: 0.6322305798530579\n",
      "Epoch: 3802, Train Loss: 0.38810262084007263, Valid Loss: 0.6481130719184875\n",
      "Epoch: 3803, Train Loss: 0.38811177015304565, Valid Loss: 0.6292337775230408\n",
      "Epoch: 3804, Train Loss: 0.3881136476993561, Valid Loss: 0.6495225429534912\n",
      "Epoch: 3805, Train Loss: 0.3881070911884308, Valid Loss: 0.6296380758285522\n",
      "Epoch: 3806, Train Loss: 0.3880964517593384, Valid Loss: 0.6475672721862793\n",
      "Epoch: 3807, Train Loss: 0.38808462023735046, Valid Loss: 0.6327310800552368\n",
      "Epoch: 3808, Train Loss: 0.38807404041290283, Valid Loss: 0.6437392234802246\n",
      "Epoch: 3809, Train Loss: 0.38806676864624023, Valid Loss: 0.6367504000663757\n",
      "Epoch: 3810, Train Loss: 0.3880629241466522, Valid Loss: 0.6399015188217163\n",
      "Epoch: 3811, Train Loss: 0.3880611062049866, Valid Loss: 0.6402377486228943\n",
      "Epoch: 3812, Train Loss: 0.38806208968162537, Valid Loss: 0.6369592547416687\n",
      "Epoch: 3813, Train Loss: 0.3880641758441925, Valid Loss: 0.6426845788955688\n",
      "Epoch: 3814, Train Loss: 0.3880669176578522, Valid Loss: 0.6351579427719116\n",
      "Epoch: 3815, Train Loss: 0.38806992769241333, Valid Loss: 0.6440303325653076\n",
      "Epoch: 3816, Train Loss: 0.3880724310874939, Valid Loss: 0.6344401836395264\n",
      "Epoch: 3817, Train Loss: 0.38807353377342224, Valid Loss: 0.6443323493003845\n",
      "Epoch: 3818, Train Loss: 0.3880729079246521, Valid Loss: 0.6346550583839417\n",
      "Epoch: 3819, Train Loss: 0.3880707919597626, Valid Loss: 0.6439073085784912\n",
      "Epoch: 3820, Train Loss: 0.38806769251823425, Valid Loss: 0.6353724002838135\n",
      "Epoch: 3821, Train Loss: 0.38806411623954773, Valid Loss: 0.6431222558021545\n",
      "Epoch: 3822, Train Loss: 0.388060986995697, Valid Loss: 0.6361843347549438\n",
      "Epoch: 3823, Train Loss: 0.3880585730075836, Valid Loss: 0.6422443389892578\n",
      "Epoch: 3824, Train Loss: 0.3880568742752075, Valid Loss: 0.6371408700942993\n",
      "Epoch: 3825, Train Loss: 0.3880555331707001, Valid Loss: 0.6412186622619629\n",
      "Epoch: 3826, Train Loss: 0.3880544900894165, Valid Loss: 0.6383383870124817\n",
      "Epoch: 3827, Train Loss: 0.38805344700813293, Valid Loss: 0.6400064826011658\n",
      "Epoch: 3828, Train Loss: 0.3880529999732971, Valid Loss: 0.6396281123161316\n",
      "Epoch: 3829, Train Loss: 0.38805267214775085, Valid Loss: 0.6388501524925232\n",
      "Epoch: 3830, Train Loss: 0.38805291056632996, Valid Loss: 0.6407381296157837\n",
      "Epoch: 3831, Train Loss: 0.38805314898490906, Valid Loss: 0.6379048228263855\n",
      "Epoch: 3832, Train Loss: 0.38805362582206726, Valid Loss: 0.6415939331054688\n",
      "Epoch: 3833, Train Loss: 0.3880539834499359, Valid Loss: 0.6372148990631104\n",
      "Epoch: 3834, Train Loss: 0.3880544900894165, Valid Loss: 0.6422764658927917\n",
      "Epoch: 3835, Train Loss: 0.38805487751960754, Valid Loss: 0.6366605162620544\n",
      "Epoch: 3836, Train Loss: 0.3880554139614105, Valid Loss: 0.642884373664856\n",
      "Epoch: 3837, Train Loss: 0.3880561888217926, Valid Loss: 0.636146068572998\n",
      "Epoch: 3838, Train Loss: 0.3880571722984314, Valid Loss: 0.643473744392395\n",
      "Epoch: 3839, Train Loss: 0.3880586624145508, Valid Loss: 0.6355736255645752\n",
      "Epoch: 3840, Train Loss: 0.3880605697631836, Valid Loss: 0.6442014575004578\n",
      "Epoch: 3841, Train Loss: 0.38806331157684326, Valid Loss: 0.6347644329071045\n",
      "Epoch: 3842, Train Loss: 0.3880671262741089, Valid Loss: 0.6453049182891846\n",
      "Epoch: 3843, Train Loss: 0.38807183504104614, Valid Loss: 0.6335141658782959\n",
      "Epoch: 3844, Train Loss: 0.3880789577960968, Valid Loss: 0.6469593048095703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3845, Train Loss: 0.3880874514579773, Valid Loss: 0.6316620707511902\n",
      "Epoch: 3846, Train Loss: 0.38810017704963684, Valid Loss: 0.6492883563041687\n",
      "Epoch: 3847, Train Loss: 0.38811519742012024, Valid Loss: 0.6291500926017761\n",
      "Epoch: 3848, Train Loss: 0.3881346583366394, Valid Loss: 0.6522690057754517\n",
      "Epoch: 3849, Train Loss: 0.38815656304359436, Valid Loss: 0.6261406540870667\n",
      "Epoch: 3850, Train Loss: 0.3881814479827881, Valid Loss: 0.6555755734443665\n",
      "Epoch: 3851, Train Loss: 0.38820281624794006, Valid Loss: 0.6232298016548157\n",
      "Epoch: 3852, Train Loss: 0.38822129368782043, Valid Loss: 0.6581707000732422\n",
      "Epoch: 3853, Train Loss: 0.3882242441177368, Valid Loss: 0.6217758655548096\n",
      "Epoch: 3854, Train Loss: 0.3882155418395996, Valid Loss: 0.6582056283950806\n",
      "Epoch: 3855, Train Loss: 0.38818612694740295, Valid Loss: 0.6235241889953613\n",
      "Epoch: 3856, Train Loss: 0.38814830780029297, Valid Loss: 0.6542478799819946\n",
      "Epoch: 3857, Train Loss: 0.3881058394908905, Valid Loss: 0.6290374994277954\n",
      "Epoch: 3858, Train Loss: 0.38807153701782227, Valid Loss: 0.6470890641212463\n",
      "Epoch: 3859, Train Loss: 0.3880506455898285, Valid Loss: 0.63663250207901\n",
      "Epoch: 3860, Train Loss: 0.3880447447299957, Valid Loss: 0.6393277049064636\n",
      "Epoch: 3861, Train Loss: 0.38805150985717773, Valid Loss: 0.6438025832176208\n",
      "Epoch: 3862, Train Loss: 0.3880660831928253, Valid Loss: 0.6332463622093201\n",
      "Epoch: 3863, Train Loss: 0.3880823254585266, Valid Loss: 0.6487777233123779\n",
      "Epoch: 3864, Train Loss: 0.38809460401535034, Valid Loss: 0.6299841403961182\n",
      "Epoch: 3865, Train Loss: 0.3880983591079712, Valid Loss: 0.6505346894264221\n",
      "Epoch: 3866, Train Loss: 0.388092964887619, Valid Loss: 0.6299619078636169\n",
      "Epoch: 3867, Train Loss: 0.38808128237724304, Valid Loss: 0.648922860622406\n",
      "Epoch: 3868, Train Loss: 0.3880667984485626, Valid Loss: 0.6328408718109131\n",
      "Epoch: 3869, Train Loss: 0.38805434107780457, Valid Loss: 0.64501953125\n",
      "Epoch: 3870, Train Loss: 0.38804465532302856, Valid Loss: 0.6372366547584534\n",
      "Epoch: 3871, Train Loss: 0.3880402743816376, Valid Loss: 0.6405479907989502\n",
      "Epoch: 3872, Train Loss: 0.3880402147769928, Valid Loss: 0.6414461731910706\n",
      "Epoch: 3873, Train Loss: 0.38804367184638977, Valid Loss: 0.6369828581809998\n",
      "Epoch: 3874, Train Loss: 0.38804835081100464, Valid Loss: 0.644385576248169\n",
      "Epoch: 3875, Train Loss: 0.38805267214775085, Valid Loss: 0.6348921060562134\n",
      "Epoch: 3876, Train Loss: 0.3880555331707001, Valid Loss: 0.6457982063293457\n",
      "Epoch: 3877, Train Loss: 0.3880561888217926, Valid Loss: 0.6342636346817017\n",
      "Epoch: 3878, Train Loss: 0.38805535435676575, Valid Loss: 0.6458582878112793\n",
      "Epoch: 3879, Train Loss: 0.3880530297756195, Valid Loss: 0.6348483562469482\n",
      "Epoch: 3880, Train Loss: 0.388049840927124, Valid Loss: 0.6448579430580139\n",
      "Epoch: 3881, Train Loss: 0.388045996427536, Valid Loss: 0.6362934708595276\n",
      "Epoch: 3882, Train Loss: 0.3880420923233032, Valid Loss: 0.6431947946548462\n",
      "Epoch: 3883, Train Loss: 0.38803917169570923, Valid Loss: 0.6381025314331055\n",
      "Epoch: 3884, Train Loss: 0.3880368173122406, Valid Loss: 0.6414163112640381\n",
      "Epoch: 3885, Train Loss: 0.38803544640541077, Valid Loss: 0.6397799849510193\n",
      "Epoch: 3886, Train Loss: 0.38803502917289734, Valid Loss: 0.6399343013763428\n",
      "Epoch: 3887, Train Loss: 0.3880349099636078, Valid Loss: 0.6411181092262268\n",
      "Epoch: 3888, Train Loss: 0.3880351483821869, Valid Loss: 0.6388542652130127\n",
      "Epoch: 3889, Train Loss: 0.38803592324256897, Valid Loss: 0.6421111822128296\n",
      "Epoch: 3890, Train Loss: 0.3880368173122406, Valid Loss: 0.6380741596221924\n",
      "Epoch: 3891, Train Loss: 0.3880372643470764, Valid Loss: 0.6428500413894653\n",
      "Epoch: 3892, Train Loss: 0.38803860545158386, Valid Loss: 0.6374735236167908\n",
      "Epoch: 3893, Train Loss: 0.3880390524864197, Valid Loss: 0.643454909324646\n",
      "Epoch: 3894, Train Loss: 0.38803955912590027, Valid Loss: 0.6369812488555908\n",
      "Epoch: 3895, Train Loss: 0.3880402743816376, Valid Loss: 0.6439527869224548\n",
      "Epoch: 3896, Train Loss: 0.38804078102111816, Valid Loss: 0.6365845799446106\n",
      "Epoch: 3897, Train Loss: 0.38804128766059875, Valid Loss: 0.6444035172462463\n",
      "Epoch: 3898, Train Loss: 0.38804200291633606, Valid Loss: 0.636191725730896\n",
      "Epoch: 3899, Train Loss: 0.3880428671836853, Valid Loss: 0.644911527633667\n",
      "Epoch: 3900, Train Loss: 0.3880440890789032, Valid Loss: 0.635678231716156\n",
      "Epoch: 3901, Train Loss: 0.38804537057876587, Valid Loss: 0.6455761790275574\n",
      "Epoch: 3902, Train Loss: 0.38804760575294495, Valid Loss: 0.6349872350692749\n",
      "Epoch: 3903, Train Loss: 0.3880499601364136, Valid Loss: 0.6464357972145081\n",
      "Epoch: 3904, Train Loss: 0.3880532383918762, Valid Loss: 0.6340950131416321\n",
      "Epoch: 3905, Train Loss: 0.3880571722984314, Valid Loss: 0.6475356817245483\n",
      "Epoch: 3906, Train Loss: 0.38806211948394775, Valid Loss: 0.6329428553581238\n",
      "Epoch: 3907, Train Loss: 0.38806870579719543, Valid Loss: 0.6489441394805908\n",
      "Epoch: 3908, Train Loss: 0.388076514005661, Valid Loss: 0.6314693689346313\n",
      "Epoch: 3909, Train Loss: 0.3880860209465027, Valid Loss: 0.6507047414779663\n",
      "Epoch: 3910, Train Loss: 0.3880968987941742, Valid Loss: 0.6296936869621277\n",
      "Epoch: 3911, Train Loss: 0.3881092965602875, Valid Loss: 0.6527217626571655\n",
      "Epoch: 3912, Train Loss: 0.3881213665008545, Valid Loss: 0.6278087496757507\n",
      "Epoch: 3913, Train Loss: 0.38813328742980957, Valid Loss: 0.6546209454536438\n",
      "Epoch: 3914, Train Loss: 0.3881411850452423, Valid Loss: 0.6263431310653687\n",
      "Epoch: 3915, Train Loss: 0.3881455063819885, Valid Loss: 0.6556943655014038\n",
      "Epoch: 3916, Train Loss: 0.38814184069633484, Valid Loss: 0.6260380744934082\n",
      "Epoch: 3917, Train Loss: 0.3881329298019409, Valid Loss: 0.6551055908203125\n",
      "Epoch: 3918, Train Loss: 0.3881157338619232, Valid Loss: 0.6275859475135803\n",
      "Epoch: 3919, Train Loss: 0.388095498085022, Valid Loss: 0.6524108648300171\n",
      "Epoch: 3920, Train Loss: 0.38807323575019836, Valid Loss: 0.6310447454452515\n",
      "Epoch: 3921, Train Loss: 0.3880539536476135, Valid Loss: 0.6481184363365173\n",
      "Epoch: 3922, Train Loss: 0.388038694858551, Valid Loss: 0.6356256604194641\n",
      "Epoch: 3923, Train Loss: 0.3880295753479004, Valid Loss: 0.6433045864105225\n",
      "Epoch: 3924, Train Loss: 0.3880262076854706, Valid Loss: 0.6402881741523743\n",
      "Epoch: 3925, Train Loss: 0.38802674412727356, Valid Loss: 0.6389864683151245\n",
      "Epoch: 3926, Train Loss: 0.38803136348724365, Valid Loss: 0.644223690032959\n",
      "Epoch: 3927, Train Loss: 0.3880373537540436, Valid Loss: 0.6356644630432129\n",
      "Epoch: 3928, Train Loss: 0.38804396986961365, Valid Loss: 0.6470448970794678\n",
      "Epoch: 3929, Train Loss: 0.3880494236946106, Valid Loss: 0.6335607767105103\n",
      "Epoch: 3930, Train Loss: 0.3880533277988434, Valid Loss: 0.6485724449157715\n",
      "Epoch: 3931, Train Loss: 0.38805460929870605, Valid Loss: 0.6327575445175171\n",
      "Epoch: 3932, Train Loss: 0.38805416226387024, Valid Loss: 0.648794412612915\n",
      "Epoch: 3933, Train Loss: 0.38805124163627625, Valid Loss: 0.6331762075424194\n",
      "Epoch: 3934, Train Loss: 0.38804689049720764, Valid Loss: 0.647914707660675\n",
      "Epoch: 3935, Train Loss: 0.3880418539047241, Valid Loss: 0.6344812512397766\n",
      "Epoch: 3936, Train Loss: 0.3880362808704376, Valid Loss: 0.64635169506073\n",
      "Epoch: 3937, Train Loss: 0.388031542301178, Valid Loss: 0.6362373232841492\n",
      "Epoch: 3938, Train Loss: 0.38802725076675415, Valid Loss: 0.644508957862854\n",
      "Epoch: 3939, Train Loss: 0.38802415132522583, Valid Loss: 0.6381238698959351\n",
      "Epoch: 3940, Train Loss: 0.388021856546402, Valid Loss: 0.6427045464515686\n",
      "Epoch: 3941, Train Loss: 0.38802069425582886, Valid Loss: 0.6398847699165344\n",
      "Epoch: 3942, Train Loss: 0.38801994919776917, Valid Loss: 0.6411471366882324\n",
      "Epoch: 3943, Train Loss: 0.38801947236061096, Valid Loss: 0.6413366198539734\n",
      "Epoch: 3944, Train Loss: 0.3880194425582886, Valid Loss: 0.6399456262588501\n",
      "Epoch: 3945, Train Loss: 0.3880196511745453, Valid Loss: 0.6424005031585693\n",
      "Epoch: 3946, Train Loss: 0.3880194425582886, Valid Loss: 0.6390971541404724\n",
      "Epoch: 3947, Train Loss: 0.3880199193954468, Valid Loss: 0.6431456208229065\n",
      "Epoch: 3948, Train Loss: 0.3880203068256378, Valid Loss: 0.6384998559951782\n",
      "Epoch: 3949, Train Loss: 0.38802120089530945, Valid Loss: 0.6437512040138245\n",
      "Epoch: 3950, Train Loss: 0.3880217671394348, Valid Loss: 0.6379531621932983\n",
      "Epoch: 3951, Train Loss: 0.3880230784416199, Valid Loss: 0.6444001793861389\n",
      "Epoch: 3952, Train Loss: 0.3880244195461273, Valid Loss: 0.6373106241226196\n",
      "Epoch: 3953, Train Loss: 0.38802602887153625, Valid Loss: 0.645215630531311\n",
      "Epoch: 3954, Train Loss: 0.3880290985107422, Valid Loss: 0.636447548866272\n",
      "Epoch: 3955, Train Loss: 0.38803237676620483, Valid Loss: 0.6463320851325989\n",
      "Epoch: 3956, Train Loss: 0.3880371153354645, Valid Loss: 0.6352113485336304\n",
      "Epoch: 3957, Train Loss: 0.3880435526371002, Valid Loss: 0.6479244232177734\n",
      "Epoch: 3958, Train Loss: 0.3880520761013031, Valid Loss: 0.6334472894668579\n",
      "Epoch: 3959, Train Loss: 0.38806307315826416, Valid Loss: 0.6501383781433105\n",
      "Epoch: 3960, Train Loss: 0.3880773186683655, Valid Loss: 0.6310391426086426\n",
      "Epoch: 3961, Train Loss: 0.3880949020385742, Valid Loss: 0.6530565619468689\n",
      "Epoch: 3962, Train Loss: 0.38811609148979187, Valid Loss: 0.6280176639556885\n",
      "Epoch: 3963, Train Loss: 0.3881404399871826, Valid Loss: 0.6564767360687256\n",
      "Epoch: 3964, Train Loss: 0.3881640136241913, Valid Loss: 0.6248570680618286\n",
      "Epoch: 3965, Train Loss: 0.38818639516830444, Valid Loss: 0.6595126986503601\n",
      "Epoch: 3966, Train Loss: 0.388196736574173, Valid Loss: 0.622766375541687\n",
      "Epoch: 3967, Train Loss: 0.3881974220275879, Valid Loss: 0.6604732275009155\n",
      "Epoch: 3968, Train Loss: 0.3881772756576538, Valid Loss: 0.6234714984893799\n",
      "Epoch: 3969, Train Loss: 0.38814690709114075, Valid Loss: 0.6576935648918152\n",
      "Epoch: 3970, Train Loss: 0.3881056308746338, Valid Loss: 0.6279548406600952\n",
      "Epoch: 3971, Train Loss: 0.3880667984485626, Valid Loss: 0.6512628197669983\n",
      "Epoch: 3972, Train Loss: 0.38803499937057495, Valid Loss: 0.6351883411407471\n",
      "Epoch: 3973, Train Loss: 0.38801780343055725, Valid Loss: 0.6433271765708923\n",
      "Epoch: 3974, Train Loss: 0.38801518082618713, Valid Loss: 0.6428743600845337\n",
      "Epoch: 3975, Train Loss: 0.3880257308483124, Valid Loss: 0.6362865567207336\n",
      "Epoch: 3976, Train Loss: 0.38804298639297485, Valid Loss: 0.6490232348442078\n",
      "Epoch: 3977, Train Loss: 0.3880588412284851, Valid Loss: 0.6316931247711182\n",
      "Epoch: 3978, Train Loss: 0.3880683481693268, Valid Loss: 0.6521461009979248\n",
      "Epoch: 3979, Train Loss: 0.3880680203437805, Valid Loss: 0.6304458975791931\n",
      "Epoch: 3980, Train Loss: 0.38806092739105225, Valid Loss: 0.6515374779701233\n",
      "Epoch: 3981, Train Loss: 0.3880471885204315, Valid Loss: 0.6327050924301147\n",
      "Epoch: 3982, Train Loss: 0.3880321681499481, Valid Loss: 0.6479080319404602\n",
      "Epoch: 3983, Train Loss: 0.38801833987236023, Valid Loss: 0.6370941996574402\n",
      "Epoch: 3984, Train Loss: 0.38801097869873047, Valid Loss: 0.6431910991668701\n",
      "Epoch: 3985, Train Loss: 0.38800913095474243, Valid Loss: 0.6416378617286682\n",
      "Epoch: 3986, Train Loss: 0.3880113363265991, Valid Loss: 0.639177143573761\n",
      "Epoch: 3987, Train Loss: 0.38801565766334534, Valid Loss: 0.6450909972190857\n",
      "Epoch: 3988, Train Loss: 0.3880200684070587, Valid Loss: 0.6365309953689575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3989, Train Loss: 0.388023316860199, Valid Loss: 0.6470627784729004\n",
      "Epoch: 3990, Train Loss: 0.38802570104599, Valid Loss: 0.6353983879089355\n",
      "Epoch: 3991, Train Loss: 0.3880258798599243, Valid Loss: 0.6475241780281067\n",
      "Epoch: 3992, Train Loss: 0.3880247473716736, Valid Loss: 0.6357356309890747\n",
      "Epoch: 3993, Train Loss: 0.388022243976593, Valid Loss: 0.646630048751831\n",
      "Epoch: 3994, Train Loss: 0.38801875710487366, Valid Loss: 0.6371869444847107\n",
      "Epoch: 3995, Train Loss: 0.3880153000354767, Valid Loss: 0.6449516415596008\n",
      "Epoch: 3996, Train Loss: 0.3880116641521454, Valid Loss: 0.6389848589897156\n",
      "Epoch: 3997, Train Loss: 0.3880085349082947, Valid Loss: 0.6432496905326843\n",
      "Epoch: 3998, Train Loss: 0.38800621032714844, Valid Loss: 0.6405078172683716\n",
      "Epoch: 3999, Train Loss: 0.3880048096179962, Valid Loss: 0.6419141888618469\n",
      "Epoch: 4000, Train Loss: 0.3880043923854828, Valid Loss: 0.6417036652565002\n",
      "Epoch: 4001, Train Loss: 0.3880048990249634, Valid Loss: 0.6408681273460388\n",
      "Epoch: 4002, Train Loss: 0.3880053460597992, Valid Loss: 0.6427819132804871\n",
      "Epoch: 4003, Train Loss: 0.388006329536438, Valid Loss: 0.6398968696594238\n",
      "Epoch: 4004, Train Loss: 0.38800695538520813, Valid Loss: 0.643770158290863\n",
      "Epoch: 4005, Train Loss: 0.38800784945487976, Valid Loss: 0.6390516757965088\n",
      "Epoch: 4006, Train Loss: 0.3880087435245514, Valid Loss: 0.644561767578125\n",
      "Epoch: 4007, Train Loss: 0.3880092203617096, Valid Loss: 0.6384375095367432\n",
      "Epoch: 4008, Train Loss: 0.38801002502441406, Valid Loss: 0.6451458930969238\n",
      "Epoch: 4009, Train Loss: 0.38801029324531555, Valid Loss: 0.6379637122154236\n",
      "Epoch: 4010, Train Loss: 0.38801097869873047, Valid Loss: 0.6456599235534668\n",
      "Epoch: 4011, Train Loss: 0.38801127672195435, Valid Loss: 0.6375048160552979\n",
      "Epoch: 4012, Train Loss: 0.3880120813846588, Valid Loss: 0.6462050676345825\n",
      "Epoch: 4013, Train Loss: 0.3880128860473633, Valid Loss: 0.6370112299919128\n",
      "Epoch: 4014, Train Loss: 0.3880140781402588, Valid Loss: 0.6467555165290833\n",
      "Epoch: 4015, Train Loss: 0.3880150616168976, Valid Loss: 0.6365156173706055\n",
      "Epoch: 4016, Train Loss: 0.38801708817481995, Valid Loss: 0.6473380923271179\n",
      "Epoch: 4017, Train Loss: 0.3880191445350647, Valid Loss: 0.6359409093856812\n",
      "Epoch: 4018, Train Loss: 0.388022243976593, Valid Loss: 0.6481015086174011\n",
      "Epoch: 4019, Train Loss: 0.38802599906921387, Valid Loss: 0.6351063251495361\n",
      "Epoch: 4020, Train Loss: 0.38803115487098694, Valid Loss: 0.6492151618003845\n",
      "Epoch: 4021, Train Loss: 0.3880373537540436, Valid Loss: 0.6338729858398438\n",
      "Epoch: 4022, Train Loss: 0.3880453407764435, Valid Loss: 0.6507968306541443\n",
      "Epoch: 4023, Train Loss: 0.38805490732192993, Valid Loss: 0.6322069764137268\n",
      "Epoch: 4024, Train Loss: 0.3880661427974701, Valid Loss: 0.6527841687202454\n",
      "Epoch: 4025, Train Loss: 0.3880786597728729, Valid Loss: 0.6302167177200317\n",
      "Epoch: 4026, Train Loss: 0.3880925476551056, Valid Loss: 0.654998242855072\n",
      "Epoch: 4027, Train Loss: 0.38810479640960693, Valid Loss: 0.6281993985176086\n",
      "Epoch: 4028, Train Loss: 0.3881162405014038, Valid Loss: 0.6569411754608154\n",
      "Epoch: 4029, Train Loss: 0.38812255859375, Valid Loss: 0.6267733573913574\n",
      "Epoch: 4030, Train Loss: 0.3881244957447052, Valid Loss: 0.6577927470207214\n",
      "Epoch: 4031, Train Loss: 0.3881167769432068, Valid Loss: 0.6268205046653748\n",
      "Epoch: 4032, Train Loss: 0.38810333609580994, Valid Loss: 0.6566194295883179\n",
      "Epoch: 4033, Train Loss: 0.3880818784236908, Valid Loss: 0.6290388703346252\n",
      "Epoch: 4034, Train Loss: 0.3880583643913269, Valid Loss: 0.6531502604484558\n",
      "Epoch: 4035, Train Loss: 0.38803473114967346, Valid Loss: 0.6332586407661438\n",
      "Epoch: 4036, Train Loss: 0.38801559805870056, Valid Loss: 0.6481435894966125\n",
      "Epoch: 4037, Train Loss: 0.38800257444381714, Valid Loss: 0.6384347677230835\n",
      "Epoch: 4038, Train Loss: 0.38799625635147095, Valid Loss: 0.6429223418235779\n",
      "Epoch: 4039, Train Loss: 0.38799652457237244, Valid Loss: 0.6433441042900085\n",
      "Epoch: 4040, Train Loss: 0.3880011737346649, Valid Loss: 0.6385509371757507\n",
      "Epoch: 4041, Train Loss: 0.3880086839199066, Valid Loss: 0.6471999883651733\n",
      "Epoch: 4042, Train Loss: 0.3880160450935364, Valid Loss: 0.6354891061782837\n",
      "Epoch: 4043, Train Loss: 0.38802310824394226, Valid Loss: 0.6496117115020752\n",
      "Epoch: 4044, Train Loss: 0.3880276381969452, Valid Loss: 0.6339160203933716\n",
      "Epoch: 4045, Train Loss: 0.3880295753479004, Valid Loss: 0.6505009531974792\n",
      "Epoch: 4046, Train Loss: 0.38802841305732727, Valid Loss: 0.6338170170783997\n",
      "Epoch: 4047, Train Loss: 0.3880248963832855, Valid Loss: 0.649992823600769\n",
      "Epoch: 4048, Train Loss: 0.38802018761634827, Valid Loss: 0.6349000334739685\n",
      "Epoch: 4049, Train Loss: 0.38801467418670654, Valid Loss: 0.6485252976417542\n",
      "Epoch: 4050, Train Loss: 0.38800904154777527, Valid Loss: 0.6366798877716064\n",
      "Epoch: 4051, Train Loss: 0.3880040943622589, Valid Loss: 0.6465815901756287\n",
      "Epoch: 4052, Train Loss: 0.38799959421157837, Valid Loss: 0.6387038826942444\n",
      "Epoch: 4053, Train Loss: 0.3879964053630829, Valid Loss: 0.6446050405502319\n",
      "Epoch: 4054, Train Loss: 0.3879939913749695, Valid Loss: 0.6406216621398926\n",
      "Epoch: 4055, Train Loss: 0.38799282908439636, Valid Loss: 0.6428446769714355\n",
      "Epoch: 4056, Train Loss: 0.3879922330379486, Valid Loss: 0.6422762274742126\n",
      "Epoch: 4057, Train Loss: 0.387991726398468, Valid Loss: 0.6414136290550232\n",
      "Epoch: 4058, Train Loss: 0.3879919648170471, Valid Loss: 0.6435704827308655\n",
      "Epoch: 4059, Train Loss: 0.3879924416542053, Valid Loss: 0.6403407454490662\n",
      "Epoch: 4060, Train Loss: 0.3879930078983307, Valid Loss: 0.644523561000824\n",
      "Epoch: 4061, Train Loss: 0.3879939913749695, Valid Loss: 0.6395622491836548\n",
      "Epoch: 4062, Train Loss: 0.38799503445625305, Valid Loss: 0.645284116268158\n",
      "Epoch: 4063, Train Loss: 0.3879965841770172, Valid Loss: 0.6388983726501465\n",
      "Epoch: 4064, Train Loss: 0.38799792528152466, Valid Loss: 0.6460118889808655\n",
      "Epoch: 4065, Train Loss: 0.3879998028278351, Valid Loss: 0.6382026076316833\n",
      "Epoch: 4066, Train Loss: 0.38800185918807983, Valid Loss: 0.6468579769134521\n",
      "Epoch: 4067, Train Loss: 0.3880044221878052, Valid Loss: 0.6373484134674072\n",
      "Epoch: 4068, Train Loss: 0.3880077302455902, Valid Loss: 0.6479050517082214\n",
      "Epoch: 4069, Train Loss: 0.38801148533821106, Valid Loss: 0.6362364292144775\n",
      "Epoch: 4070, Train Loss: 0.388016939163208, Valid Loss: 0.649281919002533\n",
      "Epoch: 4071, Train Loss: 0.3880230486392975, Valid Loss: 0.6347779035568237\n",
      "Epoch: 4072, Train Loss: 0.3880313038825989, Valid Loss: 0.6510631442070007\n",
      "Epoch: 4073, Train Loss: 0.3880409896373749, Valid Loss: 0.6328782439231873\n",
      "Epoch: 4074, Train Loss: 0.3880529999732971, Valid Loss: 0.6533116698265076\n",
      "Epoch: 4075, Train Loss: 0.3880668580532074, Valid Loss: 0.6305930614471436\n",
      "Epoch: 4076, Train Loss: 0.3880827724933624, Valid Loss: 0.6558741927146912\n",
      "Epoch: 4077, Train Loss: 0.38809850811958313, Valid Loss: 0.6281816363334656\n",
      "Epoch: 4078, Train Loss: 0.3881148099899292, Valid Loss: 0.6582868099212646\n",
      "Epoch: 4079, Train Loss: 0.3881257474422455, Valid Loss: 0.6263098120689392\n",
      "Epoch: 4080, Train Loss: 0.3881325423717499, Valid Loss: 0.65962815284729\n",
      "Epoch: 4081, Train Loss: 0.3881283700466156, Valid Loss: 0.625980019569397\n",
      "Epoch: 4082, Train Loss: 0.38811641931533813, Valid Loss: 0.6587698459625244\n",
      "Epoch: 4083, Train Loss: 0.3880936801433563, Valid Loss: 0.6280794739723206\n",
      "Epoch: 4084, Train Loss: 0.3880671262741089, Valid Loss: 0.6551930904388428\n",
      "Epoch: 4085, Train Loss: 0.38803789019584656, Valid Loss: 0.632599949836731\n",
      "Epoch: 4086, Train Loss: 0.3880127966403961, Valid Loss: 0.6496085524559021\n",
      "Epoch: 4087, Train Loss: 0.3879946768283844, Valid Loss: 0.6384680271148682\n",
      "Epoch: 4088, Train Loss: 0.38798654079437256, Valid Loss: 0.6435253620147705\n",
      "Epoch: 4089, Train Loss: 0.38798788189888, Valid Loss: 0.6442773342132568\n",
      "Epoch: 4090, Train Loss: 0.38799530267715454, Valid Loss: 0.6383007168769836\n",
      "Epoch: 4091, Train Loss: 0.3880055248737335, Valid Loss: 0.6488298773765564\n",
      "Epoch: 4092, Train Loss: 0.3880143165588379, Valid Loss: 0.6348116397857666\n",
      "Epoch: 4093, Train Loss: 0.388021320104599, Valid Loss: 0.6513524651527405\n",
      "Epoch: 4094, Train Loss: 0.3880256414413452, Valid Loss: 0.6334519982337952\n",
      "Epoch: 4095, Train Loss: 0.3880259692668915, Valid Loss: 0.6517171263694763\n",
      "Epoch: 4096, Train Loss: 0.3880213797092438, Valid Loss: 0.6340534687042236\n",
      "Epoch: 4097, Train Loss: 0.3880141079425812, Valid Loss: 0.6503703594207764\n",
      "Epoch: 4098, Train Loss: 0.3880058228969574, Valid Loss: 0.6359911561012268\n",
      "Epoch: 4099, Train Loss: 0.38799789547920227, Valid Loss: 0.6480206847190857\n",
      "Epoch: 4100, Train Loss: 0.3879910707473755, Valid Loss: 0.6385931968688965\n",
      "Epoch: 4101, Train Loss: 0.38798609375953674, Valid Loss: 0.645271897315979\n",
      "Epoch: 4102, Train Loss: 0.38798317313194275, Valid Loss: 0.6413911581039429\n",
      "Epoch: 4103, Train Loss: 0.3879825174808502, Valid Loss: 0.6425718665122986\n",
      "Epoch: 4104, Train Loss: 0.3879832923412323, Valid Loss: 0.6439732313156128\n",
      "Epoch: 4105, Train Loss: 0.38798457384109497, Valid Loss: 0.6403504014015198\n",
      "Epoch: 4106, Train Loss: 0.38798585534095764, Valid Loss: 0.6458728313446045\n",
      "Epoch: 4107, Train Loss: 0.3879871070384979, Valid Loss: 0.638963520526886\n",
      "Epoch: 4108, Train Loss: 0.38798919320106506, Valid Loss: 0.6468989849090576\n",
      "Epoch: 4109, Train Loss: 0.3879903256893158, Valid Loss: 0.6383761763572693\n",
      "Epoch: 4110, Train Loss: 0.38799142837524414, Valid Loss: 0.6472710371017456\n",
      "Epoch: 4111, Train Loss: 0.3879920542240143, Valid Loss: 0.6382091641426086\n",
      "Epoch: 4112, Train Loss: 0.3879931569099426, Valid Loss: 0.6474458575248718\n",
      "Epoch: 4113, Train Loss: 0.3879936933517456, Valid Loss: 0.6380805969238281\n",
      "Epoch: 4114, Train Loss: 0.3879944086074829, Valid Loss: 0.6476865410804749\n",
      "Epoch: 4115, Train Loss: 0.38799506425857544, Valid Loss: 0.6378697752952576\n",
      "Epoch: 4116, Train Loss: 0.3879958987236023, Valid Loss: 0.64794921875\n",
      "Epoch: 4117, Train Loss: 0.38799601793289185, Valid Loss: 0.6376715898513794\n",
      "Epoch: 4118, Train Loss: 0.3879966735839844, Valid Loss: 0.6482099890708923\n",
      "Epoch: 4119, Train Loss: 0.38799694180488586, Valid Loss: 0.6374570727348328\n",
      "Epoch: 4120, Train Loss: 0.38799798488616943, Valid Loss: 0.6485650539398193\n",
      "Epoch: 4121, Train Loss: 0.3879990875720978, Valid Loss: 0.637037992477417\n",
      "Epoch: 4122, Train Loss: 0.3880005478858948, Valid Loss: 0.6491923332214355\n",
      "Epoch: 4123, Train Loss: 0.388001948595047, Valid Loss: 0.6363239884376526\n",
      "Epoch: 4124, Train Loss: 0.388004332780838, Valid Loss: 0.6500796675682068\n",
      "Epoch: 4125, Train Loss: 0.3880072832107544, Valid Loss: 0.635378360748291\n",
      "Epoch: 4126, Train Loss: 0.38801121711730957, Valid Loss: 0.6511349678039551\n",
      "Epoch: 4127, Train Loss: 0.3880155384540558, Valid Loss: 0.6343437433242798\n",
      "Epoch: 4128, Train Loss: 0.3880208432674408, Valid Loss: 0.6522957682609558\n",
      "Epoch: 4129, Train Loss: 0.38802674412727356, Valid Loss: 0.6332283616065979\n",
      "Epoch: 4130, Train Loss: 0.38803401589393616, Valid Loss: 0.6535758376121521\n",
      "Epoch: 4131, Train Loss: 0.3880411684513092, Valid Loss: 0.6319994926452637\n",
      "Epoch: 4132, Train Loss: 0.388049453496933, Valid Loss: 0.6549402475357056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4133, Train Loss: 0.38805675506591797, Valid Loss: 0.630791962146759\n",
      "Epoch: 4134, Train Loss: 0.3880636990070343, Valid Loss: 0.6561319828033447\n",
      "Epoch: 4135, Train Loss: 0.38806840777397156, Valid Loss: 0.6299338340759277\n",
      "Epoch: 4136, Train Loss: 0.38807031512260437, Valid Loss: 0.6567075252532959\n",
      "Epoch: 4137, Train Loss: 0.38806864619255066, Valid Loss: 0.629904568195343\n",
      "Epoch: 4138, Train Loss: 0.38806280493736267, Valid Loss: 0.656179666519165\n",
      "Epoch: 4139, Train Loss: 0.38805222511291504, Valid Loss: 0.6310510039329529\n",
      "Epoch: 4140, Train Loss: 0.3880384564399719, Valid Loss: 0.6543336510658264\n",
      "Epoch: 4141, Train Loss: 0.3880232870578766, Valid Loss: 0.633383572101593\n",
      "Epoch: 4142, Train Loss: 0.38800832629203796, Valid Loss: 0.6513988971710205\n",
      "Epoch: 4143, Train Loss: 0.3879951536655426, Valid Loss: 0.6365588307380676\n",
      "Epoch: 4144, Train Loss: 0.3879849314689636, Valid Loss: 0.6479262709617615\n",
      "Epoch: 4145, Train Loss: 0.3879777491092682, Valid Loss: 0.6400222778320312\n",
      "Epoch: 4146, Train Loss: 0.38797444105148315, Valid Loss: 0.6445410847663879\n",
      "Epoch: 4147, Train Loss: 0.38797369599342346, Valid Loss: 0.6432098150253296\n",
      "Epoch: 4148, Train Loss: 0.3879750967025757, Valid Loss: 0.6416639685630798\n",
      "Epoch: 4149, Train Loss: 0.3879774510860443, Valid Loss: 0.6458279490470886\n",
      "Epoch: 4150, Train Loss: 0.38798093795776367, Valid Loss: 0.6394413709640503\n",
      "Epoch: 4151, Train Loss: 0.3879843056201935, Valid Loss: 0.6477988958358765\n",
      "Epoch: 4152, Train Loss: 0.3879879117012024, Valid Loss: 0.6378397941589355\n",
      "Epoch: 4153, Train Loss: 0.38799118995666504, Valid Loss: 0.6491995453834534\n",
      "Epoch: 4154, Train Loss: 0.38799405097961426, Valid Loss: 0.6367672085762024\n",
      "Epoch: 4155, Train Loss: 0.3879964053630829, Valid Loss: 0.6501235365867615\n",
      "Epoch: 4156, Train Loss: 0.3879978060722351, Valid Loss: 0.6361097693443298\n",
      "Epoch: 4157, Train Loss: 0.38799911737442017, Valid Loss: 0.6506864428520203\n",
      "Epoch: 4158, Train Loss: 0.38799989223480225, Valid Loss: 0.6357391476631165\n",
      "Epoch: 4159, Train Loss: 0.3880004584789276, Valid Loss: 0.6509883999824524\n",
      "Epoch: 4160, Train Loss: 0.38800036907196045, Valid Loss: 0.6355913281440735\n",
      "Epoch: 4161, Train Loss: 0.38800057768821716, Valid Loss: 0.6511021256446838\n",
      "Epoch: 4162, Train Loss: 0.3880002796649933, Valid Loss: 0.6355685591697693\n",
      "Epoch: 4163, Train Loss: 0.38800016045570374, Valid Loss: 0.6511389017105103\n",
      "Epoch: 4164, Train Loss: 0.3879997432231903, Valid Loss: 0.6356045007705688\n",
      "Epoch: 4165, Train Loss: 0.38799938559532166, Valid Loss: 0.6511327624320984\n",
      "Epoch: 4166, Train Loss: 0.38799914717674255, Valid Loss: 0.6356552243232727\n",
      "Epoch: 4167, Train Loss: 0.3879988491535187, Valid Loss: 0.6511176824569702\n",
      "Epoch: 4168, Train Loss: 0.3879985511302948, Valid Loss: 0.6357132792472839\n",
      "Epoch: 4169, Train Loss: 0.38799822330474854, Valid Loss: 0.6511163115501404\n",
      "Epoch: 4170, Train Loss: 0.3879982531070709, Valid Loss: 0.635733425617218\n",
      "Epoch: 4171, Train Loss: 0.3879983723163605, Valid Loss: 0.651160717010498\n",
      "Epoch: 4172, Train Loss: 0.38799816370010376, Valid Loss: 0.6356953978538513\n",
      "Epoch: 4173, Train Loss: 0.3879985213279724, Valid Loss: 0.6512900590896606\n",
      "Epoch: 4174, Train Loss: 0.38799935579299927, Valid Loss: 0.6355739831924438\n",
      "Epoch: 4175, Train Loss: 0.3880005478858948, Valid Loss: 0.6515088677406311\n",
      "Epoch: 4176, Train Loss: 0.388001412153244, Valid Loss: 0.6353527903556824\n",
      "Epoch: 4177, Train Loss: 0.38800370693206787, Valid Loss: 0.6518615484237671\n",
      "Epoch: 4178, Train Loss: 0.38800594210624695, Valid Loss: 0.6350052356719971\n",
      "Epoch: 4179, Train Loss: 0.38800889253616333, Valid Loss: 0.6523386240005493\n",
      "Epoch: 4180, Train Loss: 0.38801172375679016, Valid Loss: 0.6345449686050415\n",
      "Epoch: 4181, Train Loss: 0.38801515102386475, Valid Loss: 0.6529197692871094\n",
      "Epoch: 4182, Train Loss: 0.38801875710487366, Valid Loss: 0.6340231895446777\n",
      "Epoch: 4183, Train Loss: 0.38802236318588257, Valid Loss: 0.6535342335700989\n",
      "Epoch: 4184, Train Loss: 0.38802552223205566, Valid Loss: 0.6335212588310242\n",
      "Epoch: 4185, Train Loss: 0.3880278468132019, Valid Loss: 0.6540306806564331\n",
      "Epoch: 4186, Train Loss: 0.3880293071269989, Valid Loss: 0.6332083344459534\n",
      "Epoch: 4187, Train Loss: 0.38802918791770935, Valid Loss: 0.6542477607727051\n",
      "Epoch: 4188, Train Loss: 0.38802728056907654, Valid Loss: 0.6332340240478516\n",
      "Epoch: 4189, Train Loss: 0.3880235254764557, Valid Loss: 0.6539864540100098\n",
      "Epoch: 4190, Train Loss: 0.38801848888397217, Valid Loss: 0.6337353587150574\n",
      "Epoch: 4191, Train Loss: 0.3880118131637573, Valid Loss: 0.6531892418861389\n",
      "Epoch: 4192, Train Loss: 0.3880053758621216, Valid Loss: 0.6347489953041077\n",
      "Epoch: 4193, Train Loss: 0.38799887895584106, Valid Loss: 0.6519144177436829\n",
      "Epoch: 4194, Train Loss: 0.3879922330379486, Valid Loss: 0.6361352801322937\n",
      "Epoch: 4195, Train Loss: 0.3879866600036621, Valid Loss: 0.6504025459289551\n",
      "Epoch: 4196, Train Loss: 0.387982577085495, Valid Loss: 0.6376702785491943\n",
      "Epoch: 4197, Train Loss: 0.387979120016098, Valid Loss: 0.6488710641860962\n",
      "Epoch: 4198, Train Loss: 0.38797685503959656, Valid Loss: 0.6391517519950867\n",
      "Epoch: 4199, Train Loss: 0.3879752457141876, Valid Loss: 0.6474980711936951\n",
      "Epoch: 4200, Train Loss: 0.38797372579574585, Valid Loss: 0.6404740214347839\n",
      "Epoch: 4201, Train Loss: 0.3879716992378235, Valid Loss: 0.6462709903717041\n",
      "Epoch: 4202, Train Loss: 0.3879690170288086, Valid Loss: 0.6417009830474854\n",
      "Epoch: 4203, Train Loss: 0.3879665434360504, Valid Loss: 0.645073652267456\n",
      "Epoch: 4204, Train Loss: 0.38796451687812805, Valid Loss: 0.6429249048233032\n",
      "Epoch: 4205, Train Loss: 0.38796380162239075, Valid Loss: 0.6438819169998169\n",
      "Epoch: 4206, Train Loss: 0.3879634737968445, Valid Loss: 0.6441110372543335\n",
      "Epoch: 4207, Train Loss: 0.38796329498291016, Valid Loss: 0.642805278301239\n",
      "Epoch: 4208, Train Loss: 0.3879629969596863, Valid Loss: 0.6451317667961121\n",
      "Epoch: 4209, Train Loss: 0.3879629969596863, Valid Loss: 0.6419566869735718\n",
      "Epoch: 4210, Train Loss: 0.38796380162239075, Valid Loss: 0.6459283232688904\n",
      "Epoch: 4211, Train Loss: 0.38796520233154297, Valid Loss: 0.641278862953186\n",
      "Epoch: 4212, Train Loss: 0.3879665434360504, Valid Loss: 0.64664626121521\n",
      "Epoch: 4213, Train Loss: 0.387967050075531, Valid Loss: 0.64056795835495\n",
      "Epoch: 4214, Train Loss: 0.3879677951335907, Valid Loss: 0.647519588470459\n",
      "Epoch: 4215, Train Loss: 0.38796934485435486, Valid Loss: 0.6395944356918335\n",
      "Epoch: 4216, Train Loss: 0.38797175884246826, Valid Loss: 0.6487419605255127\n",
      "Epoch: 4217, Train Loss: 0.3879756033420563, Valid Loss: 0.6382215619087219\n",
      "Epoch: 4218, Train Loss: 0.38798126578330994, Valid Loss: 0.6504449248313904\n",
      "Epoch: 4219, Train Loss: 0.38798898458480835, Valid Loss: 0.6363039016723633\n",
      "Epoch: 4220, Train Loss: 0.3880009055137634, Valid Loss: 0.6528778672218323\n",
      "Epoch: 4221, Train Loss: 0.3880184292793274, Valid Loss: 0.6335205435752869\n",
      "Epoch: 4222, Train Loss: 0.3880437910556793, Valid Loss: 0.656493067741394\n",
      "Epoch: 4223, Train Loss: 0.3880787193775177, Valid Loss: 0.629475474357605\n",
      "Epoch: 4224, Train Loss: 0.3881245255470276, Valid Loss: 0.6616278290748596\n",
      "Epoch: 4225, Train Loss: 0.38817837834358215, Valid Loss: 0.6242360472679138\n",
      "Epoch: 4226, Train Loss: 0.38823753595352173, Valid Loss: 0.667528510093689\n",
      "Epoch: 4227, Train Loss: 0.38828158378601074, Valid Loss: 0.6194973587989807\n",
      "Epoch: 4228, Train Loss: 0.3883017301559448, Valid Loss: 0.6708801984786987\n",
      "Epoch: 4229, Train Loss: 0.38826894760131836, Valid Loss: 0.6193379163742065\n",
      "Epoch: 4230, Train Loss: 0.3881971836090088, Valid Loss: 0.6666551828384399\n",
      "Epoch: 4231, Train Loss: 0.3880990743637085, Valid Loss: 0.6272083520889282\n",
      "Epoch: 4232, Train Loss: 0.3880157768726349, Valid Loss: 0.6544632911682129\n",
      "Epoch: 4233, Train Loss: 0.3879711329936981, Valid Loss: 0.6405729651451111\n",
      "Epoch: 4234, Train Loss: 0.38797128200531006, Valid Loss: 0.6405503153800964\n",
      "Epoch: 4235, Train Loss: 0.38800352811813354, Valid Loss: 0.65299391746521\n",
      "Epoch: 4236, Train Loss: 0.3880469799041748, Valid Loss: 0.6310624480247498\n",
      "Epoch: 4237, Train Loss: 0.3880771994590759, Valid Loss: 0.6596303582191467\n",
      "Epoch: 4238, Train Loss: 0.38807716965675354, Valid Loss: 0.6288112998008728\n",
      "Epoch: 4239, Train Loss: 0.3880484998226166, Valid Loss: 0.6579248905181885\n",
      "Epoch: 4240, Train Loss: 0.3880062997341156, Valid Loss: 0.6337763071060181\n",
      "Epoch: 4241, Train Loss: 0.3879716992378235, Valid Loss: 0.649454653263092\n",
      "Epoch: 4242, Train Loss: 0.3879575729370117, Valid Loss: 0.6432762742042542\n",
      "Epoch: 4243, Train Loss: 0.3879651129245758, Valid Loss: 0.6398160457611084\n",
      "Epoch: 4244, Train Loss: 0.3879854083061218, Valid Loss: 0.6519797444343567\n",
      "Epoch: 4245, Train Loss: 0.38800475001335144, Valid Loss: 0.6339291930198669\n",
      "Epoch: 4246, Train Loss: 0.38801178336143494, Valid Loss: 0.6550593376159668\n",
      "Epoch: 4247, Train Loss: 0.38800328969955444, Valid Loss: 0.6341888904571533\n",
      "Epoch: 4248, Train Loss: 0.38798612356185913, Valid Loss: 0.6519132852554321\n",
      "Epoch: 4249, Train Loss: 0.3879680037498474, Valid Loss: 0.6391780972480774\n",
      "Epoch: 4250, Train Loss: 0.3879573345184326, Valid Loss: 0.6456258893013\n",
      "Epoch: 4251, Train Loss: 0.38795652985572815, Valid Loss: 0.6453459858894348\n",
      "Epoch: 4252, Train Loss: 0.3879627585411072, Valid Loss: 0.6401419043540955\n",
      "Epoch: 4253, Train Loss: 0.38797083497047424, Valid Loss: 0.6498802900314331\n",
      "Epoch: 4254, Train Loss: 0.3879764974117279, Valid Loss: 0.6375748515129089\n",
      "Epoch: 4255, Train Loss: 0.38797712326049805, Valid Loss: 0.6510034799575806\n",
      "Epoch: 4256, Train Loss: 0.3879730701446533, Valid Loss: 0.6380490064620972\n",
      "Epoch: 4257, Train Loss: 0.38796666264533997, Valid Loss: 0.6489713788032532\n",
      "Epoch: 4258, Train Loss: 0.3879605233669281, Valid Loss: 0.6409604549407959\n",
      "Epoch: 4259, Train Loss: 0.3879558742046356, Valid Loss: 0.645504891872406\n",
      "Epoch: 4260, Train Loss: 0.38795414566993713, Valid Loss: 0.6446256041526794\n",
      "Epoch: 4261, Train Loss: 0.38795506954193115, Valid Loss: 0.6422752141952515\n",
      "Epoch: 4262, Train Loss: 0.3879573941230774, Valid Loss: 0.6471967101097107\n",
      "Epoch: 4263, Train Loss: 0.38795995712280273, Valid Loss: 0.640534520149231\n",
      "Epoch: 4264, Train Loss: 0.38796189427375793, Valid Loss: 0.6481860280036926\n",
      "Epoch: 4265, Train Loss: 0.38796189427375793, Valid Loss: 0.6403810977935791\n",
      "Epoch: 4266, Train Loss: 0.3879607319831848, Valid Loss: 0.6478286981582642\n",
      "Epoch: 4267, Train Loss: 0.3879586160182953, Valid Loss: 0.6412699818611145\n",
      "Epoch: 4268, Train Loss: 0.38795575499534607, Valid Loss: 0.6466220021247864\n",
      "Epoch: 4269, Train Loss: 0.38795357942581177, Valid Loss: 0.6427221894264221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4270, Train Loss: 0.3879520297050476, Valid Loss: 0.6450774669647217\n",
      "Epoch: 4271, Train Loss: 0.3879516124725342, Valid Loss: 0.6442897915840149\n",
      "Epoch: 4272, Train Loss: 0.3879518508911133, Valid Loss: 0.6435593366622925\n",
      "Epoch: 4273, Train Loss: 0.3879525661468506, Valid Loss: 0.6456881761550903\n",
      "Epoch: 4274, Train Loss: 0.3879531919956207, Valid Loss: 0.6425173282623291\n",
      "Epoch: 4275, Train Loss: 0.3879539966583252, Valid Loss: 0.6465764045715332\n",
      "Epoch: 4276, Train Loss: 0.38795435428619385, Valid Loss: 0.6420401930809021\n",
      "Epoch: 4277, Train Loss: 0.38795411586761475, Valid Loss: 0.6468299627304077\n",
      "Epoch: 4278, Train Loss: 0.3879537284374237, Valid Loss: 0.6419925689697266\n",
      "Epoch: 4279, Train Loss: 0.38795313239097595, Valid Loss: 0.6466818451881409\n",
      "Epoch: 4280, Train Loss: 0.38795217871665955, Valid Loss: 0.6423373222351074\n",
      "Epoch: 4281, Train Loss: 0.387951523065567, Valid Loss: 0.6462867856025696\n",
      "Epoch: 4282, Train Loss: 0.38795074820518494, Valid Loss: 0.6429119110107422\n",
      "Epoch: 4283, Train Loss: 0.38795050978660583, Valid Loss: 0.6456761360168457\n",
      "Epoch: 4284, Train Loss: 0.3879495859146118, Valid Loss: 0.6436210870742798\n",
      "Epoch: 4285, Train Loss: 0.38794952630996704, Valid Loss: 0.6449969410896301\n",
      "Epoch: 4286, Train Loss: 0.3879490792751312, Valid Loss: 0.6443299651145935\n",
      "Epoch: 4287, Train Loss: 0.387949138879776, Valid Loss: 0.6443666219711304\n",
      "Epoch: 4288, Train Loss: 0.3879484236240387, Valid Loss: 0.6449247002601624\n",
      "Epoch: 4289, Train Loss: 0.38794848322868347, Valid Loss: 0.6439255475997925\n",
      "Epoch: 4290, Train Loss: 0.387948602437973, Valid Loss: 0.6453415155410767\n",
      "Epoch: 4291, Train Loss: 0.38794854283332825, Valid Loss: 0.6436102986335754\n",
      "Epoch: 4292, Train Loss: 0.38794875144958496, Valid Loss: 0.6456617712974548\n",
      "Epoch: 4293, Train Loss: 0.3879486322402954, Valid Loss: 0.6433322429656982\n",
      "Epoch: 4294, Train Loss: 0.3879483640193939, Valid Loss: 0.645956814289093\n",
      "Epoch: 4295, Train Loss: 0.3879489302635193, Valid Loss: 0.6431124210357666\n",
      "Epoch: 4296, Train Loss: 0.3879488408565521, Valid Loss: 0.6462592482566833\n",
      "Epoch: 4297, Train Loss: 0.387948602437973, Valid Loss: 0.642872154712677\n",
      "Epoch: 4298, Train Loss: 0.38794925808906555, Valid Loss: 0.6465592980384827\n",
      "Epoch: 4299, Train Loss: 0.38794925808906555, Valid Loss: 0.6425584554672241\n",
      "Epoch: 4300, Train Loss: 0.3879498839378357, Valid Loss: 0.6469769477844238\n",
      "Epoch: 4301, Train Loss: 0.38795050978660583, Valid Loss: 0.6421067714691162\n",
      "Epoch: 4302, Train Loss: 0.38795149326324463, Valid Loss: 0.6476069092750549\n",
      "Epoch: 4303, Train Loss: 0.3879523277282715, Valid Loss: 0.6413918137550354\n",
      "Epoch: 4304, Train Loss: 0.387954980134964, Valid Loss: 0.6485626697540283\n",
      "Epoch: 4305, Train Loss: 0.387957900762558, Valid Loss: 0.6403021216392517\n",
      "Epoch: 4306, Train Loss: 0.387962281703949, Valid Loss: 0.6499722003936768\n",
      "Epoch: 4307, Train Loss: 0.38796842098236084, Valid Loss: 0.6386924982070923\n",
      "Epoch: 4308, Train Loss: 0.3879771828651428, Valid Loss: 0.6520282626152039\n",
      "Epoch: 4309, Train Loss: 0.387990266084671, Valid Loss: 0.6363247632980347\n",
      "Epoch: 4310, Train Loss: 0.3880082070827484, Valid Loss: 0.6550770401954651\n",
      "Epoch: 4311, Train Loss: 0.38803330063819885, Valid Loss: 0.6329420804977417\n",
      "Epoch: 4312, Train Loss: 0.3880659341812134, Valid Loss: 0.6593438982963562\n",
      "Epoch: 4313, Train Loss: 0.388107031583786, Valid Loss: 0.6284782886505127\n",
      "Epoch: 4314, Train Loss: 0.38815271854400635, Valid Loss: 0.6645679473876953\n",
      "Epoch: 4315, Train Loss: 0.3881969451904297, Valid Loss: 0.6237868666648865\n",
      "Epoch: 4316, Train Loss: 0.3882305920124054, Valid Loss: 0.6689276099205017\n",
      "Epoch: 4317, Train Loss: 0.3882357180118561, Valid Loss: 0.6213365793228149\n",
      "Epoch: 4318, Train Loss: 0.3882107436656952, Valid Loss: 0.6687110066413879\n",
      "Epoch: 4319, Train Loss: 0.3881489038467407, Valid Loss: 0.624545693397522\n",
      "Epoch: 4320, Train Loss: 0.3880734145641327, Valid Loss: 0.6614078283309937\n",
      "Epoch: 4321, Train Loss: 0.3880038261413574, Valid Loss: 0.6340405941009521\n",
      "Epoch: 4322, Train Loss: 0.38796040415763855, Valid Loss: 0.6496164798736572\n",
      "Epoch: 4323, Train Loss: 0.38795045018196106, Valid Loss: 0.6457967162132263\n",
      "Epoch: 4324, Train Loss: 0.38796985149383545, Valid Loss: 0.6386303305625916\n",
      "Epoch: 4325, Train Loss: 0.3880033791065216, Valid Loss: 0.6551449298858643\n",
      "Epoch: 4326, Train Loss: 0.3880324959754944, Valid Loss: 0.632119357585907\n",
      "Epoch: 4327, Train Loss: 0.3880433142185211, Valid Loss: 0.6591644883155823\n",
      "Epoch: 4328, Train Loss: 0.3880319595336914, Valid Loss: 0.6313891410827637\n",
      "Epoch: 4329, Train Loss: 0.38800734281539917, Valid Loss: 0.6566318273544312\n",
      "Epoch: 4330, Train Loss: 0.3879784643650055, Valid Loss: 0.6361731886863708\n",
      "Epoch: 4331, Train Loss: 0.3879562020301819, Valid Loss: 0.6495631337165833\n",
      "Epoch: 4332, Train Loss: 0.38794487714767456, Valid Loss: 0.6440467834472656\n",
      "Epoch: 4333, Train Loss: 0.38794657588005066, Valid Loss: 0.641886830329895\n",
      "Epoch: 4334, Train Loss: 0.3879581689834595, Valid Loss: 0.6508734822273254\n",
      "Epoch: 4335, Train Loss: 0.3879724442958832, Valid Loss: 0.6369708776473999\n",
      "Epoch: 4336, Train Loss: 0.3879806101322174, Valid Loss: 0.6538097858428955\n",
      "Epoch: 4337, Train Loss: 0.38797950744628906, Valid Loss: 0.6362292170524597\n",
      "Epoch: 4338, Train Loss: 0.38797229528427124, Valid Loss: 0.6527074575424194\n",
      "Epoch: 4339, Train Loss: 0.3879627287387848, Valid Loss: 0.6387801766395569\n",
      "Epoch: 4340, Train Loss: 0.3879530727863312, Valid Loss: 0.6490745544433594\n",
      "Epoch: 4341, Train Loss: 0.387945294380188, Valid Loss: 0.6428310871124268\n",
      "Epoch: 4342, Train Loss: 0.3879413604736328, Valid Loss: 0.644939661026001\n",
      "Epoch: 4343, Train Loss: 0.3879426419734955, Valid Loss: 0.6467442512512207\n",
      "Epoch: 4344, Train Loss: 0.38794687390327454, Valid Loss: 0.64170241355896\n",
      "Epoch: 4345, Train Loss: 0.38795098662376404, Valid Loss: 0.6493540406227112\n",
      "Epoch: 4346, Train Loss: 0.3879539668560028, Valid Loss: 0.6399791240692139\n",
      "Epoch: 4347, Train Loss: 0.38795503973960876, Valid Loss: 0.6502490043640137\n",
      "Epoch: 4348, Train Loss: 0.38795432448387146, Valid Loss: 0.6399868130683899\n",
      "Epoch: 4349, Train Loss: 0.3879513740539551, Valid Loss: 0.649574339389801\n",
      "Epoch: 4350, Train Loss: 0.38794735074043274, Valid Loss: 0.6412580609321594\n",
      "Epoch: 4351, Train Loss: 0.38794365525245667, Valid Loss: 0.6478139758110046\n",
      "Epoch: 4352, Train Loss: 0.38794106245040894, Valid Loss: 0.6432293653488159\n",
      "Epoch: 4353, Train Loss: 0.3879399001598358, Valid Loss: 0.6457481980323792\n",
      "Epoch: 4354, Train Loss: 0.38793930411338806, Valid Loss: 0.6453400254249573\n",
      "Epoch: 4355, Train Loss: 0.3879399299621582, Valid Loss: 0.6439430117607117\n",
      "Epoch: 4356, Train Loss: 0.3879407048225403, Valid Loss: 0.646964967250824\n",
      "Epoch: 4357, Train Loss: 0.3879421353340149, Valid Loss: 0.6426827311515808\n",
      "Epoch: 4358, Train Loss: 0.38794296979904175, Valid Loss: 0.6479299664497375\n",
      "Epoch: 4359, Train Loss: 0.3879433274269104, Valid Loss: 0.6420603394508362\n",
      "Epoch: 4360, Train Loss: 0.38794341683387756, Valid Loss: 0.6483202576637268\n",
      "Epoch: 4361, Train Loss: 0.3879432678222656, Valid Loss: 0.6419663429260254\n",
      "Epoch: 4362, Train Loss: 0.38794243335723877, Valid Loss: 0.6482274532318115\n",
      "Epoch: 4363, Train Loss: 0.38794147968292236, Valid Loss: 0.6423138380050659\n",
      "Epoch: 4364, Train Loss: 0.38794052600860596, Valid Loss: 0.6477690935134888\n",
      "Epoch: 4365, Train Loss: 0.387939989566803, Valid Loss: 0.6429836750030518\n",
      "Epoch: 4366, Train Loss: 0.38793885707855225, Valid Loss: 0.6470356583595276\n",
      "Epoch: 4367, Train Loss: 0.3879378139972687, Valid Loss: 0.6438009142875671\n",
      "Epoch: 4368, Train Loss: 0.3879375457763672, Valid Loss: 0.6462535262107849\n",
      "Epoch: 4369, Train Loss: 0.38793694972991943, Valid Loss: 0.6445685029029846\n",
      "Epoch: 4370, Train Loss: 0.3879367709159851, Valid Loss: 0.6456355452537537\n",
      "Epoch: 4371, Train Loss: 0.38793644309043884, Valid Loss: 0.645138680934906\n",
      "Epoch: 4372, Train Loss: 0.3879363238811493, Valid Loss: 0.6451814770698547\n",
      "Epoch: 4373, Train Loss: 0.38793623447418213, Valid Loss: 0.6455513834953308\n",
      "Epoch: 4374, Train Loss: 0.387935996055603, Valid Loss: 0.6448566913604736\n",
      "Epoch: 4375, Train Loss: 0.38793569803237915, Valid Loss: 0.6459125280380249\n",
      "Epoch: 4376, Train Loss: 0.3879360854625702, Valid Loss: 0.6445776224136353\n",
      "Epoch: 4377, Train Loss: 0.38793590664863586, Valid Loss: 0.6462522745132446\n",
      "Epoch: 4378, Train Loss: 0.3879360258579254, Valid Loss: 0.6442607641220093\n",
      "Epoch: 4379, Train Loss: 0.3879360258579254, Valid Loss: 0.6466149687767029\n",
      "Epoch: 4380, Train Loss: 0.38793614506721497, Valid Loss: 0.6439222097396851\n",
      "Epoch: 4381, Train Loss: 0.387936532497406, Valid Loss: 0.6470147967338562\n",
      "Epoch: 4382, Train Loss: 0.3879367709159851, Valid Loss: 0.6435137391090393\n",
      "Epoch: 4383, Train Loss: 0.38793715834617615, Valid Loss: 0.6475473046302795\n",
      "Epoch: 4384, Train Loss: 0.38793808221817017, Valid Loss: 0.6429336667060852\n",
      "Epoch: 4385, Train Loss: 0.3879390358924866, Valid Loss: 0.6483300924301147\n",
      "Epoch: 4386, Train Loss: 0.38794076442718506, Valid Loss: 0.6420484185218811\n",
      "Epoch: 4387, Train Loss: 0.3879430890083313, Valid Loss: 0.6494710445404053\n",
      "Epoch: 4388, Train Loss: 0.3879462778568268, Valid Loss: 0.6407285928726196\n",
      "Epoch: 4389, Train Loss: 0.38795191049575806, Valid Loss: 0.6511619687080383\n",
      "Epoch: 4390, Train Loss: 0.38795945048332214, Valid Loss: 0.6387577652931213\n",
      "Epoch: 4391, Train Loss: 0.3879707455635071, Valid Loss: 0.6537191867828369\n",
      "Epoch: 4392, Train Loss: 0.38798755407333374, Valid Loss: 0.6357975602149963\n",
      "Epoch: 4393, Train Loss: 0.3880113959312439, Valid Loss: 0.6575133800506592\n",
      "Epoch: 4394, Train Loss: 0.3880453109741211, Valid Loss: 0.6315379738807678\n",
      "Epoch: 4395, Train Loss: 0.3880912661552429, Valid Loss: 0.6628813147544861\n",
      "Epoch: 4396, Train Loss: 0.38814863562583923, Valid Loss: 0.6259936690330505\n",
      "Epoch: 4397, Train Loss: 0.388213574886322, Valid Loss: 0.6692825555801392\n",
      "Epoch: 4398, Train Loss: 0.3882708251476288, Valid Loss: 0.6206201910972595\n",
      "Epoch: 4399, Train Loss: 0.38830479979515076, Valid Loss: 0.6737258434295654\n",
      "Epoch: 4400, Train Loss: 0.38828709721565247, Valid Loss: 0.6192923784255981\n",
      "Epoch: 4401, Train Loss: 0.3882199227809906, Valid Loss: 0.6707569360733032\n",
      "Epoch: 4402, Train Loss: 0.3881145417690277, Valid Loss: 0.6262176632881165\n",
      "Epoch: 4403, Train Loss: 0.38801464438438416, Valid Loss: 0.658637523651123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4404, Train Loss: 0.3879532516002655, Valid Loss: 0.6400272846221924\n",
      "Epoch: 4405, Train Loss: 0.38794270157814026, Valid Loss: 0.6435539722442627\n",
      "Epoch: 4406, Train Loss: 0.38797247409820557, Valid Loss: 0.6538762450218201\n",
      "Epoch: 4407, Train Loss: 0.38802021741867065, Valid Loss: 0.6326078176498413\n",
      "Epoch: 4408, Train Loss: 0.38805797696113586, Valid Loss: 0.6617684960365295\n",
      "Epoch: 4409, Train Loss: 0.3880648910999298, Valid Loss: 0.6294382214546204\n",
      "Epoch: 4410, Train Loss: 0.3880375921726227, Valid Loss: 0.660677969455719\n",
      "Epoch: 4411, Train Loss: 0.3879920542240143, Valid Loss: 0.6342315077781677\n",
      "Epoch: 4412, Train Loss: 0.3879519999027252, Valid Loss: 0.6520183086395264\n",
      "Epoch: 4413, Train Loss: 0.3879334032535553, Valid Loss: 0.6440051198005676\n",
      "Epoch: 4414, Train Loss: 0.3879394233226776, Valid Loss: 0.6417533755302429\n",
      "Epoch: 4415, Train Loss: 0.3879599869251251, Valid Loss: 0.6534641981124878\n",
      "Epoch: 4416, Train Loss: 0.3879810571670532, Valid Loss: 0.6352448463439941\n",
      "Epoch: 4417, Train Loss: 0.3879905641078949, Valid Loss: 0.6571521162986755\n",
      "Epoch: 4418, Train Loss: 0.3879830539226532, Valid Loss: 0.6350704431533813\n",
      "Epoch: 4419, Train Loss: 0.38796478509902954, Valid Loss: 0.6540219187736511\n",
      "Epoch: 4420, Train Loss: 0.38794490694999695, Valid Loss: 0.6402478218078613\n",
      "Epoch: 4421, Train Loss: 0.3879324197769165, Valid Loss: 0.6474416851997375\n",
      "Epoch: 4422, Train Loss: 0.38793084025382996, Valid Loss: 0.6469206809997559\n",
      "Epoch: 4423, Train Loss: 0.3879377543926239, Valid Loss: 0.6414685845375061\n",
      "Epoch: 4424, Train Loss: 0.38794752955436707, Valid Loss: 0.651686429977417\n",
      "Epoch: 4425, Train Loss: 0.38795363903045654, Valid Loss: 0.6386949419975281\n",
      "Epoch: 4426, Train Loss: 0.3879539668560028, Valid Loss: 0.652849555015564\n",
      "Epoch: 4427, Train Loss: 0.3879490792751312, Valid Loss: 0.6393744349479675\n",
      "Epoch: 4428, Train Loss: 0.38794174790382385, Valid Loss: 0.6505832076072693\n",
      "Epoch: 4429, Train Loss: 0.3879345953464508, Valid Loss: 0.6425411105155945\n",
      "Epoch: 4430, Train Loss: 0.3879305124282837, Valid Loss: 0.6467803120613098\n",
      "Epoch: 4431, Train Loss: 0.38792940974235535, Valid Loss: 0.6465205550193787\n",
      "Epoch: 4432, Train Loss: 0.38793087005615234, Valid Loss: 0.6433026194572449\n",
      "Epoch: 4433, Train Loss: 0.3879343271255493, Valid Loss: 0.6492519974708557\n",
      "Epoch: 4434, Train Loss: 0.38793715834617615, Valid Loss: 0.6414692401885986\n",
      "Epoch: 4435, Train Loss: 0.3879384696483612, Valid Loss: 0.6500966548919678\n",
      "Epoch: 4436, Train Loss: 0.3879380524158478, Valid Loss: 0.6416335105895996\n",
      "Epoch: 4437, Train Loss: 0.38793572783470154, Valid Loss: 0.6494073271751404\n",
      "Epoch: 4438, Train Loss: 0.3879328668117523, Valid Loss: 0.6429658532142639\n",
      "Epoch: 4439, Train Loss: 0.3879297971725464, Valid Loss: 0.6477252244949341\n",
      "Epoch: 4440, Train Loss: 0.3879280388355255, Valid Loss: 0.6447391510009766\n",
      "Epoch: 4441, Train Loss: 0.38792744278907776, Valid Loss: 0.6458706855773926\n",
      "Epoch: 4442, Train Loss: 0.38792741298675537, Valid Loss: 0.6465792059898376\n",
      "Epoch: 4443, Train Loss: 0.38792839646339417, Valid Loss: 0.6443167924880981\n",
      "Epoch: 4444, Train Loss: 0.38792943954467773, Valid Loss: 0.6479411125183105\n",
      "Epoch: 4445, Train Loss: 0.3879302740097046, Valid Loss: 0.643359363079071\n",
      "Epoch: 4446, Train Loss: 0.38793060183525085, Valid Loss: 0.6485598683357239\n",
      "Epoch: 4447, Train Loss: 0.3879302740097046, Valid Loss: 0.6431910991668701\n",
      "Epoch: 4448, Train Loss: 0.3879294693470001, Valid Loss: 0.6484516263008118\n",
      "Epoch: 4449, Train Loss: 0.38792845606803894, Valid Loss: 0.6436062455177307\n",
      "Epoch: 4450, Train Loss: 0.3879278600215912, Valid Loss: 0.6478374600410461\n",
      "Epoch: 4451, Train Loss: 0.38792672753334045, Valid Loss: 0.644379734992981\n",
      "Epoch: 4452, Train Loss: 0.38792577385902405, Valid Loss: 0.6470495462417603\n",
      "Epoch: 4453, Train Loss: 0.3879256546497345, Valid Loss: 0.6452903747558594\n",
      "Epoch: 4454, Train Loss: 0.3879252076148987, Valid Loss: 0.6461735367774963\n",
      "Epoch: 4455, Train Loss: 0.3879251480102539, Valid Loss: 0.6461473703384399\n",
      "Epoch: 4456, Train Loss: 0.3879252076148987, Valid Loss: 0.6453777551651001\n",
      "Epoch: 4457, Train Loss: 0.38792532682418823, Valid Loss: 0.6469175219535828\n",
      "Epoch: 4458, Train Loss: 0.3879254162311554, Valid Loss: 0.6448020935058594\n",
      "Epoch: 4459, Train Loss: 0.38792547583580017, Valid Loss: 0.6474549770355225\n",
      "Epoch: 4460, Train Loss: 0.3879257142543793, Valid Loss: 0.6444315314292908\n",
      "Epoch: 4461, Train Loss: 0.3879256248474121, Valid Loss: 0.6477013230323792\n",
      "Epoch: 4462, Train Loss: 0.3879258334636688, Valid Loss: 0.6442920565605164\n",
      "Epoch: 4463, Train Loss: 0.38792553544044495, Valid Loss: 0.6478329300880432\n",
      "Epoch: 4464, Train Loss: 0.38792556524276733, Valid Loss: 0.6442775130271912\n",
      "Epoch: 4465, Train Loss: 0.38792553544044495, Valid Loss: 0.6478802561759949\n",
      "Epoch: 4466, Train Loss: 0.38792508840560913, Valid Loss: 0.6442738175392151\n",
      "Epoch: 4467, Train Loss: 0.3879254162311554, Valid Loss: 0.647929847240448\n",
      "Epoch: 4468, Train Loss: 0.38792526721954346, Valid Loss: 0.6442536115646362\n",
      "Epoch: 4469, Train Loss: 0.387925386428833, Valid Loss: 0.6480255126953125\n",
      "Epoch: 4470, Train Loss: 0.3879254460334778, Valid Loss: 0.6441622376441956\n",
      "Epoch: 4471, Train Loss: 0.3879256248474121, Valid Loss: 0.6482192873954773\n",
      "Epoch: 4472, Train Loss: 0.38792574405670166, Valid Loss: 0.6439315676689148\n",
      "Epoch: 4473, Train Loss: 0.3879261612892151, Valid Loss: 0.6485846042633057\n",
      "Epoch: 4474, Train Loss: 0.38792684674263, Valid Loss: 0.6435298323631287\n",
      "Epoch: 4475, Train Loss: 0.387927383184433, Valid Loss: 0.6491477489471436\n",
      "Epoch: 4476, Train Loss: 0.38792890310287476, Valid Loss: 0.6428784728050232\n",
      "Epoch: 4477, Train Loss: 0.3879302442073822, Valid Loss: 0.6499865651130676\n",
      "Epoch: 4478, Train Loss: 0.38793283700942993, Valid Loss: 0.6419239640235901\n",
      "Epoch: 4479, Train Loss: 0.38793620467185974, Valid Loss: 0.6512401103973389\n",
      "Epoch: 4480, Train Loss: 0.3879411816596985, Valid Loss: 0.640500009059906\n",
      "Epoch: 4481, Train Loss: 0.38794809579849243, Valid Loss: 0.6530576348304749\n",
      "Epoch: 4482, Train Loss: 0.3879581689834595, Valid Loss: 0.6384026408195496\n",
      "Epoch: 4483, Train Loss: 0.3879719078540802, Valid Loss: 0.6557222604751587\n",
      "Epoch: 4484, Train Loss: 0.38799160718917847, Valid Loss: 0.6353952288627625\n",
      "Epoch: 4485, Train Loss: 0.3880177438259125, Valid Loss: 0.6595460772514343\n",
      "Epoch: 4486, Train Loss: 0.38805249333381653, Valid Loss: 0.6312973499298096\n",
      "Epoch: 4487, Train Loss: 0.38809433579444885, Valid Loss: 0.66449373960495\n",
      "Epoch: 4488, Train Loss: 0.3881415128707886, Valid Loss: 0.6265289187431335\n",
      "Epoch: 4489, Train Loss: 0.38818567991256714, Valid Loss: 0.669543981552124\n",
      "Epoch: 4490, Train Loss: 0.3882157802581787, Valid Loss: 0.6227812170982361\n",
      "Epoch: 4491, Train Loss: 0.38821956515312195, Valid Loss: 0.6717615723609924\n",
      "Epoch: 4492, Train Loss: 0.38818594813346863, Valid Loss: 0.6232507824897766\n",
      "Epoch: 4493, Train Loss: 0.38812315464019775, Valid Loss: 0.6675264239311218\n",
      "Epoch: 4494, Train Loss: 0.38804489374160767, Valid Loss: 0.6302328705787659\n",
      "Epoch: 4495, Train Loss: 0.3879775404930115, Valid Loss: 0.6570520997047424\n",
      "Epoch: 4496, Train Loss: 0.3879382312297821, Valid Loss: 0.6416499614715576\n",
      "Epoch: 4497, Train Loss: 0.3879324197769165, Valid Loss: 0.6450605988502502\n",
      "Epoch: 4498, Train Loss: 0.38795149326324463, Valid Loss: 0.6526556611061096\n",
      "Epoch: 4499, Train Loss: 0.3879825472831726, Valid Loss: 0.6360997557640076\n",
      "Epoch: 4500, Train Loss: 0.3880082666873932, Valid Loss: 0.6595500111579895\n",
      "Epoch: 4501, Train Loss: 0.38801854848861694, Valid Loss: 0.6323405504226685\n",
      "Epoch: 4502, Train Loss: 0.3880113959312439, Valid Loss: 0.6603870391845703\n",
      "Epoch: 4503, Train Loss: 0.3879888951778412, Valid Loss: 0.6342530846595764\n",
      "Epoch: 4504, Train Loss: 0.38795948028564453, Valid Loss: 0.6554281711578369\n",
      "Epoch: 4505, Train Loss: 0.38793283700942993, Valid Loss: 0.6408217549324036\n",
      "Epoch: 4506, Train Loss: 0.3879198133945465, Valid Loss: 0.6475851535797119\n",
      "Epoch: 4507, Train Loss: 0.3879229724407196, Valid Loss: 0.6489320397377014\n",
      "Epoch: 4508, Train Loss: 0.38793516159057617, Valid Loss: 0.6405606269836426\n",
      "Epoch: 4509, Train Loss: 0.38794824481010437, Valid Loss: 0.654409646987915\n",
      "Epoch: 4510, Train Loss: 0.3879561126232147, Valid Loss: 0.6372498273849487\n",
      "Epoch: 4511, Train Loss: 0.38795793056488037, Valid Loss: 0.6555138230323792\n",
      "Epoch: 4512, Train Loss: 0.3879528343677521, Valid Loss: 0.6382248401641846\n",
      "Epoch: 4513, Train Loss: 0.38794246315956116, Valid Loss: 0.6530813574790955\n",
      "Epoch: 4514, Train Loss: 0.3879307508468628, Valid Loss: 0.6416693329811096\n",
      "Epoch: 4515, Train Loss: 0.3879227042198181, Valid Loss: 0.6489660739898682\n",
      "Epoch: 4516, Train Loss: 0.38791921734809875, Valid Loss: 0.645810604095459\n",
      "Epoch: 4517, Train Loss: 0.38791975378990173, Valid Loss: 0.6449906229972839\n",
      "Epoch: 4518, Train Loss: 0.3879226744174957, Valid Loss: 0.6494683623313904\n",
      "Epoch: 4519, Train Loss: 0.3879268765449524, Valid Loss: 0.6420959234237671\n",
      "Epoch: 4520, Train Loss: 0.3879309594631195, Valid Loss: 0.6517075300216675\n",
      "Epoch: 4521, Train Loss: 0.387932687997818, Valid Loss: 0.6408345103263855\n",
      "Epoch: 4522, Train Loss: 0.38793227076530457, Valid Loss: 0.6519936919212341\n",
      "Epoch: 4523, Train Loss: 0.3879300057888031, Valid Loss: 0.6414819955825806\n",
      "Epoch: 4524, Train Loss: 0.3879265785217285, Valid Loss: 0.6506083607673645\n",
      "Epoch: 4525, Train Loss: 0.387923002243042, Valid Loss: 0.6433488726615906\n",
      "Epoch: 4526, Train Loss: 0.3879195749759674, Valid Loss: 0.6485311388969421\n",
      "Epoch: 4527, Train Loss: 0.38791733980178833, Valid Loss: 0.645405650138855\n",
      "Epoch: 4528, Train Loss: 0.38791653513908386, Valid Loss: 0.6466838121414185\n",
      "Epoch: 4529, Train Loss: 0.3879165053367615, Valid Loss: 0.6471058130264282\n",
      "Epoch: 4530, Train Loss: 0.3879174292087555, Valid Loss: 0.6452460289001465\n",
      "Epoch: 4531, Train Loss: 0.3879185616970062, Valid Loss: 0.648453950881958\n",
      "Epoch: 4532, Train Loss: 0.38791927695274353, Valid Loss: 0.6441097259521484\n",
      "Epoch: 4533, Train Loss: 0.38791993260383606, Valid Loss: 0.649461567401886\n",
      "Epoch: 4534, Train Loss: 0.38792067766189575, Valid Loss: 0.6433932781219482\n",
      "Epoch: 4535, Train Loss: 0.38792064785957336, Valid Loss: 0.6499160528182983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4536, Train Loss: 0.38792040944099426, Valid Loss: 0.6433026194572449\n",
      "Epoch: 4537, Train Loss: 0.38791948556900024, Valid Loss: 0.649708092212677\n",
      "Epoch: 4538, Train Loss: 0.3879184424877167, Valid Loss: 0.6437963843345642\n",
      "Epoch: 4539, Train Loss: 0.38791799545288086, Valid Loss: 0.6491386294364929\n",
      "Epoch: 4540, Train Loss: 0.38791730999946594, Valid Loss: 0.6444770693778992\n",
      "Epoch: 4541, Train Loss: 0.3879161477088928, Valid Loss: 0.6485207080841064\n",
      "Epoch: 4542, Train Loss: 0.38791587948799133, Valid Loss: 0.645099937915802\n",
      "Epoch: 4543, Train Loss: 0.3879149854183197, Valid Loss: 0.6479639410972595\n",
      "Epoch: 4544, Train Loss: 0.3879144489765167, Valid Loss: 0.6456656455993652\n",
      "Epoch: 4545, Train Loss: 0.3879142105579376, Valid Loss: 0.6474223136901855\n",
      "Epoch: 4546, Train Loss: 0.3879140615463257, Valid Loss: 0.6462530493736267\n",
      "Epoch: 4547, Train Loss: 0.38791361451148987, Valid Loss: 0.6468832492828369\n",
      "Epoch: 4548, Train Loss: 0.387913316488266, Valid Loss: 0.6467939615249634\n",
      "Epoch: 4549, Train Loss: 0.3879135251045227, Valid Loss: 0.6464541554450989\n",
      "Epoch: 4550, Train Loss: 0.3879133462905884, Valid Loss: 0.6471834778785706\n",
      "Epoch: 4551, Train Loss: 0.3879132568836212, Valid Loss: 0.6462002396583557\n",
      "Epoch: 4552, Train Loss: 0.3879133462905884, Valid Loss: 0.6474146842956543\n",
      "Epoch: 4553, Train Loss: 0.38791340589523315, Valid Loss: 0.6460334658622742\n",
      "Epoch: 4554, Train Loss: 0.3879132568836212, Valid Loss: 0.6476367712020874\n",
      "Epoch: 4555, Train Loss: 0.3879131078720093, Valid Loss: 0.6458097696304321\n",
      "Epoch: 4556, Train Loss: 0.38791322708129883, Valid Loss: 0.6479517221450806\n",
      "Epoch: 4557, Train Loss: 0.38791343569755554, Valid Loss: 0.6454712152481079\n",
      "Epoch: 4558, Train Loss: 0.38791370391845703, Valid Loss: 0.6484031677246094\n",
      "Epoch: 4559, Train Loss: 0.38791424036026, Valid Loss: 0.6449841856956482\n",
      "Epoch: 4560, Train Loss: 0.38791462779045105, Valid Loss: 0.6490315198898315\n",
      "Epoch: 4561, Train Loss: 0.38791608810424805, Valid Loss: 0.6443078517913818\n",
      "Epoch: 4562, Train Loss: 0.38791683316230774, Valid Loss: 0.6499179601669312\n",
      "Epoch: 4563, Train Loss: 0.38791966438293457, Valid Loss: 0.6432628631591797\n",
      "Epoch: 4564, Train Loss: 0.3879222571849823, Valid Loss: 0.6513003706932068\n",
      "Epoch: 4565, Train Loss: 0.38792723417282104, Valid Loss: 0.6415998935699463\n",
      "Epoch: 4566, Train Loss: 0.3879346549510956, Valid Loss: 0.6534727215766907\n",
      "Epoch: 4567, Train Loss: 0.38794612884521484, Valid Loss: 0.6390084028244019\n",
      "Epoch: 4568, Train Loss: 0.3879631459712982, Valid Loss: 0.6568355560302734\n",
      "Epoch: 4569, Train Loss: 0.3879892826080322, Valid Loss: 0.635108470916748\n",
      "Epoch: 4570, Train Loss: 0.38802728056907654, Valid Loss: 0.6618798971176147\n",
      "Epoch: 4571, Train Loss: 0.3880816102027893, Valid Loss: 0.6295097470283508\n",
      "Epoch: 4572, Train Loss: 0.3881530165672302, Valid Loss: 0.6689184308052063\n",
      "Epoch: 4573, Train Loss: 0.38823843002319336, Valid Loss: 0.6226221323013306\n",
      "Epoch: 4574, Train Loss: 0.3883206844329834, Valid Loss: 0.6764450669288635\n",
      "Epoch: 4575, Train Loss: 0.38837212324142456, Valid Loss: 0.617435097694397\n",
      "Epoch: 4576, Train Loss: 0.38836121559143066, Valid Loss: 0.6788040399551392\n",
      "Epoch: 4577, Train Loss: 0.3882696330547333, Valid Loss: 0.6199936866760254\n",
      "Epoch: 4578, Train Loss: 0.38813045620918274, Valid Loss: 0.6692872643470764\n",
      "Epoch: 4579, Train Loss: 0.3879997730255127, Valid Loss: 0.6333824396133423\n",
      "Epoch: 4580, Train Loss: 0.38793009519577026, Valid Loss: 0.6512614488601685\n",
      "Epoch: 4581, Train Loss: 0.38793277740478516, Valid Loss: 0.6512777209281921\n",
      "Epoch: 4582, Train Loss: 0.38798582553863525, Valid Loss: 0.635332465171814\n",
      "Epoch: 4583, Train Loss: 0.3880501389503479, Valid Loss: 0.6640649437904358\n",
      "Epoch: 4584, Train Loss: 0.38808587193489075, Valid Loss: 0.6284662485122681\n",
      "Epoch: 4585, Train Loss: 0.3880694806575775, Valid Loss: 0.6655833721160889\n",
      "Epoch: 4586, Train Loss: 0.3880113363265991, Valid Loss: 0.632585883140564\n",
      "Epoch: 4587, Train Loss: 0.38794854283332825, Valid Loss: 0.6559755206108093\n",
      "Epoch: 4588, Train Loss: 0.3879150450229645, Valid Loss: 0.6439810395240784\n",
      "Epoch: 4589, Train Loss: 0.38792023062705994, Valid Loss: 0.6429623961448669\n",
      "Epoch: 4590, Train Loss: 0.3879503011703491, Valid Loss: 0.6559654474258423\n",
      "Epoch: 4591, Train Loss: 0.3879806101322174, Valid Loss: 0.6347076892852783\n",
      "Epoch: 4592, Train Loss: 0.38799217343330383, Valid Loss: 0.6608766317367554\n",
      "Epoch: 4593, Train Loss: 0.3879759609699249, Valid Loss: 0.6349000334739685\n",
      "Epoch: 4594, Train Loss: 0.38794490694999695, Valid Loss: 0.6557652354240417\n",
      "Epoch: 4595, Train Loss: 0.38791853189468384, Valid Loss: 0.6425288319587708\n",
      "Epoch: 4596, Train Loss: 0.3879097104072571, Valid Loss: 0.6463996171951294\n",
      "Epoch: 4597, Train Loss: 0.38791754841804504, Valid Loss: 0.6514970660209656\n",
      "Epoch: 4598, Train Loss: 0.38793325424194336, Valid Loss: 0.6395841240882874\n",
      "Epoch: 4599, Train Loss: 0.38794490694999695, Valid Loss: 0.6558862328529358\n",
      "Epoch: 4600, Train Loss: 0.387945294380188, Valid Loss: 0.6383476853370667\n",
      "Epoch: 4601, Train Loss: 0.38793501257896423, Valid Loss: 0.654365062713623\n",
      "Epoch: 4602, Train Loss: 0.38792121410369873, Valid Loss: 0.6420339941978455\n",
      "Epoch: 4603, Train Loss: 0.3879108428955078, Valid Loss: 0.649207592010498\n",
      "Epoch: 4604, Train Loss: 0.3879086971282959, Valid Loss: 0.6475212574005127\n",
      "Epoch: 4605, Train Loss: 0.3879125416278839, Valid Loss: 0.6439993977546692\n",
      "Epoch: 4606, Train Loss: 0.3879185616970062, Valid Loss: 0.6518944501876831\n",
      "Epoch: 4607, Train Loss: 0.3879234194755554, Valid Loss: 0.6413424611091614\n",
      "Epoch: 4608, Train Loss: 0.3879237771034241, Valid Loss: 0.652981162071228\n",
      "Epoch: 4609, Train Loss: 0.3879207372665405, Valid Loss: 0.6418890357017517\n",
      "Epoch: 4610, Train Loss: 0.38791540265083313, Valid Loss: 0.6507924795150757\n",
      "Epoch: 4611, Train Loss: 0.38791024684906006, Valid Loss: 0.6448968648910522\n",
      "Epoch: 4612, Train Loss: 0.3879072964191437, Valid Loss: 0.6475304961204529\n",
      "Epoch: 4613, Train Loss: 0.3879072070121765, Valid Loss: 0.6482669115066528\n",
      "Epoch: 4614, Train Loss: 0.3879089951515198, Valid Loss: 0.6448010802268982\n",
      "Epoch: 4615, Train Loss: 0.3879117965698242, Valid Loss: 0.6502420902252197\n",
      "Epoch: 4616, Train Loss: 0.38791346549987793, Valid Loss: 0.6435201168060303\n",
      "Epoch: 4617, Train Loss: 0.38791409134864807, Valid Loss: 0.6507459282875061\n",
      "Epoch: 4618, Train Loss: 0.3879121243953705, Valid Loss: 0.6439186930656433\n",
      "Epoch: 4619, Train Loss: 0.387909859418869, Valid Loss: 0.6499301195144653\n",
      "Epoch: 4620, Train Loss: 0.38790765404701233, Valid Loss: 0.6452601552009583\n",
      "Epoch: 4621, Train Loss: 0.3879059851169586, Valid Loss: 0.6481448411941528\n",
      "Epoch: 4622, Train Loss: 0.3879057765007019, Valid Loss: 0.6471045613288879\n",
      "Epoch: 4623, Train Loss: 0.3879058361053467, Valid Loss: 0.6463634371757507\n",
      "Epoch: 4624, Train Loss: 0.3879067003726959, Valid Loss: 0.6488367319107056\n",
      "Epoch: 4625, Train Loss: 0.3879075348377228, Valid Loss: 0.6451722979545593\n",
      "Epoch: 4626, Train Loss: 0.3879079818725586, Valid Loss: 0.6496279239654541\n",
      "Epoch: 4627, Train Loss: 0.38790786266326904, Valid Loss: 0.6448244452476501\n",
      "Epoch: 4628, Train Loss: 0.3879074156284332, Valid Loss: 0.6495712399482727\n",
      "Epoch: 4629, Train Loss: 0.38790661096572876, Valid Loss: 0.6452576518058777\n",
      "Epoch: 4630, Train Loss: 0.38790571689605713, Valid Loss: 0.6489424705505371\n",
      "Epoch: 4631, Train Loss: 0.3879050016403198, Valid Loss: 0.6460990905761719\n",
      "Epoch: 4632, Train Loss: 0.38790440559387207, Valid Loss: 0.6480096578598022\n",
      "Epoch: 4633, Train Loss: 0.38790416717529297, Valid Loss: 0.6471205949783325\n",
      "Epoch: 4634, Train Loss: 0.3879041075706482, Valid Loss: 0.6470562815666199\n",
      "Epoch: 4635, Train Loss: 0.3879042863845825, Valid Loss: 0.6480801105499268\n",
      "Epoch: 4636, Train Loss: 0.3879043459892273, Valid Loss: 0.6462448239326477\n",
      "Epoch: 4637, Train Loss: 0.3879041075706482, Valid Loss: 0.6487191915512085\n",
      "Epoch: 4638, Train Loss: 0.38790467381477356, Valid Loss: 0.6458545923233032\n",
      "Epoch: 4639, Train Loss: 0.387904554605484, Valid Loss: 0.6489686369895935\n",
      "Epoch: 4640, Train Loss: 0.38790464401245117, Valid Loss: 0.6458807587623596\n",
      "Epoch: 4641, Train Loss: 0.3879040479660034, Valid Loss: 0.6488298773765564\n",
      "Epoch: 4642, Train Loss: 0.3879038393497467, Valid Loss: 0.6461279988288879\n",
      "Epoch: 4643, Train Loss: 0.3879036009311676, Valid Loss: 0.6485280394554138\n",
      "Epoch: 4644, Train Loss: 0.3879031240940094, Valid Loss: 0.6464933156967163\n",
      "Epoch: 4645, Train Loss: 0.387903094291687, Valid Loss: 0.6482469439506531\n",
      "Epoch: 4646, Train Loss: 0.38790279626846313, Valid Loss: 0.6468579769134521\n",
      "Epoch: 4647, Train Loss: 0.38790273666381836, Valid Loss: 0.6479388475418091\n",
      "Epoch: 4648, Train Loss: 0.3879024386405945, Valid Loss: 0.6471390724182129\n",
      "Epoch: 4649, Train Loss: 0.3879021406173706, Valid Loss: 0.6476881504058838\n",
      "Epoch: 4650, Train Loss: 0.38790208101272583, Valid Loss: 0.6473945379257202\n",
      "Epoch: 4651, Train Loss: 0.3879019618034363, Valid Loss: 0.6475448608398438\n",
      "Epoch: 4652, Train Loss: 0.38790181279182434, Valid Loss: 0.6475660800933838\n",
      "Epoch: 4653, Train Loss: 0.38790184259414673, Valid Loss: 0.6474286913871765\n",
      "Epoch: 4654, Train Loss: 0.38790157437324524, Valid Loss: 0.6476795673370361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4655, Train Loss: 0.3879014551639557, Valid Loss: 0.6473402976989746\n",
      "Epoch: 4656, Train Loss: 0.3879014849662781, Valid Loss: 0.6478210687637329\n",
      "Epoch: 4657, Train Loss: 0.3879013955593109, Valid Loss: 0.6472423076629639\n",
      "Epoch: 4658, Train Loss: 0.38790130615234375, Valid Loss: 0.6479982137680054\n",
      "Epoch: 4659, Train Loss: 0.3879012167453766, Valid Loss: 0.6470739841461182\n",
      "Epoch: 4660, Train Loss: 0.3879010081291199, Valid Loss: 0.6482046246528625\n",
      "Epoch: 4661, Train Loss: 0.3879010081291199, Valid Loss: 0.6468972563743591\n",
      "Epoch: 4662, Train Loss: 0.38790106773376465, Valid Loss: 0.6484390497207642\n",
      "Epoch: 4663, Train Loss: 0.38790103793144226, Valid Loss: 0.6466702818870544\n",
      "Epoch: 4664, Train Loss: 0.3879008889198303, Valid Loss: 0.6487368941307068\n",
      "Epoch: 4665, Train Loss: 0.387901246547699, Valid Loss: 0.6463648080825806\n",
      "Epoch: 4666, Train Loss: 0.3879014551639557, Valid Loss: 0.6491615176200867\n",
      "Epoch: 4667, Train Loss: 0.38790175318717957, Valid Loss: 0.6458908915519714\n",
      "Epoch: 4668, Train Loss: 0.38790225982666016, Valid Loss: 0.6497987508773804\n",
      "Epoch: 4669, Train Loss: 0.38790351152420044, Valid Loss: 0.6451272368431091\n",
      "Epoch: 4670, Train Loss: 0.3879048228263855, Valid Loss: 0.6508040428161621\n",
      "Epoch: 4671, Train Loss: 0.38790786266326904, Valid Loss: 0.6439460515975952\n",
      "Epoch: 4672, Train Loss: 0.38791197538375854, Valid Loss: 0.6523616313934326\n",
      "Epoch: 4673, Train Loss: 0.3879183828830719, Valid Loss: 0.6420649886131287\n",
      "Epoch: 4674, Train Loss: 0.3879285156726837, Valid Loss: 0.6548478007316589\n",
      "Epoch: 4675, Train Loss: 0.38794490694999695, Valid Loss: 0.6390553116798401\n",
      "Epoch: 4676, Train Loss: 0.38796985149383545, Valid Loss: 0.6588695645332336\n",
      "Epoch: 4677, Train Loss: 0.3880082666873932, Valid Loss: 0.6343385577201843\n",
      "Epoch: 4678, Train Loss: 0.3880636990070343, Valid Loss: 0.6651384234428406\n",
      "Epoch: 4679, Train Loss: 0.3881424069404602, Valid Loss: 0.627510666847229\n",
      "Epoch: 4680, Train Loss: 0.3882372975349426, Valid Loss: 0.6737115383148193\n",
      "Epoch: 4681, Train Loss: 0.3883403241634369, Valid Loss: 0.6196770668029785\n",
      "Epoch: 4682, Train Loss: 0.3884134888648987, Valid Loss: 0.6813968420028687\n",
      "Epoch: 4683, Train Loss: 0.38842037320137024, Valid Loss: 0.6158636212348938\n",
      "Epoch: 4684, Train Loss: 0.38833680748939514, Valid Loss: 0.6796457767486572\n",
      "Epoch: 4685, Train Loss: 0.3881801664829254, Valid Loss: 0.6234084963798523\n",
      "Epoch: 4686, Train Loss: 0.3880208134651184, Valid Loss: 0.6638701558113098\n",
      "Epoch: 4687, Train Loss: 0.3879266381263733, Valid Loss: 0.6418704986572266\n",
      "Epoch: 4688, Train Loss: 0.3879223167896271, Valid Loss: 0.6434268355369568\n",
      "Epoch: 4689, Train Loss: 0.3879856467247009, Valid Loss: 0.6604471802711487\n",
      "Epoch: 4690, Train Loss: 0.38806962966918945, Valid Loss: 0.6298154592514038\n",
      "Epoch: 4691, Train Loss: 0.3881107568740845, Valid Loss: 0.6688721179962158\n",
      "Epoch: 4692, Train Loss: 0.38807961344718933, Valid Loss: 0.6289330124855042\n",
      "Epoch: 4693, Train Loss: 0.38799917697906494, Valid Loss: 0.6627940535545349\n",
      "Epoch: 4694, Train Loss: 0.38792866468429565, Valid Loss: 0.6395333409309387\n",
      "Epoch: 4695, Train Loss: 0.3879052996635437, Valid Loss: 0.6479356288909912\n",
      "Epoch: 4696, Train Loss: 0.3879246115684509, Valid Loss: 0.6537984609603882\n",
      "Epoch: 4697, Train Loss: 0.387961745262146, Valid Loss: 0.6360160708427429\n",
      "Epoch: 4698, Train Loss: 0.387990802526474, Valid Loss: 0.6624125838279724\n",
      "Epoch: 4699, Train Loss: 0.3879907727241516, Valid Loss: 0.6339580416679382\n",
      "Epoch: 4700, Train Loss: 0.38796040415763855, Valid Loss: 0.6591627597808838\n",
      "Epoch: 4701, Train Loss: 0.3879210948944092, Valid Loss: 0.6412042379379272\n",
      "Epoch: 4702, Train Loss: 0.3879000246524811, Valid Loss: 0.6486018300056458\n",
      "Epoch: 4703, Train Loss: 0.3879045248031616, Valid Loss: 0.6512729525566101\n",
      "Epoch: 4704, Train Loss: 0.3879232406616211, Valid Loss: 0.6404494643211365\n",
      "Epoch: 4705, Train Loss: 0.3879382610321045, Valid Loss: 0.6570063829421997\n",
      "Epoch: 4706, Train Loss: 0.3879423141479492, Valid Loss: 0.6386371850967407\n",
      "Epoch: 4707, Train Loss: 0.3879326581954956, Valid Loss: 0.6558056473731995\n",
      "Epoch: 4708, Train Loss: 0.38791516423225403, Valid Loss: 0.6422305107116699\n",
      "Epoch: 4709, Train Loss: 0.387900173664093, Valid Loss: 0.6501043438911438\n",
      "Epoch: 4710, Train Loss: 0.3878971040248871, Valid Loss: 0.6482272148132324\n",
      "Epoch: 4711, Train Loss: 0.3879040479660034, Valid Loss: 0.6443688869476318\n",
      "Epoch: 4712, Train Loss: 0.3879123032093048, Valid Loss: 0.6532543897628784\n",
      "Epoch: 4713, Train Loss: 0.3879173994064331, Valid Loss: 0.6414863467216492\n",
      "Epoch: 4714, Train Loss: 0.38791659474372864, Valid Loss: 0.654296338558197\n",
      "Epoch: 4715, Train Loss: 0.38791024684906006, Valid Loss: 0.6423165798187256\n",
      "Epoch: 4716, Train Loss: 0.3879021406173706, Valid Loss: 0.651313304901123\n",
      "Epoch: 4717, Train Loss: 0.38789671659469604, Valid Loss: 0.6461878418922424\n",
      "Epoch: 4718, Train Loss: 0.3878965377807617, Valid Loss: 0.647162675857544\n",
      "Epoch: 4719, Train Loss: 0.38789936900138855, Valid Loss: 0.6503530740737915\n",
      "Epoch: 4720, Train Loss: 0.38790246844291687, Valid Loss: 0.6441088914871216\n",
      "Epoch: 4721, Train Loss: 0.3879047632217407, Valid Loss: 0.6522563099861145\n",
      "Epoch: 4722, Train Loss: 0.38790443539619446, Valid Loss: 0.6433464288711548\n",
      "Epoch: 4723, Train Loss: 0.3879024088382721, Valid Loss: 0.6517325639724731\n",
      "Epoch: 4724, Train Loss: 0.38789892196655273, Valid Loss: 0.6449843049049377\n",
      "Epoch: 4725, Train Loss: 0.38789626955986023, Valid Loss: 0.6495977640151978\n",
      "Epoch: 4726, Train Loss: 0.38789501786231995, Valid Loss: 0.6476203799247742\n",
      "Epoch: 4727, Train Loss: 0.38789549469947815, Valid Loss: 0.646935224533081\n",
      "Epoch: 4728, Train Loss: 0.3878961205482483, Valid Loss: 0.6498633623123169\n",
      "Epoch: 4729, Train Loss: 0.38789770007133484, Valid Loss: 0.6452037692070007\n",
      "Epoch: 4730, Train Loss: 0.38789835572242737, Valid Loss: 0.6509863138198853\n",
      "Epoch: 4731, Train Loss: 0.3878980875015259, Valid Loss: 0.6450350284576416\n",
      "Epoch: 4732, Train Loss: 0.38789716362953186, Valid Loss: 0.6505638957023621\n",
      "Epoch: 4733, Train Loss: 0.38789570331573486, Valid Loss: 0.6460557579994202\n",
      "Epoch: 4734, Train Loss: 0.3878946006298065, Valid Loss: 0.649138331413269\n",
      "Epoch: 4735, Train Loss: 0.3878938853740692, Valid Loss: 0.6475948095321655\n",
      "Epoch: 4736, Train Loss: 0.38789355754852295, Valid Loss: 0.6476917862892151\n",
      "Epoch: 4737, Train Loss: 0.3878939151763916, Valid Loss: 0.6489293575286865\n",
      "Epoch: 4738, Train Loss: 0.38789400458335876, Valid Loss: 0.6466934084892273\n",
      "Epoch: 4739, Train Loss: 0.3878946304321289, Valid Loss: 0.6496750116348267\n",
      "Epoch: 4740, Train Loss: 0.3878944516181946, Valid Loss: 0.6462879776954651\n",
      "Epoch: 4741, Train Loss: 0.38789427280426025, Valid Loss: 0.6497979164123535\n",
      "Epoch: 4742, Train Loss: 0.38789403438568115, Valid Loss: 0.6464622020721436\n",
      "Epoch: 4743, Train Loss: 0.38789358735084534, Valid Loss: 0.649478554725647\n",
      "Epoch: 4744, Train Loss: 0.3878931999206543, Valid Loss: 0.6469866037368774\n",
      "Epoch: 4745, Train Loss: 0.38789236545562744, Valid Loss: 0.6488844156265259\n",
      "Epoch: 4746, Train Loss: 0.3878926932811737, Valid Loss: 0.6477137804031372\n",
      "Epoch: 4747, Train Loss: 0.3878921568393707, Valid Loss: 0.648184061050415\n",
      "Epoch: 4748, Train Loss: 0.38789206743240356, Valid Loss: 0.6483979225158691\n",
      "Epoch: 4749, Train Loss: 0.3878921568393707, Valid Loss: 0.6475767493247986\n",
      "Epoch: 4750, Train Loss: 0.3878922462463379, Valid Loss: 0.6489547491073608\n",
      "Epoch: 4751, Train Loss: 0.3878919780254364, Valid Loss: 0.6471947431564331\n",
      "Epoch: 4752, Train Loss: 0.3878922164440155, Valid Loss: 0.6492886543273926\n",
      "Epoch: 4753, Train Loss: 0.3878920376300812, Valid Loss: 0.6470437049865723\n",
      "Epoch: 4754, Train Loss: 0.38789212703704834, Valid Loss: 0.6493325233459473\n",
      "Epoch: 4755, Train Loss: 0.3878912329673767, Valid Loss: 0.6471074819564819\n",
      "Epoch: 4756, Train Loss: 0.3878917992115021, Valid Loss: 0.6492330431938171\n",
      "Epoch: 4757, Train Loss: 0.3878914713859558, Valid Loss: 0.647306501865387\n",
      "Epoch: 4758, Train Loss: 0.3878912925720215, Valid Loss: 0.6490881443023682\n",
      "Epoch: 4759, Train Loss: 0.387891560792923, Valid Loss: 0.6475080847740173\n",
      "Epoch: 4760, Train Loss: 0.3878907561302185, Valid Loss: 0.6488815546035767\n",
      "Epoch: 4761, Train Loss: 0.3878907859325409, Valid Loss: 0.6477236151695251\n",
      "Epoch: 4762, Train Loss: 0.3878905475139618, Valid Loss: 0.6487090587615967\n",
      "Epoch: 4763, Train Loss: 0.38789039850234985, Valid Loss: 0.6479370594024658\n",
      "Epoch: 4764, Train Loss: 0.38789042830467224, Valid Loss: 0.6485881805419922\n",
      "Epoch: 4765, Train Loss: 0.38789016008377075, Valid Loss: 0.6480644941329956\n",
      "Epoch: 4766, Train Loss: 0.3878898620605469, Valid Loss: 0.6485058069229126\n",
      "Epoch: 4767, Train Loss: 0.3878898024559021, Valid Loss: 0.6481491923332214\n",
      "Epoch: 4768, Train Loss: 0.38788989186286926, Valid Loss: 0.6484739184379578\n",
      "Epoch: 4769, Train Loss: 0.3878895044326782, Valid Loss: 0.6482234001159668\n",
      "Epoch: 4770, Train Loss: 0.3878895342350006, Valid Loss: 0.6484584212303162\n",
      "Epoch: 4771, Train Loss: 0.38788917660713196, Valid Loss: 0.6482680439949036\n",
      "Epoch: 4772, Train Loss: 0.3878893554210663, Valid Loss: 0.6484339237213135\n",
      "Epoch: 4773, Train Loss: 0.38788914680480957, Valid Loss: 0.64832603931427\n",
      "Epoch: 4774, Train Loss: 0.38788917660713196, Valid Loss: 0.6484102010726929\n",
      "Epoch: 4775, Train Loss: 0.38788896799087524, Valid Loss: 0.6483860015869141\n",
      "Epoch: 4776, Train Loss: 0.3878888487815857, Valid Loss: 0.6483973860740662\n",
      "Epoch: 4777, Train Loss: 0.38788872957229614, Valid Loss: 0.6484337449073792\n",
      "Epoch: 4778, Train Loss: 0.3878885507583618, Valid Loss: 0.6483750939369202\n",
      "Epoch: 4779, Train Loss: 0.3878883421421051, Valid Loss: 0.64849454164505\n",
      "Epoch: 4780, Train Loss: 0.3878884017467499, Valid Loss: 0.6483537554740906\n",
      "Epoch: 4781, Train Loss: 0.3878883123397827, Valid Loss: 0.648542582988739\n",
      "Epoch: 4782, Train Loss: 0.3878880739212036, Valid Loss: 0.6483328938484192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4783, Train Loss: 0.3878880739212036, Valid Loss: 0.6486053466796875\n",
      "Epoch: 4784, Train Loss: 0.38788798451423645, Valid Loss: 0.6482897400856018\n",
      "Epoch: 4785, Train Loss: 0.3878878057003021, Valid Loss: 0.6487034559249878\n",
      "Epoch: 4786, Train Loss: 0.38788771629333496, Valid Loss: 0.6482129096984863\n",
      "Epoch: 4787, Train Loss: 0.3878876268863678, Valid Loss: 0.6488254070281982\n",
      "Epoch: 4788, Train Loss: 0.38788771629333496, Valid Loss: 0.6480929851531982\n",
      "Epoch: 4789, Train Loss: 0.3878878653049469, Valid Loss: 0.6490170359611511\n",
      "Epoch: 4790, Train Loss: 0.3878873586654663, Valid Loss: 0.6479039788246155\n",
      "Epoch: 4791, Train Loss: 0.3878876268863678, Valid Loss: 0.6493102312088013\n",
      "Epoch: 4792, Train Loss: 0.38788750767707825, Valid Loss: 0.6475368738174438\n",
      "Epoch: 4793, Train Loss: 0.3878880739212036, Valid Loss: 0.6498363018035889\n",
      "Epoch: 4794, Train Loss: 0.3878885507583618, Valid Loss: 0.6468764543533325\n",
      "Epoch: 4795, Train Loss: 0.38788944482803345, Valid Loss: 0.6507616639137268\n",
      "Epoch: 4796, Train Loss: 0.38789132237434387, Valid Loss: 0.6457054615020752\n",
      "Epoch: 4797, Train Loss: 0.38789474964141846, Valid Loss: 0.6523846983909607\n",
      "Epoch: 4798, Train Loss: 0.3879009783267975, Valid Loss: 0.643593966960907\n",
      "Epoch: 4799, Train Loss: 0.38791218400001526, Valid Loss: 0.6553446054458618\n",
      "Epoch: 4800, Train Loss: 0.387932687997818, Valid Loss: 0.6397603154182434\n",
      "Epoch: 4801, Train Loss: 0.38796868920326233, Valid Loss: 0.6607707142829895\n",
      "Epoch: 4802, Train Loss: 0.3880329430103302, Valid Loss: 0.6329560875892639\n",
      "Epoch: 4803, Train Loss: 0.38813814520835876, Valid Loss: 0.6704283356666565\n",
      "Epoch: 4804, Train Loss: 0.38830745220184326, Valid Loss: 0.6218978762626648\n",
      "Epoch: 4805, Train Loss: 0.38852638006210327, Valid Loss: 0.685295820236206\n",
      "Epoch: 4806, Train Loss: 0.38876423239707947, Valid Loss: 0.6088526248931885\n",
      "Epoch: 4807, Train Loss: 0.38887742161750793, Valid Loss: 0.6972389221191406\n",
      "Epoch: 4808, Train Loss: 0.38875094056129456, Valid Loss: 0.6071184277534485\n",
      "Epoch: 4809, Train Loss: 0.38839563727378845, Valid Loss: 0.6836047172546387\n",
      "Epoch: 4810, Train Loss: 0.388043612241745, Valid Loss: 0.630776047706604\n",
      "Epoch: 4811, Train Loss: 0.38792088627815247, Valid Loss: 0.6472799777984619\n",
      "Epoch: 4812, Train Loss: 0.38804563879966736, Valid Loss: 0.6658036112785339\n",
      "Epoch: 4813, Train Loss: 0.38826313614845276, Valid Loss: 0.6208288073539734\n",
      "Epoch: 4814, Train Loss: 0.38835608959198, Valid Loss: 0.6819103956222534\n",
      "Epoch: 4815, Train Loss: 0.3882178068161011, Valid Loss: 0.6233896017074585\n",
      "Epoch: 4816, Train Loss: 0.3879771828651428, Valid Loss: 0.6626587510108948\n",
      "Epoch: 4817, Train Loss: 0.3878949284553528, Valid Loss: 0.6499888896942139\n",
      "Epoch: 4818, Train Loss: 0.3880085051059723, Valid Loss: 0.6324926614761353\n",
      "Epoch: 4819, Train Loss: 0.38814064860343933, Valid Loss: 0.6716985106468201\n",
      "Epoch: 4820, Train Loss: 0.3881497383117676, Valid Loss: 0.6247899532318115\n",
      "Epoch: 4821, Train Loss: 0.38803473114967346, Valid Loss: 0.6664705872535706\n",
      "Epoch: 4822, Train Loss: 0.38791602849960327, Valid Loss: 0.6439103484153748\n",
      "Epoch: 4823, Train Loss: 0.38791000843048096, Valid Loss: 0.6414353847503662\n",
      "Epoch: 4824, Train Loss: 0.38800060749053955, Valid Loss: 0.6639609336853027\n",
      "Epoch: 4825, Train Loss: 0.38805899024009705, Valid Loss: 0.628873884677887\n",
      "Epoch: 4826, Train Loss: 0.38801905512809753, Valid Loss: 0.664218008518219\n",
      "Epoch: 4827, Train Loss: 0.38793593645095825, Valid Loss: 0.6411802172660828\n",
      "Epoch: 4828, Train Loss: 0.38789358735084534, Valid Loss: 0.6481418013572693\n",
      "Epoch: 4829, Train Loss: 0.38792476058006287, Valid Loss: 0.6576564908027649\n",
      "Epoch: 4830, Train Loss: 0.38798025250434875, Valid Loss: 0.6350471377372742\n",
      "Epoch: 4831, Train Loss: 0.38798248767852783, Valid Loss: 0.6604235172271729\n",
      "Epoch: 4832, Train Loss: 0.38793474435806274, Valid Loss: 0.6391090750694275\n",
      "Epoch: 4833, Train Loss: 0.38789403438568115, Valid Loss: 0.6522510647773743\n",
      "Epoch: 4834, Train Loss: 0.3878961205482483, Valid Loss: 0.6524417400360107\n",
      "Epoch: 4835, Train Loss: 0.3879251778125763, Valid Loss: 0.6402778625488281\n",
      "Epoch: 4836, Train Loss: 0.38794219493865967, Valid Loss: 0.6583806872367859\n",
      "Epoch: 4837, Train Loss: 0.3879258632659912, Valid Loss: 0.6390291452407837\n",
      "Epoch: 4838, Train Loss: 0.3878956735134125, Valid Loss: 0.6532238721847534\n",
      "Epoch: 4839, Train Loss: 0.3878867030143738, Valid Loss: 0.6488836407661438\n",
      "Epoch: 4840, Train Loss: 0.3879002332687378, Valid Loss: 0.6440421938896179\n",
      "Epoch: 4841, Train Loss: 0.3879121243953705, Valid Loss: 0.6560554504394531\n",
      "Epoch: 4842, Train Loss: 0.38791099190711975, Valid Loss: 0.6407868266105652\n",
      "Epoch: 4843, Train Loss: 0.38789892196655273, Valid Loss: 0.6534920334815979\n",
      "Epoch: 4844, Train Loss: 0.387886643409729, Valid Loss: 0.6463815569877625\n",
      "Epoch: 4845, Train Loss: 0.3878864347934723, Valid Loss: 0.6465141177177429\n",
      "Epoch: 4846, Train Loss: 0.38789570331573486, Valid Loss: 0.6535649299621582\n",
      "Epoch: 4847, Train Loss: 0.3879011869430542, Valid Loss: 0.6426841616630554\n",
      "Epoch: 4848, Train Loss: 0.38789573311805725, Valid Loss: 0.6538298726081848\n",
      "Epoch: 4849, Train Loss: 0.3878876268863678, Valid Loss: 0.6453595757484436\n",
      "Epoch: 4850, Train Loss: 0.38788408041000366, Valid Loss: 0.6483038067817688\n",
      "Epoch: 4851, Train Loss: 0.38788658380508423, Valid Loss: 0.6512464284896851\n",
      "Epoch: 4852, Train Loss: 0.3878914415836334, Valid Loss: 0.6442935466766357\n",
      "Epoch: 4853, Train Loss: 0.38789206743240356, Valid Loss: 0.6533227562904358\n",
      "Epoch: 4854, Train Loss: 0.38788819313049316, Valid Loss: 0.6454508304595947\n",
      "Epoch: 4855, Train Loss: 0.3878842294216156, Valid Loss: 0.6496827602386475\n",
      "Epoch: 4856, Train Loss: 0.38788318634033203, Valid Loss: 0.6493545770645142\n",
      "Epoch: 4857, Train Loss: 0.38788551092147827, Valid Loss: 0.6460871696472168\n",
      "Epoch: 4858, Train Loss: 0.38788747787475586, Valid Loss: 0.6518336534500122\n",
      "Epoch: 4859, Train Loss: 0.38788720965385437, Valid Loss: 0.645854651927948\n",
      "Epoch: 4860, Train Loss: 0.3878847360610962, Valid Loss: 0.6508481502532959\n",
      "Epoch: 4861, Train Loss: 0.3878828287124634, Valid Loss: 0.647906482219696\n",
      "Epoch: 4862, Train Loss: 0.38788238167762756, Valid Loss: 0.6479337215423584\n",
      "Epoch: 4863, Train Loss: 0.38788342475891113, Valid Loss: 0.650275707244873\n",
      "Epoch: 4864, Train Loss: 0.38788461685180664, Valid Loss: 0.6464531421661377\n",
      "Epoch: 4865, Train Loss: 0.3878844082355499, Valid Loss: 0.6510313153266907\n",
      "Epoch: 4866, Train Loss: 0.3878834843635559, Valid Loss: 0.647220253944397\n",
      "Epoch: 4867, Train Loss: 0.3878815770149231, Valid Loss: 0.6494749188423157\n",
      "Epoch: 4868, Train Loss: 0.3878815174102783, Valid Loss: 0.6489132642745972\n",
      "Epoch: 4869, Train Loss: 0.3878820240497589, Valid Loss: 0.647610068321228\n",
      "Epoch: 4870, Train Loss: 0.3878825008869171, Valid Loss: 0.6503111124038696\n",
      "Epoch: 4871, Train Loss: 0.38788264989852905, Valid Loss: 0.647206723690033\n",
      "Epoch: 4872, Train Loss: 0.3878819942474365, Valid Loss: 0.6503413319587708\n",
      "Epoch: 4873, Train Loss: 0.3878813683986664, Valid Loss: 0.6479495167732239\n",
      "Epoch: 4874, Train Loss: 0.387880802154541, Valid Loss: 0.649018406867981\n",
      "Epoch: 4875, Train Loss: 0.38788071274757385, Valid Loss: 0.6491928100585938\n",
      "Epoch: 4876, Train Loss: 0.3878810703754425, Valid Loss: 0.6478421092033386\n",
      "Epoch: 4877, Train Loss: 0.3878808617591858, Valid Loss: 0.6502007246017456\n",
      "Epoch: 4878, Train Loss: 0.3878811001777649, Valid Loss: 0.647686243057251\n",
      "Epoch: 4879, Train Loss: 0.3878805637359619, Valid Loss: 0.649899423122406\n",
      "Epoch: 4880, Train Loss: 0.3878801465034485, Valid Loss: 0.6484001278877258\n",
      "Epoch: 4881, Train Loss: 0.387879878282547, Valid Loss: 0.6487612128257751\n",
      "Epoch: 4882, Train Loss: 0.3878800868988037, Valid Loss: 0.6494550108909607\n",
      "Epoch: 4883, Train Loss: 0.38787999749183655, Valid Loss: 0.648131251335144\n",
      "Epoch: 4884, Train Loss: 0.3878800868988037, Valid Loss: 0.649919867515564\n",
      "Epoch: 4885, Train Loss: 0.3878799080848694, Valid Loss: 0.648180365562439\n",
      "Epoch: 4886, Train Loss: 0.38787949085235596, Valid Loss: 0.6495083570480347\n",
      "Epoch: 4887, Train Loss: 0.38787928223609924, Valid Loss: 0.6486901640892029\n",
      "Epoch: 4888, Train Loss: 0.3878791630268097, Valid Loss: 0.6488802433013916\n",
      "Epoch: 4889, Train Loss: 0.38787898421287537, Valid Loss: 0.6493604779243469\n",
      "Epoch: 4890, Train Loss: 0.38787901401519775, Valid Loss: 0.6484933495521545\n",
      "Epoch: 4891, Train Loss: 0.38787898421287537, Valid Loss: 0.6496511697769165\n",
      "Epoch: 4892, Train Loss: 0.387878954410553, Valid Loss: 0.6484414935112\n",
      "Epoch: 4893, Train Loss: 0.3878786861896515, Valid Loss: 0.64947110414505\n",
      "Epoch: 4894, Train Loss: 0.3878785967826843, Valid Loss: 0.6487525701522827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4895, Train Loss: 0.38787841796875, Valid Loss: 0.6491423845291138\n",
      "Epoch: 4896, Train Loss: 0.38787850737571716, Valid Loss: 0.6491819620132446\n",
      "Epoch: 4897, Train Loss: 0.38787832856178284, Valid Loss: 0.6488639712333679\n",
      "Epoch: 4898, Train Loss: 0.3878782093524933, Valid Loss: 0.6494165062904358\n",
      "Epoch: 4899, Train Loss: 0.3878780007362366, Valid Loss: 0.6487156748771667\n",
      "Epoch: 4900, Train Loss: 0.3878779709339142, Valid Loss: 0.6494649648666382\n",
      "Epoch: 4901, Train Loss: 0.3878779709339142, Valid Loss: 0.6487867832183838\n",
      "Epoch: 4902, Train Loss: 0.3878779709339142, Valid Loss: 0.6493802070617676\n",
      "Epoch: 4903, Train Loss: 0.38787734508514404, Valid Loss: 0.6489948034286499\n",
      "Epoch: 4904, Train Loss: 0.387877494096756, Valid Loss: 0.6491898894309998\n",
      "Epoch: 4905, Train Loss: 0.3878774344921112, Valid Loss: 0.6492254734039307\n",
      "Epoch: 4906, Train Loss: 0.3878772556781769, Valid Loss: 0.6489719152450562\n",
      "Epoch: 4907, Train Loss: 0.38787713646888733, Valid Loss: 0.6494026184082031\n",
      "Epoch: 4908, Train Loss: 0.3878772258758545, Valid Loss: 0.6489108204841614\n",
      "Epoch: 4909, Train Loss: 0.38787710666656494, Valid Loss: 0.6494609713554382\n",
      "Epoch: 4910, Train Loss: 0.38787683844566345, Valid Loss: 0.6489599347114563\n",
      "Epoch: 4911, Train Loss: 0.387876957654953, Valid Loss: 0.64939284324646\n",
      "Epoch: 4912, Train Loss: 0.38787660002708435, Valid Loss: 0.6490849852561951\n",
      "Epoch: 4913, Train Loss: 0.3878765106201172, Valid Loss: 0.6492522954940796\n",
      "Epoch: 4914, Train Loss: 0.38787633180618286, Valid Loss: 0.6492729187011719\n",
      "Epoch: 4915, Train Loss: 0.3878762722015381, Valid Loss: 0.649128794670105\n",
      "Epoch: 4916, Train Loss: 0.3878762423992157, Valid Loss: 0.6494147777557373\n",
      "Epoch: 4917, Train Loss: 0.38787606358528137, Valid Loss: 0.6490769982337952\n",
      "Epoch: 4918, Train Loss: 0.387876033782959, Valid Loss: 0.6494347453117371\n",
      "Epoch: 4919, Train Loss: 0.3878759443759918, Valid Loss: 0.6491080522537231\n",
      "Epoch: 4920, Train Loss: 0.38787591457366943, Valid Loss: 0.6494045257568359\n",
      "Epoch: 4921, Train Loss: 0.38787561655044556, Valid Loss: 0.6492012143135071\n",
      "Epoch: 4922, Train Loss: 0.38787591457366943, Valid Loss: 0.6493551731109619\n",
      "Epoch: 4923, Train Loss: 0.387875497341156, Valid Loss: 0.6492928862571716\n",
      "Epoch: 4924, Train Loss: 0.3878752887248993, Valid Loss: 0.6492952704429626\n",
      "Epoch: 4925, Train Loss: 0.3878750503063202, Valid Loss: 0.6493552923202515\n",
      "Epoch: 4926, Train Loss: 0.3878750503063202, Valid Loss: 0.6492576599121094\n",
      "Epoch: 4927, Train Loss: 0.3878750503063202, Valid Loss: 0.6494343280792236\n",
      "Epoch: 4928, Train Loss: 0.3878749907016754, Valid Loss: 0.6492317914962769\n",
      "Epoch: 4929, Train Loss: 0.3878748416900635, Valid Loss: 0.6494922041893005\n",
      "Epoch: 4930, Train Loss: 0.3878740966320038, Valid Loss: 0.649212658405304\n",
      "Epoch: 4931, Train Loss: 0.38787469267845154, Valid Loss: 0.6495163440704346\n",
      "Epoch: 4932, Train Loss: 0.3878745138645172, Valid Loss: 0.6492151021957397\n",
      "Epoch: 4933, Train Loss: 0.3878745138645172, Valid Loss: 0.6495385766029358\n",
      "Epoch: 4934, Train Loss: 0.3878743350505829, Valid Loss: 0.6492685675621033\n",
      "Epoch: 4935, Train Loss: 0.3878745138645172, Valid Loss: 0.6494994163513184\n",
      "Epoch: 4936, Train Loss: 0.3878740668296814, Valid Loss: 0.6493290662765503\n",
      "Epoch: 4937, Train Loss: 0.387874037027359, Valid Loss: 0.6494516134262085\n",
      "Epoch: 4938, Train Loss: 0.3878738582134247, Valid Loss: 0.6494038105010986\n",
      "Epoch: 4939, Train Loss: 0.3878737688064575, Valid Loss: 0.6494414806365967\n",
      "Epoch: 4940, Train Loss: 0.38787370920181274, Valid Loss: 0.6494320034980774\n",
      "Epoch: 4941, Train Loss: 0.38787373900413513, Valid Loss: 0.6494563221931458\n",
      "Epoch: 4942, Train Loss: 0.3878737986087799, Valid Loss: 0.6494467854499817\n",
      "Epoch: 4943, Train Loss: 0.38787320256233215, Valid Loss: 0.6494484543800354\n",
      "Epoch: 4944, Train Loss: 0.3878733813762665, Valid Loss: 0.6494879126548767\n",
      "Epoch: 4945, Train Loss: 0.3878730237483978, Valid Loss: 0.6494414806365967\n",
      "Epoch: 4946, Train Loss: 0.387873113155365, Valid Loss: 0.6495300531387329\n",
      "Epoch: 4947, Train Loss: 0.3878729045391083, Valid Loss: 0.6494258642196655\n",
      "Epoch: 4948, Train Loss: 0.38787299394607544, Valid Loss: 0.6495734453201294\n",
      "Epoch: 4949, Train Loss: 0.38787272572517395, Valid Loss: 0.6494110226631165\n",
      "Epoch: 4950, Train Loss: 0.387872576713562, Valid Loss: 0.6496273279190063\n",
      "Epoch: 4951, Train Loss: 0.387872576713562, Valid Loss: 0.6493747234344482\n",
      "Epoch: 4952, Train Loss: 0.38787248730659485, Valid Loss: 0.6496954560279846\n",
      "Epoch: 4953, Train Loss: 0.3878723680973053, Valid Loss: 0.6493312120437622\n",
      "Epoch: 4954, Train Loss: 0.38787218928337097, Valid Loss: 0.6497870683670044\n",
      "Epoch: 4955, Train Loss: 0.3878721594810486, Valid Loss: 0.6492391228675842\n",
      "Epoch: 4956, Train Loss: 0.38787201046943665, Valid Loss: 0.6499374508857727\n",
      "Epoch: 4957, Train Loss: 0.38787201046943665, Valid Loss: 0.6490951776504517\n",
      "Epoch: 4958, Train Loss: 0.38787174224853516, Valid Loss: 0.6501384973526001\n",
      "Epoch: 4959, Train Loss: 0.38787180185317993, Valid Loss: 0.6489023566246033\n",
      "Epoch: 4960, Train Loss: 0.3878720700740814, Valid Loss: 0.6503830552101135\n",
      "Epoch: 4961, Train Loss: 0.38787195086479187, Valid Loss: 0.648640513420105\n",
      "Epoch: 4962, Train Loss: 0.38787218928337097, Valid Loss: 0.6507411003112793\n",
      "Epoch: 4963, Train Loss: 0.3878723978996277, Valid Loss: 0.6482244729995728\n",
      "Epoch: 4964, Train Loss: 0.3878728151321411, Valid Loss: 0.6512988805770874\n",
      "Epoch: 4965, Train Loss: 0.3878737688064575, Valid Loss: 0.6475557684898376\n",
      "Epoch: 4966, Train Loss: 0.38787493109703064, Valid Loss: 0.6522011756896973\n",
      "Epoch: 4967, Train Loss: 0.3878768980503082, Valid Loss: 0.6464486122131348\n",
      "Epoch: 4968, Train Loss: 0.38788023591041565, Valid Loss: 0.6536785364151001\n",
      "Epoch: 4969, Train Loss: 0.3878864049911499, Valid Loss: 0.6446233987808228\n",
      "Epoch: 4970, Train Loss: 0.3878953158855438, Valid Loss: 0.6561248302459717\n",
      "Epoch: 4971, Train Loss: 0.387910395860672, Valid Loss: 0.6416133046150208\n",
      "Epoch: 4972, Train Loss: 0.38793453574180603, Valid Loss: 0.6602126359939575\n",
      "Epoch: 4973, Train Loss: 0.3879740238189697, Valid Loss: 0.6366912722587585\n",
      "Epoch: 4974, Train Loss: 0.3880329132080078, Valid Loss: 0.6669125556945801\n",
      "Epoch: 4975, Train Loss: 0.38812246918678284, Valid Loss: 0.6291678547859192\n",
      "Epoch: 4976, Train Loss: 0.38823533058166504, Valid Loss: 0.676761269569397\n",
      "Epoch: 4977, Train Loss: 0.3883737027645111, Valid Loss: 0.6197811365127563\n",
      "Epoch: 4978, Train Loss: 0.38848039507865906, Valid Loss: 0.6868870258331299\n",
      "Epoch: 4979, Train Loss: 0.3885248005390167, Valid Loss: 0.6138389706611633\n",
      "Epoch: 4980, Train Loss: 0.3884388506412506, Valid Loss: 0.6868574619293213\n",
      "Epoch: 4981, Train Loss: 0.38824784755706787, Valid Loss: 0.6210824847221375\n",
      "Epoch: 4982, Train Loss: 0.38802826404571533, Valid Loss: 0.6687840819358826\n",
      "Epoch: 4983, Train Loss: 0.3878946602344513, Valid Loss: 0.6428629159927368\n",
      "Epoch: 4984, Train Loss: 0.3878931403160095, Valid Loss: 0.6438584923744202\n",
      "Epoch: 4985, Train Loss: 0.3879874050617218, Valid Loss: 0.6656042337417603\n",
      "Epoch: 4986, Train Loss: 0.38809651136398315, Valid Loss: 0.6278945803642273\n",
      "Epoch: 4987, Train Loss: 0.3881334066390991, Valid Loss: 0.6743934154510498\n",
      "Epoch: 4988, Train Loss: 0.3880775570869446, Valid Loss: 0.628938615322113\n",
      "Epoch: 4989, Train Loss: 0.3879718482494354, Valid Loss: 0.6642776727676392\n",
      "Epoch: 4990, Train Loss: 0.3878943622112274, Valid Loss: 0.6439688801765442\n",
      "Epoch: 4991, Train Loss: 0.3878818452358246, Valid Loss: 0.6458479166030884\n",
      "Epoch: 4992, Train Loss: 0.3879214823246002, Valid Loss: 0.659970223903656\n",
      "Epoch: 4993, Train Loss: 0.38797420263290405, Valid Loss: 0.6344709992408752\n",
      "Epoch: 4994, Train Loss: 0.38799601793289185, Valid Loss: 0.6660387516021729\n",
      "Epoch: 4995, Train Loss: 0.38797059655189514, Valid Loss: 0.636272668838501\n",
      "Epoch: 4996, Train Loss: 0.38791611790657043, Valid Loss: 0.6588804125785828\n",
      "Epoch: 4997, Train Loss: 0.3878762722015381, Valid Loss: 0.6465563774108887\n",
      "Epoch: 4998, Train Loss: 0.3878745138645172, Valid Loss: 0.646145761013031\n",
      "Epoch: 4999, Train Loss: 0.3879005014896393, Valid Loss: 0.6570297479629517\n",
      "Epoch: 5000, Train Loss: 0.38792699575424194, Valid Loss: 0.6392095685005188\n",
      "Epoch: 5001, Train Loss: 0.3879321217536926, Valid Loss: 0.6609407663345337\n",
      "Epoch: 5002, Train Loss: 0.3879150152206421, Valid Loss: 0.6406795978546143\n",
      "Epoch: 5003, Train Loss: 0.38788890838623047, Valid Loss: 0.6557365655899048\n",
      "Epoch: 5004, Train Loss: 0.38787174224853516, Valid Loss: 0.6470763683319092\n",
      "Epoch: 5005, Train Loss: 0.3878725469112396, Valid Loss: 0.6472037434577942\n",
      "Epoch: 5006, Train Loss: 0.38788604736328125, Valid Loss: 0.6548216342926025\n",
      "Epoch: 5007, Train Loss: 0.38789862394332886, Valid Loss: 0.6423740983009338\n",
      "Epoch: 5008, Train Loss: 0.3878999352455139, Valid Loss: 0.6581112742424011\n",
      "Epoch: 5009, Train Loss: 0.3878912925720215, Valid Loss: 0.6424784660339355\n",
      "Epoch: 5010, Train Loss: 0.3878793716430664, Valid Loss: 0.6543582081794739\n",
      "Epoch: 5011, Train Loss: 0.387871116399765, Valid Loss: 0.6471664309501648\n",
      "Epoch: 5012, Train Loss: 0.38786935806274414, Valid Loss: 0.648478627204895\n",
      "Epoch: 5013, Train Loss: 0.38787418603897095, Valid Loss: 0.6534177660942078\n",
      "Epoch: 5014, Train Loss: 0.38788095116615295, Valid Loss: 0.6444154381752014\n",
      "Epoch: 5015, Train Loss: 0.3878842294216156, Valid Loss: 0.6557354927062988\n",
      "Epoch: 5016, Train Loss: 0.3878813683986664, Valid Loss: 0.6438721418380737\n",
      "Epoch: 5017, Train Loss: 0.387874960899353, Valid Loss: 0.6535800695419312\n",
      "Epoch: 5018, Train Loss: 0.3878699243068695, Valid Loss: 0.647407591342926\n",
      "Epoch: 5019, Train Loss: 0.38786807656288147, Valid Loss: 0.6498759388923645\n",
      "Epoch: 5020, Train Loss: 0.3878689706325531, Valid Loss: 0.6516139507293701\n",
      "Epoch: 5021, Train Loss: 0.38787126541137695, Valid Loss: 0.6465599536895752\n",
      "Epoch: 5022, Train Loss: 0.3878736197948456, Valid Loss: 0.6534503102302551\n",
      "Epoch: 5023, Train Loss: 0.3878745436668396, Valid Loss: 0.6456791162490845\n",
      "Epoch: 5024, Train Loss: 0.3878728747367859, Valid Loss: 0.6531080007553101\n",
      "Epoch: 5025, Train Loss: 0.3878701329231262, Valid Loss: 0.6473944783210754\n",
      "Epoch: 5026, Train Loss: 0.38786789774894714, Valid Loss: 0.6511234045028687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5027, Train Loss: 0.3878667950630188, Valid Loss: 0.6496263742446899\n",
      "Epoch: 5028, Train Loss: 0.38786688446998596, Valid Loss: 0.6487166881561279\n",
      "Epoch: 5029, Train Loss: 0.38786792755126953, Valid Loss: 0.6514045000076294\n",
      "Epoch: 5030, Train Loss: 0.38786908984184265, Valid Loss: 0.6475595831871033\n",
      "Epoch: 5031, Train Loss: 0.387869656085968, Valid Loss: 0.6522870659828186\n",
      "Epoch: 5032, Train Loss: 0.3878692090511322, Valid Loss: 0.6475310325622559\n",
      "Epoch: 5033, Train Loss: 0.3878682851791382, Valid Loss: 0.6517993211746216\n",
      "Epoch: 5034, Train Loss: 0.38786688446998596, Valid Loss: 0.6482698321342468\n",
      "Epoch: 5035, Train Loss: 0.38786622881889343, Valid Loss: 0.6506198048591614\n",
      "Epoch: 5036, Train Loss: 0.38786566257476807, Valid Loss: 0.6496509313583374\n",
      "Epoch: 5037, Train Loss: 0.3878656029701233, Valid Loss: 0.6494207978248596\n",
      "Epoch: 5038, Train Loss: 0.3878663182258606, Valid Loss: 0.6508991122245789\n",
      "Epoch: 5039, Train Loss: 0.38786637783050537, Valid Loss: 0.6484085917472839\n",
      "Epoch: 5040, Train Loss: 0.38786670565605164, Valid Loss: 0.6515200734138489\n",
      "Epoch: 5041, Train Loss: 0.3878666162490845, Valid Loss: 0.6481263637542725\n",
      "Epoch: 5042, Train Loss: 0.3878661096096039, Valid Loss: 0.6515089273452759\n",
      "Epoch: 5043, Train Loss: 0.3878657817840576, Valid Loss: 0.6486052870750427\n",
      "Epoch: 5044, Train Loss: 0.3878651559352875, Valid Loss: 0.6508604288101196\n",
      "Epoch: 5045, Train Loss: 0.3878647983074188, Valid Loss: 0.6494312882423401\n",
      "Epoch: 5046, Train Loss: 0.38786473870277405, Valid Loss: 0.6499724388122559\n",
      "Epoch: 5047, Train Loss: 0.3878646194934845, Valid Loss: 0.6502642631530762\n",
      "Epoch: 5048, Train Loss: 0.3878646790981293, Valid Loss: 0.6493244767189026\n",
      "Epoch: 5049, Train Loss: 0.3878645896911621, Valid Loss: 0.6508306860923767\n",
      "Epoch: 5050, Train Loss: 0.38786476850509644, Valid Loss: 0.6489947438240051\n",
      "Epoch: 5051, Train Loss: 0.3878645598888397, Valid Loss: 0.6509854793548584\n",
      "Epoch: 5052, Train Loss: 0.3878645896911621, Valid Loss: 0.6490240693092346\n",
      "Epoch: 5053, Train Loss: 0.3878644108772278, Valid Loss: 0.6508657336235046\n",
      "Epoch: 5054, Train Loss: 0.38786429166793823, Valid Loss: 0.6492714881896973\n",
      "Epoch: 5055, Train Loss: 0.3878641128540039, Valid Loss: 0.6506219506263733\n",
      "Epoch: 5056, Train Loss: 0.3878633975982666, Valid Loss: 0.649563193321228\n",
      "Epoch: 5057, Train Loss: 0.3878635764122009, Valid Loss: 0.6503546833992004\n",
      "Epoch: 5058, Train Loss: 0.3878633379936218, Valid Loss: 0.6498536467552185\n",
      "Epoch: 5059, Train Loss: 0.3878633975982666, Valid Loss: 0.6501224637031555\n",
      "Epoch: 5060, Train Loss: 0.3878630995750427, Valid Loss: 0.6500878930091858\n",
      "Epoch: 5061, Train Loss: 0.38786330819129944, Valid Loss: 0.649925708770752\n",
      "Epoch: 5062, Train Loss: 0.3878630995750427, Valid Loss: 0.6503089070320129\n",
      "Epoch: 5063, Train Loss: 0.38786324858665466, Valid Loss: 0.6497718691825867\n",
      "Epoch: 5064, Train Loss: 0.3878629505634308, Valid Loss: 0.6504821181297302\n",
      "Epoch: 5065, Train Loss: 0.3878628611564636, Valid Loss: 0.6496585011482239\n",
      "Epoch: 5066, Train Loss: 0.3878629505634308, Valid Loss: 0.6506056189537048\n",
      "Epoch: 5067, Train Loss: 0.3878624439239502, Valid Loss: 0.6495729088783264\n",
      "Epoch: 5068, Train Loss: 0.38786253333091736, Valid Loss: 0.650688648223877\n",
      "Epoch: 5069, Train Loss: 0.3878624439239502, Valid Loss: 0.649576723575592\n",
      "Epoch: 5070, Train Loss: 0.3878623843193054, Valid Loss: 0.6507105231285095\n",
      "Epoch: 5071, Train Loss: 0.38786301016807556, Valid Loss: 0.6496052742004395\n",
      "Epoch: 5072, Train Loss: 0.38786205649375916, Valid Loss: 0.650664746761322\n",
      "Epoch: 5073, Train Loss: 0.3878617286682129, Valid Loss: 0.6496742367744446\n",
      "Epoch: 5074, Train Loss: 0.3878619968891144, Valid Loss: 0.6506382822990417\n",
      "Epoch: 5075, Train Loss: 0.38786184787750244, Valid Loss: 0.6497563123703003\n",
      "Epoch: 5076, Train Loss: 0.3878616392612457, Valid Loss: 0.6506067514419556\n",
      "Epoch: 5077, Train Loss: 0.38786160945892334, Valid Loss: 0.6497984528541565\n",
      "Epoch: 5078, Train Loss: 0.3878615200519562, Valid Loss: 0.6505955457687378\n",
      "Epoch: 5079, Train Loss: 0.3878616392612457, Valid Loss: 0.6498017311096191\n",
      "Epoch: 5080, Train Loss: 0.3878615200519562, Valid Loss: 0.6506533026695251\n",
      "Epoch: 5081, Train Loss: 0.387861430644989, Valid Loss: 0.6497644186019897\n",
      "Epoch: 5082, Train Loss: 0.3878612220287323, Valid Loss: 0.6507611274719238\n",
      "Epoch: 5083, Train Loss: 0.3878612220287323, Valid Loss: 0.6496508717536926\n",
      "Epoch: 5084, Train Loss: 0.38786113262176514, Valid Loss: 0.6509197950363159\n",
      "Epoch: 5085, Train Loss: 0.38786110281944275, Valid Loss: 0.6494922041893005\n",
      "Epoch: 5086, Train Loss: 0.38786113262176514, Valid Loss: 0.6511428952217102\n",
      "Epoch: 5087, Train Loss: 0.387861043214798, Valid Loss: 0.6492655873298645\n",
      "Epoch: 5088, Train Loss: 0.38786131143569946, Valid Loss: 0.6514652967453003\n",
      "Epoch: 5089, Train Loss: 0.3878614604473114, Valid Loss: 0.6488966345787048\n",
      "Epoch: 5090, Train Loss: 0.38786157965660095, Valid Loss: 0.6519522070884705\n",
      "Epoch: 5091, Train Loss: 0.3878622055053711, Valid Loss: 0.6483067274093628\n",
      "Epoch: 5092, Train Loss: 0.38786324858665466, Valid Loss: 0.6527681946754456\n",
      "Epoch: 5093, Train Loss: 0.38786500692367554, Valid Loss: 0.647315502166748\n",
      "Epoch: 5094, Train Loss: 0.38786742091178894, Valid Loss: 0.6540896892547607\n",
      "Epoch: 5095, Train Loss: 0.38787195086479187, Valid Loss: 0.6456770300865173\n",
      "Epoch: 5096, Train Loss: 0.3878781795501709, Valid Loss: 0.6562597155570984\n",
      "Epoch: 5097, Train Loss: 0.38788902759552, Valid Loss: 0.6430004835128784\n",
      "Epoch: 5098, Train Loss: 0.3879062831401825, Valid Loss: 0.6598474383354187\n",
      "Epoch: 5099, Train Loss: 0.3879345953464508, Valid Loss: 0.6386488080024719\n",
      "Epoch: 5100, Train Loss: 0.387978196144104, Valid Loss: 0.6656925678253174\n",
      "Epoch: 5101, Train Loss: 0.38804754614830017, Valid Loss: 0.6318721175193787\n",
      "Epoch: 5102, Train Loss: 0.3881446421146393, Valid Loss: 0.6746652126312256\n",
      "Epoch: 5103, Train Loss: 0.3882809579372406, Valid Loss: 0.6226151585578918\n",
      "Epoch: 5104, Train Loss: 0.38842320442199707, Valid Loss: 0.6858171224594116\n",
      "Epoch: 5105, Train Loss: 0.3885517120361328, Valid Loss: 0.6141796112060547\n",
      "Epoch: 5106, Train Loss: 0.388563334941864, Valid Loss: 0.6915304660797119\n",
      "Epoch: 5107, Train Loss: 0.3884456753730774, Valid Loss: 0.6157950758934021\n",
      "Epoch: 5108, Train Loss: 0.38820645213127136, Valid Loss: 0.679405927658081\n",
      "Epoch: 5109, Train Loss: 0.38798201084136963, Valid Loss: 0.6337893009185791\n",
      "Epoch: 5110, Train Loss: 0.38787469267845154, Valid Loss: 0.6533713340759277\n",
      "Epoch: 5111, Train Loss: 0.38790881633758545, Valid Loss: 0.6591522097587585\n",
      "Epoch: 5112, Train Loss: 0.38802722096443176, Valid Loss: 0.631950855255127\n",
      "Epoch: 5113, Train Loss: 0.3881307542324066, Valid Loss: 0.6755133271217346\n",
      "Epoch: 5114, Train Loss: 0.3881448805332184, Valid Loss: 0.6262902021408081\n",
      "Epoch: 5115, Train Loss: 0.3880504071712494, Valid Loss: 0.6714226603507996\n",
      "Epoch: 5116, Train Loss: 0.3879300057888031, Valid Loss: 0.6378285884857178\n",
      "Epoch: 5117, Train Loss: 0.38786590099334717, Valid Loss: 0.6524533033370972\n",
      "Epoch: 5118, Train Loss: 0.3878847360610962, Valid Loss: 0.6565876603126526\n",
      "Epoch: 5119, Train Loss: 0.38794925808906555, Valid Loss: 0.6364294290542603\n",
      "Epoch: 5120, Train Loss: 0.387997031211853, Valid Loss: 0.66805100440979\n",
      "Epoch: 5121, Train Loss: 0.3879917860031128, Valid Loss: 0.633788526058197\n",
      "Epoch: 5122, Train Loss: 0.3879377245903015, Valid Loss: 0.6636216640472412\n",
      "Epoch: 5123, Train Loss: 0.3878822922706604, Valid Loss: 0.6433984637260437\n",
      "Epoch: 5124, Train Loss: 0.38786083459854126, Valid Loss: 0.6493822336196899\n",
      "Epoch: 5125, Train Loss: 0.3878794312477112, Valid Loss: 0.6568571329116821\n",
      "Epoch: 5126, Train Loss: 0.3879140317440033, Valid Loss: 0.6391609311103821\n",
      "Epoch: 5127, Train Loss: 0.387932151556015, Valid Loss: 0.6633212566375732\n",
      "Epoch: 5128, Train Loss: 0.38791942596435547, Valid Loss: 0.6392757296562195\n",
      "Epoch: 5129, Train Loss: 0.38788777589797974, Valid Loss: 0.6580003499984741\n",
      "Epoch: 5130, Train Loss: 0.38786375522613525, Valid Loss: 0.6470210552215576\n",
      "Epoch: 5131, Train Loss: 0.3878604769706726, Valid Loss: 0.6480880975723267\n",
      "Epoch: 5132, Train Loss: 0.3878737688064575, Valid Loss: 0.6559018492698669\n",
      "Epoch: 5133, Train Loss: 0.38788923621177673, Valid Loss: 0.6423068046569824\n",
      "Epoch: 5134, Train Loss: 0.3878940939903259, Valid Loss: 0.6591628789901733\n",
      "Epoch: 5135, Train Loss: 0.38788560032844543, Valid Loss: 0.6429148316383362\n",
      "Epoch: 5136, Train Loss: 0.387871652841568, Valid Loss: 0.6552039980888367\n",
      "Epoch: 5137, Train Loss: 0.38786041736602783, Valid Loss: 0.6481663584709167\n",
      "Epoch: 5138, Train Loss: 0.38785839080810547, Valid Loss: 0.648863673210144\n",
      "Epoch: 5139, Train Loss: 0.3878651559352875, Valid Loss: 0.6541906595230103\n",
      "Epoch: 5140, Train Loss: 0.3878731429576874, Valid Loss: 0.6448791027069092\n",
      "Epoch: 5141, Train Loss: 0.3878755569458008, Valid Loss: 0.6564708948135376\n",
      "Epoch: 5142, Train Loss: 0.3878715932369232, Valid Loss: 0.6447422504425049\n",
      "Epoch: 5143, Train Loss: 0.3878646790981293, Valid Loss: 0.6541749835014343\n",
      "Epoch: 5144, Train Loss: 0.3878590166568756, Valid Loss: 0.6482530236244202\n",
      "Epoch: 5145, Train Loss: 0.3878568410873413, Valid Loss: 0.6500555276870728\n",
      "Epoch: 5146, Train Loss: 0.38785943388938904, Valid Loss: 0.6526448726654053\n",
      "Epoch: 5147, Train Loss: 0.38786283135414124, Valid Loss: 0.6468053460121155\n",
      "Epoch: 5148, Train Loss: 0.3878653049468994, Valid Loss: 0.6546157598495483\n",
      "Epoch: 5149, Train Loss: 0.3878650963306427, Valid Loss: 0.6461377739906311\n",
      "Epoch: 5150, Train Loss: 0.38786211609840393, Valid Loss: 0.6537932753562927\n",
      "Epoch: 5151, Train Loss: 0.3878587484359741, Valid Loss: 0.6481655240058899\n",
      "Epoch: 5152, Train Loss: 0.38785654306411743, Valid Loss: 0.6513125896453857\n",
      "Epoch: 5153, Train Loss: 0.3878563344478607, Valid Loss: 0.6509987711906433\n",
      "Epoch: 5154, Train Loss: 0.3878575563430786, Valid Loss: 0.6486147046089172\n",
      "Epoch: 5155, Train Loss: 0.3878590762615204, Valid Loss: 0.6529666185379028\n",
      "Epoch: 5156, Train Loss: 0.38785994052886963, Valid Loss: 0.6474296450614929\n",
      "Epoch: 5157, Train Loss: 0.3878597021102905, Valid Loss: 0.6533944606781006\n",
      "Epoch: 5158, Train Loss: 0.38785839080810547, Valid Loss: 0.6480867266654968\n",
      "Epoch: 5159, Train Loss: 0.3878571689128876, Valid Loss: 0.6521711945533752\n",
      "Epoch: 5160, Train Loss: 0.38785579800605774, Valid Loss: 0.6496587991714478\n",
      "Epoch: 5161, Train Loss: 0.3878553807735443, Valid Loss: 0.6503186821937561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5162, Train Loss: 0.3878556489944458, Valid Loss: 0.6514137983322144\n",
      "Epoch: 5163, Train Loss: 0.38785651326179504, Valid Loss: 0.6490018963813782\n",
      "Epoch: 5164, Train Loss: 0.38785651326179504, Valid Loss: 0.6524388790130615\n",
      "Epoch: 5165, Train Loss: 0.38785693049430847, Valid Loss: 0.6485714912414551\n",
      "Epoch: 5166, Train Loss: 0.387856662273407, Valid Loss: 0.6523401141166687\n",
      "Epoch: 5167, Train Loss: 0.38785573840141296, Valid Loss: 0.6490195393562317\n",
      "Epoch: 5168, Train Loss: 0.3878551125526428, Valid Loss: 0.6515922546386719\n",
      "Epoch: 5169, Train Loss: 0.38785475492477417, Valid Loss: 0.6500461101531982\n",
      "Epoch: 5170, Train Loss: 0.3878546953201294, Valid Loss: 0.6506627798080444\n",
      "Epoch: 5171, Train Loss: 0.38785436749458313, Valid Loss: 0.6509867310523987\n",
      "Epoch: 5172, Train Loss: 0.3878548741340637, Valid Loss: 0.6498269438743591\n",
      "Epoch: 5173, Train Loss: 0.38785460591316223, Valid Loss: 0.6516022682189941\n",
      "Epoch: 5174, Train Loss: 0.3878547251224518, Valid Loss: 0.649462878704071\n",
      "Epoch: 5175, Train Loss: 0.3878548741340637, Valid Loss: 0.651852548122406\n",
      "Epoch: 5176, Train Loss: 0.387854665517807, Valid Loss: 0.6495203375816345\n",
      "Epoch: 5177, Train Loss: 0.3878542184829712, Valid Loss: 0.6516484618186951\n",
      "Epoch: 5178, Train Loss: 0.38785409927368164, Valid Loss: 0.6498410105705261\n",
      "Epoch: 5179, Train Loss: 0.38785380125045776, Valid Loss: 0.6511947512626648\n",
      "Epoch: 5180, Train Loss: 0.38785380125045776, Valid Loss: 0.6503856182098389\n",
      "Epoch: 5181, Train Loss: 0.38785338401794434, Valid Loss: 0.6507401466369629\n",
      "Epoch: 5182, Train Loss: 0.38785338401794434, Valid Loss: 0.6508960127830505\n",
      "Epoch: 5183, Train Loss: 0.3878532648086548, Valid Loss: 0.650310754776001\n",
      "Epoch: 5184, Train Loss: 0.3878532350063324, Valid Loss: 0.6512292623519897\n",
      "Epoch: 5185, Train Loss: 0.38785335421562195, Valid Loss: 0.6500658988952637\n",
      "Epoch: 5186, Train Loss: 0.38785320520401, Valid Loss: 0.6514450311660767\n",
      "Epoch: 5187, Train Loss: 0.38785305619239807, Valid Loss: 0.6499924659729004\n",
      "Epoch: 5188, Train Loss: 0.3878532946109772, Valid Loss: 0.651505708694458\n",
      "Epoch: 5189, Train Loss: 0.3878529965877533, Valid Loss: 0.649997889995575\n",
      "Epoch: 5190, Train Loss: 0.3878527879714966, Valid Loss: 0.6514496803283691\n",
      "Epoch: 5191, Train Loss: 0.3878526985645294, Valid Loss: 0.6501362323760986\n",
      "Epoch: 5192, Train Loss: 0.3878524899482727, Valid Loss: 0.6513143181800842\n",
      "Epoch: 5193, Train Loss: 0.3878524899482727, Valid Loss: 0.6503587961196899\n",
      "Epoch: 5194, Train Loss: 0.3878522217273712, Valid Loss: 0.6511256694793701\n",
      "Epoch: 5195, Train Loss: 0.3878522515296936, Valid Loss: 0.6505612134933472\n",
      "Epoch: 5196, Train Loss: 0.3878523111343384, Valid Loss: 0.6509429812431335\n",
      "Epoch: 5197, Train Loss: 0.38785189390182495, Valid Loss: 0.6507545709609985\n",
      "Epoch: 5198, Train Loss: 0.38785186409950256, Valid Loss: 0.6508074402809143\n",
      "Epoch: 5199, Train Loss: 0.38785189390182495, Valid Loss: 0.6509227752685547\n",
      "Epoch: 5200, Train Loss: 0.3878517150878906, Valid Loss: 0.6506901383399963\n",
      "Epoch: 5201, Train Loss: 0.38785144686698914, Valid Loss: 0.6510406732559204\n",
      "Epoch: 5202, Train Loss: 0.38785144686698914, Valid Loss: 0.6506039500236511\n",
      "Epoch: 5203, Train Loss: 0.387851357460022, Valid Loss: 0.6511374115943909\n",
      "Epoch: 5204, Train Loss: 0.3878517746925354, Valid Loss: 0.6505611538887024\n",
      "Epoch: 5205, Train Loss: 0.38785144686698914, Valid Loss: 0.6512216925621033\n",
      "Epoch: 5206, Train Loss: 0.38785114884376526, Valid Loss: 0.6505041718482971\n",
      "Epoch: 5207, Train Loss: 0.3878512382507324, Valid Loss: 0.6513121128082275\n",
      "Epoch: 5208, Train Loss: 0.38785111904144287, Valid Loss: 0.650431752204895\n",
      "Epoch: 5209, Train Loss: 0.38785111904144287, Valid Loss: 0.6514055728912354\n",
      "Epoch: 5210, Train Loss: 0.3878507912158966, Valid Loss: 0.6503516435623169\n",
      "Epoch: 5211, Train Loss: 0.38785067200660706, Valid Loss: 0.6515455842018127\n",
      "Epoch: 5212, Train Loss: 0.3878507614135742, Valid Loss: 0.6502320766448975\n",
      "Epoch: 5213, Train Loss: 0.3878507614135742, Valid Loss: 0.6517032384872437\n",
      "Epoch: 5214, Train Loss: 0.38785073161125183, Valid Loss: 0.6500729322433472\n",
      "Epoch: 5215, Train Loss: 0.3878509998321533, Valid Loss: 0.6519267559051514\n",
      "Epoch: 5216, Train Loss: 0.3878510296344757, Valid Loss: 0.649828314781189\n",
      "Epoch: 5217, Train Loss: 0.3878505229949951, Valid Loss: 0.652266263961792\n",
      "Epoch: 5218, Train Loss: 0.3878512978553772, Valid Loss: 0.6494537591934204\n",
      "Epoch: 5219, Train Loss: 0.3878515958786011, Valid Loss: 0.6527725458145142\n",
      "Epoch: 5220, Train Loss: 0.3878523111343384, Valid Loss: 0.6488391757011414\n",
      "Epoch: 5221, Train Loss: 0.38785338401794434, Valid Loss: 0.6535820960998535\n",
      "Epoch: 5222, Train Loss: 0.3878552317619324, Valid Loss: 0.6478688716888428\n",
      "Epoch: 5223, Train Loss: 0.3878578245639801, Valid Loss: 0.6548745036125183\n",
      "Epoch: 5224, Train Loss: 0.38786235451698303, Valid Loss: 0.6462819576263428\n",
      "Epoch: 5225, Train Loss: 0.38786888122558594, Valid Loss: 0.6569745540618896\n",
      "Epoch: 5226, Train Loss: 0.38787978887557983, Valid Loss: 0.6437183618545532\n",
      "Epoch: 5227, Train Loss: 0.3878966271877289, Valid Loss: 0.6603885889053345\n",
      "Epoch: 5228, Train Loss: 0.3879242241382599, Valid Loss: 0.6396215558052063\n",
      "Epoch: 5229, Train Loss: 0.38796499371528625, Valid Loss: 0.6658802628517151\n",
      "Epoch: 5230, Train Loss: 0.3880295753479004, Valid Loss: 0.6333416104316711\n",
      "Epoch: 5231, Train Loss: 0.3881162703037262, Valid Loss: 0.674185574054718\n",
      "Epoch: 5232, Train Loss: 0.3882368505001068, Valid Loss: 0.6248250007629395\n",
      "Epoch: 5233, Train Loss: 0.38835760951042175, Valid Loss: 0.6844558715820312\n",
      "Epoch: 5234, Train Loss: 0.38847264647483826, Valid Loss: 0.6167957186698914\n",
      "Epoch: 5235, Train Loss: 0.3884921371936798, Valid Loss: 0.6904183030128479\n",
      "Epoch: 5236, Train Loss: 0.3884161114692688, Valid Loss: 0.6168593764305115\n",
      "Epoch: 5237, Train Loss: 0.3882266879081726, Valid Loss: 0.6814509034156799\n",
      "Epoch: 5238, Train Loss: 0.38802778720855713, Valid Loss: 0.6313071250915527\n",
      "Epoch: 5239, Train Loss: 0.387893944978714, Valid Loss: 0.6591272950172424\n",
      "Epoch: 5240, Train Loss: 0.3878723084926605, Valid Loss: 0.6541120409965515\n",
      "Epoch: 5241, Train Loss: 0.3879452347755432, Valid Loss: 0.6379655003547668\n",
      "Epoch: 5242, Train Loss: 0.3880451023578644, Valid Loss: 0.671846866607666\n",
      "Epoch: 5243, Train Loss: 0.38810408115386963, Valid Loss: 0.6282050609588623\n",
      "Epoch: 5244, Train Loss: 0.3880694806575775, Valid Loss: 0.6738528609275818\n",
      "Epoch: 5245, Train Loss: 0.3879789113998413, Valid Loss: 0.6338408589363098\n",
      "Epoch: 5246, Train Loss: 0.38789254426956177, Valid Loss: 0.6602232456207275\n",
      "Epoch: 5247, Train Loss: 0.3878574073314667, Valid Loss: 0.6500095129013062\n",
      "Epoch: 5248, Train Loss: 0.3878762722015381, Valid Loss: 0.6434846520423889\n",
      "Epoch: 5249, Train Loss: 0.387922465801239, Valid Loss: 0.6641200184822083\n",
      "Epoch: 5250, Train Loss: 0.38796141743659973, Valid Loss: 0.635242223739624\n",
      "Epoch: 5251, Train Loss: 0.387959748506546, Valid Loss: 0.6666563153266907\n",
      "Epoch: 5252, Train Loss: 0.38792064785957336, Valid Loss: 0.6388747692108154\n",
      "Epoch: 5253, Train Loss: 0.3878745436668396, Valid Loss: 0.6578015089035034\n",
      "Epoch: 5254, Train Loss: 0.3878531754016876, Valid Loss: 0.6498837471008301\n",
      "Epoch: 5255, Train Loss: 0.38785865902900696, Valid Loss: 0.6464629173278809\n",
      "Epoch: 5256, Train Loss: 0.38787832856178284, Valid Loss: 0.6590889096260071\n",
      "Epoch: 5257, Train Loss: 0.3878977298736572, Valid Loss: 0.6408789157867432\n",
      "Epoch: 5258, Train Loss: 0.387903094291687, Valid Loss: 0.6610913276672363\n",
      "Epoch: 5259, Train Loss: 0.3878895938396454, Valid Loss: 0.6425394415855408\n",
      "Epoch: 5260, Train Loss: 0.3878660202026367, Valid Loss: 0.6567986011505127\n",
      "Epoch: 5261, Train Loss: 0.38785073161125183, Valid Loss: 0.6483463048934937\n",
      "Epoch: 5262, Train Loss: 0.38785025477409363, Valid Loss: 0.6497352123260498\n",
      "Epoch: 5263, Train Loss: 0.3878590166568756, Valid Loss: 0.654939591884613\n",
      "Epoch: 5264, Train Loss: 0.3878691494464874, Valid Loss: 0.6444999575614929\n",
      "Epoch: 5265, Train Loss: 0.3878745436668396, Valid Loss: 0.6585533618927002\n",
      "Epoch: 5266, Train Loss: 0.3878718614578247, Valid Loss: 0.6438440084457397\n",
      "Epoch: 5267, Train Loss: 0.3878622055053711, Valid Loss: 0.6567193865776062\n",
      "Epoch: 5268, Train Loss: 0.38785237073898315, Valid Loss: 0.6472572088241577\n",
      "Epoch: 5269, Train Loss: 0.3878479599952698, Valid Loss: 0.6517502665519714\n",
      "Epoch: 5270, Train Loss: 0.38784947991371155, Valid Loss: 0.6524472832679749\n",
      "Epoch: 5271, Train Loss: 0.38785290718078613, Valid Loss: 0.6474080681800842\n",
      "Epoch: 5272, Train Loss: 0.38785722851753235, Valid Loss: 0.6559508442878723\n",
      "Epoch: 5273, Train Loss: 0.38785985112190247, Valid Loss: 0.6456546783447266\n",
      "Epoch: 5274, Train Loss: 0.3878576457500458, Valid Loss: 0.6558535695075989\n",
      "Epoch: 5275, Train Loss: 0.38785335421562195, Valid Loss: 0.6470886468887329\n",
      "Epoch: 5276, Train Loss: 0.3878490626811981, Valid Loss: 0.6533702611923218\n",
      "Epoch: 5277, Train Loss: 0.3878467381000519, Valid Loss: 0.650331437587738\n",
      "Epoch: 5278, Train Loss: 0.3878469467163086, Valid Loss: 0.6502628922462463\n",
      "Epoch: 5279, Train Loss: 0.3878483474254608, Valid Loss: 0.6531990766525269\n",
      "Epoch: 5280, Train Loss: 0.38784998655319214, Valid Loss: 0.6479339599609375\n",
      "Epoch: 5281, Train Loss: 0.3878512978553772, Valid Loss: 0.6545356512069702\n",
      "Epoch: 5282, Train Loss: 0.3878513276576996, Valid Loss: 0.647631824016571\n",
      "Epoch: 5283, Train Loss: 0.38784995675086975, Valid Loss: 0.6540573835372925\n",
      "Epoch: 5284, Train Loss: 0.3878481686115265, Valid Loss: 0.6489896178245544\n",
      "Epoch: 5285, Train Loss: 0.38784658908843994, Valid Loss: 0.6522908210754395\n",
      "Epoch: 5286, Train Loss: 0.38784584403038025, Valid Loss: 0.6507892608642578\n",
      "Epoch: 5287, Train Loss: 0.387845516204834, Valid Loss: 0.6505426168441772\n",
      "Epoch: 5288, Train Loss: 0.38784605264663696, Valid Loss: 0.6523236632347107\n",
      "Epoch: 5289, Train Loss: 0.38784676790237427, Valid Loss: 0.6494863033294678\n",
      "Epoch: 5290, Train Loss: 0.38784730434417725, Valid Loss: 0.6531684994697571\n",
      "Epoch: 5291, Train Loss: 0.38784733414649963, Valid Loss: 0.6490814089775085\n",
      "Epoch: 5292, Train Loss: 0.3878472149372101, Valid Loss: 0.653160572052002\n",
      "Epoch: 5293, Train Loss: 0.38784635066986084, Valid Loss: 0.6493710279464722\n",
      "Epoch: 5294, Train Loss: 0.3878457248210907, Valid Loss: 0.6526329517364502\n",
      "Epoch: 5295, Train Loss: 0.38784533739089966, Valid Loss: 0.6501944065093994\n",
      "Epoch: 5296, Train Loss: 0.38784459233283997, Valid Loss: 0.651745080947876\n",
      "Epoch: 5297, Train Loss: 0.38784462213516235, Valid Loss: 0.6512029767036438\n",
      "Epoch: 5298, Train Loss: 0.38784459233283997, Valid Loss: 0.6507244110107422\n",
      "Epoch: 5299, Train Loss: 0.38784468173980713, Valid Loss: 0.6521139740943909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5300, Train Loss: 0.38784486055374146, Valid Loss: 0.650065541267395\n",
      "Epoch: 5301, Train Loss: 0.3878449499607086, Valid Loss: 0.6526281237602234\n",
      "Epoch: 5302, Train Loss: 0.387844979763031, Valid Loss: 0.6498721837997437\n",
      "Epoch: 5303, Train Loss: 0.38784486055374146, Valid Loss: 0.6526595950126648\n",
      "Epoch: 5304, Train Loss: 0.38784465193748474, Valid Loss: 0.6499941349029541\n",
      "Epoch: 5305, Train Loss: 0.387844443321228, Valid Loss: 0.6524004936218262\n",
      "Epoch: 5306, Train Loss: 0.38784393668174744, Valid Loss: 0.6504054069519043\n",
      "Epoch: 5307, Train Loss: 0.3878438472747803, Valid Loss: 0.6519836187362671\n",
      "Epoch: 5308, Train Loss: 0.38784360885620117, Valid Loss: 0.6509068012237549\n",
      "Epoch: 5309, Train Loss: 0.38784343004226685, Valid Loss: 0.6515014171600342\n",
      "Epoch: 5310, Train Loss: 0.38784340023994446, Valid Loss: 0.6513447761535645\n",
      "Epoch: 5311, Train Loss: 0.3878431022167206, Valid Loss: 0.6511250138282776\n",
      "Epoch: 5312, Train Loss: 0.38784313201904297, Valid Loss: 0.6517159938812256\n",
      "Epoch: 5313, Train Loss: 0.38784322142601013, Valid Loss: 0.6508813500404358\n",
      "Epoch: 5314, Train Loss: 0.38784313201904297, Valid Loss: 0.651954710483551\n",
      "Epoch: 5315, Train Loss: 0.3878431022167206, Valid Loss: 0.6507124900817871\n",
      "Epoch: 5316, Train Loss: 0.38784322142601013, Valid Loss: 0.6520928740501404\n",
      "Epoch: 5317, Train Loss: 0.38784295320510864, Valid Loss: 0.6506202816963196\n",
      "Epoch: 5318, Train Loss: 0.3878428637981415, Valid Loss: 0.6522141098976135\n",
      "Epoch: 5319, Train Loss: 0.38784289360046387, Valid Loss: 0.6505558490753174\n",
      "Epoch: 5320, Train Loss: 0.3878427743911743, Valid Loss: 0.6523200869560242\n",
      "Epoch: 5321, Train Loss: 0.38784322142601013, Valid Loss: 0.650489330291748\n",
      "Epoch: 5322, Train Loss: 0.3878426253795624, Valid Loss: 0.6523563861846924\n",
      "Epoch: 5323, Train Loss: 0.3878425061702728, Valid Loss: 0.6504995226860046\n",
      "Epoch: 5324, Train Loss: 0.38784223794937134, Valid Loss: 0.6523846387863159\n",
      "Epoch: 5325, Train Loss: 0.38784217834472656, Valid Loss: 0.6505174040794373\n",
      "Epoch: 5326, Train Loss: 0.3878422677516937, Valid Loss: 0.652424156665802\n",
      "Epoch: 5327, Train Loss: 0.3878425061702728, Valid Loss: 0.6504892110824585\n",
      "Epoch: 5328, Train Loss: 0.3878421485424042, Valid Loss: 0.6524729132652283\n",
      "Epoch: 5329, Train Loss: 0.38784199953079224, Valid Loss: 0.6504361033439636\n",
      "Epoch: 5330, Train Loss: 0.38784193992614746, Valid Loss: 0.6526014804840088\n",
      "Epoch: 5331, Train Loss: 0.387842059135437, Valid Loss: 0.6503043174743652\n",
      "Epoch: 5332, Train Loss: 0.38784196972846985, Valid Loss: 0.6528334021568298\n",
      "Epoch: 5333, Train Loss: 0.38784244656562805, Valid Loss: 0.6500148773193359\n",
      "Epoch: 5334, Train Loss: 0.3878426253795624, Valid Loss: 0.653206467628479\n",
      "Epoch: 5335, Train Loss: 0.3878428637981415, Valid Loss: 0.6495825052261353\n",
      "Epoch: 5336, Train Loss: 0.38784337043762207, Valid Loss: 0.6538102030754089\n",
      "Epoch: 5337, Train Loss: 0.38784435391426086, Valid Loss: 0.6488816738128662\n",
      "Epoch: 5338, Train Loss: 0.38784554600715637, Valid Loss: 0.6547105312347412\n",
      "Epoch: 5339, Train Loss: 0.3878476321697235, Valid Loss: 0.6478203535079956\n",
      "Epoch: 5340, Train Loss: 0.38785043358802795, Valid Loss: 0.656048059463501\n",
      "Epoch: 5341, Train Loss: 0.3878549337387085, Valid Loss: 0.6462323665618896\n",
      "Epoch: 5342, Train Loss: 0.38786134123802185, Valid Loss: 0.6581211686134338\n",
      "Epoch: 5343, Train Loss: 0.38787156343460083, Valid Loss: 0.6437628269195557\n",
      "Epoch: 5344, Train Loss: 0.3878866136074066, Valid Loss: 0.6613246202468872\n",
      "Epoch: 5345, Train Loss: 0.3879098892211914, Valid Loss: 0.639987587928772\n",
      "Epoch: 5346, Train Loss: 0.38794374465942383, Valid Loss: 0.6662663817405701\n",
      "Epoch: 5347, Train Loss: 0.38799533247947693, Valid Loss: 0.6343869566917419\n",
      "Epoch: 5348, Train Loss: 0.38806402683258057, Valid Loss: 0.6734937429428101\n",
      "Epoch: 5349, Train Loss: 0.3881603479385376, Valid Loss: 0.6269343495368958\n",
      "Epoch: 5350, Train Loss: 0.3882620334625244, Valid Loss: 0.6824048757553101\n",
      "Epoch: 5351, Train Loss: 0.38837146759033203, Valid Loss: 0.6196325421333313\n",
      "Epoch: 5352, Train Loss: 0.38841623067855835, Valid Loss: 0.6886248588562012\n",
      "Epoch: 5353, Train Loss: 0.3883955478668213, Valid Loss: 0.6182050108909607\n",
      "Epoch: 5354, Train Loss: 0.38825953006744385, Valid Loss: 0.6836735606193542\n",
      "Epoch: 5355, Train Loss: 0.3880837857723236, Valid Loss: 0.6285146474838257\n",
      "Epoch: 5356, Train Loss: 0.3879243731498718, Valid Loss: 0.6654929518699646\n",
      "Epoch: 5357, Train Loss: 0.3878486752510071, Valid Loss: 0.6480061411857605\n",
      "Epoch: 5358, Train Loss: 0.3878648281097412, Valid Loss: 0.6448114514350891\n",
      "Epoch: 5359, Train Loss: 0.38794058561325073, Valid Loss: 0.666566014289856\n",
      "Epoch: 5360, Train Loss: 0.3880235552787781, Valid Loss: 0.6319939494132996\n",
      "Epoch: 5361, Train Loss: 0.3880566954612732, Valid Loss: 0.6742624640464783\n",
      "Epoch: 5362, Train Loss: 0.3880288302898407, Valid Loss: 0.6314281225204468\n",
      "Epoch: 5363, Train Loss: 0.3879515528678894, Valid Loss: 0.6675894260406494\n",
      "Epoch: 5364, Train Loss: 0.3878776431083679, Valid Loss: 0.642171323299408\n",
      "Epoch: 5365, Train Loss: 0.3878418207168579, Valid Loss: 0.6530399322509766\n",
      "Epoch: 5366, Train Loss: 0.3878524899482727, Valid Loss: 0.6566620469093323\n",
      "Epoch: 5367, Train Loss: 0.3878915309906006, Valid Loss: 0.6407873630523682\n",
      "Epoch: 5368, Train Loss: 0.3879265785217285, Valid Loss: 0.6657311916351318\n",
      "Epoch: 5369, Train Loss: 0.3879372775554657, Valid Loss: 0.6368904113769531\n",
      "Epoch: 5370, Train Loss: 0.38791608810424805, Valid Loss: 0.6648159623146057\n",
      "Epoch: 5371, Train Loss: 0.3878805637359619, Valid Loss: 0.6420246362686157\n",
      "Epoch: 5372, Train Loss: 0.3878501355648041, Valid Loss: 0.6561581492424011\n",
      "Epoch: 5373, Train Loss: 0.3878392279148102, Valid Loss: 0.6517972350120544\n",
      "Epoch: 5374, Train Loss: 0.38784870505332947, Valid Loss: 0.6465993523597717\n",
      "Epoch: 5375, Train Loss: 0.3878670334815979, Valid Loss: 0.6596007347106934\n",
      "Epoch: 5376, Train Loss: 0.38788172602653503, Valid Loss: 0.6418174505233765\n",
      "Epoch: 5377, Train Loss: 0.387882798910141, Valid Loss: 0.6613733172416687\n",
      "Epoch: 5378, Train Loss: 0.3878720998764038, Valid Loss: 0.6431918144226074\n",
      "Epoch: 5379, Train Loss: 0.3878558576107025, Valid Loss: 0.6574355363845825\n",
      "Epoch: 5380, Train Loss: 0.38784295320510864, Valid Loss: 0.6485956311225891\n",
      "Epoch: 5381, Train Loss: 0.38783881068229675, Valid Loss: 0.6511721611022949\n",
      "Epoch: 5382, Train Loss: 0.38784289360046387, Valid Loss: 0.6545301675796509\n",
      "Epoch: 5383, Train Loss: 0.3878505527973175, Valid Loss: 0.6463649272918701\n",
      "Epoch: 5384, Train Loss: 0.3878568112850189, Valid Loss: 0.6578959822654724\n",
      "Epoch: 5385, Train Loss: 0.3878585398197174, Valid Loss: 0.6450274586677551\n",
      "Epoch: 5386, Train Loss: 0.38785499334335327, Valid Loss: 0.6574812531471252\n",
      "Epoch: 5387, Train Loss: 0.38784828782081604, Valid Loss: 0.6469361782073975\n",
      "Epoch: 5388, Train Loss: 0.38784199953079224, Valid Loss: 0.6543400287628174\n",
      "Epoch: 5389, Train Loss: 0.3878381848335266, Valid Loss: 0.6506240367889404\n",
      "Epoch: 5390, Train Loss: 0.3878380358219147, Valid Loss: 0.6505659222602844\n",
      "Epoch: 5391, Train Loss: 0.3878404498100281, Valid Loss: 0.654123067855835\n",
      "Epoch: 5392, Train Loss: 0.3878437578678131, Valid Loss: 0.647941529750824\n",
      "Epoch: 5393, Train Loss: 0.38784608244895935, Valid Loss: 0.6558440327644348\n",
      "Epoch: 5394, Train Loss: 0.38784632086753845, Valid Loss: 0.6473374962806702\n",
      "Epoch: 5395, Train Loss: 0.3878445029258728, Valid Loss: 0.6555168628692627\n",
      "Epoch: 5396, Train Loss: 0.38784199953079224, Valid Loss: 0.6485129594802856\n",
      "Epoch: 5397, Train Loss: 0.3878391981124878, Valid Loss: 0.6538196802139282\n",
      "Epoch: 5398, Train Loss: 0.3878374993801117, Valid Loss: 0.6505619883537292\n",
      "Epoch: 5399, Train Loss: 0.3878370523452759, Valid Loss: 0.651633620262146\n",
      "Epoch: 5400, Train Loss: 0.38783740997314453, Valid Loss: 0.6526386141777039\n",
      "Epoch: 5401, Train Loss: 0.3878384530544281, Valid Loss: 0.6498667001724243\n",
      "Epoch: 5402, Train Loss: 0.3878397047519684, Valid Loss: 0.6540563106536865\n",
      "Epoch: 5403, Train Loss: 0.38784006237983704, Valid Loss: 0.6490213871002197\n",
      "Epoch: 5404, Train Loss: 0.3878399133682251, Valid Loss: 0.6544589996337891\n",
      "Epoch: 5405, Train Loss: 0.38783976435661316, Valid Loss: 0.6491023302078247\n",
      "Epoch: 5406, Train Loss: 0.38783878087997437, Valid Loss: 0.6539908051490784\n",
      "Epoch: 5407, Train Loss: 0.3878372311592102, Valid Loss: 0.6499262452125549\n",
      "Epoch: 5408, Train Loss: 0.387836754322052, Valid Loss: 0.6529837250709534\n",
      "Epoch: 5409, Train Loss: 0.3878364562988281, Valid Loss: 0.6511039137840271\n",
      "Epoch: 5410, Train Loss: 0.3878357410430908, Valid Loss: 0.6518227458000183\n",
      "Epoch: 5411, Train Loss: 0.3878360688686371, Valid Loss: 0.6522113084793091\n",
      "Epoch: 5412, Train Loss: 0.38783612847328186, Valid Loss: 0.6508699655532837\n",
      "Epoch: 5413, Train Loss: 0.38783639669418335, Valid Loss: 0.6530144214630127\n",
      "Epoch: 5414, Train Loss: 0.38783690333366394, Valid Loss: 0.65031898021698\n",
      "Epoch: 5415, Train Loss: 0.3878364562988281, Valid Loss: 0.6534372568130493\n",
      "Epoch: 5416, Train Loss: 0.38783663511276245, Valid Loss: 0.6501154899597168\n",
      "Epoch: 5417, Train Loss: 0.3878364861011505, Valid Loss: 0.6535081267356873\n",
      "Epoch: 5418, Train Loss: 0.38783636689186096, Valid Loss: 0.6502155065536499\n",
      "Epoch: 5419, Train Loss: 0.387836217880249, Valid Loss: 0.653312623500824\n",
      "Epoch: 5420, Train Loss: 0.3878360092639923, Valid Loss: 0.6505696773529053\n",
      "Epoch: 5421, Train Loss: 0.38783571124076843, Valid Loss: 0.6529324054718018\n",
      "Epoch: 5422, Train Loss: 0.38783514499664307, Valid Loss: 0.651018500328064\n",
      "Epoch: 5423, Train Loss: 0.3878350257873535, Valid Loss: 0.6524810194969177\n",
      "Epoch: 5424, Train Loss: 0.387834757566452, Valid Loss: 0.6514800190925598\n",
      "Epoch: 5425, Train Loss: 0.38783493638038635, Valid Loss: 0.6520675420761108\n",
      "Epoch: 5426, Train Loss: 0.3878345489501953, Valid Loss: 0.6518900394439697\n",
      "Epoch: 5427, Train Loss: 0.38783445954322815, Valid Loss: 0.6517432332038879\n",
      "Epoch: 5428, Train Loss: 0.3878343105316162, Valid Loss: 0.6522150635719299\n",
      "Epoch: 5429, Train Loss: 0.3878342807292938, Valid Loss: 0.6514745354652405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5430, Train Loss: 0.3878342807292938, Valid Loss: 0.6524806022644043\n",
      "Epoch: 5431, Train Loss: 0.3878346383571625, Valid Loss: 0.6512706279754639\n",
      "Epoch: 5432, Train Loss: 0.387834370136261, Valid Loss: 0.6527019739151001\n",
      "Epoch: 5433, Train Loss: 0.3878345489501953, Valid Loss: 0.6511041522026062\n",
      "Epoch: 5434, Train Loss: 0.3878342807292938, Valid Loss: 0.6528827548027039\n",
      "Epoch: 5435, Train Loss: 0.3878340423107147, Valid Loss: 0.6509522199630737\n",
      "Epoch: 5436, Train Loss: 0.3878342807292938, Valid Loss: 0.6530755758285522\n",
      "Epoch: 5437, Train Loss: 0.3878343105316162, Valid Loss: 0.6507789492607117\n",
      "Epoch: 5438, Train Loss: 0.38783445954322815, Valid Loss: 0.653309166431427\n",
      "Epoch: 5439, Train Loss: 0.38783448934555054, Valid Loss: 0.6505266427993774\n",
      "Epoch: 5440, Train Loss: 0.3878348767757416, Valid Loss: 0.6536461710929871\n",
      "Epoch: 5441, Train Loss: 0.38783499598503113, Valid Loss: 0.6501664519309998\n",
      "Epoch: 5442, Train Loss: 0.3878357708454132, Valid Loss: 0.6540974974632263\n",
      "Epoch: 5443, Train Loss: 0.38783612847328186, Valid Loss: 0.649671196937561\n",
      "Epoch: 5444, Train Loss: 0.38783690333366394, Valid Loss: 0.6547353863716125\n",
      "Epoch: 5445, Train Loss: 0.3878379762172699, Valid Loss: 0.6489385962486267\n",
      "Epoch: 5446, Train Loss: 0.3878394663333893, Valid Loss: 0.655681848526001\n",
      "Epoch: 5447, Train Loss: 0.3878421187400818, Valid Loss: 0.6478220224380493\n",
      "Epoch: 5448, Train Loss: 0.3878457546234131, Valid Loss: 0.6571104526519775\n",
      "Epoch: 5449, Train Loss: 0.38785111904144287, Valid Loss: 0.64613938331604\n",
      "Epoch: 5450, Train Loss: 0.3878591060638428, Valid Loss: 0.6592799425125122\n",
      "Epoch: 5451, Train Loss: 0.3878713846206665, Valid Loss: 0.6435759663581848\n",
      "Epoch: 5452, Train Loss: 0.38788846135139465, Valid Loss: 0.6625992655754089\n",
      "Epoch: 5453, Train Loss: 0.3879147469997406, Valid Loss: 0.6397525668144226\n",
      "Epoch: 5454, Train Loss: 0.3879506289958954, Valid Loss: 0.667543351650238\n",
      "Epoch: 5455, Train Loss: 0.3880038261413574, Valid Loss: 0.6343255639076233\n",
      "Epoch: 5456, Train Loss: 0.3880690634250641, Valid Loss: 0.6744219064712524\n",
      "Epoch: 5457, Train Loss: 0.3881570100784302, Valid Loss: 0.6275022029876709\n",
      "Epoch: 5458, Train Loss: 0.3882386088371277, Valid Loss: 0.6822785139083862\n",
      "Epoch: 5459, Train Loss: 0.38831958174705505, Valid Loss: 0.6214219331741333\n",
      "Epoch: 5460, Train Loss: 0.38833633065223694, Valid Loss: 0.6868497729301453\n",
      "Epoch: 5461, Train Loss: 0.38830289244651794, Valid Loss: 0.6209758520126343\n",
      "Epoch: 5462, Train Loss: 0.38818439841270447, Valid Loss: 0.6815477609634399\n",
      "Epoch: 5463, Train Loss: 0.38804641366004944, Valid Loss: 0.6304129958152771\n",
      "Epoch: 5464, Train Loss: 0.38792064785957336, Valid Loss: 0.665881335735321\n",
      "Epoch: 5465, Train Loss: 0.3878563642501831, Valid Loss: 0.6471904516220093\n",
      "Epoch: 5466, Train Loss: 0.38785961270332336, Valid Loss: 0.6481708288192749\n",
      "Epoch: 5467, Train Loss: 0.38790982961654663, Valid Loss: 0.6634819507598877\n",
      "Epoch: 5468, Train Loss: 0.38797247409820557, Valid Loss: 0.6358290910720825\n",
      "Epoch: 5469, Train Loss: 0.3880058825016022, Valid Loss: 0.6720125079154968\n",
      "Epoch: 5470, Train Loss: 0.3880026638507843, Valid Loss: 0.6326828598976135\n",
      "Epoch: 5471, Train Loss: 0.3879600167274475, Valid Loss: 0.6693647503852844\n",
      "Epoch: 5472, Train Loss: 0.3879035413265228, Valid Loss: 0.6395685076713562\n",
      "Epoch: 5473, Train Loss: 0.3878529965877533, Valid Loss: 0.6583376526832581\n",
      "Epoch: 5474, Train Loss: 0.38783255219459534, Valid Loss: 0.6518647074699402\n",
      "Epoch: 5475, Train Loss: 0.3878474533557892, Valid Loss: 0.6461712718009949\n",
      "Epoch: 5476, Train Loss: 0.3878788352012634, Valid Loss: 0.6622505784034729\n",
      "Epoch: 5477, Train Loss: 0.3879021406173706, Valid Loss: 0.6392518877983093\n",
      "Epoch: 5478, Train Loss: 0.38790667057037354, Valid Loss: 0.6654422283172607\n",
      "Epoch: 5479, Train Loss: 0.3878958523273468, Valid Loss: 0.6402557492256165\n",
      "Epoch: 5480, Train Loss: 0.3878723382949829, Valid Loss: 0.6609633564949036\n",
      "Epoch: 5481, Train Loss: 0.3878481984138489, Valid Loss: 0.6468269228935242\n",
      "Epoch: 5482, Train Loss: 0.3878343999385834, Valid Loss: 0.6533122062683105\n",
      "Epoch: 5483, Train Loss: 0.3878346383571625, Valid Loss: 0.6540402173995972\n",
      "Epoch: 5484, Train Loss: 0.3878433406352997, Valid Loss: 0.6470109820365906\n",
      "Epoch: 5485, Train Loss: 0.3878541886806488, Valid Loss: 0.6588571667671204\n",
      "Epoch: 5486, Train Loss: 0.38786306977272034, Valid Loss: 0.6440597772598267\n",
      "Epoch: 5487, Train Loss: 0.38786348700523376, Valid Loss: 0.660146176815033\n",
      "Epoch: 5488, Train Loss: 0.38785627484321594, Valid Loss: 0.6448800563812256\n",
      "Epoch: 5489, Train Loss: 0.3878457546234131, Valid Loss: 0.6575944423675537\n",
      "Epoch: 5490, Train Loss: 0.3878370523452759, Valid Loss: 0.6484987735748291\n",
      "Epoch: 5491, Train Loss: 0.38783150911331177, Valid Loss: 0.653047502040863\n",
      "Epoch: 5492, Train Loss: 0.3878309428691864, Valid Loss: 0.6530005931854248\n",
      "Epoch: 5493, Train Loss: 0.38783493638038635, Valid Loss: 0.6491547226905823\n",
      "Epoch: 5494, Train Loss: 0.3878403604030609, Valid Loss: 0.6563530564308167\n",
      "Epoch: 5495, Train Loss: 0.3878430128097534, Valid Loss: 0.6469458937644958\n",
      "Epoch: 5496, Train Loss: 0.3878438174724579, Valid Loss: 0.657450258731842\n",
      "Epoch: 5497, Train Loss: 0.38784244656562805, Valid Loss: 0.6468843817710876\n",
      "Epoch: 5498, Train Loss: 0.38783907890319824, Valid Loss: 0.6564603447914124\n",
      "Epoch: 5499, Train Loss: 0.38783493638038635, Valid Loss: 0.6487587094306946\n",
      "Epoch: 5500, Train Loss: 0.38783159852027893, Valid Loss: 0.6542266607284546\n",
      "Epoch: 5501, Train Loss: 0.38783004879951477, Valid Loss: 0.6512625813484192\n",
      "Epoch: 5502, Train Loss: 0.3878302276134491, Valid Loss: 0.6516826152801514\n",
      "Epoch: 5503, Train Loss: 0.3878307640552521, Valid Loss: 0.6535804271697998\n",
      "Epoch: 5504, Train Loss: 0.3878321051597595, Valid Loss: 0.6496899127960205\n",
      "Epoch: 5505, Train Loss: 0.38783371448516846, Valid Loss: 0.6552755236625671\n",
      "Epoch: 5506, Train Loss: 0.38783493638038635, Valid Loss: 0.6486887335777283\n",
      "Epoch: 5507, Train Loss: 0.3878342807292938, Valid Loss: 0.6557052135467529\n",
      "Epoch: 5508, Train Loss: 0.38783395290374756, Valid Loss: 0.6488445997238159\n",
      "Epoch: 5509, Train Loss: 0.3878324627876282, Valid Loss: 0.6549885272979736\n",
      "Epoch: 5510, Train Loss: 0.3878316581249237, Valid Loss: 0.6499066948890686\n",
      "Epoch: 5511, Train Loss: 0.3878302276134491, Valid Loss: 0.6538600921630859\n",
      "Epoch: 5512, Train Loss: 0.3878295123577118, Valid Loss: 0.6511857509613037\n",
      "Epoch: 5513, Train Loss: 0.38782867789268494, Valid Loss: 0.6526299118995667\n",
      "Epoch: 5514, Train Loss: 0.38782867789268494, Valid Loss: 0.6523540616035461\n",
      "Epoch: 5515, Train Loss: 0.3878282904624939, Valid Loss: 0.6515489220619202\n",
      "Epoch: 5516, Train Loss: 0.3878287971019745, Valid Loss: 0.6532966494560242\n",
      "Epoch: 5517, Train Loss: 0.3878292441368103, Valid Loss: 0.6508744955062866\n",
      "Epoch: 5518, Train Loss: 0.38782960176467896, Valid Loss: 0.653907299041748\n",
      "Epoch: 5519, Train Loss: 0.38782981038093567, Valid Loss: 0.6504452228546143\n",
      "Epoch: 5520, Train Loss: 0.38782989978790283, Valid Loss: 0.6542037725448608\n",
      "Epoch: 5521, Train Loss: 0.38782989978790283, Valid Loss: 0.6502664089202881\n",
      "Epoch: 5522, Train Loss: 0.3878297805786133, Valid Loss: 0.6542952060699463\n",
      "Epoch: 5523, Train Loss: 0.3878295421600342, Valid Loss: 0.6503590941429138\n",
      "Epoch: 5524, Train Loss: 0.387829065322876, Valid Loss: 0.6541781425476074\n",
      "Epoch: 5525, Train Loss: 0.38782909512519836, Valid Loss: 0.6505888104438782\n",
      "Epoch: 5526, Train Loss: 0.3878288269042969, Valid Loss: 0.6539129018783569\n",
      "Epoch: 5527, Train Loss: 0.38782843947410583, Valid Loss: 0.6508707404136658\n",
      "Epoch: 5528, Train Loss: 0.38782772421836853, Valid Loss: 0.6536657810211182\n",
      "Epoch: 5529, Train Loss: 0.3878278434276581, Valid Loss: 0.6511804461479187\n",
      "Epoch: 5530, Train Loss: 0.38782766461372375, Valid Loss: 0.6534048318862915\n",
      "Epoch: 5531, Train Loss: 0.3878275156021118, Valid Loss: 0.6514405608177185\n",
      "Epoch: 5532, Train Loss: 0.38782694935798645, Valid Loss: 0.6531739830970764\n",
      "Epoch: 5533, Train Loss: 0.3878271281719208, Valid Loss: 0.6516575813293457\n",
      "Epoch: 5534, Train Loss: 0.38782769441604614, Valid Loss: 0.6530246138572693\n",
      "Epoch: 5535, Train Loss: 0.3878268599510193, Valid Loss: 0.6518243551254272\n",
      "Epoch: 5536, Train Loss: 0.3878268003463745, Valid Loss: 0.6529138088226318\n",
      "Epoch: 5537, Train Loss: 0.3878268897533417, Valid Loss: 0.6519380211830139\n",
      "Epoch: 5538, Train Loss: 0.3878268003463745, Valid Loss: 0.6528533697128296\n",
      "Epoch: 5539, Train Loss: 0.3878263831138611, Valid Loss: 0.6519718170166016\n",
      "Epoch: 5540, Train Loss: 0.38782647252082825, Valid Loss: 0.6529008746147156\n",
      "Epoch: 5541, Train Loss: 0.38782626390457153, Valid Loss: 0.6519477367401123\n",
      "Epoch: 5542, Train Loss: 0.3878261148929596, Valid Loss: 0.6529877185821533\n",
      "Epoch: 5543, Train Loss: 0.387826144695282, Valid Loss: 0.6518579125404358\n",
      "Epoch: 5544, Train Loss: 0.3878263235092163, Valid Loss: 0.6531097292900085\n",
      "Epoch: 5545, Train Loss: 0.3878263235092163, Valid Loss: 0.6517221331596375\n",
      "Epoch: 5546, Train Loss: 0.3878260850906372, Valid Loss: 0.6533234119415283\n",
      "Epoch: 5547, Train Loss: 0.387826144695282, Valid Loss: 0.6514999866485596\n",
      "Epoch: 5548, Train Loss: 0.3878263235092163, Valid Loss: 0.6536546349525452\n",
      "Epoch: 5549, Train Loss: 0.38782671093940735, Valid Loss: 0.6511175036430359\n",
      "Epoch: 5550, Train Loss: 0.3878273069858551, Valid Loss: 0.6541476249694824\n",
      "Epoch: 5551, Train Loss: 0.3878273069858551, Valid Loss: 0.6505283117294312\n",
      "Epoch: 5552, Train Loss: 0.3878284990787506, Valid Loss: 0.6549310088157654\n",
      "Epoch: 5553, Train Loss: 0.38782960176467896, Valid Loss: 0.6495788097381592\n",
      "Epoch: 5554, Train Loss: 0.3878316581249237, Valid Loss: 0.6561927795410156\n",
      "Epoch: 5555, Train Loss: 0.3878350555896759, Valid Loss: 0.6480351090431213\n",
      "Epoch: 5556, Train Loss: 0.3878406286239624, Valid Loss: 0.6582182049751282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5557, Train Loss: 0.3878498077392578, Valid Loss: 0.6455124020576477\n",
      "Epoch: 5558, Train Loss: 0.3878646194934845, Valid Loss: 0.661614179611206\n",
      "Epoch: 5559, Train Loss: 0.38788890838623047, Valid Loss: 0.641340970993042\n",
      "Epoch: 5560, Train Loss: 0.3879273235797882, Valid Loss: 0.6672726273536682\n",
      "Epoch: 5561, Train Loss: 0.38799118995666504, Valid Loss: 0.6346350312232971\n",
      "Epoch: 5562, Train Loss: 0.3880831003189087, Valid Loss: 0.6763030290603638\n",
      "Epoch: 5563, Train Loss: 0.3882265090942383, Valid Loss: 0.6249040365219116\n",
      "Epoch: 5564, Train Loss: 0.38839104771614075, Valid Loss: 0.6886790990829468\n",
      "Epoch: 5565, Train Loss: 0.38858914375305176, Valid Loss: 0.6144412755966187\n",
      "Epoch: 5566, Train Loss: 0.3886745274066925, Valid Loss: 0.6983742713928223\n",
      "Epoch: 5567, Train Loss: 0.3886491060256958, Valid Loss: 0.6121840476989746\n",
      "Epoch: 5568, Train Loss: 0.3883974552154541, Valid Loss: 0.6908034682273865\n",
      "Epoch: 5569, Train Loss: 0.3881044387817383, Valid Loss: 0.6278150081634521\n",
      "Epoch: 5570, Train Loss: 0.38788923621177673, Valid Loss: 0.663330614566803\n",
      "Epoch: 5571, Train Loss: 0.38785216212272644, Valid Loss: 0.6555439829826355\n",
      "Epoch: 5572, Train Loss: 0.38795942068099976, Valid Loss: 0.6364876627922058\n",
      "Epoch: 5573, Train Loss: 0.3881041407585144, Valid Loss: 0.6781512498855591\n",
      "Epoch: 5574, Train Loss: 0.3881831467151642, Valid Loss: 0.6257530450820923\n",
      "Epoch: 5575, Train Loss: 0.38811057806015015, Valid Loss: 0.6791302561759949\n",
      "Epoch: 5576, Train Loss: 0.3879673480987549, Valid Loss: 0.6345874667167664\n",
      "Epoch: 5577, Train Loss: 0.38784992694854736, Valid Loss: 0.6592287421226501\n",
      "Epoch: 5578, Train Loss: 0.3878366947174072, Valid Loss: 0.6557266116142273\n",
      "Epoch: 5579, Train Loss: 0.3879074156284332, Valid Loss: 0.6389791369438171\n",
      "Epoch: 5580, Train Loss: 0.3879835605621338, Valid Loss: 0.6721341013908386\n",
      "Epoch: 5581, Train Loss: 0.3879999816417694, Valid Loss: 0.6330641508102417\n",
      "Epoch: 5582, Train Loss: 0.3879395127296448, Valid Loss: 0.6691936254501343\n",
      "Epoch: 5583, Train Loss: 0.3878636658191681, Valid Loss: 0.6426434516906738\n",
      "Epoch: 5584, Train Loss: 0.3878268003463745, Valid Loss: 0.6527532935142517\n",
      "Epoch: 5585, Train Loss: 0.3878452181816101, Valid Loss: 0.65909743309021\n",
      "Epoch: 5586, Train Loss: 0.387888640165329, Valid Loss: 0.6401181221008301\n",
      "Epoch: 5587, Train Loss: 0.387913316488266, Valid Loss: 0.6673375964164734\n",
      "Epoch: 5588, Train Loss: 0.3879006803035736, Valid Loss: 0.6397369503974915\n",
      "Epoch: 5589, Train Loss: 0.3878627419471741, Valid Loss: 0.661048948764801\n",
      "Epoch: 5590, Train Loss: 0.3878321945667267, Valid Loss: 0.6488938927650452\n",
      "Epoch: 5591, Train Loss: 0.3878265619277954, Valid Loss: 0.6497758626937866\n",
      "Epoch: 5592, Train Loss: 0.3878439962863922, Valid Loss: 0.6590585112571716\n",
      "Epoch: 5593, Train Loss: 0.3878646790981293, Valid Loss: 0.6433204412460327\n",
      "Epoch: 5594, Train Loss: 0.3878687024116516, Valid Loss: 0.6621747016906738\n",
      "Epoch: 5595, Train Loss: 0.3878563642501831, Valid Loss: 0.6443101763725281\n",
      "Epoch: 5596, Train Loss: 0.38783639669418335, Valid Loss: 0.6573407649993896\n",
      "Epoch: 5597, Train Loss: 0.3878253698348999, Valid Loss: 0.6508718729019165\n",
      "Epoch: 5598, Train Loss: 0.3878268301486969, Valid Loss: 0.6499200463294983\n",
      "Epoch: 5599, Train Loss: 0.3878359794616699, Valid Loss: 0.6575695276260376\n",
      "Epoch: 5600, Train Loss: 0.3878445029258728, Valid Loss: 0.645744264125824\n",
      "Epoch: 5601, Train Loss: 0.38784539699554443, Valid Loss: 0.6592902541160583\n",
      "Epoch: 5602, Train Loss: 0.3878385126590729, Valid Loss: 0.6468014717102051\n",
      "Epoch: 5603, Train Loss: 0.38782891631126404, Valid Loss: 0.6557357907295227\n",
      "Epoch: 5604, Train Loss: 0.3878234326839447, Valid Loss: 0.6515254378318787\n",
      "Epoch: 5605, Train Loss: 0.3878246545791626, Valid Loss: 0.6506699919700623\n",
      "Epoch: 5606, Train Loss: 0.38782936334609985, Valid Loss: 0.6560935378074646\n",
      "Epoch: 5607, Train Loss: 0.38783374428749084, Valid Loss: 0.6478074789047241\n",
      "Epoch: 5608, Train Loss: 0.3878338634967804, Valid Loss: 0.6573023796081543\n",
      "Epoch: 5609, Train Loss: 0.3878307044506073, Valid Loss: 0.6483532190322876\n",
      "Epoch: 5610, Train Loss: 0.3878263235092163, Valid Loss: 0.6552230715751648\n",
      "Epoch: 5611, Train Loss: 0.3878234922885895, Valid Loss: 0.651315450668335\n",
      "Epoch: 5612, Train Loss: 0.38782283663749695, Valid Loss: 0.6519636511802673\n",
      "Epoch: 5613, Train Loss: 0.3878246545791626, Valid Loss: 0.6545281410217285\n",
      "Epoch: 5614, Train Loss: 0.38782647252082825, Valid Loss: 0.6495077013969421\n",
      "Epoch: 5615, Train Loss: 0.3878277838230133, Valid Loss: 0.6560060977935791\n",
      "Epoch: 5616, Train Loss: 0.3878268003463745, Valid Loss: 0.6491758823394775\n",
      "Epoch: 5617, Train Loss: 0.3878251314163208, Valid Loss: 0.6551864743232727\n",
      "Epoch: 5618, Train Loss: 0.3878231942653656, Valid Loss: 0.6509377956390381\n",
      "Epoch: 5619, Train Loss: 0.38782209157943726, Valid Loss: 0.6530040502548218\n",
      "Epoch: 5620, Train Loss: 0.3878220021724701, Valid Loss: 0.6532830595970154\n",
      "Epoch: 5621, Train Loss: 0.3878227174282074, Valid Loss: 0.6509571075439453\n",
      "Epoch: 5622, Train Loss: 0.38782358169555664, Valid Loss: 0.6547790765762329\n",
      "Epoch: 5623, Train Loss: 0.38782399892807007, Valid Loss: 0.6501886248588562\n",
      "Epoch: 5624, Train Loss: 0.38782399892807007, Valid Loss: 0.6549298763275146\n",
      "Epoch: 5625, Train Loss: 0.3878229260444641, Valid Loss: 0.6507786512374878\n",
      "Epoch: 5626, Train Loss: 0.3878221809864044, Valid Loss: 0.6538962721824646\n",
      "Epoch: 5627, Train Loss: 0.38782164454460144, Valid Loss: 0.6521152257919312\n",
      "Epoch: 5628, Train Loss: 0.3878212869167328, Valid Loss: 0.6524641513824463\n",
      "Epoch: 5629, Train Loss: 0.3878212869167328, Valid Loss: 0.6534769535064697\n",
      "Epoch: 5630, Train Loss: 0.3878217339515686, Valid Loss: 0.651416003704071\n",
      "Epoch: 5631, Train Loss: 0.38782164454460144, Valid Loss: 0.6542603373527527\n",
      "Epoch: 5632, Train Loss: 0.38782188296318054, Valid Loss: 0.6510818004608154\n",
      "Epoch: 5633, Train Loss: 0.3878217935562134, Valid Loss: 0.6542167663574219\n",
      "Epoch: 5634, Train Loss: 0.3878214359283447, Valid Loss: 0.6514796614646912\n",
      "Epoch: 5635, Train Loss: 0.3878209888935089, Valid Loss: 0.6535818576812744\n",
      "Epoch: 5636, Train Loss: 0.38782069087028503, Valid Loss: 0.6523260474205017\n",
      "Epoch: 5637, Train Loss: 0.38782042264938354, Valid Loss: 0.65274977684021\n",
      "Epoch: 5638, Train Loss: 0.38782042264938354, Valid Loss: 0.6531214714050293\n",
      "Epoch: 5639, Train Loss: 0.3878205716609955, Valid Loss: 0.6521192789077759\n",
      "Epoch: 5640, Train Loss: 0.3878205716609955, Valid Loss: 0.6535906791687012\n",
      "Epoch: 5641, Train Loss: 0.38782042264938354, Valid Loss: 0.6518554091453552\n",
      "Epoch: 5642, Train Loss: 0.3878204822540283, Valid Loss: 0.6537482738494873\n",
      "Epoch: 5643, Train Loss: 0.3878202736377716, Valid Loss: 0.6518917679786682\n",
      "Epoch: 5644, Train Loss: 0.3878195881843567, Valid Loss: 0.6536151766777039\n",
      "Epoch: 5645, Train Loss: 0.38781973719596863, Valid Loss: 0.6521502733230591\n",
      "Epoch: 5646, Train Loss: 0.3878195881843567, Valid Loss: 0.6533108353614807\n",
      "Epoch: 5647, Train Loss: 0.3878195881843567, Valid Loss: 0.6525309085845947\n",
      "Epoch: 5648, Train Loss: 0.3878193497657776, Valid Loss: 0.6529492139816284\n",
      "Epoch: 5649, Train Loss: 0.38781920075416565, Valid Loss: 0.6529452800750732\n",
      "Epoch: 5650, Train Loss: 0.3878195881843567, Valid Loss: 0.652588427066803\n",
      "Epoch: 5651, Train Loss: 0.3878195583820343, Valid Loss: 0.6532726883888245\n",
      "Epoch: 5652, Train Loss: 0.3878196179866791, Valid Loss: 0.6523512005805969\n",
      "Epoch: 5653, Train Loss: 0.38781973719596863, Valid Loss: 0.6534717082977295\n",
      "Epoch: 5654, Train Loss: 0.3878191113471985, Valid Loss: 0.6522656083106995\n",
      "Epoch: 5655, Train Loss: 0.387818843126297, Valid Loss: 0.6535239219665527\n",
      "Epoch: 5656, Train Loss: 0.3878189027309418, Valid Loss: 0.6523010730743408\n",
      "Epoch: 5657, Train Loss: 0.3878188729286194, Valid Loss: 0.6534598469734192\n",
      "Epoch: 5658, Train Loss: 0.387818843126297, Valid Loss: 0.6524480581283569\n",
      "Epoch: 5659, Train Loss: 0.38781869411468506, Valid Loss: 0.6532954573631287\n",
      "Epoch: 5660, Train Loss: 0.3878183364868164, Valid Loss: 0.6526592969894409\n",
      "Epoch: 5661, Train Loss: 0.3878186047077179, Valid Loss: 0.653117835521698\n",
      "Epoch: 5662, Train Loss: 0.38781818747520447, Valid Loss: 0.6528524160385132\n",
      "Epoch: 5663, Train Loss: 0.38781824707984924, Valid Loss: 0.6529713273048401\n",
      "Epoch: 5664, Train Loss: 0.3878181576728821, Valid Loss: 0.6530010104179382\n",
      "Epoch: 5665, Train Loss: 0.3878181278705597, Valid Loss: 0.6528723239898682\n",
      "Epoch: 5666, Train Loss: 0.38781821727752686, Valid Loss: 0.6531094908714294\n",
      "Epoch: 5667, Train Loss: 0.38781794905662537, Valid Loss: 0.6528116464614868\n",
      "Epoch: 5668, Train Loss: 0.3878178894519806, Valid Loss: 0.6531699895858765\n",
      "Epoch: 5669, Train Loss: 0.38781797885894775, Valid Loss: 0.6528014540672302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5670, Train Loss: 0.3878175616264343, Valid Loss: 0.6531975269317627\n",
      "Epoch: 5671, Train Loss: 0.38781777024269104, Valid Loss: 0.6527947783470154\n",
      "Epoch: 5672, Train Loss: 0.3878176510334015, Valid Loss: 0.6532448530197144\n",
      "Epoch: 5673, Train Loss: 0.3878174126148224, Valid Loss: 0.6527657508850098\n",
      "Epoch: 5674, Train Loss: 0.38781750202178955, Valid Loss: 0.6533045172691345\n",
      "Epoch: 5675, Train Loss: 0.3878173232078552, Valid Loss: 0.652717113494873\n",
      "Epoch: 5676, Train Loss: 0.3878175616264343, Valid Loss: 0.653400719165802\n",
      "Epoch: 5677, Train Loss: 0.3878171741962433, Valid Loss: 0.6526279449462891\n",
      "Epoch: 5678, Train Loss: 0.3878173232078552, Valid Loss: 0.6535305976867676\n",
      "Epoch: 5679, Train Loss: 0.38781729340553284, Valid Loss: 0.6525092124938965\n",
      "Epoch: 5680, Train Loss: 0.38781747221946716, Valid Loss: 0.6536905765533447\n",
      "Epoch: 5681, Train Loss: 0.38781654834747314, Valid Loss: 0.6523524522781372\n",
      "Epoch: 5682, Train Loss: 0.3878171145915985, Valid Loss: 0.6539009213447571\n",
      "Epoch: 5683, Train Loss: 0.38781705498695374, Valid Loss: 0.6521322727203369\n",
      "Epoch: 5684, Train Loss: 0.3878171443939209, Valid Loss: 0.6541845798492432\n",
      "Epoch: 5685, Train Loss: 0.38781729340553284, Valid Loss: 0.6518247723579407\n",
      "Epoch: 5686, Train Loss: 0.3878176212310791, Valid Loss: 0.6545894145965576\n",
      "Epoch: 5687, Train Loss: 0.3878176808357239, Valid Loss: 0.6513414978981018\n",
      "Epoch: 5688, Train Loss: 0.3878188133239746, Valid Loss: 0.6552314162254333\n",
      "Epoch: 5689, Train Loss: 0.38781967759132385, Valid Loss: 0.650577187538147\n",
      "Epoch: 5690, Train Loss: 0.3878210484981537, Valid Loss: 0.6562256813049316\n",
      "Epoch: 5691, Train Loss: 0.3878234922885895, Valid Loss: 0.6493721604347229\n",
      "Epoch: 5692, Train Loss: 0.3878272473812103, Valid Loss: 0.6578006744384766\n",
      "Epoch: 5693, Train Loss: 0.387832909822464, Valid Loss: 0.6474405527114868\n",
      "Epoch: 5694, Train Loss: 0.387842059135437, Valid Loss: 0.660358190536499\n",
      "Epoch: 5695, Train Loss: 0.3878573477268219, Valid Loss: 0.644314169883728\n",
      "Epoch: 5696, Train Loss: 0.3878805637359619, Valid Loss: 0.6645514965057373\n",
      "Epoch: 5697, Train Loss: 0.38791850209236145, Valid Loss: 0.6393222808837891\n",
      "Epoch: 5698, Train Loss: 0.3879738450050354, Valid Loss: 0.6712387204170227\n",
      "Epoch: 5699, Train Loss: 0.38806280493736267, Valid Loss: 0.631806492805481\n",
      "Epoch: 5700, Train Loss: 0.38817501068115234, Valid Loss: 0.6811259984970093\n",
      "Epoch: 5701, Train Loss: 0.3883345127105713, Valid Loss: 0.6221336126327515\n",
      "Epoch: 5702, Train Loss: 0.3884677588939667, Valid Loss: 0.6923667788505554\n",
      "Epoch: 5703, Train Loss: 0.38858845829963684, Valid Loss: 0.6145594120025635\n",
      "Epoch: 5704, Train Loss: 0.3885418176651001, Valid Loss: 0.696075975894928\n",
      "Epoch: 5705, Train Loss: 0.3883965015411377, Valid Loss: 0.6182703971862793\n",
      "Epoch: 5706, Train Loss: 0.38813668489456177, Valid Loss: 0.6814618110656738\n",
      "Epoch: 5707, Train Loss: 0.38792940974235535, Valid Loss: 0.6374686360359192\n",
      "Epoch: 5708, Train Loss: 0.3878396153450012, Valid Loss: 0.6552954912185669\n",
      "Epoch: 5709, Train Loss: 0.38788095116615295, Valid Loss: 0.6626344919204712\n",
      "Epoch: 5710, Train Loss: 0.38799849152565, Valid Loss: 0.6346117258071899\n",
      "Epoch: 5711, Train Loss: 0.3880910575389862, Valid Loss: 0.6786139011383057\n",
      "Epoch: 5712, Train Loss: 0.38810789585113525, Valid Loss: 0.628376305103302\n",
      "Epoch: 5713, Train Loss: 0.3880198001861572, Valid Loss: 0.6752897500991821\n",
      "Epoch: 5714, Train Loss: 0.38790807127952576, Valid Loss: 0.63852858543396\n",
      "Epoch: 5715, Train Loss: 0.3878330588340759, Valid Loss: 0.6576482653617859\n",
      "Epoch: 5716, Train Loss: 0.38782915472984314, Valid Loss: 0.6572974920272827\n",
      "Epoch: 5717, Train Loss: 0.38788092136383057, Valid Loss: 0.6408814191818237\n",
      "Epoch: 5718, Train Loss: 0.38793787360191345, Valid Loss: 0.6701511144638062\n",
      "Epoch: 5719, Train Loss: 0.38795599341392517, Valid Loss: 0.6354522705078125\n",
      "Epoch: 5720, Train Loss: 0.38791707158088684, Valid Loss: 0.6683883666992188\n",
      "Epoch: 5721, Train Loss: 0.3878617286682129, Valid Loss: 0.6429527997970581\n",
      "Epoch: 5722, Train Loss: 0.3878255784511566, Valid Loss: 0.6560575366020203\n",
      "Epoch: 5723, Train Loss: 0.38782307505607605, Valid Loss: 0.6562022566795349\n",
      "Epoch: 5724, Train Loss: 0.38784345984458923, Valid Loss: 0.6445849537849426\n",
      "Epoch: 5725, Train Loss: 0.3878708481788635, Valid Loss: 0.6643006205558777\n",
      "Epoch: 5726, Train Loss: 0.38788214325904846, Valid Loss: 0.6414163708686829\n",
      "Epoch: 5727, Train Loss: 0.38786780834198, Valid Loss: 0.6630120873451233\n",
      "Epoch: 5728, Train Loss: 0.38784199953079224, Valid Loss: 0.6461324095726013\n",
      "Epoch: 5729, Train Loss: 0.3878212869167328, Valid Loss: 0.6559619307518005\n",
      "Epoch: 5730, Train Loss: 0.38781628012657166, Valid Loss: 0.6538206338882446\n",
      "Epoch: 5731, Train Loss: 0.3878260850906372, Valid Loss: 0.6483663320541382\n",
      "Epoch: 5732, Train Loss: 0.38784071803092957, Valid Loss: 0.659848153591156\n",
      "Epoch: 5733, Train Loss: 0.38784801959991455, Valid Loss: 0.6447707414627075\n",
      "Epoch: 5734, Train Loss: 0.3878434896469116, Valid Loss: 0.6609298586845398\n",
      "Epoch: 5735, Train Loss: 0.38783204555511475, Valid Loss: 0.6468191742897034\n",
      "Epoch: 5736, Train Loss: 0.3878204822540283, Valid Loss: 0.6565736532211304\n",
      "Epoch: 5737, Train Loss: 0.387814998626709, Valid Loss: 0.652106761932373\n",
      "Epoch: 5738, Train Loss: 0.38781681656837463, Valid Loss: 0.6508259773254395\n",
      "Epoch: 5739, Train Loss: 0.3878230154514313, Valid Loss: 0.6571269035339355\n",
      "Epoch: 5740, Train Loss: 0.38782840967178345, Valid Loss: 0.6475812792778015\n",
      "Epoch: 5741, Train Loss: 0.38782981038093567, Valid Loss: 0.6589540243148804\n",
      "Epoch: 5742, Train Loss: 0.3878263235092163, Valid Loss: 0.6477922797203064\n",
      "Epoch: 5743, Train Loss: 0.3878209590911865, Valid Loss: 0.6568868160247803\n",
      "Epoch: 5744, Train Loss: 0.3878159523010254, Valid Loss: 0.6508228778839111\n",
      "Epoch: 5745, Train Loss: 0.3878137171268463, Valid Loss: 0.6531690359115601\n",
      "Epoch: 5746, Train Loss: 0.3878147006034851, Valid Loss: 0.6546587347984314\n",
      "Epoch: 5747, Train Loss: 0.3878176212310791, Valid Loss: 0.6501721143722534\n",
      "Epoch: 5748, Train Loss: 0.3878198266029358, Valid Loss: 0.6569323539733887\n",
      "Epoch: 5749, Train Loss: 0.3878205418586731, Valid Loss: 0.6489900350570679\n",
      "Epoch: 5750, Train Loss: 0.38781899213790894, Valid Loss: 0.6567962765693665\n",
      "Epoch: 5751, Train Loss: 0.3878168761730194, Valid Loss: 0.650158166885376\n",
      "Epoch: 5752, Train Loss: 0.38781464099884033, Valid Loss: 0.6548771858215332\n",
      "Epoch: 5753, Train Loss: 0.3878132104873657, Valid Loss: 0.6527052521705627\n",
      "Epoch: 5754, Train Loss: 0.3878132998943329, Valid Loss: 0.6524025201797485\n",
      "Epoch: 5755, Train Loss: 0.38781410455703735, Valid Loss: 0.6548007130622864\n",
      "Epoch: 5756, Train Loss: 0.38781508803367615, Valid Loss: 0.6508336663246155\n",
      "Epoch: 5757, Train Loss: 0.3878156542778015, Valid Loss: 0.6556511521339417\n",
      "Epoch: 5758, Train Loss: 0.3878157138824463, Valid Loss: 0.6507179141044617\n",
      "Epoch: 5759, Train Loss: 0.38781502842903137, Valid Loss: 0.655407726764679\n",
      "Epoch: 5760, Train Loss: 0.38781416416168213, Valid Loss: 0.6514814496040344\n",
      "Epoch: 5761, Train Loss: 0.3878132700920105, Valid Loss: 0.6543756127357483\n",
      "Epoch: 5762, Train Loss: 0.38781243562698364, Valid Loss: 0.6526190042495728\n",
      "Epoch: 5763, Train Loss: 0.3878122568130493, Valid Loss: 0.6531639099121094\n",
      "Epoch: 5764, Train Loss: 0.38781246542930603, Valid Loss: 0.6538374423980713\n",
      "Epoch: 5765, Train Loss: 0.3878127634525299, Valid Loss: 0.6521996259689331\n",
      "Epoch: 5766, Train Loss: 0.38781312108039856, Valid Loss: 0.6546911001205444\n",
      "Epoch: 5767, Train Loss: 0.38781341910362244, Valid Loss: 0.6516587734222412\n",
      "Epoch: 5768, Train Loss: 0.38781291246414185, Valid Loss: 0.6549167633056641\n",
      "Epoch: 5769, Train Loss: 0.3878125250339508, Valid Loss: 0.6517044305801392\n",
      "Epoch: 5770, Train Loss: 0.38781240582466125, Valid Loss: 0.6546276807785034\n",
      "Epoch: 5771, Train Loss: 0.38781219720840454, Valid Loss: 0.6522800922393799\n",
      "Epoch: 5772, Train Loss: 0.38781172037124634, Valid Loss: 0.6540212035179138\n",
      "Epoch: 5773, Train Loss: 0.3878113925457001, Valid Loss: 0.6529480218887329\n",
      "Epoch: 5774, Train Loss: 0.38781145215034485, Valid Loss: 0.6533578634262085\n",
      "Epoch: 5775, Train Loss: 0.3878115117549896, Valid Loss: 0.6535582542419434\n",
      "Epoch: 5776, Train Loss: 0.38781145215034485, Valid Loss: 0.6528459787368774\n",
      "Epoch: 5777, Train Loss: 0.3878113031387329, Valid Loss: 0.6540607213973999\n",
      "Epoch: 5778, Train Loss: 0.38781121373176575, Valid Loss: 0.6525070071220398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5779, Train Loss: 0.3878112733364105, Valid Loss: 0.6543161869049072\n",
      "Epoch: 5780, Train Loss: 0.3878113329410553, Valid Loss: 0.6523761749267578\n",
      "Epoch: 5781, Train Loss: 0.38781094551086426, Valid Loss: 0.6543246507644653\n",
      "Epoch: 5782, Train Loss: 0.38781049847602844, Valid Loss: 0.6524930000305176\n",
      "Epoch: 5783, Train Loss: 0.38781094551086426, Valid Loss: 0.6542151570320129\n",
      "Epoch: 5784, Train Loss: 0.38781070709228516, Valid Loss: 0.6527097821235657\n",
      "Epoch: 5785, Train Loss: 0.38781067728996277, Valid Loss: 0.6540042161941528\n",
      "Epoch: 5786, Train Loss: 0.3878105878829956, Valid Loss: 0.6529213190078735\n",
      "Epoch: 5787, Train Loss: 0.3878103792667389, Valid Loss: 0.6538171172142029\n",
      "Epoch: 5788, Train Loss: 0.3878103494644165, Valid Loss: 0.6531233787536621\n",
      "Epoch: 5789, Train Loss: 0.3878101706504822, Valid Loss: 0.6536787152290344\n",
      "Epoch: 5790, Train Loss: 0.3878101110458374, Valid Loss: 0.6533128619194031\n",
      "Epoch: 5791, Train Loss: 0.38780996203422546, Valid Loss: 0.6535127758979797\n",
      "Epoch: 5792, Train Loss: 0.38781026005744934, Valid Loss: 0.6535012125968933\n",
      "Epoch: 5793, Train Loss: 0.38780996203422546, Valid Loss: 0.6533330678939819\n",
      "Epoch: 5794, Train Loss: 0.3878096640110016, Valid Loss: 0.6536896228790283\n",
      "Epoch: 5795, Train Loss: 0.3878101408481598, Valid Loss: 0.6531932353973389\n",
      "Epoch: 5796, Train Loss: 0.387809693813324, Valid Loss: 0.6538403034210205\n",
      "Epoch: 5797, Train Loss: 0.3878098130226135, Valid Loss: 0.6530987620353699\n",
      "Epoch: 5798, Train Loss: 0.3878096640110016, Valid Loss: 0.6539347171783447\n",
      "Epoch: 5799, Train Loss: 0.3878093957901001, Valid Loss: 0.653047502040863\n",
      "Epoch: 5800, Train Loss: 0.38780948519706726, Valid Loss: 0.6540083289146423\n",
      "Epoch: 5801, Train Loss: 0.3878093957901001, Valid Loss: 0.6529850959777832\n",
      "Epoch: 5802, Train Loss: 0.3878093659877777, Valid Loss: 0.6541385054588318\n",
      "Epoch: 5803, Train Loss: 0.38780948519706726, Valid Loss: 0.6528578996658325\n",
      "Epoch: 5804, Train Loss: 0.38780897855758667, Valid Loss: 0.6543075442314148\n",
      "Epoch: 5805, Train Loss: 0.38780948519706726, Valid Loss: 0.6526769995689392\n",
      "Epoch: 5806, Train Loss: 0.38780930638313293, Valid Loss: 0.6545530557632446\n",
      "Epoch: 5807, Train Loss: 0.3878093361854553, Valid Loss: 0.6524326801300049\n",
      "Epoch: 5808, Train Loss: 0.3878095746040344, Valid Loss: 0.6548816561698914\n",
      "Epoch: 5809, Train Loss: 0.3878098428249359, Valid Loss: 0.6520503759384155\n",
      "Epoch: 5810, Train Loss: 0.38781002163887024, Valid Loss: 0.6553693413734436\n",
      "Epoch: 5811, Train Loss: 0.38781070709228516, Valid Loss: 0.6514883637428284\n",
      "Epoch: 5812, Train Loss: 0.387811541557312, Valid Loss: 0.6560959815979004\n",
      "Epoch: 5813, Train Loss: 0.3878123462200165, Valid Loss: 0.6506296396255493\n",
      "Epoch: 5814, Train Loss: 0.3878151476383209, Valid Loss: 0.6572120785713196\n",
      "Epoch: 5815, Train Loss: 0.38781747221946716, Valid Loss: 0.6492947340011597\n",
      "Epoch: 5816, Train Loss: 0.3878215551376343, Valid Loss: 0.6589188575744629\n",
      "Epoch: 5817, Train Loss: 0.387828528881073, Valid Loss: 0.6472427845001221\n",
      "Epoch: 5818, Train Loss: 0.3878384530544281, Valid Loss: 0.6615963578224182\n",
      "Epoch: 5819, Train Loss: 0.38785427808761597, Valid Loss: 0.6440370082855225\n",
      "Epoch: 5820, Train Loss: 0.3878780007362366, Valid Loss: 0.6658174395561218\n",
      "Epoch: 5821, Train Loss: 0.3879159688949585, Valid Loss: 0.6390768885612488\n",
      "Epoch: 5822, Train Loss: 0.3879692852497101, Valid Loss: 0.6723637580871582\n",
      "Epoch: 5823, Train Loss: 0.3880535662174225, Valid Loss: 0.6318308115005493\n",
      "Epoch: 5824, Train Loss: 0.3881562054157257, Valid Loss: 0.6817106604576111\n",
      "Epoch: 5825, Train Loss: 0.3883008062839508, Valid Loss: 0.6228341460227966\n",
      "Epoch: 5826, Train Loss: 0.3884193003177643, Valid Loss: 0.6919021010398865\n",
      "Epoch: 5827, Train Loss: 0.3885303735733032, Valid Loss: 0.6160581707954407\n",
      "Epoch: 5828, Train Loss: 0.38849103450775146, Valid Loss: 0.6951863169670105\n",
      "Epoch: 5829, Train Loss: 0.3883684277534485, Valid Loss: 0.6195368766784668\n",
      "Epoch: 5830, Train Loss: 0.38813138008117676, Valid Loss: 0.6821610927581787\n",
      "Epoch: 5831, Train Loss: 0.3879300653934479, Valid Loss: 0.6369352340698242\n",
      "Epoch: 5832, Train Loss: 0.38782399892807007, Valid Loss: 0.6578579545021057\n",
      "Epoch: 5833, Train Loss: 0.38783910870552063, Valid Loss: 0.6604267954826355\n",
      "Epoch: 5834, Train Loss: 0.3879348635673523, Valid Loss: 0.6373940110206604\n",
      "Epoch: 5835, Train Loss: 0.3880351781845093, Valid Loss: 0.6770352721214294\n",
      "Epoch: 5836, Train Loss: 0.38808462023735046, Valid Loss: 0.6294394135475159\n",
      "Epoch: 5837, Train Loss: 0.38803398609161377, Valid Loss: 0.6770876049995422\n",
      "Epoch: 5838, Train Loss: 0.3879373371601105, Valid Loss: 0.6363357305526733\n",
      "Epoch: 5839, Train Loss: 0.38784414529800415, Valid Loss: 0.6625562906265259\n",
      "Epoch: 5840, Train Loss: 0.387808620929718, Valid Loss: 0.6528873443603516\n",
      "Epoch: 5841, Train Loss: 0.38783425092697144, Valid Loss: 0.645717442035675\n",
      "Epoch: 5842, Train Loss: 0.3878878653049469, Valid Loss: 0.667305588722229\n",
      "Epoch: 5843, Train Loss: 0.38792890310287476, Valid Loss: 0.6370397210121155\n",
      "Epoch: 5844, Train Loss: 0.38792553544044495, Valid Loss: 0.6703600287437439\n",
      "Epoch: 5845, Train Loss: 0.3878881633281708, Valid Loss: 0.6399440169334412\n",
      "Epoch: 5846, Train Loss: 0.38783979415893555, Valid Loss: 0.6618612408638\n",
      "Epoch: 5847, Train Loss: 0.38781097531318665, Valid Loss: 0.6510104537010193\n",
      "Epoch: 5848, Train Loss: 0.38781264424324036, Valid Loss: 0.6498622298240662\n",
      "Epoch: 5849, Train Loss: 0.3878346383571625, Valid Loss: 0.6616812348365784\n",
      "Epoch: 5850, Train Loss: 0.3878582715988159, Valid Loss: 0.642690896987915\n",
      "Epoch: 5851, Train Loss: 0.38786551356315613, Valid Loss: 0.6650267243385315\n",
      "Epoch: 5852, Train Loss: 0.38785508275032043, Valid Loss: 0.6434149146080017\n",
      "Epoch: 5853, Train Loss: 0.3878327012062073, Valid Loss: 0.6607694029808044\n",
      "Epoch: 5854, Train Loss: 0.3878147006034851, Valid Loss: 0.649803876876831\n",
      "Epoch: 5855, Train Loss: 0.387807160615921, Valid Loss: 0.6532366275787354\n",
      "Epoch: 5856, Train Loss: 0.38781243562698364, Valid Loss: 0.6569445729255676\n",
      "Epoch: 5857, Train Loss: 0.3878234326839447, Valid Loss: 0.6472818851470947\n",
      "Epoch: 5858, Train Loss: 0.3878325819969177, Valid Loss: 0.6609112024307251\n",
      "Epoch: 5859, Train Loss: 0.38783377408981323, Valid Loss: 0.6459263563156128\n",
      "Epoch: 5860, Train Loss: 0.3878268599510193, Valid Loss: 0.6601442098617554\n",
      "Epoch: 5861, Train Loss: 0.3878173828125, Valid Loss: 0.6487919092178345\n",
      "Epoch: 5862, Train Loss: 0.3878091871738434, Valid Loss: 0.6558153629302979\n",
      "Epoch: 5863, Train Loss: 0.3878062665462494, Valid Loss: 0.6534973382949829\n",
      "Epoch: 5864, Train Loss: 0.38780859112739563, Valid Loss: 0.651123583316803\n",
      "Epoch: 5865, Train Loss: 0.3878137171268463, Valid Loss: 0.6575170755386353\n",
      "Epoch: 5866, Train Loss: 0.3878178596496582, Valid Loss: 0.6485887765884399\n",
      "Epoch: 5867, Train Loss: 0.3878187835216522, Valid Loss: 0.6588149070739746\n",
      "Epoch: 5868, Train Loss: 0.38781625032424927, Valid Loss: 0.648804783821106\n",
      "Epoch: 5869, Train Loss: 0.387812077999115, Valid Loss: 0.6572213172912598\n",
      "Epoch: 5870, Train Loss: 0.3878079950809479, Valid Loss: 0.6511918902397156\n",
      "Epoch: 5871, Train Loss: 0.38780587911605835, Valid Loss: 0.6543781757354736\n",
      "Epoch: 5872, Train Loss: 0.3878060281276703, Valid Loss: 0.6542285084724426\n",
      "Epoch: 5873, Train Loss: 0.3878079354763031, Valid Loss: 0.6517568826675415\n",
      "Epoch: 5874, Train Loss: 0.3878093957901001, Valid Loss: 0.6563858985900879\n",
      "Epoch: 5875, Train Loss: 0.3878108859062195, Valid Loss: 0.6502862572669983\n",
      "Epoch: 5876, Train Loss: 0.3878105878829956, Valid Loss: 0.6570531725883484\n",
      "Epoch: 5877, Train Loss: 0.38780948519706726, Valid Loss: 0.6504451036453247\n",
      "Epoch: 5878, Train Loss: 0.38780778646469116, Valid Loss: 0.6562545299530029\n",
      "Epoch: 5879, Train Loss: 0.38780680298805237, Valid Loss: 0.6518466472625732\n",
      "Epoch: 5880, Train Loss: 0.3878052234649658, Valid Loss: 0.6545395851135254\n",
      "Epoch: 5881, Train Loss: 0.38780492544174194, Valid Loss: 0.6536514163017273\n",
      "Epoch: 5882, Train Loss: 0.3878048062324524, Valid Loss: 0.6528121829032898\n",
      "Epoch: 5883, Train Loss: 0.3878057897090912, Valid Loss: 0.6551873683929443\n",
      "Epoch: 5884, Train Loss: 0.3878065049648285, Valid Loss: 0.6517328023910522\n",
      "Epoch: 5885, Train Loss: 0.38780659437179565, Valid Loss: 0.6559321880340576\n",
      "Epoch: 5886, Train Loss: 0.3878065347671509, Valid Loss: 0.6514946222305298\n",
      "Epoch: 5887, Train Loss: 0.38780611753463745, Valid Loss: 0.6557952761650085\n",
      "Epoch: 5888, Train Loss: 0.3878057301044464, Valid Loss: 0.6519672274589539\n",
      "Epoch: 5889, Train Loss: 0.38780513405799866, Valid Loss: 0.6550984382629395\n",
      "Epoch: 5890, Train Loss: 0.38780462741851807, Valid Loss: 0.652854859828949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5891, Train Loss: 0.3878043591976166, Valid Loss: 0.6542248725891113\n",
      "Epoch: 5892, Train Loss: 0.3878038823604584, Valid Loss: 0.6537691354751587\n",
      "Epoch: 5893, Train Loss: 0.3878040909767151, Valid Loss: 0.6533821225166321\n",
      "Epoch: 5894, Train Loss: 0.3878042697906494, Valid Loss: 0.654503345489502\n",
      "Epoch: 5895, Train Loss: 0.3878040313720703, Valid Loss: 0.6528124213218689\n",
      "Epoch: 5896, Train Loss: 0.3878042995929718, Valid Loss: 0.6549467444419861\n",
      "Epoch: 5897, Train Loss: 0.3878043591976166, Valid Loss: 0.6526049971580505\n",
      "Epoch: 5898, Train Loss: 0.3878040313720703, Valid Loss: 0.6550519466400146\n",
      "Epoch: 5899, Train Loss: 0.3878041207790375, Valid Loss: 0.652641236782074\n",
      "Epoch: 5900, Train Loss: 0.3878041207790375, Valid Loss: 0.6549288034439087\n",
      "Epoch: 5901, Train Loss: 0.387803852558136, Valid Loss: 0.6528562307357788\n",
      "Epoch: 5902, Train Loss: 0.3878042995929718, Valid Loss: 0.6547008752822876\n",
      "Epoch: 5903, Train Loss: 0.38780316710472107, Valid Loss: 0.6531745195388794\n",
      "Epoch: 5904, Train Loss: 0.38780343532562256, Valid Loss: 0.6544012427330017\n",
      "Epoch: 5905, Train Loss: 0.38780322670936584, Valid Loss: 0.6534823775291443\n",
      "Epoch: 5906, Train Loss: 0.38780319690704346, Valid Loss: 0.654137372970581\n",
      "Epoch: 5907, Train Loss: 0.3878025710582733, Valid Loss: 0.6537386178970337\n",
      "Epoch: 5908, Train Loss: 0.3878028392791748, Valid Loss: 0.6539357900619507\n",
      "Epoch: 5909, Train Loss: 0.3878026008605957, Valid Loss: 0.6539958119392395\n",
      "Epoch: 5910, Train Loss: 0.3878026604652405, Valid Loss: 0.6537123322486877\n",
      "Epoch: 5911, Train Loss: 0.38780272006988525, Valid Loss: 0.654238224029541\n",
      "Epoch: 5912, Train Loss: 0.3878026306629181, Valid Loss: 0.6535058617591858\n",
      "Epoch: 5913, Train Loss: 0.3878024220466614, Valid Loss: 0.6544395685195923\n",
      "Epoch: 5914, Train Loss: 0.387802392244339, Valid Loss: 0.6533722877502441\n",
      "Epoch: 5915, Train Loss: 0.3878025412559509, Valid Loss: 0.6546008586883545\n",
      "Epoch: 5916, Train Loss: 0.3878026008605957, Valid Loss: 0.653236985206604\n",
      "Epoch: 5917, Train Loss: 0.3878020644187927, Valid Loss: 0.6547603607177734\n",
      "Epoch: 5918, Train Loss: 0.3878025710582733, Valid Loss: 0.6530922651290894\n",
      "Epoch: 5919, Train Loss: 0.3878021240234375, Valid Loss: 0.654921293258667\n",
      "Epoch: 5920, Train Loss: 0.38780221343040466, Valid Loss: 0.6529543399810791\n",
      "Epoch: 5921, Train Loss: 0.3878025412559509, Valid Loss: 0.6551230549812317\n",
      "Epoch: 5922, Train Loss: 0.38780221343040466, Valid Loss: 0.6527557373046875\n",
      "Epoch: 5923, Train Loss: 0.3878026604652405, Valid Loss: 0.6553796529769897\n",
      "Epoch: 5924, Train Loss: 0.38780272006988525, Valid Loss: 0.6524723172187805\n",
      "Epoch: 5925, Train Loss: 0.3878030776977539, Valid Loss: 0.6557447910308838\n",
      "Epoch: 5926, Train Loss: 0.3878033459186554, Valid Loss: 0.6520683169364929\n",
      "Epoch: 5927, Train Loss: 0.387803852558136, Valid Loss: 0.6562834978103638\n",
      "Epoch: 5928, Train Loss: 0.3878045678138733, Valid Loss: 0.6514396667480469\n",
      "Epoch: 5929, Train Loss: 0.38780564069747925, Valid Loss: 0.6570815443992615\n",
      "Epoch: 5930, Train Loss: 0.38780757784843445, Valid Loss: 0.6504971385002136\n",
      "Epoch: 5931, Train Loss: 0.38780972361564636, Valid Loss: 0.6582868695259094\n",
      "Epoch: 5932, Train Loss: 0.38781338930130005, Valid Loss: 0.6490836143493652\n",
      "Epoch: 5933, Train Loss: 0.3878188133239746, Valid Loss: 0.6601043939590454\n",
      "Epoch: 5934, Train Loss: 0.38782674074172974, Valid Loss: 0.6469160318374634\n",
      "Epoch: 5935, Train Loss: 0.38783881068229675, Valid Loss: 0.6629220843315125\n",
      "Epoch: 5936, Train Loss: 0.38785770535469055, Valid Loss: 0.6435744762420654\n",
      "Epoch: 5937, Train Loss: 0.38788363337516785, Valid Loss: 0.6673104763031006\n",
      "Epoch: 5938, Train Loss: 0.3879263699054718, Valid Loss: 0.6385402083396912\n",
      "Epoch: 5939, Train Loss: 0.38798242807388306, Valid Loss: 0.6738747358322144\n",
      "Epoch: 5940, Train Loss: 0.38806819915771484, Valid Loss: 0.6315084099769592\n",
      "Epoch: 5941, Train Loss: 0.3881642520427704, Valid Loss: 0.6827496290206909\n",
      "Epoch: 5942, Train Loss: 0.38829419016838074, Valid Loss: 0.6233213543891907\n",
      "Epoch: 5943, Train Loss: 0.3883819580078125, Valid Loss: 0.6915329098701477\n",
      "Epoch: 5944, Train Loss: 0.38845643401145935, Valid Loss: 0.6180294156074524\n",
      "Epoch: 5945, Train Loss: 0.3883931636810303, Valid Loss: 0.6929326057434082\n",
      "Epoch: 5946, Train Loss: 0.388274222612381, Valid Loss: 0.6223624348640442\n",
      "Epoch: 5947, Train Loss: 0.3880753219127655, Valid Loss: 0.6801996827125549\n",
      "Epoch: 5948, Train Loss: 0.3879162073135376, Valid Loss: 0.6384499073028564\n",
      "Epoch: 5949, Train Loss: 0.3878307640552521, Valid Loss: 0.6587972044944763\n",
      "Epoch: 5950, Train Loss: 0.38783544301986694, Valid Loss: 0.659292995929718\n",
      "Epoch: 5951, Train Loss: 0.3879038095474243, Valid Loss: 0.640377938747406\n",
      "Epoch: 5952, Train Loss: 0.38798272609710693, Valid Loss: 0.6746457815170288\n",
      "Epoch: 5953, Train Loss: 0.388034850358963, Valid Loss: 0.6316176652908325\n",
      "Epoch: 5954, Train Loss: 0.3880138695240021, Valid Loss: 0.6769105792045593\n",
      "Epoch: 5955, Train Loss: 0.38794830441474915, Valid Loss: 0.6356361508369446\n",
      "Epoch: 5956, Train Loss: 0.3878630995750427, Valid Loss: 0.6659601330757141\n",
      "Epoch: 5957, Train Loss: 0.38780930638313293, Valid Loss: 0.6495150923728943\n",
      "Epoch: 5958, Train Loss: 0.38780635595321655, Valid Loss: 0.6504263877868652\n",
      "Epoch: 5959, Train Loss: 0.3878422677516937, Valid Loss: 0.6637726426124573\n",
      "Epoch: 5960, Train Loss: 0.3878849744796753, Valid Loss: 0.6399844884872437\n",
      "Epoch: 5961, Train Loss: 0.3879031240940094, Valid Loss: 0.6698142290115356\n",
      "Epoch: 5962, Train Loss: 0.3878929018974304, Valid Loss: 0.6393036842346191\n",
      "Epoch: 5963, Train Loss: 0.38786080479621887, Valid Loss: 0.6653978228569031\n",
      "Epoch: 5964, Train Loss: 0.38782748579978943, Valid Loss: 0.6471536755561829\n",
      "Epoch: 5965, Train Loss: 0.38780611753463745, Valid Loss: 0.6556136608123779\n",
      "Epoch: 5966, Train Loss: 0.38780415058135986, Valid Loss: 0.6568602919578552\n",
      "Epoch: 5967, Train Loss: 0.387818306684494, Valid Loss: 0.6474126577377319\n",
      "Epoch: 5968, Train Loss: 0.38783544301986694, Valid Loss: 0.6625175476074219\n",
      "Epoch: 5969, Train Loss: 0.38784557580947876, Valid Loss: 0.6443713307380676\n",
      "Epoch: 5970, Train Loss: 0.38784247636795044, Valid Loss: 0.6630847454071045\n",
      "Epoch: 5971, Train Loss: 0.3878297507762909, Valid Loss: 0.6464511752128601\n",
      "Epoch: 5972, Train Loss: 0.3878139555454254, Valid Loss: 0.6592488288879395\n",
      "Epoch: 5973, Train Loss: 0.38780251145362854, Valid Loss: 0.6513962745666504\n",
      "Epoch: 5974, Train Loss: 0.387800008058548, Valid Loss: 0.6531686186790466\n",
      "Epoch: 5975, Train Loss: 0.38780510425567627, Valid Loss: 0.6569011807441711\n",
      "Epoch: 5976, Train Loss: 0.3878132402896881, Valid Loss: 0.6487693190574646\n",
      "Epoch: 5977, Train Loss: 0.38781923055648804, Valid Loss: 0.6603775024414062\n",
      "Epoch: 5978, Train Loss: 0.3878198266029358, Valid Loss: 0.6474683880805969\n",
      "Epoch: 5979, Train Loss: 0.387815922498703, Valid Loss: 0.6600763201713562\n",
      "Epoch: 5980, Train Loss: 0.3878098428249359, Valid Loss: 0.6489474773406982\n",
      "Epoch: 5981, Train Loss: 0.38780394196510315, Valid Loss: 0.6571102738380432\n",
      "Epoch: 5982, Train Loss: 0.3878001868724823, Valid Loss: 0.6525594592094421\n",
      "Epoch: 5983, Train Loss: 0.3877992331981659, Valid Loss: 0.6535341739654541\n",
      "Epoch: 5984, Train Loss: 0.3878011703491211, Valid Loss: 0.6561529636383057\n",
      "Epoch: 5985, Train Loss: 0.3878041207790375, Valid Loss: 0.6506749987602234\n",
      "Epoch: 5986, Train Loss: 0.38780659437179565, Valid Loss: 0.6581089496612549\n",
      "Epoch: 5987, Train Loss: 0.38780727982521057, Valid Loss: 0.6494892835617065\n",
      "Epoch: 5988, Train Loss: 0.38780590891838074, Valid Loss: 0.6583497524261475\n",
      "Epoch: 5989, Train Loss: 0.3878043591976166, Valid Loss: 0.6503255367279053\n",
      "Epoch: 5990, Train Loss: 0.38780179619789124, Valid Loss: 0.6569388508796692\n",
      "Epoch: 5991, Train Loss: 0.38779962062835693, Valid Loss: 0.6523857116699219\n",
      "Epoch: 5992, Train Loss: 0.3877983093261719, Valid Loss: 0.6545138359069824\n",
      "Epoch: 5993, Train Loss: 0.3877983093261719, Valid Loss: 0.6546602845191956\n",
      "Epoch: 5994, Train Loss: 0.3877987861633301, Valid Loss: 0.6524980664253235\n",
      "Epoch: 5995, Train Loss: 0.387800008058548, Valid Loss: 0.656302273273468\n",
      "Epoch: 5996, Train Loss: 0.38780081272125244, Valid Loss: 0.6515600681304932\n",
      "Epoch: 5997, Train Loss: 0.38780108094215393, Valid Loss: 0.6568357944488525\n",
      "Epoch: 5998, Train Loss: 0.38780084252357483, Valid Loss: 0.6514756679534912\n",
      "Epoch: 5999, Train Loss: 0.3878006339073181, Valid Loss: 0.6565014719963074\n",
      "Epoch: 6000, Train Loss: 0.38780003786087036, Valid Loss: 0.6520513296127319\n",
      "Epoch: 6001, Train Loss: 0.387798935174942, Valid Loss: 0.6558274626731873\n",
      "Epoch: 6002, Train Loss: 0.3877983093261719, Valid Loss: 0.652987539768219\n",
      "Epoch: 6003, Train Loss: 0.3877975642681122, Valid Loss: 0.6549192070960999\n",
      "Epoch: 6004, Train Loss: 0.3877972960472107, Valid Loss: 0.6539172530174255\n",
      "Epoch: 6005, Train Loss: 0.3877972960472107, Valid Loss: 0.6539557576179504\n",
      "Epoch: 6006, Train Loss: 0.38779735565185547, Valid Loss: 0.6548107862472534\n",
      "Epoch: 6007, Train Loss: 0.38779738545417786, Valid Loss: 0.653221845626831\n",
      "Epoch: 6008, Train Loss: 0.3877972662448883, Valid Loss: 0.6555300951004028\n",
      "Epoch: 6009, Train Loss: 0.3877979815006256, Valid Loss: 0.6527577042579651\n",
      "Epoch: 6010, Train Loss: 0.3877980411052704, Valid Loss: 0.6558218598365784\n",
      "Epoch: 6011, Train Loss: 0.38779786229133606, Valid Loss: 0.6525941491127014\n",
      "Epoch: 6012, Train Loss: 0.38779789209365845, Valid Loss: 0.6558546423912048\n",
      "Epoch: 6013, Train Loss: 0.38779765367507935, Valid Loss: 0.6526936292648315\n",
      "Epoch: 6014, Train Loss: 0.3877973258495331, Valid Loss: 0.6557785272598267\n",
      "Epoch: 6015, Train Loss: 0.38779717683792114, Valid Loss: 0.6528910994529724\n",
      "Epoch: 6016, Train Loss: 0.3877970278263092, Valid Loss: 0.6555262207984924\n",
      "Epoch: 6017, Train Loss: 0.38779664039611816, Valid Loss: 0.6531740427017212\n",
      "Epoch: 6018, Train Loss: 0.3877969980239868, Valid Loss: 0.6552146077156067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6019, Train Loss: 0.3877964913845062, Valid Loss: 0.6535339951515198\n",
      "Epoch: 6020, Train Loss: 0.38779619336128235, Valid Loss: 0.6549353003501892\n",
      "Epoch: 6021, Train Loss: 0.38779595494270325, Valid Loss: 0.6538413166999817\n",
      "Epoch: 6022, Train Loss: 0.3877958655357361, Valid Loss: 0.6546979546546936\n",
      "Epoch: 6023, Train Loss: 0.38779565691947937, Valid Loss: 0.6540380716323853\n",
      "Epoch: 6024, Train Loss: 0.3877960741519928, Valid Loss: 0.6545467376708984\n",
      "Epoch: 6025, Train Loss: 0.3877955377101898, Valid Loss: 0.6541732549667358\n",
      "Epoch: 6026, Train Loss: 0.38779571652412415, Valid Loss: 0.6545101404190063\n",
      "Epoch: 6027, Train Loss: 0.38779568672180176, Valid Loss: 0.6542330980300903\n",
      "Epoch: 6028, Train Loss: 0.3877955973148346, Valid Loss: 0.6544848084449768\n",
      "Epoch: 6029, Train Loss: 0.3877958357334137, Valid Loss: 0.6542801856994629\n",
      "Epoch: 6030, Train Loss: 0.38779523968696594, Valid Loss: 0.6544279456138611\n",
      "Epoch: 6031, Train Loss: 0.3877950608730316, Valid Loss: 0.6543765068054199\n",
      "Epoch: 6032, Train Loss: 0.38779500126838684, Valid Loss: 0.654375433921814\n",
      "Epoch: 6033, Train Loss: 0.38779589533805847, Valid Loss: 0.6544725894927979\n",
      "Epoch: 6034, Train Loss: 0.387795090675354, Valid Loss: 0.6543087959289551\n",
      "Epoch: 6035, Train Loss: 0.38779497146606445, Valid Loss: 0.6545437574386597\n",
      "Epoch: 6036, Train Loss: 0.3877948522567749, Valid Loss: 0.6542546153068542\n",
      "Epoch: 6037, Train Loss: 0.3877948522567749, Valid Loss: 0.6546130180358887\n",
      "Epoch: 6038, Train Loss: 0.3877944350242615, Valid Loss: 0.6542194485664368\n",
      "Epoch: 6039, Train Loss: 0.3877948820590973, Valid Loss: 0.6546943187713623\n",
      "Epoch: 6040, Train Loss: 0.3877946436405182, Valid Loss: 0.6541608572006226\n",
      "Epoch: 6041, Train Loss: 0.3877945840358734, Valid Loss: 0.6547788977622986\n",
      "Epoch: 6042, Train Loss: 0.3877945840358734, Valid Loss: 0.6540767550468445\n",
      "Epoch: 6043, Train Loss: 0.3877945840358734, Valid Loss: 0.6549060344696045\n",
      "Epoch: 6044, Train Loss: 0.3877944052219391, Valid Loss: 0.6539602875709534\n",
      "Epoch: 6045, Train Loss: 0.3877944350242615, Valid Loss: 0.6550906896591187\n",
      "Epoch: 6046, Train Loss: 0.3877944052219391, Valid Loss: 0.653761088848114\n",
      "Epoch: 6047, Train Loss: 0.38779452443122864, Valid Loss: 0.6553672552108765\n",
      "Epoch: 6048, Train Loss: 0.3877944350242615, Valid Loss: 0.6534148454666138\n",
      "Epoch: 6049, Train Loss: 0.38779494166374207, Valid Loss: 0.6558619737625122\n",
      "Epoch: 6050, Train Loss: 0.38779526948928833, Valid Loss: 0.6527857780456543\n",
      "Epoch: 6051, Train Loss: 0.38779616355895996, Valid Loss: 0.6567428708076477\n",
      "Epoch: 6052, Train Loss: 0.38779783248901367, Valid Loss: 0.6516655683517456\n",
      "Epoch: 6053, Train Loss: 0.3878001868724823, Valid Loss: 0.6582517027854919\n",
      "Epoch: 6054, Train Loss: 0.38780495524406433, Valid Loss: 0.649741530418396\n",
      "Epoch: 6055, Train Loss: 0.3878121078014374, Valid Loss: 0.6608331799507141\n",
      "Epoch: 6056, Train Loss: 0.38782545924186707, Valid Loss: 0.6464751362800598\n",
      "Epoch: 6057, Train Loss: 0.3878476917743683, Valid Loss: 0.6653347611427307\n",
      "Epoch: 6058, Train Loss: 0.3878873884677887, Valid Loss: 0.640841543674469\n",
      "Epoch: 6059, Train Loss: 0.38795173168182373, Valid Loss: 0.6731706857681274\n",
      "Epoch: 6060, Train Loss: 0.388065367937088, Valid Loss: 0.6315136551856995\n",
      "Epoch: 6061, Train Loss: 0.3882282078266144, Valid Loss: 0.6861357092857361\n",
      "Epoch: 6062, Train Loss: 0.38849425315856934, Valid Loss: 0.6180673837661743\n",
      "Epoch: 6063, Train Loss: 0.3887504041194916, Valid Loss: 0.7031434774398804\n",
      "Epoch: 6064, Train Loss: 0.38903510570526123, Valid Loss: 0.6061590909957886\n",
      "Epoch: 6065, Train Loss: 0.38896384835243225, Valid Loss: 0.7104318141937256\n",
      "Epoch: 6066, Train Loss: 0.3886977732181549, Valid Loss: 0.6118313074111938\n",
      "Epoch: 6067, Train Loss: 0.3881971836090088, Valid Loss: 0.6868182420730591\n",
      "Epoch: 6068, Train Loss: 0.3878795802593231, Valid Loss: 0.6417372822761536\n",
      "Epoch: 6069, Train Loss: 0.3878558576107025, Valid Loss: 0.6467058062553406\n",
      "Epoch: 6070, Train Loss: 0.38805052638053894, Valid Loss: 0.6774482727050781\n",
      "Epoch: 6071, Train Loss: 0.3882863223552704, Valid Loss: 0.6233741044998169\n",
      "Epoch: 6072, Train Loss: 0.38830244541168213, Valid Loss: 0.6910300254821777\n",
      "Epoch: 6073, Train Loss: 0.3881281912326813, Valid Loss: 0.6283414959907532\n",
      "Epoch: 6074, Train Loss: 0.38788536190986633, Valid Loss: 0.6688043475151062\n",
      "Epoch: 6075, Train Loss: 0.3878069519996643, Valid Loss: 0.6541172862052917\n",
      "Epoch: 6076, Train Loss: 0.3879074454307556, Valid Loss: 0.6385576128959656\n",
      "Epoch: 6077, Train Loss: 0.3880418837070465, Valid Loss: 0.678693413734436\n",
      "Epoch: 6078, Train Loss: 0.38807836174964905, Valid Loss: 0.6299870014190674\n",
      "Epoch: 6079, Train Loss: 0.3879660367965698, Valid Loss: 0.675645649433136\n",
      "Epoch: 6080, Train Loss: 0.38783952593803406, Valid Loss: 0.6446778774261475\n",
      "Epoch: 6081, Train Loss: 0.38780227303504944, Valid Loss: 0.6506677865982056\n",
      "Epoch: 6082, Train Loss: 0.3878636360168457, Valid Loss: 0.6662188768386841\n",
      "Epoch: 6083, Train Loss: 0.38794124126434326, Valid Loss: 0.6355577707290649\n",
      "Epoch: 6084, Train Loss: 0.38794103264808655, Valid Loss: 0.6733146905899048\n",
      "Epoch: 6085, Train Loss: 0.38787540793418884, Valid Loss: 0.6420184373855591\n",
      "Epoch: 6086, Train Loss: 0.387808620929718, Valid Loss: 0.6592040061950684\n",
      "Epoch: 6087, Train Loss: 0.3878011703491211, Valid Loss: 0.6578115224838257\n",
      "Epoch: 6088, Train Loss: 0.3878437876701355, Valid Loss: 0.6430525183677673\n",
      "Epoch: 6089, Train Loss: 0.3878791332244873, Valid Loss: 0.6673354506492615\n",
      "Epoch: 6090, Train Loss: 0.3878723084926605, Valid Loss: 0.6417224407196045\n",
      "Epoch: 6091, Train Loss: 0.3878317177295685, Valid Loss: 0.6633211374282837\n",
      "Epoch: 6092, Train Loss: 0.3878001868724823, Valid Loss: 0.6517475843429565\n",
      "Epoch: 6093, Train Loss: 0.38780003786087036, Valid Loss: 0.6509412527084351\n",
      "Epoch: 6094, Train Loss: 0.38782331347465515, Valid Loss: 0.6614128947257996\n",
      "Epoch: 6095, Train Loss: 0.38784274458885193, Valid Loss: 0.6435317993164062\n",
      "Epoch: 6096, Train Loss: 0.38783642649650574, Valid Loss: 0.6636329889297485\n",
      "Epoch: 6097, Train Loss: 0.38781312108039856, Valid Loss: 0.6479261517524719\n",
      "Epoch: 6098, Train Loss: 0.38779520988464355, Valid Loss: 0.6566919088363647\n",
      "Epoch: 6099, Train Loss: 0.3877970576286316, Valid Loss: 0.6567665934562683\n",
      "Epoch: 6100, Train Loss: 0.3878106474876404, Valid Loss: 0.6479277610778809\n",
      "Epoch: 6101, Train Loss: 0.3878192901611328, Valid Loss: 0.6612629890441895\n",
      "Epoch: 6102, Train Loss: 0.3878163993358612, Valid Loss: 0.6468483209609985\n",
      "Epoch: 6103, Train Loss: 0.38780489563941956, Valid Loss: 0.6594699025154114\n",
      "Epoch: 6104, Train Loss: 0.3877950608730316, Valid Loss: 0.6526263952255249\n",
      "Epoch: 6105, Train Loss: 0.3877936005592346, Valid Loss: 0.6531172394752502\n",
      "Epoch: 6106, Train Loss: 0.3878004550933838, Valid Loss: 0.658078134059906\n",
      "Epoch: 6107, Train Loss: 0.38780704140663147, Valid Loss: 0.6483213305473328\n",
      "Epoch: 6108, Train Loss: 0.3878059685230255, Valid Loss: 0.6596912145614624\n",
      "Epoch: 6109, Train Loss: 0.38780030608177185, Valid Loss: 0.6500312685966492\n",
      "Epoch: 6110, Train Loss: 0.3877946138381958, Valid Loss: 0.6567628383636475\n",
      "Epoch: 6111, Train Loss: 0.38779252767562866, Valid Loss: 0.6548115611076355\n",
      "Epoch: 6112, Train Loss: 0.3877949118614197, Valid Loss: 0.6517252326011658\n",
      "Epoch: 6113, Train Loss: 0.3877981901168823, Valid Loss: 0.6580019593238831\n",
      "Epoch: 6114, Train Loss: 0.38779982924461365, Valid Loss: 0.6498253345489502\n",
      "Epoch: 6115, Train Loss: 0.3877977132797241, Valid Loss: 0.6580246686935425\n",
      "Epoch: 6116, Train Loss: 0.38779452443122864, Valid Loss: 0.6522713303565979\n",
      "Epoch: 6117, Train Loss: 0.38779187202453613, Valid Loss: 0.6550347805023193\n",
      "Epoch: 6118, Train Loss: 0.3877921998500824, Valid Loss: 0.6555442214012146\n",
      "Epoch: 6119, Train Loss: 0.3877939283847809, Valid Loss: 0.6518874168395996\n",
      "Epoch: 6120, Train Loss: 0.38779518008232117, Valid Loss: 0.6571386456489563\n",
      "Epoch: 6121, Train Loss: 0.38779520988464355, Valid Loss: 0.6515641808509827\n",
      "Epoch: 6122, Train Loss: 0.3877936005592346, Valid Loss: 0.6567146182060242\n",
      "Epoch: 6123, Train Loss: 0.38779231905937195, Valid Loss: 0.6533827185630798\n",
      "Epoch: 6124, Train Loss: 0.38779109716415405, Valid Loss: 0.6546310186386108\n",
      "Epoch: 6125, Train Loss: 0.38779163360595703, Valid Loss: 0.6553239226341248\n",
      "Epoch: 6126, Train Loss: 0.3877924382686615, Valid Loss: 0.6526443958282471\n",
      "Epoch: 6127, Train Loss: 0.38779303431510925, Valid Loss: 0.6565185785293579\n",
      "Epoch: 6128, Train Loss: 0.38779303431510925, Valid Loss: 0.6525219678878784\n",
      "Epoch: 6129, Train Loss: 0.3877919912338257, Valid Loss: 0.6562725901603699\n",
      "Epoch: 6130, Train Loss: 0.38779133558273315, Valid Loss: 0.6536800265312195\n",
      "Epoch: 6131, Train Loss: 0.3877906799316406, Valid Loss: 0.6546707153320312\n",
      "Epoch: 6132, Train Loss: 0.38779065012931824, Valid Loss: 0.6550126671791077\n",
      "Epoch: 6133, Train Loss: 0.38779133558273315, Valid Loss: 0.653354823589325\n",
      "Epoch: 6134, Train Loss: 0.38779136538505554, Valid Loss: 0.6560551524162292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6135, Train Loss: 0.38779163360595703, Valid Loss: 0.6531389355659485\n",
      "Epoch: 6136, Train Loss: 0.387791246175766, Valid Loss: 0.6559968590736389\n",
      "Epoch: 6137, Train Loss: 0.3877912163734436, Valid Loss: 0.6536232233047485\n",
      "Epoch: 6138, Train Loss: 0.38779014348983765, Valid Loss: 0.6550025939941406\n",
      "Epoch: 6139, Train Loss: 0.3877902925014496, Valid Loss: 0.6545924544334412\n",
      "Epoch: 6140, Train Loss: 0.38778993487358093, Valid Loss: 0.6541206240653992\n",
      "Epoch: 6141, Train Loss: 0.38779017329216003, Valid Loss: 0.655538022518158\n",
      "Epoch: 6142, Train Loss: 0.3877897262573242, Valid Loss: 0.6536508202552795\n",
      "Epoch: 6143, Train Loss: 0.3877902328968048, Valid Loss: 0.6557323932647705\n",
      "Epoch: 6144, Train Loss: 0.3877907693386078, Valid Loss: 0.6536923050880432\n",
      "Epoch: 6145, Train Loss: 0.38779017329216003, Valid Loss: 0.6552949547767639\n",
      "Epoch: 6146, Train Loss: 0.3877895176410675, Valid Loss: 0.654319167137146\n",
      "Epoch: 6147, Train Loss: 0.38778990507125854, Valid Loss: 0.6547263860702515\n",
      "Epoch: 6148, Train Loss: 0.38778918981552124, Valid Loss: 0.6550254821777344\n",
      "Epoch: 6149, Train Loss: 0.387789785861969, Valid Loss: 0.6542366743087769\n",
      "Epoch: 6150, Train Loss: 0.38778939843177795, Valid Loss: 0.6553245782852173\n",
      "Epoch: 6151, Train Loss: 0.3877892792224884, Valid Loss: 0.6540137529373169\n",
      "Epoch: 6152, Train Loss: 0.3877895176410675, Valid Loss: 0.6553581953048706\n",
      "Epoch: 6153, Train Loss: 0.3877897262573242, Valid Loss: 0.6542131304740906\n",
      "Epoch: 6154, Train Loss: 0.3877890408039093, Valid Loss: 0.6551912426948547\n",
      "Epoch: 6155, Train Loss: 0.3877889811992645, Valid Loss: 0.6545480489730835\n",
      "Epoch: 6156, Train Loss: 0.3877890110015869, Valid Loss: 0.6548014879226685\n",
      "Epoch: 6157, Train Loss: 0.3877888023853302, Valid Loss: 0.6548636555671692\n",
      "Epoch: 6158, Train Loss: 0.38778868317604065, Valid Loss: 0.6544840335845947\n",
      "Epoch: 6159, Train Loss: 0.3877885937690735, Valid Loss: 0.6551661491394043\n",
      "Epoch: 6160, Train Loss: 0.3877885639667511, Valid Loss: 0.6543890237808228\n",
      "Epoch: 6161, Train Loss: 0.3877885937690735, Valid Loss: 0.6552684903144836\n",
      "Epoch: 6162, Train Loss: 0.3877886235713959, Valid Loss: 0.6543781757354736\n",
      "Epoch: 6163, Train Loss: 0.3877885341644287, Valid Loss: 0.655144214630127\n",
      "Epoch: 6164, Train Loss: 0.38778823614120483, Valid Loss: 0.6545282006263733\n",
      "Epoch: 6165, Train Loss: 0.38778817653656006, Valid Loss: 0.6550226807594299\n",
      "Epoch: 6166, Train Loss: 0.3877881169319153, Valid Loss: 0.654741108417511\n",
      "Epoch: 6167, Train Loss: 0.3877882659435272, Valid Loss: 0.6548848748207092\n",
      "Epoch: 6168, Train Loss: 0.3877880871295929, Valid Loss: 0.6549096703529358\n",
      "Epoch: 6169, Train Loss: 0.3877881169319153, Valid Loss: 0.654691755771637\n",
      "Epoch: 6170, Train Loss: 0.38778743147850037, Valid Loss: 0.6550704836845398\n",
      "Epoch: 6171, Train Loss: 0.3877878189086914, Valid Loss: 0.654588520526886\n",
      "Epoch: 6172, Train Loss: 0.3877873420715332, Valid Loss: 0.6551966071128845\n",
      "Epoch: 6173, Train Loss: 0.38778766989707947, Valid Loss: 0.6545765399932861\n",
      "Epoch: 6174, Train Loss: 0.38778746128082275, Valid Loss: 0.6551849842071533\n",
      "Epoch: 6175, Train Loss: 0.38778746128082275, Valid Loss: 0.6546282172203064\n",
      "Epoch: 6176, Train Loss: 0.38778746128082275, Valid Loss: 0.6550973653793335\n",
      "Epoch: 6177, Train Loss: 0.3877873122692108, Valid Loss: 0.6547485589981079\n",
      "Epoch: 6178, Train Loss: 0.3877871334552765, Valid Loss: 0.6550162434577942\n",
      "Epoch: 6179, Train Loss: 0.3877871334552765, Valid Loss: 0.6548759341239929\n",
      "Epoch: 6180, Train Loss: 0.3877871036529541, Valid Loss: 0.6549285650253296\n",
      "Epoch: 6181, Train Loss: 0.3877868950366974, Valid Loss: 0.6549645066261292\n",
      "Epoch: 6182, Train Loss: 0.38778695464134216, Valid Loss: 0.6548514366149902\n",
      "Epoch: 6183, Train Loss: 0.3877866864204407, Valid Loss: 0.6550418734550476\n",
      "Epoch: 6184, Train Loss: 0.3877863883972168, Valid Loss: 0.6548241376876831\n",
      "Epoch: 6185, Train Loss: 0.38778695464134216, Valid Loss: 0.6551100015640259\n",
      "Epoch: 6186, Train Loss: 0.3877866268157959, Valid Loss: 0.6548023819923401\n",
      "Epoch: 6187, Train Loss: 0.3877865970134735, Valid Loss: 0.6551304459571838\n",
      "Epoch: 6188, Train Loss: 0.3877864181995392, Valid Loss: 0.6547742486000061\n",
      "Epoch: 6189, Train Loss: 0.38778677582740784, Valid Loss: 0.6551913619041443\n",
      "Epoch: 6190, Train Loss: 0.3877864181995392, Valid Loss: 0.6547361016273499\n",
      "Epoch: 6191, Train Loss: 0.38778653740882874, Valid Loss: 0.6552600860595703\n",
      "Epoch: 6192, Train Loss: 0.3877868950366974, Valid Loss: 0.6547226905822754\n",
      "Epoch: 6193, Train Loss: 0.3877861797809601, Valid Loss: 0.6552753448486328\n",
      "Epoch: 6194, Train Loss: 0.38778626918792725, Valid Loss: 0.6547248959541321\n",
      "Epoch: 6195, Train Loss: 0.3877859115600586, Valid Loss: 0.6552842855453491\n",
      "Epoch: 6196, Train Loss: 0.38778597116470337, Valid Loss: 0.6547348499298096\n",
      "Epoch: 6197, Train Loss: 0.3877859115600586, Valid Loss: 0.6553071737289429\n",
      "Epoch: 6198, Train Loss: 0.38778579235076904, Valid Loss: 0.6547368764877319\n",
      "Epoch: 6199, Train Loss: 0.3877856731414795, Valid Loss: 0.6553452014923096\n",
      "Epoch: 6200, Train Loss: 0.38778576254844666, Valid Loss: 0.6546943187713623\n",
      "Epoch: 6201, Train Loss: 0.38778555393218994, Valid Loss: 0.6554126143455505\n",
      "Epoch: 6202, Train Loss: 0.3877856433391571, Valid Loss: 0.6546363830566406\n",
      "Epoch: 6203, Train Loss: 0.3877856731414795, Valid Loss: 0.6555100083351135\n",
      "Epoch: 6204, Train Loss: 0.38778579235076904, Valid Loss: 0.6545450091362\n",
      "Epoch: 6205, Train Loss: 0.3877854347229004, Valid Loss: 0.6556653380393982\n",
      "Epoch: 6206, Train Loss: 0.3877853453159332, Valid Loss: 0.6543601751327515\n",
      "Epoch: 6207, Train Loss: 0.3877853453159332, Valid Loss: 0.6559107303619385\n",
      "Epoch: 6208, Train Loss: 0.38778528571128845, Valid Loss: 0.6540911197662354\n",
      "Epoch: 6209, Train Loss: 0.3877857029438019, Valid Loss: 0.6562524437904358\n",
      "Epoch: 6210, Train Loss: 0.3877859115600586, Valid Loss: 0.653717577457428\n",
      "Epoch: 6211, Train Loss: 0.38778626918792725, Valid Loss: 0.6567374467849731\n",
      "Epoch: 6212, Train Loss: 0.3877866566181183, Valid Loss: 0.6531269550323486\n",
      "Epoch: 6213, Train Loss: 0.38778746128082275, Valid Loss: 0.6575160026550293\n",
      "Epoch: 6214, Train Loss: 0.3877890408039093, Valid Loss: 0.6521755456924438\n",
      "Epoch: 6215, Train Loss: 0.38779088854789734, Valid Loss: 0.658760130405426\n",
      "Epoch: 6216, Train Loss: 0.38779470324516296, Valid Loss: 0.6506649851799011\n",
      "Epoch: 6217, Train Loss: 0.38779979944229126, Valid Loss: 0.6607325673103333\n",
      "Epoch: 6218, Train Loss: 0.3878082036972046, Valid Loss: 0.6482388377189636\n",
      "Epoch: 6219, Train Loss: 0.38782134652137756, Valid Loss: 0.6639385223388672\n",
      "Epoch: 6220, Train Loss: 0.38784322142601013, Valid Loss: 0.6443549990653992\n",
      "Epoch: 6221, Train Loss: 0.38787609338760376, Valid Loss: 0.6691321730613708\n",
      "Epoch: 6222, Train Loss: 0.3879310190677643, Valid Loss: 0.6382561922073364\n",
      "Epoch: 6223, Train Loss: 0.38800784945487976, Valid Loss: 0.6773380041122437\n",
      "Epoch: 6224, Train Loss: 0.3881334066390991, Valid Loss: 0.6293032169342041\n",
      "Epoch: 6225, Train Loss: 0.38827696442604065, Valid Loss: 0.689007580280304\n",
      "Epoch: 6226, Train Loss: 0.38848191499710083, Valid Loss: 0.6186789274215698\n",
      "Epoch: 6227, Train Loss: 0.38860294222831726, Valid Loss: 0.7004934549331665\n",
      "Epoch: 6228, Train Loss: 0.38869670033454895, Valid Loss: 0.6128019690513611\n",
      "Epoch: 6229, Train Loss: 0.3885365128517151, Valid Loss: 0.6997508406639099\n",
      "Epoch: 6230, Train Loss: 0.3882993459701538, Valid Loss: 0.6218271851539612\n",
      "Epoch: 6231, Train Loss: 0.38799864053726196, Valid Loss: 0.6781558394432068\n",
      "Epoch: 6232, Train Loss: 0.3878238797187805, Valid Loss: 0.6462129950523376\n",
      "Epoch: 6233, Train Loss: 0.38781216740608215, Valid Loss: 0.6491818428039551\n",
      "Epoch: 6234, Train Loss: 0.387923926115036, Valid Loss: 0.672688364982605\n",
      "Epoch: 6235, Train Loss: 0.38807085156440735, Valid Loss: 0.6306271553039551\n",
      "Epoch: 6236, Train Loss: 0.3881255090236664, Valid Loss: 0.6845251321792603\n",
      "Epoch: 6237, Train Loss: 0.3880789279937744, Valid Loss: 0.6297535300254822\n",
      "Epoch: 6238, Train Loss: 0.38793835043907166, Valid Loss: 0.6742976307868958\n",
      "Epoch: 6239, Train Loss: 0.3878230154514313, Valid Loss: 0.6454914808273315\n",
      "Epoch: 6240, Train Loss: 0.38778963685035706, Valid Loss: 0.6531500220298767\n",
      "Epoch: 6241, Train Loss: 0.38783544301986694, Valid Loss: 0.6656090617179871\n",
      "Epoch: 6242, Train Loss: 0.3879092037677765, Valid Loss: 0.6381376385688782\n",
      "Epoch: 6243, Train Loss: 0.38794463872909546, Valid Loss: 0.6748553514480591\n",
      "Epoch: 6244, Train Loss: 0.3879260718822479, Valid Loss: 0.6373198628425598\n",
      "Epoch: 6245, Train Loss: 0.3878614604473114, Valid Loss: 0.667904794216156\n",
      "Epoch: 6246, Train Loss: 0.387803852558136, Valid Loss: 0.6487109661102295\n",
      "Epoch: 6247, Train Loss: 0.38778603076934814, Valid Loss: 0.653228759765625\n",
      "Epoch: 6248, Train Loss: 0.3878088891506195, Valid Loss: 0.6625815629959106\n",
      "Epoch: 6249, Train Loss: 0.38784536719322205, Valid Loss: 0.6431851387023926\n",
      "Epoch: 6250, Train Loss: 0.3878619372844696, Valid Loss: 0.668326735496521\n",
      "Epoch: 6251, Train Loss: 0.3878515660762787, Valid Loss: 0.6431405544281006\n",
      "Epoch: 6252, Train Loss: 0.38782110810279846, Valid Loss: 0.6634471416473389\n",
      "Epoch: 6253, Train Loss: 0.387794554233551, Valid Loss: 0.6507517099380493\n",
      "Epoch: 6254, Train Loss: 0.3877852261066437, Valid Loss: 0.6540606021881104\n",
      "Epoch: 6255, Train Loss: 0.3877944052219391, Valid Loss: 0.6594982743263245\n",
      "Epoch: 6256, Train Loss: 0.3878117799758911, Valid Loss: 0.6471824049949646\n",
      "Epoch: 6257, Train Loss: 0.38782215118408203, Valid Loss: 0.663809597492218\n",
      "Epoch: 6258, Train Loss: 0.38781940937042236, Valid Loss: 0.6463654041290283\n",
      "Epoch: 6259, Train Loss: 0.38780471682548523, Valid Loss: 0.6616814136505127\n",
      "Epoch: 6260, Train Loss: 0.3877900540828705, Valid Loss: 0.650876522064209\n",
      "Epoch: 6261, Train Loss: 0.38778385519981384, Valid Loss: 0.655468761920929\n",
      "Epoch: 6262, Train Loss: 0.3877871036529541, Valid Loss: 0.6570925116539001\n",
      "Epoch: 6263, Train Loss: 0.3877945840358734, Valid Loss: 0.650093138217926\n",
      "Epoch: 6264, Train Loss: 0.38780054450035095, Valid Loss: 0.6610885858535767\n",
      "Epoch: 6265, Train Loss: 0.38780152797698975, Valid Loss: 0.6485661268234253\n",
      "Epoch: 6266, Train Loss: 0.387797087430954, Valid Loss: 0.6606009602546692\n",
      "Epoch: 6267, Train Loss: 0.38779017329216003, Valid Loss: 0.650851845741272\n",
      "Epoch: 6268, Train Loss: 0.387784481048584, Valid Loss: 0.6567534804344177\n",
      "Epoch: 6269, Train Loss: 0.38778263330459595, Valid Loss: 0.6551719903945923\n",
      "Epoch: 6270, Train Loss: 0.3877851366996765, Valid Loss: 0.6527217626571655\n",
      "Epoch: 6271, Train Loss: 0.38778871297836304, Valid Loss: 0.6586630940437317\n",
      "Epoch: 6272, Train Loss: 0.38779115676879883, Valid Loss: 0.6506478190422058\n",
      "Epoch: 6273, Train Loss: 0.38779109716415405, Valid Loss: 0.659397304058075\n",
      "Epoch: 6274, Train Loss: 0.387788861989975, Valid Loss: 0.6511627435684204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6275, Train Loss: 0.3877858817577362, Valid Loss: 0.6576892137527466\n",
      "Epoch: 6276, Train Loss: 0.3877835273742676, Valid Loss: 0.6536401510238647\n",
      "Epoch: 6277, Train Loss: 0.3877822458744049, Valid Loss: 0.6549503803253174\n",
      "Epoch: 6278, Train Loss: 0.38778290152549744, Valid Loss: 0.6564272046089172\n",
      "Epoch: 6279, Train Loss: 0.38778451085090637, Valid Loss: 0.6527200937271118\n",
      "Epoch: 6280, Train Loss: 0.38778552412986755, Valid Loss: 0.6579314470291138\n",
      "Epoch: 6281, Train Loss: 0.38778582215309143, Valid Loss: 0.6520197987556458\n",
      "Epoch: 6282, Train Loss: 0.38778531551361084, Valid Loss: 0.6578198075294495\n",
      "Epoch: 6283, Train Loss: 0.38778409361839294, Valid Loss: 0.6528873443603516\n",
      "Epoch: 6284, Train Loss: 0.3877826929092407, Valid Loss: 0.6565840840339661\n",
      "Epoch: 6285, Train Loss: 0.38778191804885864, Valid Loss: 0.6544677019119263\n",
      "Epoch: 6286, Train Loss: 0.3877810537815094, Valid Loss: 0.6549785137176514\n",
      "Epoch: 6287, Train Loss: 0.3877818286418915, Valid Loss: 0.6559069752693176\n",
      "Epoch: 6288, Train Loss: 0.3877822458744049, Valid Loss: 0.6538137793540955\n",
      "Epoch: 6289, Train Loss: 0.3877826929092407, Valid Loss: 0.6568086743354797\n",
      "Epoch: 6290, Train Loss: 0.38778263330459595, Valid Loss: 0.6534053683280945\n",
      "Epoch: 6291, Train Loss: 0.38778284192085266, Valid Loss: 0.6569611430168152\n",
      "Epoch: 6292, Train Loss: 0.3877825438976288, Valid Loss: 0.6536051034927368\n",
      "Epoch: 6293, Train Loss: 0.3877818286418915, Valid Loss: 0.6564592719078064\n",
      "Epoch: 6294, Train Loss: 0.3877812623977661, Valid Loss: 0.6542898416519165\n",
      "Epoch: 6295, Train Loss: 0.38778096437454224, Valid Loss: 0.6556878685951233\n",
      "Epoch: 6296, Train Loss: 0.3877808749675751, Valid Loss: 0.6551792621612549\n",
      "Epoch: 6297, Train Loss: 0.387781023979187, Valid Loss: 0.6548950672149658\n",
      "Epoch: 6298, Train Loss: 0.38778114318847656, Valid Loss: 0.6558949947357178\n",
      "Epoch: 6299, Train Loss: 0.38778117299079895, Valid Loss: 0.6543276309967041\n",
      "Epoch: 6300, Train Loss: 0.38778141140937805, Valid Loss: 0.6562886834144592\n",
      "Epoch: 6301, Train Loss: 0.3877810835838318, Valid Loss: 0.6541576385498047\n",
      "Epoch: 6302, Train Loss: 0.38778069615364075, Valid Loss: 0.656343400478363\n",
      "Epoch: 6303, Train Loss: 0.3877807557582855, Valid Loss: 0.6542949080467224\n",
      "Epoch: 6304, Train Loss: 0.38778069615364075, Valid Loss: 0.6561439633369446\n",
      "Epoch: 6305, Train Loss: 0.38778048753738403, Valid Loss: 0.6545878648757935\n",
      "Epoch: 6306, Train Loss: 0.38778018951416016, Valid Loss: 0.6557965278625488\n",
      "Epoch: 6307, Train Loss: 0.38778024911880493, Valid Loss: 0.6549979448318481\n",
      "Epoch: 6308, Train Loss: 0.3877805173397064, Valid Loss: 0.6554298996925354\n",
      "Epoch: 6309, Train Loss: 0.38778001070022583, Valid Loss: 0.655384361743927\n",
      "Epoch: 6310, Train Loss: 0.38777998089790344, Valid Loss: 0.6551357507705688\n",
      "Epoch: 6311, Train Loss: 0.38777995109558105, Valid Loss: 0.6556589007377625\n",
      "Epoch: 6312, Train Loss: 0.38777977228164673, Valid Loss: 0.654923677444458\n",
      "Epoch: 6313, Train Loss: 0.3877798020839691, Valid Loss: 0.6558409929275513\n",
      "Epoch: 6314, Train Loss: 0.3877798914909363, Valid Loss: 0.654822587966919\n",
      "Epoch: 6315, Train Loss: 0.38777956366539, Valid Loss: 0.6559502482414246\n",
      "Epoch: 6316, Train Loss: 0.3877796530723572, Valid Loss: 0.6547999382019043\n",
      "Epoch: 6317, Train Loss: 0.3877796530723572, Valid Loss: 0.6559543013572693\n",
      "Epoch: 6318, Train Loss: 0.3877793848514557, Valid Loss: 0.6548246145248413\n",
      "Epoch: 6319, Train Loss: 0.38778001070022583, Valid Loss: 0.6559416055679321\n",
      "Epoch: 6320, Train Loss: 0.38777923583984375, Valid Loss: 0.6548736691474915\n",
      "Epoch: 6321, Train Loss: 0.3877791464328766, Valid Loss: 0.6559179425239563\n",
      "Epoch: 6322, Train Loss: 0.38777920603752136, Valid Loss: 0.6549350023269653\n",
      "Epoch: 6323, Train Loss: 0.3877791464328766, Valid Loss: 0.6558665633201599\n",
      "Epoch: 6324, Train Loss: 0.3877788186073303, Valid Loss: 0.654997706413269\n",
      "Epoch: 6325, Train Loss: 0.3877789080142975, Valid Loss: 0.655833899974823\n",
      "Epoch: 6326, Train Loss: 0.3877788484096527, Valid Loss: 0.6550537943840027\n",
      "Epoch: 6327, Train Loss: 0.3877786695957184, Valid Loss: 0.6558213829994202\n",
      "Epoch: 6328, Train Loss: 0.38777878880500793, Valid Loss: 0.6550976037979126\n",
      "Epoch: 6329, Train Loss: 0.3877788186073303, Valid Loss: 0.6558058261871338\n",
      "Epoch: 6330, Train Loss: 0.38777849078178406, Valid Loss: 0.6551229357719421\n",
      "Epoch: 6331, Train Loss: 0.38777852058410645, Valid Loss: 0.6558145880699158\n",
      "Epoch: 6332, Train Loss: 0.38777852058410645, Valid Loss: 0.6551294922828674\n",
      "Epoch: 6333, Train Loss: 0.38777846097946167, Valid Loss: 0.6558446288108826\n",
      "Epoch: 6334, Train Loss: 0.38777828216552734, Valid Loss: 0.655110776424408\n",
      "Epoch: 6335, Train Loss: 0.38777807354927063, Valid Loss: 0.6559086441993713\n",
      "Epoch: 6336, Train Loss: 0.38777828216552734, Valid Loss: 0.6550213694572449\n",
      "Epoch: 6337, Train Loss: 0.3877779543399811, Valid Loss: 0.6560576558113098\n",
      "Epoch: 6338, Train Loss: 0.38777807354927063, Valid Loss: 0.6548592448234558\n",
      "Epoch: 6339, Train Loss: 0.38777777552604675, Valid Loss: 0.6562837362289429\n",
      "Epoch: 6340, Train Loss: 0.387778103351593, Valid Loss: 0.6546266674995422\n",
      "Epoch: 6341, Train Loss: 0.3877781629562378, Valid Loss: 0.6565826535224915\n",
      "Epoch: 6342, Train Loss: 0.38777828216552734, Valid Loss: 0.6542935967445374\n",
      "Epoch: 6343, Train Loss: 0.3877786695957184, Valid Loss: 0.6570203900337219\n",
      "Epoch: 6344, Train Loss: 0.3877788186073303, Valid Loss: 0.6537612080574036\n",
      "Epoch: 6345, Train Loss: 0.3877795338630676, Valid Loss: 0.6577345132827759\n",
      "Epoch: 6346, Train Loss: 0.3877808451652527, Valid Loss: 0.6528999209403992\n",
      "Epoch: 6347, Train Loss: 0.3877824544906616, Valid Loss: 0.6588534712791443\n",
      "Epoch: 6348, Train Loss: 0.3877851366996765, Valid Loss: 0.6515151858329773\n",
      "Epoch: 6349, Train Loss: 0.3877895176410675, Valid Loss: 0.6606788635253906\n",
      "Epoch: 6350, Train Loss: 0.3877967894077301, Valid Loss: 0.6492726802825928\n",
      "Epoch: 6351, Train Loss: 0.3878078758716583, Valid Loss: 0.6636396646499634\n",
      "Epoch: 6352, Train Loss: 0.38782593607902527, Valid Loss: 0.6456565260887146\n",
      "Epoch: 6353, Train Loss: 0.3878542184829712, Valid Loss: 0.6684910655021667\n",
      "Epoch: 6354, Train Loss: 0.38790202140808105, Valid Loss: 0.6398633718490601\n",
      "Epoch: 6355, Train Loss: 0.3879709839820862, Valid Loss: 0.6763314604759216\n",
      "Epoch: 6356, Train Loss: 0.3880857825279236, Valid Loss: 0.6311080455780029\n",
      "Epoch: 6357, Train Loss: 0.3882274925708771, Valid Loss: 0.6879759430885315\n",
      "Epoch: 6358, Train Loss: 0.38844263553619385, Valid Loss: 0.61991947889328\n",
      "Epoch: 6359, Train Loss: 0.3886016309261322, Valid Loss: 0.7010162472724915\n",
      "Epoch: 6360, Train Loss: 0.3887658715248108, Valid Loss: 0.6117817759513855\n",
      "Epoch: 6361, Train Loss: 0.38866040110588074, Valid Loss: 0.7041277885437012\n",
      "Epoch: 6362, Train Loss: 0.3884585201740265, Valid Loss: 0.6177794933319092\n",
      "Epoch: 6363, Train Loss: 0.3881131410598755, Valid Loss: 0.6849133372306824\n",
      "Epoch: 6364, Train Loss: 0.3878753185272217, Valid Loss: 0.6412513852119446\n",
      "Epoch: 6365, Train Loss: 0.3878052532672882, Valid Loss: 0.6540224552154541\n",
      "Epoch: 6366, Train Loss: 0.3878909945487976, Valid Loss: 0.6699464321136475\n",
      "Epoch: 6367, Train Loss: 0.3880506753921509, Valid Loss: 0.6321002244949341\n",
      "Epoch: 6368, Train Loss: 0.3881414532661438, Valid Loss: 0.685954749584198\n",
      "Epoch: 6369, Train Loss: 0.38812682032585144, Valid Loss: 0.6282150745391846\n",
      "Epoch: 6370, Train Loss: 0.38797998428344727, Valid Loss: 0.6780787110328674\n",
      "Epoch: 6371, Train Loss: 0.38784053921699524, Valid Loss: 0.6429319977760315\n",
      "Epoch: 6372, Train Loss: 0.38778334856033325, Valid Loss: 0.6554585099220276\n",
      "Epoch: 6373, Train Loss: 0.3878239095211029, Valid Loss: 0.6651584506034851\n",
      "Epoch: 6374, Train Loss: 0.38790756464004517, Valid Loss: 0.6381127834320068\n",
      "Epoch: 6375, Train Loss: 0.3879548907279968, Valid Loss: 0.6767958998680115\n",
      "Epoch: 6376, Train Loss: 0.38794004917144775, Valid Loss: 0.6363598704338074\n",
      "Epoch: 6377, Train Loss: 0.3878651261329651, Valid Loss: 0.6694417595863342\n",
      "Epoch: 6378, Train Loss: 0.3877980709075928, Valid Loss: 0.648582935333252\n",
      "Epoch: 6379, Train Loss: 0.38778042793273926, Valid Loss: 0.6530492305755615\n",
      "Epoch: 6380, Train Loss: 0.3878091871738434, Valid Loss: 0.6640663146972656\n",
      "Epoch: 6381, Train Loss: 0.38784927129745483, Valid Loss: 0.6425178647041321\n",
      "Epoch: 6382, Train Loss: 0.38786378502845764, Valid Loss: 0.6697798371315002\n",
      "Epoch: 6383, Train Loss: 0.3878486752510071, Valid Loss: 0.6432631611824036\n",
      "Epoch: 6384, Train Loss: 0.3878137469291687, Valid Loss: 0.6633540391921997\n",
      "Epoch: 6385, Train Loss: 0.38778626918792725, Valid Loss: 0.6519796848297119\n",
      "Epoch: 6386, Train Loss: 0.3877788782119751, Valid Loss: 0.653302788734436\n",
      "Epoch: 6387, Train Loss: 0.3877931833267212, Valid Loss: 0.6611285209655762\n",
      "Epoch: 6388, Train Loss: 0.38781365752220154, Valid Loss: 0.6467394828796387\n",
      "Epoch: 6389, Train Loss: 0.38782069087028503, Valid Loss: 0.6648082733154297\n",
      "Epoch: 6390, Train Loss: 0.3878121078014374, Valid Loss: 0.6467397809028625\n",
      "Epoch: 6391, Train Loss: 0.387793630361557, Valid Loss: 0.661426305770874\n",
      "Epoch: 6392, Train Loss: 0.38778001070022583, Valid Loss: 0.6523876190185547\n",
      "Epoch: 6393, Train Loss: 0.38777750730514526, Valid Loss: 0.6543811559677124\n",
      "Epoch: 6394, Train Loss: 0.3877841830253601, Valid Loss: 0.6590426564216614\n",
      "Epoch: 6395, Train Loss: 0.3877931535243988, Valid Loss: 0.649351954460144\n",
      "Epoch: 6396, Train Loss: 0.38779744505882263, Valid Loss: 0.6621865630149841\n",
      "Epoch: 6397, Train Loss: 0.3877950608730316, Valid Loss: 0.6489318609237671\n",
      "Epoch: 6398, Train Loss: 0.38778677582740784, Valid Loss: 0.6603471636772156\n",
      "Epoch: 6399, Train Loss: 0.387779176235199, Valid Loss: 0.6523855328559875\n",
      "Epoch: 6400, Train Loss: 0.3877759873867035, Valid Loss: 0.6556704640388489\n",
      "Epoch: 6401, Train Loss: 0.38777777552604675, Valid Loss: 0.6572424173355103\n",
      "Epoch: 6402, Train Loss: 0.3877817988395691, Valid Loss: 0.6516873240470886\n",
      "Epoch: 6403, Train Loss: 0.3877851665019989, Valid Loss: 0.6601515412330627\n",
      "Epoch: 6404, Train Loss: 0.3877854645252228, Valid Loss: 0.6505467295646667\n",
      "Epoch: 6405, Train Loss: 0.3877830505371094, Valid Loss: 0.6596217155456543\n",
      "Epoch: 6406, Train Loss: 0.38777920603752136, Valid Loss: 0.6523787975311279\n",
      "Epoch: 6407, Train Loss: 0.38777607679367065, Valid Loss: 0.6567809581756592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6408, Train Loss: 0.3877747356891632, Valid Loss: 0.6556974649429321\n",
      "Epoch: 6409, Train Loss: 0.38777661323547363, Valid Loss: 0.6537036895751953\n",
      "Epoch: 6410, Train Loss: 0.3877781331539154, Valid Loss: 0.6582974791526794\n",
      "Epoch: 6411, Train Loss: 0.38777950406074524, Valid Loss: 0.652152419090271\n",
      "Epoch: 6412, Train Loss: 0.38777968287467957, Valid Loss: 0.6587483286857605\n",
      "Epoch: 6413, Train Loss: 0.3877783715724945, Valid Loss: 0.6526639461517334\n",
      "Epoch: 6414, Train Loss: 0.38777679204940796, Valid Loss: 0.6574864387512207\n",
      "Epoch: 6415, Train Loss: 0.38777557015419006, Valid Loss: 0.6544475555419922\n",
      "Epoch: 6416, Train Loss: 0.38777482509613037, Valid Loss: 0.6556682586669922\n",
      "Epoch: 6417, Train Loss: 0.387774795293808, Valid Loss: 0.6562606692314148\n",
      "Epoch: 6418, Train Loss: 0.38777539134025574, Valid Loss: 0.654103696346283\n",
      "Epoch: 6419, Train Loss: 0.3877762258052826, Valid Loss: 0.6574164628982544\n",
      "Epoch: 6420, Train Loss: 0.38777631521224976, Valid Loss: 0.6534755825996399\n",
      "Epoch: 6421, Train Loss: 0.38777634501457214, Valid Loss: 0.6576499938964844\n",
      "Epoch: 6422, Train Loss: 0.38777586817741394, Valid Loss: 0.6538427472114563\n",
      "Epoch: 6423, Train Loss: 0.38777509331703186, Valid Loss: 0.656989336013794\n",
      "Epoch: 6424, Train Loss: 0.38777440786361694, Valid Loss: 0.6547342538833618\n",
      "Epoch: 6425, Train Loss: 0.3877742886543274, Valid Loss: 0.6559394598007202\n",
      "Epoch: 6426, Train Loss: 0.38777419924736023, Valid Loss: 0.655804455280304\n",
      "Epoch: 6427, Train Loss: 0.38777419924736023, Valid Loss: 0.6550180912017822\n",
      "Epoch: 6428, Train Loss: 0.3877743184566498, Valid Loss: 0.6566424369812012\n",
      "Epoch: 6429, Train Loss: 0.38777464628219604, Valid Loss: 0.6544811129570007\n",
      "Epoch: 6430, Train Loss: 0.38777437806129456, Valid Loss: 0.6569385528564453\n",
      "Epoch: 6431, Train Loss: 0.3877739906311035, Valid Loss: 0.6544265747070312\n",
      "Epoch: 6432, Train Loss: 0.38777419924736023, Valid Loss: 0.6567777395248413\n",
      "Epoch: 6433, Train Loss: 0.3877737820148468, Valid Loss: 0.654788076877594\n",
      "Epoch: 6434, Train Loss: 0.3877732455730438, Valid Loss: 0.6563503742218018\n",
      "Epoch: 6435, Train Loss: 0.3877732455730438, Valid Loss: 0.6553552150726318\n",
      "Epoch: 6436, Train Loss: 0.38777342438697815, Valid Loss: 0.6557902693748474\n",
      "Epoch: 6437, Train Loss: 0.3877734839916229, Valid Loss: 0.6559107899665833\n",
      "Epoch: 6438, Train Loss: 0.3877730667591095, Valid Loss: 0.6552975177764893\n",
      "Epoch: 6439, Train Loss: 0.3877732455730438, Valid Loss: 0.6563398241996765\n",
      "Epoch: 6440, Train Loss: 0.387773334980011, Valid Loss: 0.6550475358963013\n",
      "Epoch: 6441, Train Loss: 0.3877732455730438, Valid Loss: 0.6565414667129517\n",
      "Epoch: 6442, Train Loss: 0.3877730369567871, Valid Loss: 0.6549851894378662\n",
      "Epoch: 6443, Train Loss: 0.3877730965614319, Valid Loss: 0.6565325856208801\n",
      "Epoch: 6444, Train Loss: 0.38777294754981995, Valid Loss: 0.6550703644752502\n",
      "Epoch: 6445, Train Loss: 0.38777291774749756, Valid Loss: 0.6564143896102905\n",
      "Epoch: 6446, Train Loss: 0.38777273893356323, Valid Loss: 0.6552781462669373\n",
      "Epoch: 6447, Train Loss: 0.3877726197242737, Valid Loss: 0.6562464237213135\n",
      "Epoch: 6448, Train Loss: 0.38777297735214233, Valid Loss: 0.6554855108261108\n",
      "Epoch: 6449, Train Loss: 0.38777220249176025, Valid Loss: 0.6560590863227844\n",
      "Epoch: 6450, Train Loss: 0.3877722918987274, Valid Loss: 0.6556748151779175\n",
      "Epoch: 6451, Train Loss: 0.3877723217010498, Valid Loss: 0.6559008955955505\n",
      "Epoch: 6452, Train Loss: 0.3877720534801483, Valid Loss: 0.6558632850646973\n",
      "Epoch: 6453, Train Loss: 0.38777226209640503, Valid Loss: 0.6557473540306091\n",
      "Epoch: 6454, Train Loss: 0.3877720236778259, Valid Loss: 0.6560215950012207\n",
      "Epoch: 6455, Train Loss: 0.3877720236778259, Valid Loss: 0.6556488871574402\n",
      "Epoch: 6456, Train Loss: 0.3877719044685364, Valid Loss: 0.6561146378517151\n",
      "Epoch: 6457, Train Loss: 0.3877717852592468, Valid Loss: 0.6555942296981812\n",
      "Epoch: 6458, Train Loss: 0.3877718150615692, Valid Loss: 0.6561651825904846\n",
      "Epoch: 6459, Train Loss: 0.3877716362476349, Valid Loss: 0.6555941700935364\n",
      "Epoch: 6460, Train Loss: 0.38777151703834534, Valid Loss: 0.6561980247497559\n",
      "Epoch: 6461, Train Loss: 0.3877713978290558, Valid Loss: 0.6555862426757812\n",
      "Epoch: 6462, Train Loss: 0.3877720236778259, Valid Loss: 0.6562319397926331\n",
      "Epoch: 6463, Train Loss: 0.3877715468406677, Valid Loss: 0.6555745601654053\n",
      "Epoch: 6464, Train Loss: 0.38777101039886475, Valid Loss: 0.6562623381614685\n",
      "Epoch: 6465, Train Loss: 0.3877711892127991, Valid Loss: 0.6555649638175964\n",
      "Epoch: 6466, Train Loss: 0.38777121901512146, Valid Loss: 0.6563044786453247\n",
      "Epoch: 6467, Train Loss: 0.38777124881744385, Valid Loss: 0.6555451154708862\n",
      "Epoch: 6468, Train Loss: 0.3877711892127991, Valid Loss: 0.6563552021980286\n",
      "Epoch: 6469, Train Loss: 0.3877710998058319, Valid Loss: 0.6555066108703613\n",
      "Epoch: 6470, Train Loss: 0.3877708315849304, Valid Loss: 0.6564338803291321\n",
      "Epoch: 6471, Train Loss: 0.3877709209918976, Valid Loss: 0.6554433703422546\n",
      "Epoch: 6472, Train Loss: 0.38777095079421997, Valid Loss: 0.6565380692481995\n",
      "Epoch: 6473, Train Loss: 0.38777074217796326, Valid Loss: 0.655325710773468\n",
      "Epoch: 6474, Train Loss: 0.3877708315849304, Valid Loss: 0.6567124724388123\n",
      "Epoch: 6475, Train Loss: 0.38777101039886475, Valid Loss: 0.6551359295845032\n",
      "Epoch: 6476, Train Loss: 0.38777127861976624, Valid Loss: 0.6569711565971375\n",
      "Epoch: 6477, Train Loss: 0.3877711892127991, Valid Loss: 0.6548507809638977\n",
      "Epoch: 6478, Train Loss: 0.3877713680267334, Valid Loss: 0.6573410034179688\n",
      "Epoch: 6479, Train Loss: 0.38777151703834534, Valid Loss: 0.6544148325920105\n",
      "Epoch: 6480, Train Loss: 0.387771874666214, Valid Loss: 0.6579309105873108\n",
      "Epoch: 6481, Train Loss: 0.3877725601196289, Valid Loss: 0.6536905765533447\n",
      "Epoch: 6482, Train Loss: 0.38777410984039307, Valid Loss: 0.6588795185089111\n",
      "Epoch: 6483, Train Loss: 0.38777580857276917, Valid Loss: 0.652540385723114\n",
      "Epoch: 6484, Train Loss: 0.3877785801887512, Valid Loss: 0.660367488861084\n",
      "Epoch: 6485, Train Loss: 0.38778337836265564, Valid Loss: 0.6507341861724854\n",
      "Epoch: 6486, Train Loss: 0.3877905011177063, Valid Loss: 0.662738025188446\n",
      "Epoch: 6487, Train Loss: 0.38780221343040466, Valid Loss: 0.6478257179260254\n",
      "Epoch: 6488, Train Loss: 0.3878202438354492, Valid Loss: 0.6665796041488647\n",
      "Epoch: 6489, Train Loss: 0.3878510892391205, Valid Loss: 0.6431995630264282\n",
      "Epoch: 6490, Train Loss: 0.3878953456878662, Valid Loss: 0.6728013753890991\n",
      "Epoch: 6491, Train Loss: 0.38797086477279663, Valid Loss: 0.6360167264938354\n",
      "Epoch: 6492, Train Loss: 0.38807082176208496, Valid Loss: 0.682426929473877\n",
      "Epoch: 6493, Train Loss: 0.388233482837677, Valid Loss: 0.6259417533874512\n",
      "Epoch: 6494, Train Loss: 0.3883969187736511, Valid Loss: 0.6951754093170166\n",
      "Epoch: 6495, Train Loss: 0.3886200785636902, Valid Loss: 0.6154740452766418\n",
      "Epoch: 6496, Train Loss: 0.38868463039398193, Valid Loss: 0.7049151659011841\n",
      "Epoch: 6497, Train Loss: 0.38869062066078186, Valid Loss: 0.6131161451339722\n",
      "Epoch: 6498, Train Loss: 0.3884194791316986, Valid Loss: 0.6978116035461426\n",
      "Epoch: 6499, Train Loss: 0.38812506198883057, Valid Loss: 0.62788987159729\n",
      "Epoch: 6500, Train Loss: 0.387869656085968, Valid Loss: 0.6708755493164062\n",
      "Epoch: 6501, Train Loss: 0.38778653740882874, Valid Loss: 0.6553183197975159\n",
      "Epoch: 6502, Train Loss: 0.38786283135414124, Valid Loss: 0.6427180767059326\n",
      "Epoch: 6503, Train Loss: 0.38800907135009766, Valid Loss: 0.6799068450927734\n",
      "Epoch: 6504, Train Loss: 0.38813304901123047, Valid Loss: 0.6285517811775208\n",
      "Epoch: 6505, Train Loss: 0.3881119191646576, Valid Loss: 0.6856943368911743\n",
      "Epoch: 6506, Train Loss: 0.38800254464149475, Valid Loss: 0.633108377456665\n",
      "Epoch: 6507, Train Loss: 0.3878540098667145, Valid Loss: 0.6699495911598206\n",
      "Epoch: 6508, Train Loss: 0.3877774178981781, Valid Loss: 0.6522110104560852\n",
      "Epoch: 6509, Train Loss: 0.3877967894077301, Valid Loss: 0.6481612920761108\n",
      "Epoch: 6510, Train Loss: 0.38787198066711426, Valid Loss: 0.6714347004890442\n",
      "Epoch: 6511, Train Loss: 0.3879377841949463, Valid Loss: 0.6364774107933044\n",
      "Epoch: 6512, Train Loss: 0.3879348933696747, Valid Loss: 0.6762863397598267\n",
      "Epoch: 6513, Train Loss: 0.38788145780563354, Valid Loss: 0.6399010419845581\n",
      "Epoch: 6514, Train Loss: 0.38780930638313293, Valid Loss: 0.6648989319801331\n",
      "Epoch: 6515, Train Loss: 0.3877716064453125, Valid Loss: 0.6539895534515381\n",
      "Epoch: 6516, Train Loss: 0.3877840042114258, Valid Loss: 0.6495888233184814\n",
      "Epoch: 6517, Train Loss: 0.3878226578235626, Valid Loss: 0.6673097014427185\n",
      "Epoch: 6518, Train Loss: 0.38785240054130554, Valid Loss: 0.6421851515769958\n",
      "Epoch: 6519, Train Loss: 0.3878483176231384, Valid Loss: 0.6694580316543579\n",
      "Epoch: 6520, Train Loss: 0.3878207504749298, Valid Loss: 0.6453423500061035\n",
      "Epoch: 6521, Train Loss: 0.387787789106369, Valid Loss: 0.6614077687263489\n",
      "Epoch: 6522, Train Loss: 0.3877717852592468, Valid Loss: 0.6548470258712769\n",
      "Epoch: 6523, Train Loss: 0.38777637481689453, Valid Loss: 0.6517376899719238\n",
      "Epoch: 6524, Train Loss: 0.3877934217453003, Valid Loss: 0.6631230115890503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6525, Train Loss: 0.3878077268600464, Valid Loss: 0.6466506719589233\n",
      "Epoch: 6526, Train Loss: 0.387808620929718, Valid Loss: 0.664984941482544\n",
      "Epoch: 6527, Train Loss: 0.38779690861701965, Valid Loss: 0.6481647491455078\n",
      "Epoch: 6528, Train Loss: 0.3877808749675751, Valid Loss: 0.660523533821106\n",
      "Epoch: 6529, Train Loss: 0.3877699673175812, Valid Loss: 0.654152512550354\n",
      "Epoch: 6530, Train Loss: 0.3877703547477722, Valid Loss: 0.6538922190666199\n",
      "Epoch: 6531, Train Loss: 0.38777822256088257, Valid Loss: 0.6601366996765137\n",
      "Epoch: 6532, Train Loss: 0.3877863585948944, Valid Loss: 0.6497254371643066\n",
      "Epoch: 6533, Train Loss: 0.38778865337371826, Valid Loss: 0.6623979210853577\n",
      "Epoch: 6534, Train Loss: 0.38778477907180786, Valid Loss: 0.6498860120773315\n",
      "Epoch: 6535, Train Loss: 0.3877773582935333, Valid Loss: 0.6602007150650024\n",
      "Epoch: 6536, Train Loss: 0.3877708911895752, Valid Loss: 0.653445303440094\n",
      "Epoch: 6537, Train Loss: 0.3877686858177185, Valid Loss: 0.6558823585510254\n",
      "Epoch: 6538, Train Loss: 0.38777029514312744, Valid Loss: 0.6577602624893188\n",
      "Epoch: 6539, Train Loss: 0.38777396082878113, Valid Loss: 0.6523826122283936\n",
      "Epoch: 6540, Train Loss: 0.38777676224708557, Valid Loss: 0.6602287888526917\n",
      "Epoch: 6541, Train Loss: 0.3877774775028229, Valid Loss: 0.651339590549469\n",
      "Epoch: 6542, Train Loss: 0.3877750039100647, Valid Loss: 0.6599525213241577\n",
      "Epoch: 6543, Train Loss: 0.3877720534801483, Valid Loss: 0.6528249979019165\n",
      "Epoch: 6544, Train Loss: 0.38776901364326477, Valid Loss: 0.6576064825057983\n",
      "Epoch: 6545, Train Loss: 0.38776805996894836, Valid Loss: 0.6556612253189087\n",
      "Epoch: 6546, Train Loss: 0.3877684473991394, Valid Loss: 0.6547772288322449\n",
      "Epoch: 6547, Train Loss: 0.3877696692943573, Valid Loss: 0.6582026481628418\n",
      "Epoch: 6548, Train Loss: 0.38777127861976624, Valid Loss: 0.653008222579956\n",
      "Epoch: 6549, Train Loss: 0.3877720534801483, Valid Loss: 0.659136950969696\n",
      "Epoch: 6550, Train Loss: 0.38777101039886475, Valid Loss: 0.6529895067214966\n",
      "Epoch: 6551, Train Loss: 0.3877699077129364, Valid Loss: 0.6583654284477234\n",
      "Epoch: 6552, Train Loss: 0.38776835799217224, Valid Loss: 0.6544023752212524\n",
      "Epoch: 6553, Train Loss: 0.3877674639225006, Valid Loss: 0.6566864252090454\n",
      "Epoch: 6554, Train Loss: 0.3877670466899872, Valid Loss: 0.6562203764915466\n",
      "Epoch: 6555, Train Loss: 0.3877674341201782, Valid Loss: 0.6550592184066772\n",
      "Epoch: 6556, Train Loss: 0.38776788115501404, Valid Loss: 0.6575791835784912\n",
      "Epoch: 6557, Train Loss: 0.38776853680610657, Valid Loss: 0.6541573405265808\n",
      "Epoch: 6558, Train Loss: 0.3877686858177185, Valid Loss: 0.6580810546875\n",
      "Epoch: 6559, Train Loss: 0.38776853680610657, Valid Loss: 0.6541597843170166\n",
      "Epoch: 6560, Train Loss: 0.38776808977127075, Valid Loss: 0.6577385067939758\n",
      "Epoch: 6561, Train Loss: 0.3877677023410797, Valid Loss: 0.6548382043838501\n",
      "Epoch: 6562, Train Loss: 0.3877670168876648, Valid Loss: 0.6569167971611023\n",
      "Epoch: 6563, Train Loss: 0.387766569852829, Valid Loss: 0.6557782888412476\n",
      "Epoch: 6564, Train Loss: 0.38776645064353943, Valid Loss: 0.6559860706329346\n",
      "Epoch: 6565, Train Loss: 0.3877660632133484, Valid Loss: 0.6566705107688904\n",
      "Epoch: 6566, Train Loss: 0.38776662945747375, Valid Loss: 0.6552857756614685\n",
      "Epoch: 6567, Train Loss: 0.3877670168876648, Valid Loss: 0.6572233438491821\n",
      "Epoch: 6568, Train Loss: 0.38776707649230957, Valid Loss: 0.6549726128578186\n",
      "Epoch: 6569, Train Loss: 0.38776659965515137, Valid Loss: 0.6573349833488464\n",
      "Epoch: 6570, Train Loss: 0.38776686787605286, Valid Loss: 0.6550554037094116\n",
      "Epoch: 6571, Train Loss: 0.38776668906211853, Valid Loss: 0.6571445465087891\n",
      "Epoch: 6572, Train Loss: 0.3877657949924469, Valid Loss: 0.6554070115089417\n",
      "Epoch: 6573, Train Loss: 0.3877659738063812, Valid Loss: 0.6567767262458801\n",
      "Epoch: 6574, Train Loss: 0.38776594400405884, Valid Loss: 0.6558479070663452\n",
      "Epoch: 6575, Train Loss: 0.3877655267715454, Valid Loss: 0.6563202142715454\n",
      "Epoch: 6576, Train Loss: 0.3877659738063812, Valid Loss: 0.6563247442245483\n",
      "Epoch: 6577, Train Loss: 0.3877657353878021, Valid Loss: 0.6559312343597412\n",
      "Epoch: 6578, Train Loss: 0.3877657949924469, Valid Loss: 0.6566959619522095\n",
      "Epoch: 6579, Train Loss: 0.3877655267715454, Valid Loss: 0.6556606292724609\n",
      "Epoch: 6580, Train Loss: 0.38776543736457825, Valid Loss: 0.6569327712059021\n",
      "Epoch: 6581, Train Loss: 0.38776513934135437, Valid Loss: 0.6555129289627075\n",
      "Epoch: 6582, Train Loss: 0.38776546716690063, Valid Loss: 0.6570473313331604\n",
      "Epoch: 6583, Train Loss: 0.3877653479576111, Valid Loss: 0.6555116772651672\n",
      "Epoch: 6584, Train Loss: 0.38776540756225586, Valid Loss: 0.6570162177085876\n",
      "Epoch: 6585, Train Loss: 0.3877652883529663, Valid Loss: 0.6556135416030884\n",
      "Epoch: 6586, Train Loss: 0.3877653479576111, Valid Loss: 0.6569246053695679\n",
      "Epoch: 6587, Train Loss: 0.38776519894599915, Valid Loss: 0.6557402610778809\n",
      "Epoch: 6588, Train Loss: 0.38776493072509766, Valid Loss: 0.6567972302436829\n",
      "Epoch: 6589, Train Loss: 0.38776496052742004, Valid Loss: 0.6559053063392639\n",
      "Epoch: 6590, Train Loss: 0.3877648711204529, Valid Loss: 0.6566494703292847\n",
      "Epoch: 6591, Train Loss: 0.3877646327018738, Valid Loss: 0.6560820937156677\n",
      "Epoch: 6592, Train Loss: 0.38776344060897827, Valid Loss: 0.6565113067626953\n",
      "Epoch: 6593, Train Loss: 0.38776442408561707, Valid Loss: 0.6562256813049316\n",
      "Epoch: 6594, Train Loss: 0.3877643346786499, Valid Loss: 0.6564116477966309\n",
      "Epoch: 6595, Train Loss: 0.3877642750740051, Valid Loss: 0.6563244462013245\n",
      "Epoch: 6596, Train Loss: 0.38776442408561707, Valid Loss: 0.6563575267791748\n",
      "Epoch: 6597, Train Loss: 0.3877643942832947, Valid Loss: 0.6563899517059326\n",
      "Epoch: 6598, Train Loss: 0.38776424527168274, Valid Loss: 0.6563273072242737\n",
      "Epoch: 6599, Train Loss: 0.387764036655426, Valid Loss: 0.6564610004425049\n",
      "Epoch: 6600, Train Loss: 0.38776394724845886, Valid Loss: 0.6562705039978027\n",
      "Epoch: 6601, Train Loss: 0.387763649225235, Valid Loss: 0.6565260887145996\n",
      "Epoch: 6602, Train Loss: 0.3877638280391693, Valid Loss: 0.6562467813491821\n",
      "Epoch: 6603, Train Loss: 0.38776370882987976, Valid Loss: 0.656575620174408\n",
      "Epoch: 6604, Train Loss: 0.3877641558647156, Valid Loss: 0.6562256813049316\n",
      "Epoch: 6605, Train Loss: 0.3877638280391693, Valid Loss: 0.6566168069839478\n",
      "Epoch: 6606, Train Loss: 0.3877638876438141, Valid Loss: 0.6561979651451111\n",
      "Epoch: 6607, Train Loss: 0.3877638876438141, Valid Loss: 0.6566680073738098\n",
      "Epoch: 6608, Train Loss: 0.3877634108066559, Valid Loss: 0.6561424732208252\n",
      "Epoch: 6609, Train Loss: 0.38776353001594543, Valid Loss: 0.6567826271057129\n",
      "Epoch: 6610, Train Loss: 0.38776347041130066, Valid Loss: 0.6560310125350952\n",
      "Epoch: 6611, Train Loss: 0.38776347041130066, Valid Loss: 0.6569409966468811\n",
      "Epoch: 6612, Train Loss: 0.3877640664577484, Valid Loss: 0.6558718085289001\n",
      "Epoch: 6613, Train Loss: 0.38776350021362305, Valid Loss: 0.6571404337882996\n",
      "Epoch: 6614, Train Loss: 0.38776347041130066, Valid Loss: 0.6556493639945984\n",
      "Epoch: 6615, Train Loss: 0.38776353001594543, Valid Loss: 0.6574603915214539\n",
      "Epoch: 6616, Train Loss: 0.3877635598182678, Valid Loss: 0.6552698016166687\n",
      "Epoch: 6617, Train Loss: 0.38776445388793945, Valid Loss: 0.6579657196998596\n",
      "Epoch: 6618, Train Loss: 0.3877643942832947, Valid Loss: 0.6546598076820374\n",
      "Epoch: 6619, Train Loss: 0.387765109539032, Valid Loss: 0.658765971660614\n",
      "Epoch: 6620, Train Loss: 0.3877665400505066, Valid Loss: 0.653666079044342\n",
      "Epoch: 6621, Train Loss: 0.38776880502700806, Valid Loss: 0.660084068775177\n",
      "Epoch: 6622, Train Loss: 0.38777220249176025, Valid Loss: 0.6520397067070007\n",
      "Epoch: 6623, Train Loss: 0.38777828216552734, Valid Loss: 0.6622649431228638\n",
      "Epoch: 6624, Train Loss: 0.3877880275249481, Valid Loss: 0.6493093371391296\n",
      "Epoch: 6625, Train Loss: 0.3878038823604584, Valid Loss: 0.6659282445907593\n",
      "Epoch: 6626, Train Loss: 0.3878316283226013, Valid Loss: 0.6447802186012268\n",
      "Epoch: 6627, Train Loss: 0.3878747820854187, Valid Loss: 0.6721376776695251\n",
      "Epoch: 6628, Train Loss: 0.3879503309726715, Valid Loss: 0.6373967528343201\n",
      "Epoch: 6629, Train Loss: 0.38805726170539856, Valid Loss: 0.6823331713676453\n",
      "Epoch: 6630, Train Loss: 0.3882402777671814, Valid Loss: 0.626325249671936\n",
      "Epoch: 6631, Train Loss: 0.38844063878059387, Valid Loss: 0.6970195174217224\n",
      "Epoch: 6632, Train Loss: 0.3887338638305664, Valid Loss: 0.6136141419410706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6633, Train Loss: 0.38884854316711426, Valid Loss: 0.7101200222969055\n",
      "Epoch: 6634, Train Loss: 0.3889033794403076, Valid Loss: 0.6090255379676819\n",
      "Epoch: 6635, Train Loss: 0.38857680559158325, Valid Loss: 0.7039515972137451\n",
      "Epoch: 6636, Train Loss: 0.38821765780448914, Valid Loss: 0.6249021887779236\n",
      "Epoch: 6637, Train Loss: 0.3878996670246124, Valid Loss: 0.6727461814880371\n",
      "Epoch: 6638, Train Loss: 0.38780614733695984, Valid Loss: 0.6565710306167603\n",
      "Epoch: 6639, Train Loss: 0.3879111111164093, Valid Loss: 0.6402890682220459\n",
      "Epoch: 6640, Train Loss: 0.38809436559677124, Valid Loss: 0.6848210692405701\n",
      "Epoch: 6641, Train Loss: 0.3882327377796173, Valid Loss: 0.6255287528038025\n",
      "Epoch: 6642, Train Loss: 0.3881519138813019, Valid Loss: 0.688707709312439\n",
      "Epoch: 6643, Train Loss: 0.3879740238189697, Valid Loss: 0.6339936852455139\n",
      "Epoch: 6644, Train Loss: 0.3878101110458374, Valid Loss: 0.6658971905708313\n",
      "Epoch: 6645, Train Loss: 0.3877788186073303, Valid Loss: 0.6591748595237732\n",
      "Epoch: 6646, Train Loss: 0.3878598213195801, Valid Loss: 0.6408759355545044\n",
      "Epoch: 6647, Train Loss: 0.3879580795764923, Valid Loss: 0.6790413856506348\n",
      "Epoch: 6648, Train Loss: 0.38799408078193665, Valid Loss: 0.6338444352149963\n",
      "Epoch: 6649, Train Loss: 0.38791748881340027, Valid Loss: 0.6755317449569702\n",
      "Epoch: 6650, Train Loss: 0.38781777024269104, Valid Loss: 0.645500123500824\n",
      "Epoch: 6651, Train Loss: 0.38777071237564087, Valid Loss: 0.6564146280288696\n",
      "Epoch: 6652, Train Loss: 0.38779303431510925, Valid Loss: 0.6637312173843384\n",
      "Epoch: 6653, Train Loss: 0.38784196972846985, Valid Loss: 0.6424291729927063\n",
      "Epoch: 6654, Train Loss: 0.38787052035331726, Valid Loss: 0.6723846197128296\n",
      "Epoch: 6655, Train Loss: 0.3878621459007263, Valid Loss: 0.642719566822052\n",
      "Epoch: 6656, Train Loss: 0.3878146708011627, Valid Loss: 0.6655963659286499\n",
      "Epoch: 6657, Train Loss: 0.38777294754981995, Valid Loss: 0.652568519115448\n",
      "Epoch: 6658, Train Loss: 0.3877659738063812, Valid Loss: 0.6534064412117004\n",
      "Epoch: 6659, Train Loss: 0.38779088854789734, Valid Loss: 0.6629453897476196\n",
      "Epoch: 6660, Train Loss: 0.3878173828125, Valid Loss: 0.6459440588951111\n",
      "Epoch: 6661, Train Loss: 0.3878193199634552, Valid Loss: 0.6672396659851074\n",
      "Epoch: 6662, Train Loss: 0.3878013491630554, Valid Loss: 0.6471524238586426\n",
      "Epoch: 6663, Train Loss: 0.38777604699134827, Valid Loss: 0.6617977023124695\n",
      "Epoch: 6664, Train Loss: 0.3877648413181305, Valid Loss: 0.6548217535018921\n",
      "Epoch: 6665, Train Loss: 0.3877694606781006, Valid Loss: 0.6524682641029358\n",
      "Epoch: 6666, Train Loss: 0.38778311014175415, Valid Loss: 0.6623731255531311\n",
      "Epoch: 6667, Train Loss: 0.3877928555011749, Valid Loss: 0.6481468677520752\n",
      "Epoch: 6668, Train Loss: 0.3877895176410675, Valid Loss: 0.6642431616783142\n",
      "Epoch: 6669, Train Loss: 0.3877779245376587, Valid Loss: 0.650126576423645\n",
      "Epoch: 6670, Train Loss: 0.38776686787605286, Valid Loss: 0.659573495388031\n",
      "Epoch: 6671, Train Loss: 0.3877622187137604, Valid Loss: 0.6558083295822144\n",
      "Epoch: 6672, Train Loss: 0.3877662718296051, Valid Loss: 0.6528729200363159\n",
      "Epoch: 6673, Train Loss: 0.3877732753753662, Valid Loss: 0.6615468859672546\n",
      "Epoch: 6674, Train Loss: 0.3877778649330139, Valid Loss: 0.6500244140625\n",
      "Epoch: 6675, Train Loss: 0.3877752721309662, Valid Loss: 0.6622478365898132\n",
      "Epoch: 6676, Train Loss: 0.38776895403862, Valid Loss: 0.6520684957504272\n",
      "Epoch: 6677, Train Loss: 0.38776323199272156, Valid Loss: 0.6581225395202637\n",
      "Epoch: 6678, Train Loss: 0.3877616822719574, Valid Loss: 0.6563836932182312\n",
      "Epoch: 6679, Train Loss: 0.3877636790275574, Valid Loss: 0.6538307070732117\n",
      "Epoch: 6680, Train Loss: 0.38776642084121704, Valid Loss: 0.6599833965301514\n",
      "Epoch: 6681, Train Loss: 0.3877687454223633, Valid Loss: 0.6522124409675598\n",
      "Epoch: 6682, Train Loss: 0.3877682089805603, Valid Loss: 0.6603540182113647\n",
      "Epoch: 6683, Train Loss: 0.38776513934135437, Valid Loss: 0.6532835960388184\n",
      "Epoch: 6684, Train Loss: 0.38776230812072754, Valid Loss: 0.6579369306564331\n",
      "Epoch: 6685, Train Loss: 0.38776081800460815, Valid Loss: 0.6559063196182251\n",
      "Epoch: 6686, Train Loss: 0.38776111602783203, Valid Loss: 0.6553755402565002\n",
      "Epoch: 6687, Train Loss: 0.3877623379230499, Valid Loss: 0.6583322286605835\n",
      "Epoch: 6688, Train Loss: 0.3877638578414917, Valid Loss: 0.6539080739021301\n",
      "Epoch: 6689, Train Loss: 0.3877640962600708, Valid Loss: 0.6591997742652893\n",
      "Epoch: 6690, Train Loss: 0.38776329159736633, Valid Loss: 0.6537916660308838\n",
      "Epoch: 6691, Train Loss: 0.38776180148124695, Valid Loss: 0.6583061218261719\n",
      "Epoch: 6692, Train Loss: 0.38776078820228577, Valid Loss: 0.6552370190620422\n",
      "Epoch: 6693, Train Loss: 0.3877604007720947, Valid Loss: 0.6567143201828003\n",
      "Epoch: 6694, Train Loss: 0.3877602517604828, Valid Loss: 0.6570703387260437\n",
      "Epoch: 6695, Train Loss: 0.38776087760925293, Valid Loss: 0.6553035974502563\n",
      "Epoch: 6696, Train Loss: 0.38776129484176636, Valid Loss: 0.6581223011016846\n",
      "Epoch: 6697, Train Loss: 0.3877611756324768, Valid Loss: 0.6545810699462891\n",
      "Epoch: 6698, Train Loss: 0.3877612352371216, Valid Loss: 0.6582987308502197\n",
      "Epoch: 6699, Train Loss: 0.3877602517604828, Valid Loss: 0.6549989581108093\n",
      "Epoch: 6700, Train Loss: 0.38776007294654846, Valid Loss: 0.6575908660888672\n",
      "Epoch: 6701, Train Loss: 0.3877594470977783, Valid Loss: 0.6561554670333862\n",
      "Epoch: 6702, Train Loss: 0.38775941729545593, Valid Loss: 0.6563799977302551\n",
      "Epoch: 6703, Train Loss: 0.3877597451210022, Valid Loss: 0.6571817994117737\n",
      "Epoch: 6704, Train Loss: 0.38775959610939026, Valid Loss: 0.6555270552635193\n",
      "Epoch: 6705, Train Loss: 0.38775983452796936, Valid Loss: 0.6577301025390625\n",
      "Epoch: 6706, Train Loss: 0.3877597153186798, Valid Loss: 0.6553874015808105\n",
      "Epoch: 6707, Train Loss: 0.3877595067024231, Valid Loss: 0.6577153205871582\n",
      "Epoch: 6708, Train Loss: 0.38775956630706787, Valid Loss: 0.6557053923606873\n",
      "Epoch: 6709, Train Loss: 0.38775911927223206, Valid Loss: 0.6572219133377075\n",
      "Epoch: 6710, Train Loss: 0.38775864243507385, Valid Loss: 0.6562319993972778\n",
      "Epoch: 6711, Train Loss: 0.3877587616443634, Valid Loss: 0.6566789746284485\n",
      "Epoch: 6712, Train Loss: 0.38775885105133057, Valid Loss: 0.6568058133125305\n",
      "Epoch: 6713, Train Loss: 0.38775888085365295, Valid Loss: 0.6562831401824951\n",
      "Epoch: 6714, Train Loss: 0.38775885105133057, Valid Loss: 0.6572059392929077\n",
      "Epoch: 6715, Train Loss: 0.3877587616443634, Valid Loss: 0.656015157699585\n",
      "Epoch: 6716, Train Loss: 0.3877588212490082, Valid Loss: 0.6573340892791748\n",
      "Epoch: 6717, Train Loss: 0.38775885105133057, Valid Loss: 0.655994713306427\n",
      "Epoch: 6718, Train Loss: 0.387758731842041, Valid Loss: 0.657299816608429\n",
      "Epoch: 6719, Train Loss: 0.38775837421417236, Valid Loss: 0.656191885471344\n",
      "Epoch: 6720, Train Loss: 0.38775840401649475, Valid Loss: 0.6571150422096252\n",
      "Epoch: 6721, Train Loss: 0.38775834441185, Valid Loss: 0.656444251537323\n",
      "Epoch: 6722, Train Loss: 0.3877580463886261, Valid Loss: 0.656843900680542\n",
      "Epoch: 6723, Train Loss: 0.38775816559791565, Valid Loss: 0.656724214553833\n",
      "Epoch: 6724, Train Loss: 0.3877578675746918, Valid Loss: 0.6565792560577393\n",
      "Epoch: 6725, Train Loss: 0.3877578377723694, Valid Loss: 0.6570188999176025\n",
      "Epoch: 6726, Train Loss: 0.38775748014450073, Valid Loss: 0.6563946604728699\n",
      "Epoch: 6727, Train Loss: 0.3877580463886261, Valid Loss: 0.6571937799453735\n",
      "Epoch: 6728, Train Loss: 0.3877575695514679, Valid Loss: 0.6562972068786621\n",
      "Epoch: 6729, Train Loss: 0.38775768876075745, Valid Loss: 0.6572126150131226\n",
      "Epoch: 6730, Train Loss: 0.38775748014450073, Valid Loss: 0.6563289165496826\n",
      "Epoch: 6731, Train Loss: 0.3877575397491455, Valid Loss: 0.6571844220161438\n",
      "Epoch: 6732, Train Loss: 0.3877575099468231, Valid Loss: 0.6564293503761292\n",
      "Epoch: 6733, Train Loss: 0.3877573013305664, Valid Loss: 0.6571217179298401\n",
      "Epoch: 6734, Train Loss: 0.3877573311328888, Valid Loss: 0.6565273404121399\n",
      "Epoch: 6735, Train Loss: 0.3877573013305664, Valid Loss: 0.6570069193840027\n",
      "Epoch: 6736, Train Loss: 0.38775739073753357, Valid Loss: 0.6566469073295593\n",
      "Epoch: 6737, Train Loss: 0.38775742053985596, Valid Loss: 0.6569437980651855\n",
      "Epoch: 6738, Train Loss: 0.38775715231895447, Valid Loss: 0.6567450761795044\n",
      "Epoch: 6739, Train Loss: 0.3877567946910858, Valid Loss: 0.6568929553031921\n",
      "Epoch: 6740, Train Loss: 0.3877567946910858, Valid Loss: 0.6568254232406616\n",
      "Epoch: 6741, Train Loss: 0.3877567946910858, Valid Loss: 0.6568134427070618\n",
      "Epoch: 6742, Train Loss: 0.3877568542957306, Valid Loss: 0.6569094657897949\n",
      "Epoch: 6743, Train Loss: 0.3877567946910858, Valid Loss: 0.6567662954330444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6744, Train Loss: 0.3877566456794739, Valid Loss: 0.656985342502594\n",
      "Epoch: 6745, Train Loss: 0.3877566456794739, Valid Loss: 0.6567256450653076\n",
      "Epoch: 6746, Train Loss: 0.38775643706321716, Valid Loss: 0.6570443511009216\n",
      "Epoch: 6747, Train Loss: 0.3877564072608948, Valid Loss: 0.6566841006278992\n",
      "Epoch: 6748, Train Loss: 0.38775649666786194, Valid Loss: 0.6570830345153809\n",
      "Epoch: 6749, Train Loss: 0.38775634765625, Valid Loss: 0.6566831469535828\n",
      "Epoch: 6750, Train Loss: 0.3877566456794739, Valid Loss: 0.6571061611175537\n",
      "Epoch: 6751, Train Loss: 0.3877561688423157, Valid Loss: 0.6566948890686035\n",
      "Epoch: 6752, Train Loss: 0.3877560496330261, Valid Loss: 0.6571275591850281\n",
      "Epoch: 6753, Train Loss: 0.3877560794353485, Valid Loss: 0.6566819548606873\n",
      "Epoch: 6754, Train Loss: 0.3877560794353485, Valid Loss: 0.6571806073188782\n",
      "Epoch: 6755, Train Loss: 0.38775578141212463, Valid Loss: 0.6566089391708374\n",
      "Epoch: 6756, Train Loss: 0.38775596022605896, Valid Loss: 0.6573089361190796\n",
      "Epoch: 6757, Train Loss: 0.3877556622028351, Valid Loss: 0.6564937829971313\n",
      "Epoch: 6758, Train Loss: 0.38775578141212463, Valid Loss: 0.6574752330780029\n",
      "Epoch: 6759, Train Loss: 0.38775575160980225, Valid Loss: 0.6563172340393066\n",
      "Epoch: 6760, Train Loss: 0.3877559304237366, Valid Loss: 0.6576864719390869\n",
      "Epoch: 6761, Train Loss: 0.3877558410167694, Valid Loss: 0.656093418598175\n",
      "Epoch: 6762, Train Loss: 0.3877559006214142, Valid Loss: 0.6579914689064026\n",
      "Epoch: 6763, Train Loss: 0.38775599002838135, Valid Loss: 0.6557507514953613\n",
      "Epoch: 6764, Train Loss: 0.38775554299354553, Valid Loss: 0.6584299206733704\n",
      "Epoch: 6765, Train Loss: 0.3877567648887634, Valid Loss: 0.6552450656890869\n",
      "Epoch: 6766, Train Loss: 0.3877571225166321, Valid Loss: 0.6590889096260071\n",
      "Epoch: 6767, Train Loss: 0.3877579867839813, Valid Loss: 0.6544429659843445\n",
      "Epoch: 6768, Train Loss: 0.3877595365047455, Valid Loss: 0.6601300835609436\n",
      "Epoch: 6769, Train Loss: 0.38776227831840515, Valid Loss: 0.6531598567962646\n",
      "Epoch: 6770, Train Loss: 0.3877653479576111, Valid Loss: 0.6618379354476929\n",
      "Epoch: 6771, Train Loss: 0.38777148723602295, Valid Loss: 0.6510710120201111\n",
      "Epoch: 6772, Train Loss: 0.3877807557582855, Valid Loss: 0.6645867228507996\n",
      "Epoch: 6773, Train Loss: 0.3877964913845062, Valid Loss: 0.6476851105690002\n",
      "Epoch: 6774, Train Loss: 0.38781988620758057, Valid Loss: 0.6691115498542786\n",
      "Epoch: 6775, Train Loss: 0.3878604471683502, Valid Loss: 0.6422269344329834\n",
      "Epoch: 6776, Train Loss: 0.38791945576667786, Valid Loss: 0.6765105724334717\n",
      "Epoch: 6777, Train Loss: 0.3880208730697632, Valid Loss: 0.6337701678276062\n",
      "Epoch: 6778, Train Loss: 0.3881509006023407, Valid Loss: 0.6878727078437805\n",
      "Epoch: 6779, Train Loss: 0.3883628845214844, Valid Loss: 0.622322142124176\n",
      "Epoch: 6780, Train Loss: 0.3885478079319, Valid Loss: 0.7019867897033691\n",
      "Epoch: 6781, Train Loss: 0.388788104057312, Valid Loss: 0.6120540499687195\n",
      "Epoch: 6782, Train Loss: 0.3887694180011749, Valid Loss: 0.7094465494155884\n",
      "Epoch: 6783, Train Loss: 0.38866254687309265, Valid Loss: 0.6139454245567322\n",
      "Epoch: 6784, Train Loss: 0.3882826864719391, Valid Loss: 0.694832444190979\n",
      "Epoch: 6785, Train Loss: 0.387956440448761, Valid Loss: 0.6351867914199829\n",
      "Epoch: 6786, Train Loss: 0.38777586817741394, Valid Loss: 0.6623568534851074\n",
      "Epoch: 6787, Train Loss: 0.38780391216278076, Valid Loss: 0.6660757660865784\n",
      "Epoch: 6788, Train Loss: 0.3879702687263489, Valid Loss: 0.635263204574585\n",
      "Epoch: 6789, Train Loss: 0.3881237506866455, Valid Loss: 0.6879169940948486\n",
      "Epoch: 6790, Train Loss: 0.3881821930408478, Valid Loss: 0.6268814206123352\n",
      "Epoch: 6791, Train Loss: 0.3880539536476135, Valid Loss: 0.684877336025238\n",
      "Epoch: 6792, Train Loss: 0.3878859579563141, Valid Loss: 0.639312744140625\n",
      "Epoch: 6793, Train Loss: 0.38777101039886475, Valid Loss: 0.6620621681213379\n",
      "Epoch: 6794, Train Loss: 0.3877730965614319, Valid Loss: 0.6624712347984314\n",
      "Epoch: 6795, Train Loss: 0.38785797357559204, Valid Loss: 0.6411124467849731\n",
      "Epoch: 6796, Train Loss: 0.3879365026950836, Valid Loss: 0.6782190799713135\n",
      "Epoch: 6797, Train Loss: 0.38795578479766846, Valid Loss: 0.6358534097671509\n",
      "Epoch: 6798, Train Loss: 0.38788875937461853, Valid Loss: 0.6748468279838562\n",
      "Epoch: 6799, Train Loss: 0.3878058195114136, Valid Loss: 0.6461834907531738\n",
      "Epoch: 6800, Train Loss: 0.3877585232257843, Valid Loss: 0.6581303477287292\n",
      "Epoch: 6801, Train Loss: 0.38777074217796326, Valid Loss: 0.662649929523468\n",
      "Epoch: 6802, Train Loss: 0.3878171443939209, Valid Loss: 0.644375741481781\n",
      "Epoch: 6803, Train Loss: 0.3878508508205414, Valid Loss: 0.6721616983413696\n",
      "Epoch: 6804, Train Loss: 0.387848824262619, Valid Loss: 0.6426181197166443\n",
      "Epoch: 6805, Train Loss: 0.38780996203422546, Valid Loss: 0.6678551435470581\n",
      "Epoch: 6806, Train Loss: 0.3877714276313782, Valid Loss: 0.6509514451026917\n",
      "Epoch: 6807, Train Loss: 0.38775554299354553, Valid Loss: 0.6561518907546997\n",
      "Epoch: 6808, Train Loss: 0.38776734471321106, Valid Loss: 0.6618106961250305\n",
      "Epoch: 6809, Train Loss: 0.3877905011177063, Valid Loss: 0.6476641297340393\n",
      "Epoch: 6810, Train Loss: 0.38780370354652405, Valid Loss: 0.6673311591148376\n",
      "Epoch: 6811, Train Loss: 0.3877995014190674, Valid Loss: 0.64704430103302\n",
      "Epoch: 6812, Train Loss: 0.38777995109558105, Valid Loss: 0.6641611456871033\n",
      "Epoch: 6813, Train Loss: 0.38776102662086487, Valid Loss: 0.652813732624054\n",
      "Epoch: 6814, Train Loss: 0.3877542018890381, Valid Loss: 0.6561801433563232\n",
      "Epoch: 6815, Train Loss: 0.3877607583999634, Valid Loss: 0.6602561473846436\n",
      "Epoch: 6816, Train Loss: 0.3877723813056946, Valid Loss: 0.6503223180770874\n",
      "Epoch: 6817, Train Loss: 0.38777944445610046, Valid Loss: 0.6642761826515198\n",
      "Epoch: 6818, Train Loss: 0.3877774477005005, Valid Loss: 0.6497714519500732\n",
      "Epoch: 6819, Train Loss: 0.3877677023410797, Valid Loss: 0.6623399257659912\n",
      "Epoch: 6820, Train Loss: 0.38775795698165894, Valid Loss: 0.6534793972969055\n",
      "Epoch: 6821, Train Loss: 0.3877539038658142, Valid Loss: 0.6569854021072388\n",
      "Epoch: 6822, Train Loss: 0.38775572180747986, Valid Loss: 0.658740758895874\n",
      "Epoch: 6823, Train Loss: 0.38776105642318726, Valid Loss: 0.6527783274650574\n",
      "Epoch: 6824, Train Loss: 0.3877650499343872, Valid Loss: 0.6619353294372559\n",
      "Epoch: 6825, Train Loss: 0.3877652883529663, Valid Loss: 0.6517312526702881\n",
      "Epoch: 6826, Train Loss: 0.3877619802951813, Valid Loss: 0.6612000465393066\n",
      "Epoch: 6827, Train Loss: 0.3877571225166321, Valid Loss: 0.6536915302276611\n",
      "Epoch: 6828, Train Loss: 0.38775381445884705, Valid Loss: 0.6580585241317749\n",
      "Epoch: 6829, Train Loss: 0.3877531886100769, Valid Loss: 0.6572001576423645\n",
      "Epoch: 6830, Train Loss: 0.38775572180747986, Valid Loss: 0.6549748778343201\n",
      "Epoch: 6831, Train Loss: 0.3877570927143097, Valid Loss: 0.6599339842796326\n",
      "Epoch: 6832, Train Loss: 0.3877585530281067, Valid Loss: 0.653362512588501\n",
      "Epoch: 6833, Train Loss: 0.38775816559791565, Valid Loss: 0.6603748798370361\n",
      "Epoch: 6834, Train Loss: 0.3877562880516052, Valid Loss: 0.6538676619529724\n",
      "Epoch: 6835, Train Loss: 0.38775435090065, Valid Loss: 0.6588796377182007\n",
      "Epoch: 6836, Train Loss: 0.38775280117988586, Valid Loss: 0.6560189127922058\n",
      "Epoch: 6837, Train Loss: 0.38775280117988586, Valid Loss: 0.6567309498786926\n",
      "Epoch: 6838, Train Loss: 0.3877532184123993, Valid Loss: 0.658221960067749\n",
      "Epoch: 6839, Train Loss: 0.38775405287742615, Valid Loss: 0.6549891829490662\n",
      "Epoch: 6840, Train Loss: 0.3877546489238739, Valid Loss: 0.6592788696289062\n",
      "Epoch: 6841, Train Loss: 0.387754887342453, Valid Loss: 0.6545277237892151\n",
      "Epoch: 6842, Train Loss: 0.38775432109832764, Valid Loss: 0.6591355800628662\n",
      "Epoch: 6843, Train Loss: 0.38775336742401123, Valid Loss: 0.6553706526756287\n",
      "Epoch: 6844, Train Loss: 0.38775262236595154, Valid Loss: 0.6580624580383301\n",
      "Epoch: 6845, Train Loss: 0.38775211572647095, Valid Loss: 0.6567093729972839\n",
      "Epoch: 6846, Train Loss: 0.38775211572647095, Valid Loss: 0.6566911935806274\n",
      "Epoch: 6847, Train Loss: 0.38775208592414856, Valid Loss: 0.6578935384750366\n",
      "Epoch: 6848, Train Loss: 0.3877531588077545, Valid Loss: 0.655768871307373\n",
      "Epoch: 6849, Train Loss: 0.3877527117729187, Valid Loss: 0.6585740447044373\n",
      "Epoch: 6850, Train Loss: 0.387752890586853, Valid Loss: 0.6555505394935608\n",
      "Epoch: 6851, Train Loss: 0.387752890586853, Valid Loss: 0.6585414409637451\n",
      "Epoch: 6852, Train Loss: 0.3877529501914978, Valid Loss: 0.6558745503425598\n",
      "Epoch: 6853, Train Loss: 0.38775166869163513, Valid Loss: 0.657965898513794\n",
      "Epoch: 6854, Train Loss: 0.38775166869163513, Valid Loss: 0.656554102897644\n",
      "Epoch: 6855, Train Loss: 0.3877514600753784, Valid Loss: 0.6572960615158081\n",
      "Epoch: 6856, Train Loss: 0.38775140047073364, Valid Loss: 0.6572738885879517\n",
      "Epoch: 6857, Train Loss: 0.38775119185447693, Valid Loss: 0.6567492485046387\n",
      "Epoch: 6858, Train Loss: 0.3877513110637665, Valid Loss: 0.6577535271644592\n",
      "Epoch: 6859, Train Loss: 0.38775181770324707, Valid Loss: 0.6563848257064819\n",
      "Epoch: 6860, Train Loss: 0.38775160908699036, Valid Loss: 0.6579666137695312\n",
      "Epoch: 6861, Train Loss: 0.3877515196800232, Valid Loss: 0.6563184857368469\n",
      "Epoch: 6862, Train Loss: 0.38775116205215454, Valid Loss: 0.6579974889755249\n",
      "Epoch: 6863, Train Loss: 0.3877510726451874, Valid Loss: 0.6564712524414062\n",
      "Epoch: 6864, Train Loss: 0.3877510130405426, Valid Loss: 0.6578220129013062\n",
      "Epoch: 6865, Train Loss: 0.38775116205215454, Valid Loss: 0.6567037105560303\n",
      "Epoch: 6866, Train Loss: 0.38775089383125305, Valid Loss: 0.6575511693954468\n",
      "Epoch: 6867, Train Loss: 0.38775044679641724, Valid Loss: 0.6570079326629639\n",
      "Epoch: 6868, Train Loss: 0.38775065541267395, Valid Loss: 0.6572878360748291\n",
      "Epoch: 6869, Train Loss: 0.3877505362033844, Valid Loss: 0.657325804233551\n",
      "Epoch: 6870, Train Loss: 0.38775062561035156, Valid Loss: 0.6570439338684082\n",
      "Epoch: 6871, Train Loss: 0.38775011897087097, Valid Loss: 0.6575478911399841\n",
      "Epoch: 6872, Train Loss: 0.3877502679824829, Valid Loss: 0.6568750739097595\n",
      "Epoch: 6873, Train Loss: 0.3877502977848053, Valid Loss: 0.6576905250549316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6874, Train Loss: 0.3877503573894501, Valid Loss: 0.6567955017089844\n",
      "Epoch: 6875, Train Loss: 0.3877500295639038, Valid Loss: 0.6577835083007812\n",
      "Epoch: 6876, Train Loss: 0.38774970173835754, Valid Loss: 0.6567882299423218\n",
      "Epoch: 6877, Train Loss: 0.3877498507499695, Valid Loss: 0.6577851176261902\n",
      "Epoch: 6878, Train Loss: 0.3877500295639038, Valid Loss: 0.6568102836608887\n",
      "Epoch: 6879, Train Loss: 0.38774964213371277, Valid Loss: 0.6577432751655579\n",
      "Epoch: 6880, Train Loss: 0.3877498209476471, Valid Loss: 0.6569045186042786\n",
      "Epoch: 6881, Train Loss: 0.38774991035461426, Valid Loss: 0.6576789617538452\n",
      "Epoch: 6882, Train Loss: 0.38774967193603516, Valid Loss: 0.6570231914520264\n",
      "Epoch: 6883, Train Loss: 0.3877507746219635, Valid Loss: 0.6575872898101807\n",
      "Epoch: 6884, Train Loss: 0.3877492845058441, Valid Loss: 0.65712571144104\n",
      "Epoch: 6885, Train Loss: 0.38774919509887695, Valid Loss: 0.6574991345405579\n",
      "Epoch: 6886, Train Loss: 0.3877492845058441, Valid Loss: 0.6572144031524658\n",
      "Epoch: 6887, Train Loss: 0.38774919509887695, Valid Loss: 0.6574569940567017\n",
      "Epoch: 6888, Train Loss: 0.3877491354942322, Valid Loss: 0.6572850942611694\n",
      "Epoch: 6889, Train Loss: 0.38774892687797546, Valid Loss: 0.657427191734314\n",
      "Epoch: 6890, Train Loss: 0.387749046087265, Valid Loss: 0.6573387980461121\n",
      "Epoch: 6891, Train Loss: 0.3877488672733307, Valid Loss: 0.6573807001113892\n",
      "Epoch: 6892, Train Loss: 0.38774871826171875, Valid Loss: 0.657393217086792\n",
      "Epoch: 6893, Train Loss: 0.3877488076686859, Valid Loss: 0.6573589444160461\n",
      "Epoch: 6894, Train Loss: 0.3877487778663635, Valid Loss: 0.6574357748031616\n",
      "Epoch: 6895, Train Loss: 0.3877488374710083, Valid Loss: 0.6573657989501953\n",
      "Epoch: 6896, Train Loss: 0.3877488672733307, Valid Loss: 0.6574406623840332\n",
      "Epoch: 6897, Train Loss: 0.38774850964546204, Valid Loss: 0.6573795080184937\n",
      "Epoch: 6898, Train Loss: 0.3877486288547516, Valid Loss: 0.6574552655220032\n",
      "Epoch: 6899, Train Loss: 0.38774818181991577, Valid Loss: 0.6573742628097534\n",
      "Epoch: 6900, Train Loss: 0.3877483010292053, Valid Loss: 0.6574881076812744\n",
      "Epoch: 6901, Train Loss: 0.3877481520175934, Valid Loss: 0.6573582291603088\n",
      "Epoch: 6902, Train Loss: 0.38774824142456055, Valid Loss: 0.657551109790802\n",
      "Epoch: 6903, Train Loss: 0.38774827122688293, Valid Loss: 0.6573037505149841\n",
      "Epoch: 6904, Train Loss: 0.38774797320365906, Valid Loss: 0.6576153635978699\n",
      "Epoch: 6905, Train Loss: 0.3877478241920471, Valid Loss: 0.6572715044021606\n",
      "Epoch: 6906, Train Loss: 0.3877478539943695, Valid Loss: 0.657677173614502\n",
      "Epoch: 6907, Train Loss: 0.38774779438972473, Valid Loss: 0.6572033166885376\n",
      "Epoch: 6908, Train Loss: 0.3877476751804352, Valid Loss: 0.6578006148338318\n",
      "Epoch: 6909, Train Loss: 0.38774773478507996, Valid Loss: 0.6570733785629272\n",
      "Epoch: 6910, Train Loss: 0.3877476155757904, Valid Loss: 0.6579900979995728\n",
      "Epoch: 6911, Train Loss: 0.38774794340133667, Valid Loss: 0.656849205493927\n",
      "Epoch: 6912, Train Loss: 0.38774827122688293, Valid Loss: 0.6583011150360107\n",
      "Epoch: 6913, Train Loss: 0.38774794340133667, Valid Loss: 0.6564742922782898\n",
      "Epoch: 6914, Train Loss: 0.38774827122688293, Valid Loss: 0.658812403678894\n",
      "Epoch: 6915, Train Loss: 0.3877483904361725, Valid Loss: 0.655866265296936\n",
      "Epoch: 6916, Train Loss: 0.38774991035461426, Valid Loss: 0.6596383452415466\n",
      "Epoch: 6917, Train Loss: 0.3877507448196411, Valid Loss: 0.6548053622245789\n",
      "Epoch: 6918, Train Loss: 0.38775330781936646, Valid Loss: 0.6610729694366455\n",
      "Epoch: 6919, Train Loss: 0.38775762915611267, Valid Loss: 0.6529721021652222\n",
      "Epoch: 6920, Train Loss: 0.38776516914367676, Valid Loss: 0.663570761680603\n",
      "Epoch: 6921, Train Loss: 0.3877779245376587, Valid Loss: 0.6497917771339417\n",
      "Epoch: 6922, Train Loss: 0.38780009746551514, Valid Loss: 0.6679744720458984\n",
      "Epoch: 6923, Train Loss: 0.3878401517868042, Valid Loss: 0.6442503929138184\n",
      "Epoch: 6924, Train Loss: 0.3879042863845825, Valid Loss: 0.6757893562316895\n",
      "Epoch: 6925, Train Loss: 0.3880217373371124, Valid Loss: 0.634928286075592\n",
      "Epoch: 6926, Train Loss: 0.3881875276565552, Valid Loss: 0.6890527606010437\n",
      "Epoch: 6927, Train Loss: 0.3884753882884979, Valid Loss: 0.6209743618965149\n",
      "Epoch: 6928, Train Loss: 0.3887455463409424, Valid Loss: 0.7076748013496399\n",
      "Epoch: 6929, Train Loss: 0.3891134262084961, Valid Loss: 0.6067862510681152\n",
      "Epoch: 6930, Train Loss: 0.3890921473503113, Valid Loss: 0.7192978858947754\n",
      "Epoch: 6931, Train Loss: 0.38894474506378174, Valid Loss: 0.6078696846961975\n",
      "Epoch: 6932, Train Loss: 0.38840633630752563, Valid Loss: 0.6998787522315979\n",
      "Epoch: 6933, Train Loss: 0.38799795508384705, Valid Loss: 0.6353607773780823\n",
      "Epoch: 6934, Train Loss: 0.38781267404556274, Valid Loss: 0.6579598784446716\n",
      "Epoch: 6935, Train Loss: 0.38791877031326294, Valid Loss: 0.6749482154846191\n",
      "Epoch: 6936, Train Loss: 0.3882013261318207, Valid Loss: 0.6270143389701843\n",
      "Epoch: 6937, Train Loss: 0.38832899928092957, Valid Loss: 0.6976897716522217\n",
      "Epoch: 6938, Train Loss: 0.3882425129413605, Valid Loss: 0.6242101788520813\n",
      "Epoch: 6939, Train Loss: 0.3879641592502594, Valid Loss: 0.6805354952812195\n",
      "Epoch: 6940, Train Loss: 0.3877856433391571, Valid Loss: 0.6502180695533752\n",
      "Epoch: 6941, Train Loss: 0.38779664039611816, Valid Loss: 0.6459634900093079\n",
      "Epoch: 6942, Train Loss: 0.3879395127296448, Valid Loss: 0.679595410823822\n",
      "Epoch: 6943, Train Loss: 0.3880532383918762, Valid Loss: 0.6316158771514893\n",
      "Epoch: 6944, Train Loss: 0.3879897892475128, Valid Loss: 0.6815336346626282\n",
      "Epoch: 6945, Train Loss: 0.38787221908569336, Valid Loss: 0.642952024936676\n",
      "Epoch: 6946, Train Loss: 0.3877876400947571, Valid Loss: 0.6603425741195679\n",
      "Epoch: 6947, Train Loss: 0.38777437806129456, Valid Loss: 0.6636649966239929\n",
      "Epoch: 6948, Train Loss: 0.38783571124076843, Valid Loss: 0.6424838900566101\n",
      "Epoch: 6949, Train Loss: 0.3878977596759796, Valid Loss: 0.6744093894958496\n",
      "Epoch: 6950, Train Loss: 0.3878866732120514, Valid Loss: 0.6420903205871582\n",
      "Epoch: 6951, Train Loss: 0.38781487941741943, Valid Loss: 0.6678659319877625\n",
      "Epoch: 6952, Train Loss: 0.3877600133419037, Valid Loss: 0.6539190411567688\n",
      "Epoch: 6953, Train Loss: 0.38776063919067383, Valid Loss: 0.6531943678855896\n",
      "Epoch: 6954, Train Loss: 0.3878060579299927, Valid Loss: 0.6658627390861511\n",
      "Epoch: 6955, Train Loss: 0.38783735036849976, Valid Loss: 0.6439138054847717\n",
      "Epoch: 6956, Train Loss: 0.38781774044036865, Valid Loss: 0.6695019006729126\n",
      "Epoch: 6957, Train Loss: 0.38778308033943176, Valid Loss: 0.6483592391014099\n",
      "Epoch: 6958, Train Loss: 0.3877580761909485, Valid Loss: 0.6608097553253174\n",
      "Epoch: 6959, Train Loss: 0.3877573013305664, Valid Loss: 0.6592321991920471\n",
      "Epoch: 6960, Train Loss: 0.3877754509449005, Valid Loss: 0.6493471264839172\n",
      "Epoch: 6961, Train Loss: 0.38779154419898987, Valid Loss: 0.6664184331893921\n",
      "Epoch: 6962, Train Loss: 0.38778945803642273, Valid Loss: 0.6466881036758423\n",
      "Epoch: 6963, Train Loss: 0.38777047395706177, Valid Loss: 0.6649079322814941\n",
      "Epoch: 6964, Train Loss: 0.38775262236595154, Valid Loss: 0.6538925170898438\n",
      "Epoch: 6965, Train Loss: 0.3877488076686859, Valid Loss: 0.6552862524986267\n",
      "Epoch: 6966, Train Loss: 0.38776087760925293, Valid Loss: 0.6628848910331726\n",
      "Epoch: 6967, Train Loss: 0.3877714276313782, Valid Loss: 0.6488167643547058\n",
      "Epoch: 6968, Train Loss: 0.38776978850364685, Valid Loss: 0.6643467545509338\n",
      "Epoch: 6969, Train Loss: 0.3877604007720947, Valid Loss: 0.6518157720565796\n",
      "Epoch: 6970, Train Loss: 0.38775110244750977, Valid Loss: 0.6595850586891174\n",
      "Epoch: 6971, Train Loss: 0.3877488076686859, Valid Loss: 0.6580973863601685\n",
      "Epoch: 6972, Train Loss: 0.3877519369125366, Valid Loss: 0.6537497639656067\n",
      "Epoch: 6973, Train Loss: 0.3877565264701843, Valid Loss: 0.6619184613227844\n",
      "Epoch: 6974, Train Loss: 0.38775956630706787, Valid Loss: 0.6517295241355896\n",
      "Epoch: 6975, Train Loss: 0.38775619864463806, Valid Loss: 0.661251425743103\n",
      "Epoch: 6976, Train Loss: 0.3877507150173187, Valid Loss: 0.6548078656196594\n",
      "Epoch: 6977, Train Loss: 0.387746661901474, Valid Loss: 0.6578846573829651\n",
      "Epoch: 6978, Train Loss: 0.3877470791339874, Valid Loss: 0.6585090756416321\n",
      "Epoch: 6979, Train Loss: 0.38775041699409485, Valid Loss: 0.6546087861061096\n",
      "Epoch: 6980, Train Loss: 0.38775280117988586, Valid Loss: 0.6603996753692627\n",
      "Epoch: 6981, Train Loss: 0.38775205612182617, Valid Loss: 0.6534503698348999\n",
      "Epoch: 6982, Train Loss: 0.38774946331977844, Valid Loss: 0.6603771448135376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6983, Train Loss: 0.38774749636650085, Valid Loss: 0.6554551124572754\n",
      "Epoch: 6984, Train Loss: 0.3877456784248352, Valid Loss: 0.6577298045158386\n",
      "Epoch: 6985, Train Loss: 0.38774651288986206, Valid Loss: 0.658437967300415\n",
      "Epoch: 6986, Train Loss: 0.38774755597114563, Valid Loss: 0.6549186110496521\n",
      "Epoch: 6987, Train Loss: 0.38774892687797546, Valid Loss: 0.6600496768951416\n",
      "Epoch: 6988, Train Loss: 0.3877484202384949, Valid Loss: 0.6544363498687744\n",
      "Epoch: 6989, Train Loss: 0.3877473771572113, Valid Loss: 0.6596827507019043\n",
      "Epoch: 6990, Train Loss: 0.3877456784248352, Valid Loss: 0.6562007665634155\n",
      "Epoch: 6991, Train Loss: 0.38774508237838745, Valid Loss: 0.6574815511703491\n",
      "Epoch: 6992, Train Loss: 0.387745201587677, Valid Loss: 0.6584028601646423\n",
      "Epoch: 6993, Train Loss: 0.38774585723876953, Valid Loss: 0.6555898785591125\n",
      "Epoch: 6994, Train Loss: 0.3877463936805725, Valid Loss: 0.6593844890594482\n",
      "Epoch: 6995, Train Loss: 0.38774657249450684, Valid Loss: 0.6555793881416321\n",
      "Epoch: 6996, Train Loss: 0.38774600625038147, Valid Loss: 0.6590405106544495\n",
      "Epoch: 6997, Train Loss: 0.38774585723876953, Valid Loss: 0.6565780639648438\n",
      "Epoch: 6998, Train Loss: 0.3877449631690979, Valid Loss: 0.6578372120857239\n",
      "Epoch: 6999, Train Loss: 0.3877445161342621, Valid Loss: 0.657725989818573\n",
      "Epoch: 7000, Train Loss: 0.38774481415748596, Valid Loss: 0.6566435098648071\n",
      "Epoch: 7001, Train Loss: 0.3877451419830322, Valid Loss: 0.6585851311683655\n",
      "Epoch: 7002, Train Loss: 0.38774505257606506, Valid Loss: 0.6563287377357483\n",
      "Epoch: 7003, Train Loss: 0.38774511218070984, Valid Loss: 0.658775806427002\n",
      "Epoch: 7004, Train Loss: 0.3877447843551636, Valid Loss: 0.6565156579017639\n",
      "Epoch: 7005, Train Loss: 0.38774433732032776, Valid Loss: 0.6583187580108643\n",
      "Epoch: 7006, Train Loss: 0.3877437710762024, Valid Loss: 0.657091498374939\n",
      "Epoch: 7007, Train Loss: 0.38774409890174866, Valid Loss: 0.6574849486351013\n",
      "Epoch: 7008, Train Loss: 0.3877439796924591, Valid Loss: 0.658051073551178\n",
      "Epoch: 7009, Train Loss: 0.3877440392971039, Valid Loss: 0.6568107604980469\n",
      "Epoch: 7010, Train Loss: 0.3877440392971039, Valid Loss: 0.6585834622383118\n",
      "Epoch: 7011, Train Loss: 0.38774368166923523, Valid Loss: 0.6566628217697144\n",
      "Epoch: 7012, Train Loss: 0.38774392008781433, Valid Loss: 0.6584486365318298\n",
      "Epoch: 7013, Train Loss: 0.38774389028549194, Valid Loss: 0.6569466590881348\n",
      "Epoch: 7014, Train Loss: 0.38774344325065613, Valid Loss: 0.6580080389976501\n",
      "Epoch: 7015, Train Loss: 0.38774368166923523, Valid Loss: 0.6575947403907776\n",
      "Epoch: 7016, Train Loss: 0.38774344325065613, Valid Loss: 0.6574842929840088\n",
      "Epoch: 7017, Train Loss: 0.38774374127388, Valid Loss: 0.6580989360809326\n",
      "Epoch: 7018, Train Loss: 0.38774359226226807, Valid Loss: 0.6571455597877502\n",
      "Epoch: 7019, Train Loss: 0.38774344325065613, Valid Loss: 0.6582331657409668\n",
      "Epoch: 7020, Train Loss: 0.3877440392971039, Valid Loss: 0.6571201086044312\n",
      "Epoch: 7021, Train Loss: 0.3877432942390442, Valid Loss: 0.6582168340682983\n",
      "Epoch: 7022, Train Loss: 0.38774311542510986, Valid Loss: 0.6573042869567871\n",
      "Epoch: 7023, Train Loss: 0.3877430260181427, Valid Loss: 0.658070981502533\n",
      "Epoch: 7024, Train Loss: 0.3877429664134979, Valid Loss: 0.6575184464454651\n",
      "Epoch: 7025, Train Loss: 0.38774287700653076, Valid Loss: 0.6577861309051514\n",
      "Epoch: 7026, Train Loss: 0.387742817401886, Valid Loss: 0.6577767729759216\n",
      "Epoch: 7027, Train Loss: 0.38774245977401733, Valid Loss: 0.6575796604156494\n",
      "Epoch: 7028, Train Loss: 0.3877426087856293, Valid Loss: 0.6580268144607544\n",
      "Epoch: 7029, Train Loss: 0.3877427279949188, Valid Loss: 0.6574249267578125\n",
      "Epoch: 7030, Train Loss: 0.38774245977401733, Valid Loss: 0.658176600933075\n",
      "Epoch: 7031, Train Loss: 0.3877425193786621, Valid Loss: 0.6573574542999268\n",
      "Epoch: 7032, Train Loss: 0.38774245977401733, Valid Loss: 0.6581437587738037\n",
      "Epoch: 7033, Train Loss: 0.3877425193786621, Valid Loss: 0.6574740409851074\n",
      "Epoch: 7034, Train Loss: 0.38774222135543823, Valid Loss: 0.6580320000648499\n",
      "Epoch: 7035, Train Loss: 0.38774219155311584, Valid Loss: 0.6576586365699768\n",
      "Epoch: 7036, Train Loss: 0.3877425491809845, Valid Loss: 0.6578838229179382\n",
      "Epoch: 7037, Train Loss: 0.38774192333221436, Valid Loss: 0.657829225063324\n",
      "Epoch: 7038, Train Loss: 0.38774165511131287, Valid Loss: 0.6577380299568176\n",
      "Epoch: 7039, Train Loss: 0.38774192333221436, Valid Loss: 0.6579554677009583\n",
      "Epoch: 7040, Train Loss: 0.3877420127391815, Valid Loss: 0.6576631665229797\n",
      "Epoch: 7041, Train Loss: 0.38774198293685913, Valid Loss: 0.6580538749694824\n",
      "Epoch: 7042, Train Loss: 0.38774189352989197, Valid Loss: 0.6576108336448669\n",
      "Epoch: 7043, Train Loss: 0.3877415060997009, Valid Loss: 0.6581390500068665\n",
      "Epoch: 7044, Train Loss: 0.3877415359020233, Valid Loss: 0.6575478911399841\n",
      "Epoch: 7045, Train Loss: 0.3877415955066681, Valid Loss: 0.6581854224205017\n",
      "Epoch: 7046, Train Loss: 0.387741357088089, Valid Loss: 0.6575518846511841\n",
      "Epoch: 7047, Train Loss: 0.387741357088089, Valid Loss: 0.6581792235374451\n",
      "Epoch: 7048, Train Loss: 0.3877412676811218, Valid Loss: 0.6576202511787415\n",
      "Epoch: 7049, Train Loss: 0.3877413868904114, Valid Loss: 0.6581487059593201\n",
      "Epoch: 7050, Train Loss: 0.3877411186695099, Valid Loss: 0.65767502784729\n",
      "Epoch: 7051, Train Loss: 0.3877411186695099, Valid Loss: 0.6580819487571716\n",
      "Epoch: 7052, Train Loss: 0.387740820646286, Valid Loss: 0.6577612161636353\n",
      "Epoch: 7053, Train Loss: 0.3877410292625427, Valid Loss: 0.6580278873443604\n",
      "Epoch: 7054, Train Loss: 0.38774076104164124, Valid Loss: 0.6578409671783447\n",
      "Epoch: 7055, Train Loss: 0.3877410888671875, Valid Loss: 0.6579908728599548\n",
      "Epoch: 7056, Train Loss: 0.38774070143699646, Valid Loss: 0.6578993201255798\n",
      "Epoch: 7057, Train Loss: 0.38774093985557556, Valid Loss: 0.6579412817955017\n",
      "Epoch: 7058, Train Loss: 0.3877405524253845, Valid Loss: 0.657958984375\n",
      "Epoch: 7059, Train Loss: 0.38774073123931885, Valid Loss: 0.6579076647758484\n",
      "Epoch: 7060, Train Loss: 0.3877404034137726, Valid Loss: 0.65802401304245\n",
      "Epoch: 7061, Train Loss: 0.38774028420448303, Valid Loss: 0.6578700542449951\n",
      "Epoch: 7062, Train Loss: 0.38774043321609497, Valid Loss: 0.6580909490585327\n",
      "Epoch: 7063, Train Loss: 0.3877403736114502, Valid Loss: 0.6578196883201599\n",
      "Epoch: 7064, Train Loss: 0.38774022459983826, Valid Loss: 0.6581576466560364\n",
      "Epoch: 7065, Train Loss: 0.38774022459983826, Valid Loss: 0.6577739119529724\n",
      "Epoch: 7066, Train Loss: 0.38774028420448303, Valid Loss: 0.6582198143005371\n",
      "Epoch: 7067, Train Loss: 0.38773995637893677, Valid Loss: 0.6577417254447937\n",
      "Epoch: 7068, Train Loss: 0.3877398669719696, Valid Loss: 0.6582741737365723\n",
      "Epoch: 7069, Train Loss: 0.3877401351928711, Valid Loss: 0.6577218770980835\n",
      "Epoch: 7070, Train Loss: 0.38773980736732483, Valid Loss: 0.6583137512207031\n",
      "Epoch: 7071, Train Loss: 0.3877399265766144, Valid Loss: 0.6576901078224182\n",
      "Epoch: 7072, Train Loss: 0.3877395987510681, Valid Loss: 0.6583864092826843\n",
      "Epoch: 7073, Train Loss: 0.3877396285533905, Valid Loss: 0.6576260328292847\n",
      "Epoch: 7074, Train Loss: 0.38773953914642334, Valid Loss: 0.6585087776184082\n",
      "Epoch: 7075, Train Loss: 0.3877395987510681, Valid Loss: 0.657473087310791\n",
      "Epoch: 7076, Train Loss: 0.3877395689487457, Valid Loss: 0.6587212085723877\n",
      "Epoch: 7077, Train Loss: 0.38773977756500244, Valid Loss: 0.6572328209877014\n",
      "Epoch: 7078, Train Loss: 0.38773995637893677, Valid Loss: 0.6590331196784973\n",
      "Epoch: 7079, Train Loss: 0.38773980736732483, Valid Loss: 0.6568957567214966\n",
      "Epoch: 7080, Train Loss: 0.3877401053905487, Valid Loss: 0.6594801545143127\n",
      "Epoch: 7081, Train Loss: 0.3877403736114502, Valid Loss: 0.6563534736633301\n",
      "Epoch: 7082, Train Loss: 0.38774099946022034, Valid Loss: 0.6601932048797607\n",
      "Epoch: 7083, Train Loss: 0.3877420723438263, Valid Loss: 0.6554773449897766\n",
      "Epoch: 7084, Train Loss: 0.3877433240413666, Valid Loss: 0.6613562703132629\n",
      "Epoch: 7085, Train Loss: 0.3877464234828949, Valid Loss: 0.654014527797699\n",
      "Epoch: 7086, Train Loss: 0.38775086402893066, Valid Loss: 0.6633174419403076\n",
      "Epoch: 7087, Train Loss: 0.3877580463886261, Valid Loss: 0.651561439037323\n",
      "Epoch: 7088, Train Loss: 0.3877698481082916, Valid Loss: 0.6665968298912048\n",
      "Epoch: 7089, Train Loss: 0.3877902626991272, Valid Loss: 0.6474860906600952\n",
      "Epoch: 7090, Train Loss: 0.3878222405910492, Valid Loss: 0.6721238493919373\n",
      "Epoch: 7091, Train Loss: 0.38787832856178284, Valid Loss: 0.6408017873764038\n",
      "Epoch: 7092, Train Loss: 0.38796094059944153, Valid Loss: 0.6812894940376282\n",
      "Epoch: 7093, Train Loss: 0.3881065249443054, Valid Loss: 0.6304311752319336\n",
      "Epoch: 7094, Train Loss: 0.38828733563423157, Valid Loss: 0.6953070759773254\n",
      "Epoch: 7095, Train Loss: 0.3885829746723175, Valid Loss: 0.6169564723968506\n",
      "Epoch: 7096, Train Loss: 0.3887937366962433, Valid Loss: 0.7112798094749451\n",
      "Epoch: 7097, Train Loss: 0.38903898000717163, Valid Loss: 0.6075294613838196\n",
      "Epoch: 7098, Train Loss: 0.3888571560382843, Valid Loss: 0.7142341732978821\n",
      "Epoch: 7099, Train Loss: 0.38855934143066406, Valid Loss: 0.6166070103645325\n",
      "Epoch: 7100, Train Loss: 0.3880741000175476, Valid Loss: 0.6881734728813171\n",
      "Epoch: 7101, Train Loss: 0.38778528571128845, Valid Loss: 0.6468683481216431\n",
      "Epoch: 7102, Train Loss: 0.38776931166648865, Valid Loss: 0.6495180726051331\n",
      "Epoch: 7103, Train Loss: 0.38796091079711914, Valid Loss: 0.6812254190444946\n",
      "Epoch: 7104, Train Loss: 0.388200044631958, Valid Loss: 0.6264002323150635\n",
      "Epoch: 7105, Train Loss: 0.3882428705692291, Valid Loss: 0.6953098177909851\n",
      "Epoch: 7106, Train Loss: 0.3881223499774933, Valid Loss: 0.6291975975036621\n",
      "Epoch: 7107, Train Loss: 0.38788455724716187, Valid Loss: 0.6770574450492859\n",
      "Epoch: 7108, Train Loss: 0.38774916529655457, Valid Loss: 0.6528937816619873\n",
      "Epoch: 7109, Train Loss: 0.38777437806129456, Valid Loss: 0.6477135419845581\n",
      "Epoch: 7110, Train Loss: 0.38789379596710205, Valid Loss: 0.6773967742919922\n",
      "Epoch: 7111, Train Loss: 0.3879930078983307, Valid Loss: 0.6338779926300049\n",
      "Epoch: 7112, Train Loss: 0.3879670798778534, Valid Loss: 0.6819353699684143\n",
      "Epoch: 7113, Train Loss: 0.38786861300468445, Valid Loss: 0.6417385339736938\n",
      "Epoch: 7114, Train Loss: 0.38776740431785583, Valid Loss: 0.6648213267326355\n",
      "Epoch: 7115, Train Loss: 0.38774430751800537, Valid Loss: 0.6604357957839966\n",
      "Epoch: 7116, Train Loss: 0.38779422640800476, Valid Loss: 0.645592451095581\n",
      "Epoch: 7117, Train Loss: 0.3878535330295563, Valid Loss: 0.6740028858184814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7118, Train Loss: 0.38787227869033813, Valid Loss: 0.6411306858062744\n",
      "Epoch: 7119, Train Loss: 0.3878266513347626, Valid Loss: 0.6720115542411804\n",
      "Epoch: 7120, Train Loss: 0.38776788115501404, Valid Loss: 0.6506616473197937\n",
      "Epoch: 7121, Train Loss: 0.38773930072784424, Valid Loss: 0.6579518914222717\n",
      "Epoch: 7122, Train Loss: 0.3877566158771515, Valid Loss: 0.6633245944976807\n",
      "Epoch: 7123, Train Loss: 0.3877933919429779, Valid Loss: 0.6465358734130859\n",
      "Epoch: 7124, Train Loss: 0.3878107964992523, Valid Loss: 0.6700834631919861\n",
      "Epoch: 7125, Train Loss: 0.3877984285354614, Valid Loss: 0.6467643976211548\n",
      "Epoch: 7126, Train Loss: 0.3877652883529663, Valid Loss: 0.6659995913505554\n",
      "Epoch: 7127, Train Loss: 0.3877415060997009, Valid Loss: 0.6550067067146301\n",
      "Epoch: 7128, Train Loss: 0.3877418637275696, Valid Loss: 0.6550785303115845\n",
      "Epoch: 7129, Train Loss: 0.3877592086791992, Valid Loss: 0.6636021137237549\n",
      "Epoch: 7130, Train Loss: 0.3877747654914856, Valid Loss: 0.6485170722007751\n",
      "Epoch: 7131, Train Loss: 0.3877745270729065, Valid Loss: 0.6669102311134338\n",
      "Epoch: 7132, Train Loss: 0.38776156306266785, Valid Loss: 0.6506617069244385\n",
      "Epoch: 7133, Train Loss: 0.38774552941322327, Valid Loss: 0.6623567938804626\n",
      "Epoch: 7134, Train Loss: 0.38773876428604126, Valid Loss: 0.6571635603904724\n",
      "Epoch: 7135, Train Loss: 0.3877430260181427, Valid Loss: 0.6543848514556885\n",
      "Epoch: 7136, Train Loss: 0.387751966714859, Valid Loss: 0.6630210280418396\n",
      "Epoch: 7137, Train Loss: 0.38775792717933655, Valid Loss: 0.6507625579833984\n",
      "Epoch: 7138, Train Loss: 0.38775527477264404, Valid Loss: 0.6646068096160889\n",
      "Epoch: 7139, Train Loss: 0.3877476453781128, Valid Loss: 0.6531208157539368\n",
      "Epoch: 7140, Train Loss: 0.38774043321609497, Valid Loss: 0.6604652404785156\n",
      "Epoch: 7141, Train Loss: 0.3877376317977905, Valid Loss: 0.6579026579856873\n",
      "Epoch: 7142, Train Loss: 0.38774073123931885, Valid Loss: 0.6548606753349304\n",
      "Epoch: 7143, Train Loss: 0.38774529099464417, Valid Loss: 0.6619842052459717\n",
      "Epoch: 7144, Train Loss: 0.38774779438972473, Valid Loss: 0.652862548828125\n",
      "Epoch: 7145, Train Loss: 0.38774606585502625, Valid Loss: 0.6627724170684814\n",
      "Epoch: 7146, Train Loss: 0.38774242997169495, Valid Loss: 0.6546229720115662\n",
      "Epoch: 7147, Train Loss: 0.38773855566978455, Valid Loss: 0.6596486568450928\n",
      "Epoch: 7148, Train Loss: 0.38773736357688904, Valid Loss: 0.6578728556632996\n",
      "Epoch: 7149, Train Loss: 0.3877391219139099, Valid Loss: 0.6559237837791443\n",
      "Epoch: 7150, Train Loss: 0.3877405822277069, Valid Loss: 0.6607914566993713\n",
      "Epoch: 7151, Train Loss: 0.3877421021461487, Valid Loss: 0.6545925140380859\n",
      "Epoch: 7152, Train Loss: 0.3877415657043457, Valid Loss: 0.6614764332771301\n",
      "Epoch: 7153, Train Loss: 0.38773995637893677, Valid Loss: 0.6554175019264221\n",
      "Epoch: 7154, Train Loss: 0.3877379596233368, Valid Loss: 0.6595744490623474\n",
      "Epoch: 7155, Train Loss: 0.3877367675304413, Valid Loss: 0.6573939323425293\n",
      "Epoch: 7156, Train Loss: 0.38773685693740845, Valid Loss: 0.6571959853172302\n",
      "Epoch: 7157, Train Loss: 0.3877376317977905, Valid Loss: 0.6596067547798157\n",
      "Epoch: 7158, Train Loss: 0.38773807883262634, Valid Loss: 0.6559917330741882\n",
      "Epoch: 7159, Train Loss: 0.3877388834953308, Valid Loss: 0.660489559173584\n",
      "Epoch: 7160, Train Loss: 0.38773852586746216, Valid Loss: 0.655955970287323\n",
      "Epoch: 7161, Train Loss: 0.3877377212047577, Valid Loss: 0.6596537232398987\n",
      "Epoch: 7162, Train Loss: 0.38773706555366516, Valid Loss: 0.6569658517837524\n",
      "Epoch: 7163, Train Loss: 0.38773635029792786, Valid Loss: 0.6583630442619324\n",
      "Epoch: 7164, Train Loss: 0.3877362608909607, Valid Loss: 0.6585108041763306\n",
      "Epoch: 7165, Train Loss: 0.3877362012863159, Valid Loss: 0.6573052406311035\n",
      "Epoch: 7166, Train Loss: 0.3877367079257965, Valid Loss: 0.6594426035881042\n",
      "Epoch: 7167, Train Loss: 0.3877370059490204, Valid Loss: 0.6566715836524963\n",
      "Epoch: 7168, Train Loss: 0.3877367675304413, Valid Loss: 0.6595173478126526\n",
      "Epoch: 7169, Train Loss: 0.3877364993095398, Valid Loss: 0.6568496823310852\n",
      "Epoch: 7170, Train Loss: 0.38773635029792786, Valid Loss: 0.6591039896011353\n",
      "Epoch: 7171, Train Loss: 0.38773584365844727, Valid Loss: 0.6576762199401855\n",
      "Epoch: 7172, Train Loss: 0.3877355456352234, Valid Loss: 0.6583687663078308\n",
      "Epoch: 7173, Train Loss: 0.3877355456352234, Valid Loss: 0.6584540605545044\n",
      "Epoch: 7174, Train Loss: 0.38773563504219055, Valid Loss: 0.6575708985328674\n",
      "Epoch: 7175, Train Loss: 0.3877357542514801, Valid Loss: 0.6590065956115723\n",
      "Epoch: 7176, Train Loss: 0.3877357840538025, Valid Loss: 0.6572189927101135\n",
      "Epoch: 7177, Train Loss: 0.38773584365844727, Valid Loss: 0.6592589020729065\n",
      "Epoch: 7178, Train Loss: 0.38773563504219055, Valid Loss: 0.6573564410209656\n",
      "Epoch: 7179, Train Loss: 0.38773515820503235, Valid Loss: 0.6590534448623657\n",
      "Epoch: 7180, Train Loss: 0.3877347707748413, Valid Loss: 0.6577042937278748\n",
      "Epoch: 7181, Train Loss: 0.387734979391098, Valid Loss: 0.6585161089897156\n",
      "Epoch: 7182, Train Loss: 0.38773515820503235, Valid Loss: 0.6582417488098145\n",
      "Epoch: 7183, Train Loss: 0.38773447275161743, Valid Loss: 0.6580284833908081\n",
      "Epoch: 7184, Train Loss: 0.3877345323562622, Valid Loss: 0.6588142514228821\n",
      "Epoch: 7185, Train Loss: 0.3877347409725189, Valid Loss: 0.6576857566833496\n",
      "Epoch: 7186, Train Loss: 0.38773488998413086, Valid Loss: 0.6590418219566345\n",
      "Epoch: 7187, Train Loss: 0.3877347707748413, Valid Loss: 0.6575486660003662\n",
      "Epoch: 7188, Train Loss: 0.387734591960907, Valid Loss: 0.6590049862861633\n",
      "Epoch: 7189, Train Loss: 0.3877345621585846, Valid Loss: 0.6577063202857971\n",
      "Epoch: 7190, Train Loss: 0.38773468136787415, Valid Loss: 0.6588720083236694\n",
      "Epoch: 7191, Train Loss: 0.38773441314697266, Valid Loss: 0.657986044883728\n",
      "Epoch: 7192, Train Loss: 0.38773465156555176, Valid Loss: 0.6586132049560547\n",
      "Epoch: 7193, Train Loss: 0.38773420453071594, Valid Loss: 0.6582409143447876\n",
      "Epoch: 7194, Train Loss: 0.38773423433303833, Valid Loss: 0.6583343744277954\n",
      "Epoch: 7195, Train Loss: 0.38773423433303833, Valid Loss: 0.6584938168525696\n",
      "Epoch: 7196, Train Loss: 0.38773396611213684, Valid Loss: 0.6581758856773376\n",
      "Epoch: 7197, Train Loss: 0.38773417472839355, Valid Loss: 0.6586846113204956\n",
      "Epoch: 7198, Train Loss: 0.38773414492607117, Valid Loss: 0.6580809950828552\n",
      "Epoch: 7199, Train Loss: 0.38773322105407715, Valid Loss: 0.6587571501731873\n",
      "Epoch: 7200, Train Loss: 0.3877338171005249, Valid Loss: 0.6580217480659485\n",
      "Epoch: 7201, Train Loss: 0.387734055519104, Valid Loss: 0.6587854027748108\n",
      "Epoch: 7202, Train Loss: 0.38773372769355774, Valid Loss: 0.6580448150634766\n",
      "Epoch: 7203, Train Loss: 0.38773372769355774, Valid Loss: 0.658793568611145\n",
      "Epoch: 7204, Train Loss: 0.38773348927497864, Valid Loss: 0.6581151485443115\n",
      "Epoch: 7205, Train Loss: 0.38773325085639954, Valid Loss: 0.6587533354759216\n",
      "Epoch: 7206, Train Loss: 0.3877335786819458, Valid Loss: 0.6581602692604065\n",
      "Epoch: 7207, Train Loss: 0.3877333104610443, Valid Loss: 0.658693253993988\n",
      "Epoch: 7208, Train Loss: 0.3877333700656891, Valid Loss: 0.6582472920417786\n",
      "Epoch: 7209, Train Loss: 0.38773313164711, Valid Loss: 0.6586366295814514\n",
      "Epoch: 7210, Train Loss: 0.38773325085639954, Valid Loss: 0.6583530306816101\n",
      "Epoch: 7211, Train Loss: 0.38773271441459656, Valid Loss: 0.6585733294487\n",
      "Epoch: 7212, Train Loss: 0.3877330422401428, Valid Loss: 0.6584267616271973\n",
      "Epoch: 7213, Train Loss: 0.38773277401924133, Valid Loss: 0.6585153341293335\n",
      "Epoch: 7214, Train Loss: 0.38773301243782043, Valid Loss: 0.6584880948066711\n",
      "Epoch: 7215, Train Loss: 0.3877328336238861, Valid Loss: 0.6584905982017517\n",
      "Epoch: 7216, Train Loss: 0.38773292303085327, Valid Loss: 0.6585469245910645\n",
      "Epoch: 7217, Train Loss: 0.38773274421691895, Valid Loss: 0.6584770679473877\n",
      "Epoch: 7218, Train Loss: 0.38773274421691895, Valid Loss: 0.6585754156112671\n",
      "Epoch: 7219, Train Loss: 0.38773268461227417, Valid Loss: 0.6584573984146118\n",
      "Epoch: 7220, Train Loss: 0.38773247599601746, Valid Loss: 0.6585972309112549\n",
      "Epoch: 7221, Train Loss: 0.38773244619369507, Valid Loss: 0.6584610939025879\n",
      "Epoch: 7222, Train Loss: 0.38773250579833984, Valid Loss: 0.6586410403251648\n",
      "Epoch: 7223, Train Loss: 0.38773244619369507, Valid Loss: 0.6584522724151611\n",
      "Epoch: 7224, Train Loss: 0.3877323865890503, Valid Loss: 0.6586704850196838\n",
      "Epoch: 7225, Train Loss: 0.3877312242984772, Valid Loss: 0.6584191918373108\n",
      "Epoch: 7226, Train Loss: 0.3877324163913727, Valid Loss: 0.6587172150611877\n",
      "Epoch: 7227, Train Loss: 0.38773196935653687, Valid Loss: 0.6584044098854065\n",
      "Epoch: 7228, Train Loss: 0.38773202896118164, Valid Loss: 0.6587707996368408\n",
      "Epoch: 7229, Train Loss: 0.3877320885658264, Valid Loss: 0.6583802700042725\n",
      "Epoch: 7230, Train Loss: 0.3877314627170563, Valid Loss: 0.6588219404220581\n",
      "Epoch: 7231, Train Loss: 0.3877319097518921, Valid Loss: 0.658316969871521\n",
      "Epoch: 7232, Train Loss: 0.3877321183681488, Valid Loss: 0.6589481830596924\n",
      "Epoch: 7233, Train Loss: 0.387731671333313, Valid Loss: 0.6581829786300659\n",
      "Epoch: 7234, Train Loss: 0.38773199915885925, Valid Loss: 0.6591246724128723\n",
      "Epoch: 7235, Train Loss: 0.38773205876350403, Valid Loss: 0.6580064296722412\n",
      "Epoch: 7236, Train Loss: 0.38773176074028015, Valid Loss: 0.6593751311302185\n",
      "Epoch: 7237, Train Loss: 0.38773199915885925, Valid Loss: 0.6577073931694031\n",
      "Epoch: 7238, Train Loss: 0.3877321183681488, Valid Loss: 0.6597701907157898\n",
      "Epoch: 7239, Train Loss: 0.3877324163913727, Valid Loss: 0.6572285294532776\n",
      "Epoch: 7240, Train Loss: 0.38773268461227417, Valid Loss: 0.6604090332984924\n",
      "Epoch: 7241, Train Loss: 0.387733519077301, Valid Loss: 0.656460702419281\n",
      "Epoch: 7242, Train Loss: 0.38773468136787415, Valid Loss: 0.6614439487457275\n",
      "Epoch: 7243, Train Loss: 0.3877369463443756, Valid Loss: 0.6551598310470581\n",
      "Epoch: 7244, Train Loss: 0.38774046301841736, Valid Loss: 0.663175106048584\n",
      "Epoch: 7245, Train Loss: 0.38774633407592773, Valid Loss: 0.652968168258667\n",
      "Epoch: 7246, Train Loss: 0.38775646686553955, Valid Loss: 0.6661219000816345\n",
      "Epoch: 7247, Train Loss: 0.38777342438697815, Valid Loss: 0.6492915153503418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7248, Train Loss: 0.38780105113983154, Valid Loss: 0.6711543202400208\n",
      "Epoch: 7249, Train Loss: 0.38785070180892944, Valid Loss: 0.643114447593689\n",
      "Epoch: 7250, Train Loss: 0.3879244327545166, Valid Loss: 0.6797305345535278\n",
      "Epoch: 7251, Train Loss: 0.38805902004241943, Valid Loss: 0.6331947445869446\n",
      "Epoch: 7252, Train Loss: 0.38823193311691284, Valid Loss: 0.6934810876846313\n",
      "Epoch: 7253, Train Loss: 0.3885240852832794, Valid Loss: 0.6194500923156738\n",
      "Epoch: 7254, Train Loss: 0.38875889778137207, Valid Loss: 0.710788369178772\n",
      "Epoch: 7255, Train Loss: 0.38906365633010864, Valid Loss: 0.6076562404632568\n",
      "Epoch: 7256, Train Loss: 0.388957679271698, Valid Loss: 0.7180169820785522\n",
      "Epoch: 7257, Train Loss: 0.3887420892715454, Valid Loss: 0.6124524474143982\n",
      "Epoch: 7258, Train Loss: 0.38823649287223816, Valid Loss: 0.6958174705505371\n",
      "Epoch: 7259, Train Loss: 0.3878882825374603, Valid Loss: 0.6405702233314514\n",
      "Epoch: 7260, Train Loss: 0.3877774477005005, Valid Loss: 0.6564384698867798\n",
      "Epoch: 7261, Train Loss: 0.38790377974510193, Valid Loss: 0.6770195960998535\n",
      "Epoch: 7262, Train Loss: 0.38814684748649597, Valid Loss: 0.6289865374565125\n",
      "Epoch: 7263, Train Loss: 0.3882565498352051, Valid Loss: 0.6968327164649963\n",
      "Epoch: 7264, Train Loss: 0.38819825649261475, Valid Loss: 0.626413106918335\n",
      "Epoch: 7265, Train Loss: 0.3879491090774536, Valid Loss: 0.6825180053710938\n",
      "Epoch: 7266, Train Loss: 0.3877670466899872, Valid Loss: 0.6486819386482239\n",
      "Epoch: 7267, Train Loss: 0.3877524435520172, Valid Loss: 0.651170551776886\n",
      "Epoch: 7268, Train Loss: 0.3878675401210785, Valid Loss: 0.6768776178359985\n",
      "Epoch: 7269, Train Loss: 0.3879891335964203, Valid Loss: 0.6337825655937195\n",
      "Epoch: 7270, Train Loss: 0.3879857063293457, Valid Loss: 0.6845431327819824\n",
      "Epoch: 7271, Train Loss: 0.38788971304893494, Valid Loss: 0.6400404572486877\n",
      "Epoch: 7272, Train Loss: 0.38777613639831543, Valid Loss: 0.6670633554458618\n",
      "Epoch: 7273, Train Loss: 0.38774317502975464, Valid Loss: 0.6596952676773071\n",
      "Epoch: 7274, Train Loss: 0.387783944606781, Valid Loss: 0.6465986371040344\n",
      "Epoch: 7275, Train Loss: 0.3878397047519684, Valid Loss: 0.6748803853988647\n",
      "Epoch: 7276, Train Loss: 0.38786566257476807, Valid Loss: 0.6414030194282532\n",
      "Epoch: 7277, Train Loss: 0.38783085346221924, Valid Loss: 0.6725527048110962\n",
      "Epoch: 7278, Train Loss: 0.38777270913124084, Valid Loss: 0.650790274143219\n",
      "Epoch: 7279, Train Loss: 0.3877350986003876, Valid Loss: 0.6587592363357544\n",
      "Epoch: 7280, Train Loss: 0.38774603605270386, Valid Loss: 0.6633763313293457\n",
      "Epoch: 7281, Train Loss: 0.38778290152549744, Valid Loss: 0.647828221321106\n",
      "Epoch: 7282, Train Loss: 0.3878033459186554, Valid Loss: 0.6699116230010986\n",
      "Epoch: 7283, Train Loss: 0.387794554233551, Valid Loss: 0.6473416090011597\n",
      "Epoch: 7284, Train Loss: 0.38776135444641113, Valid Loss: 0.666524350643158\n",
      "Epoch: 7285, Train Loss: 0.3877354562282562, Valid Loss: 0.6551254987716675\n",
      "Epoch: 7286, Train Loss: 0.387734979391098, Valid Loss: 0.6559886932373047\n",
      "Epoch: 7287, Train Loss: 0.3877529799938202, Valid Loss: 0.6637919545173645\n",
      "Epoch: 7288, Train Loss: 0.38776829838752747, Valid Loss: 0.6492766737937927\n",
      "Epoch: 7289, Train Loss: 0.38776734471321106, Valid Loss: 0.6671834588050842\n",
      "Epoch: 7290, Train Loss: 0.3877551257610321, Valid Loss: 0.6511270403862\n",
      "Epoch: 7291, Train Loss: 0.3877391517162323, Valid Loss: 0.6630520820617676\n",
      "Epoch: 7292, Train Loss: 0.38773199915885925, Valid Loss: 0.6573138236999512\n",
      "Epoch: 7293, Train Loss: 0.3877356946468353, Valid Loss: 0.6551522612571716\n",
      "Epoch: 7294, Train Loss: 0.3877447545528412, Valid Loss: 0.663581907749176\n",
      "Epoch: 7295, Train Loss: 0.387750506401062, Valid Loss: 0.6510757207870483\n",
      "Epoch: 7296, Train Loss: 0.3877484202384949, Valid Loss: 0.6653066873550415\n",
      "Epoch: 7297, Train Loss: 0.3877401649951935, Valid Loss: 0.6535108089447021\n",
      "Epoch: 7298, Train Loss: 0.3877323269844055, Valid Loss: 0.6607811450958252\n",
      "Epoch: 7299, Train Loss: 0.3877302408218384, Valid Loss: 0.6588044166564941\n",
      "Epoch: 7300, Train Loss: 0.3877338171005249, Valid Loss: 0.6550431847572327\n",
      "Epoch: 7301, Train Loss: 0.387738436460495, Valid Loss: 0.6628096103668213\n",
      "Epoch: 7302, Train Loss: 0.3877406418323517, Valid Loss: 0.6532296538352966\n",
      "Epoch: 7303, Train Loss: 0.3877381980419159, Valid Loss: 0.66313636302948\n",
      "Epoch: 7304, Train Loss: 0.38773396611213684, Valid Loss: 0.6554336547851562\n",
      "Epoch: 7305, Train Loss: 0.38773050904273987, Valid Loss: 0.6597109436988831\n",
      "Epoch: 7306, Train Loss: 0.3877296447753906, Valid Loss: 0.6589038968086243\n",
      "Epoch: 7307, Train Loss: 0.387731671333313, Valid Loss: 0.6561093926429749\n",
      "Epoch: 7308, Train Loss: 0.387733519077301, Valid Loss: 0.6614168286323547\n",
      "Epoch: 7309, Train Loss: 0.3877342641353607, Valid Loss: 0.6552139520645142\n",
      "Epoch: 7310, Train Loss: 0.38773372769355774, Valid Loss: 0.6616719961166382\n",
      "Epoch: 7311, Train Loss: 0.38773202896118164, Valid Loss: 0.6562913656234741\n",
      "Epoch: 7312, Train Loss: 0.387730211019516, Valid Loss: 0.6597387194633484\n",
      "Epoch: 7313, Train Loss: 0.38772937655448914, Valid Loss: 0.6582759022712708\n",
      "Epoch: 7314, Train Loss: 0.3877294659614563, Valid Loss: 0.657480776309967\n",
      "Epoch: 7315, Train Loss: 0.3877301514148712, Valid Loss: 0.660260796546936\n",
      "Epoch: 7316, Train Loss: 0.38773113489151, Valid Loss: 0.656487226486206\n",
      "Epoch: 7317, Train Loss: 0.38773107528686523, Valid Loss: 0.6608998775482178\n",
      "Epoch: 7318, Train Loss: 0.3877306878566742, Valid Loss: 0.6566963791847229\n",
      "Epoch: 7319, Train Loss: 0.38772979378700256, Valid Loss: 0.6600038409233093\n",
      "Epoch: 7320, Train Loss: 0.38772863149642944, Valid Loss: 0.6577454209327698\n",
      "Epoch: 7321, Train Loss: 0.3877284526824951, Valid Loss: 0.6586726307868958\n",
      "Epoch: 7322, Train Loss: 0.3877287209033966, Valid Loss: 0.6592758893966675\n",
      "Epoch: 7323, Train Loss: 0.3877289295196533, Valid Loss: 0.6575645208358765\n",
      "Epoch: 7324, Train Loss: 0.3877294957637787, Valid Loss: 0.6602756977081299\n",
      "Epoch: 7325, Train Loss: 0.3877297639846802, Valid Loss: 0.6570486426353455\n",
      "Epoch: 7326, Train Loss: 0.3877291977405548, Valid Loss: 0.6601387858390808\n",
      "Epoch: 7327, Train Loss: 0.38772889971733093, Valid Loss: 0.6574774384498596\n",
      "Epoch: 7328, Train Loss: 0.3877282738685608, Valid Loss: 0.6594190001487732\n",
      "Epoch: 7329, Train Loss: 0.3877280056476593, Valid Loss: 0.6585423946380615\n",
      "Epoch: 7330, Train Loss: 0.38772812485694885, Valid Loss: 0.6585074067115784\n",
      "Epoch: 7331, Train Loss: 0.3877285122871399, Valid Loss: 0.6594597101211548\n",
      "Epoch: 7332, Train Loss: 0.38772833347320557, Valid Loss: 0.6577194333076477\n",
      "Epoch: 7333, Train Loss: 0.38772860169410706, Valid Loss: 0.6598682999610901\n",
      "Epoch: 7334, Train Loss: 0.3877280354499817, Valid Loss: 0.6575924754142761\n",
      "Epoch: 7335, Train Loss: 0.3877279758453369, Valid Loss: 0.6598085165023804\n",
      "Epoch: 7336, Train Loss: 0.38772812485694885, Valid Loss: 0.6580280065536499\n",
      "Epoch: 7337, Train Loss: 0.38772764801979065, Valid Loss: 0.6593620777130127\n",
      "Epoch: 7338, Train Loss: 0.38772761821746826, Valid Loss: 0.6585740447044373\n",
      "Epoch: 7339, Train Loss: 0.387727290391922, Valid Loss: 0.65875643491745\n",
      "Epoch: 7340, Train Loss: 0.38772740960121155, Valid Loss: 0.6590903401374817\n",
      "Epoch: 7341, Train Loss: 0.3877275586128235, Valid Loss: 0.6583696603775024\n",
      "Epoch: 7342, Train Loss: 0.3877274692058563, Valid Loss: 0.6594559550285339\n",
      "Epoch: 7343, Train Loss: 0.3877268135547638, Valid Loss: 0.6582649350166321\n",
      "Epoch: 7344, Train Loss: 0.3877273499965668, Valid Loss: 0.6594939231872559\n",
      "Epoch: 7345, Train Loss: 0.38772764801979065, Valid Loss: 0.6582872271537781\n",
      "Epoch: 7346, Train Loss: 0.3877270519733429, Valid Loss: 0.6593663692474365\n",
      "Epoch: 7347, Train Loss: 0.38772690296173096, Valid Loss: 0.6584833264350891\n",
      "Epoch: 7348, Train Loss: 0.3877267837524414, Valid Loss: 0.6591897010803223\n",
      "Epoch: 7349, Train Loss: 0.387726366519928, Valid Loss: 0.6587734818458557\n",
      "Epoch: 7350, Train Loss: 0.3877267837524414, Valid Loss: 0.6589449048042297\n",
      "Epoch: 7351, Train Loss: 0.38772669434547424, Valid Loss: 0.6590213179588318\n",
      "Epoch: 7352, Train Loss: 0.38772642612457275, Valid Loss: 0.6587066054344177\n",
      "Epoch: 7353, Train Loss: 0.3877267837524414, Valid Loss: 0.6592198014259338\n",
      "Epoch: 7354, Train Loss: 0.387726366519928, Valid Loss: 0.6585900783538818\n",
      "Epoch: 7355, Train Loss: 0.38772639632225037, Valid Loss: 0.6593616008758545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7356, Train Loss: 0.38772663474082947, Valid Loss: 0.6585578322410583\n",
      "Epoch: 7357, Train Loss: 0.3877262473106384, Valid Loss: 0.6593654155731201\n",
      "Epoch: 7358, Train Loss: 0.38772621750831604, Valid Loss: 0.6585948467254639\n",
      "Epoch: 7359, Train Loss: 0.38772597908973694, Valid Loss: 0.6592906713485718\n",
      "Epoch: 7360, Train Loss: 0.3877261281013489, Valid Loss: 0.6587045192718506\n",
      "Epoch: 7361, Train Loss: 0.3877262771129608, Valid Loss: 0.6592172384262085\n",
      "Epoch: 7362, Train Loss: 0.3877260684967041, Valid Loss: 0.6588523387908936\n",
      "Epoch: 7363, Train Loss: 0.38772618770599365, Valid Loss: 0.6590912342071533\n",
      "Epoch: 7364, Train Loss: 0.387725830078125, Valid Loss: 0.6589775085449219\n",
      "Epoch: 7365, Train Loss: 0.3877258598804474, Valid Loss: 0.6589922904968262\n",
      "Epoch: 7366, Train Loss: 0.387725830078125, Valid Loss: 0.6590726971626282\n",
      "Epoch: 7367, Train Loss: 0.38772574067115784, Valid Loss: 0.6589493751525879\n",
      "Epoch: 7368, Train Loss: 0.3877258598804474, Valid Loss: 0.6591581106185913\n",
      "Epoch: 7369, Train Loss: 0.3877256214618683, Valid Loss: 0.6589115858078003\n",
      "Epoch: 7370, Train Loss: 0.3877258002758026, Valid Loss: 0.6592056751251221\n",
      "Epoch: 7371, Train Loss: 0.3877253234386444, Valid Loss: 0.6588639616966248\n",
      "Epoch: 7372, Train Loss: 0.3877255916595459, Valid Loss: 0.6592719554901123\n",
      "Epoch: 7373, Train Loss: 0.38772550225257874, Valid Loss: 0.6588321924209595\n",
      "Epoch: 7374, Train Loss: 0.3877256512641907, Valid Loss: 0.6593284010887146\n",
      "Epoch: 7375, Train Loss: 0.38772520422935486, Valid Loss: 0.658816933631897\n",
      "Epoch: 7376, Train Loss: 0.3877253830432892, Valid Loss: 0.659379243850708\n",
      "Epoch: 7377, Train Loss: 0.38772523403167725, Valid Loss: 0.6587709784507751\n",
      "Epoch: 7378, Train Loss: 0.3877251446247101, Valid Loss: 0.6594406366348267\n",
      "Epoch: 7379, Train Loss: 0.38772499561309814, Valid Loss: 0.6587224006652832\n",
      "Epoch: 7380, Train Loss: 0.3877250552177429, Valid Loss: 0.6595385670661926\n",
      "Epoch: 7381, Train Loss: 0.38772448897361755, Valid Loss: 0.6586483120918274\n",
      "Epoch: 7382, Train Loss: 0.38772493600845337, Valid Loss: 0.6596589684486389\n",
      "Epoch: 7383, Train Loss: 0.3877248764038086, Valid Loss: 0.6585211753845215\n",
      "Epoch: 7384, Train Loss: 0.3877248167991638, Valid Loss: 0.6598114967346191\n",
      "Epoch: 7385, Train Loss: 0.3877248167991638, Valid Loss: 0.6583589911460876\n",
      "Epoch: 7386, Train Loss: 0.38772493600845337, Valid Loss: 0.6600447297096252\n",
      "Epoch: 7387, Train Loss: 0.3877248764038086, Valid Loss: 0.6581252813339233\n",
      "Epoch: 7388, Train Loss: 0.3877250552177429, Valid Loss: 0.6603508591651917\n",
      "Epoch: 7389, Train Loss: 0.38772520422935486, Valid Loss: 0.6577641367912292\n",
      "Epoch: 7390, Train Loss: 0.3877253532409668, Valid Loss: 0.6608248353004456\n",
      "Epoch: 7391, Train Loss: 0.3877260684967041, Valid Loss: 0.6572097539901733\n",
      "Epoch: 7392, Train Loss: 0.38772687315940857, Valid Loss: 0.6615336537361145\n",
      "Epoch: 7393, Train Loss: 0.3877277672290802, Valid Loss: 0.6564041972160339\n",
      "Epoch: 7394, Train Loss: 0.3877291977405548, Valid Loss: 0.6625587344169617\n",
      "Epoch: 7395, Train Loss: 0.3877314627170563, Valid Loss: 0.6551639437675476\n",
      "Epoch: 7396, Train Loss: 0.387734979391098, Valid Loss: 0.6641520857810974\n",
      "Epoch: 7397, Train Loss: 0.3877405524253845, Valid Loss: 0.6532299518585205\n",
      "Epoch: 7398, Train Loss: 0.3877484202384949, Valid Loss: 0.6666725277900696\n",
      "Epoch: 7399, Train Loss: 0.3877619206905365, Valid Loss: 0.6502083539962769\n",
      "Epoch: 7400, Train Loss: 0.3877810537815094, Valid Loss: 0.670651912689209\n",
      "Epoch: 7401, Train Loss: 0.38781318068504333, Valid Loss: 0.6454795598983765\n",
      "Epoch: 7402, Train Loss: 0.3878587484359741, Valid Loss: 0.6769373416900635\n",
      "Epoch: 7403, Train Loss: 0.38793492317199707, Valid Loss: 0.638347864151001\n",
      "Epoch: 7404, Train Loss: 0.3880299925804138, Valid Loss: 0.6864105463027954\n",
      "Epoch: 7405, Train Loss: 0.38818785548210144, Valid Loss: 0.628565788269043\n",
      "Epoch: 7406, Train Loss: 0.3883363902568817, Valid Loss: 0.6987770199775696\n",
      "Epoch: 7407, Train Loss: 0.38855478167533875, Valid Loss: 0.6183059811592102\n",
      "Epoch: 7408, Train Loss: 0.3886207044124603, Valid Loss: 0.7087081670761108\n",
      "Epoch: 7409, Train Loss: 0.38867008686065674, Valid Loss: 0.6148613691329956\n",
      "Epoch: 7410, Train Loss: 0.3884400427341461, Valid Loss: 0.7041252851486206\n",
      "Epoch: 7411, Train Loss: 0.38818442821502686, Valid Loss: 0.6267196536064148\n",
      "Epoch: 7412, Train Loss: 0.3878995478153229, Valid Loss: 0.6804265379905701\n",
      "Epoch: 7413, Train Loss: 0.3877517580986023, Valid Loss: 0.6518985033035278\n",
      "Epoch: 7414, Train Loss: 0.38775455951690674, Valid Loss: 0.6520363688468933\n",
      "Epoch: 7415, Train Loss: 0.3878677785396576, Valid Loss: 0.6777760982513428\n",
      "Epoch: 7416, Train Loss: 0.3880137503147125, Valid Loss: 0.63373202085495\n",
      "Epoch: 7417, Train Loss: 0.38806983828544617, Valid Loss: 0.6896915435791016\n",
      "Epoch: 7418, Train Loss: 0.3880409896373749, Valid Loss: 0.6319968104362488\n",
      "Epoch: 7419, Train Loss: 0.38790902495384216, Valid Loss: 0.6808714866638184\n",
      "Epoch: 7420, Train Loss: 0.38778766989707947, Valid Loss: 0.6465778350830078\n",
      "Epoch: 7421, Train Loss: 0.38772818446159363, Valid Loss: 0.6604678630828857\n",
      "Epoch: 7422, Train Loss: 0.3877480924129486, Valid Loss: 0.6665821075439453\n",
      "Epoch: 7423, Train Loss: 0.38781359791755676, Valid Loss: 0.644133448600769\n",
      "Epoch: 7424, Train Loss: 0.3878665268421173, Valid Loss: 0.6782810688018799\n",
      "Epoch: 7425, Train Loss: 0.3878806233406067, Valid Loss: 0.6400318741798401\n",
      "Epoch: 7426, Train Loss: 0.3878372609615326, Valid Loss: 0.6754103302955627\n",
      "Epoch: 7427, Train Loss: 0.3877803087234497, Valid Loss: 0.6480840444564819\n",
      "Epoch: 7428, Train Loss: 0.38773736357688904, Valid Loss: 0.662868320941925\n",
      "Epoch: 7429, Train Loss: 0.38772889971733093, Valid Loss: 0.6615135669708252\n",
      "Epoch: 7430, Train Loss: 0.3877500593662262, Valid Loss: 0.6508117914199829\n",
      "Epoch: 7431, Train Loss: 0.38777828216552734, Valid Loss: 0.6704773902893066\n",
      "Epoch: 7432, Train Loss: 0.38779550790786743, Valid Loss: 0.6462351083755493\n",
      "Epoch: 7433, Train Loss: 0.3877878189086914, Valid Loss: 0.6706740856170654\n",
      "Epoch: 7434, Train Loss: 0.3877670168876648, Valid Loss: 0.6499598622322083\n",
      "Epoch: 7435, Train Loss: 0.38774052262306213, Valid Loss: 0.6642076969146729\n",
      "Epoch: 7436, Train Loss: 0.38772571086883545, Valid Loss: 0.6577847003936768\n",
      "Epoch: 7437, Train Loss: 0.3877266049385071, Valid Loss: 0.6558200120925903\n",
      "Epoch: 7438, Train Loss: 0.38773974776268005, Valid Loss: 0.6647382974624634\n",
      "Epoch: 7439, Train Loss: 0.3877539336681366, Valid Loss: 0.6508549451828003\n",
      "Epoch: 7440, Train Loss: 0.38775864243507385, Valid Loss: 0.6674526929855347\n",
      "Epoch: 7441, Train Loss: 0.38775354623794556, Valid Loss: 0.6512797474861145\n",
      "Epoch: 7442, Train Loss: 0.38774022459983826, Valid Loss: 0.6649815440177917\n",
      "Epoch: 7443, Train Loss: 0.3877284526824951, Valid Loss: 0.6553164720535278\n",
      "Epoch: 7444, Train Loss: 0.3877233862876892, Valid Loss: 0.6597046852111816\n",
      "Epoch: 7445, Train Loss: 0.3877248167991638, Valid Loss: 0.6603834629058838\n",
      "Epoch: 7446, Train Loss: 0.38773059844970703, Valid Loss: 0.6551645398139954\n",
      "Epoch: 7447, Train Loss: 0.38773614168167114, Valid Loss: 0.6641510725021362\n",
      "Epoch: 7448, Train Loss: 0.3877384066581726, Valid Loss: 0.6533224582672119\n",
      "Epoch: 7449, Train Loss: 0.38773635029792786, Valid Loss: 0.6646934747695923\n",
      "Epoch: 7450, Train Loss: 0.38773250579833984, Valid Loss: 0.6542761921882629\n",
      "Epoch: 7451, Train Loss: 0.38772618770599365, Valid Loss: 0.6622142791748047\n",
      "Epoch: 7452, Train Loss: 0.38772332668304443, Valid Loss: 0.6573195457458496\n",
      "Epoch: 7453, Train Loss: 0.387722373008728, Valid Loss: 0.6588010191917419\n",
      "Epoch: 7454, Train Loss: 0.38772422075271606, Valid Loss: 0.6609211564064026\n",
      "Epoch: 7455, Train Loss: 0.3877265155315399, Valid Loss: 0.6560304760932922\n",
      "Epoch: 7456, Train Loss: 0.38772860169410706, Valid Loss: 0.66303551197052\n",
      "Epoch: 7457, Train Loss: 0.3877291977405548, Valid Loss: 0.6548675298690796\n",
      "Epoch: 7458, Train Loss: 0.38772812485694885, Valid Loss: 0.6629472374916077\n",
      "Epoch: 7459, Train Loss: 0.38772591948509216, Valid Loss: 0.6558734178543091\n",
      "Epoch: 7460, Train Loss: 0.3877238929271698, Valid Loss: 0.6613263487815857\n",
      "Epoch: 7461, Train Loss: 0.3877224028110504, Valid Loss: 0.6581301689147949\n",
      "Epoch: 7462, Train Loss: 0.3877218961715698, Valid Loss: 0.6591009497642517\n",
      "Epoch: 7463, Train Loss: 0.3877224028110504, Valid Loss: 0.6602379083633423\n",
      "Epoch: 7464, Train Loss: 0.38772276043891907, Valid Loss: 0.6572391390800476\n",
      "Epoch: 7465, Train Loss: 0.387723833322525, Valid Loss: 0.6615630388259888\n",
      "Epoch: 7466, Train Loss: 0.3877241313457489, Valid Loss: 0.6565312147140503\n",
      "Epoch: 7467, Train Loss: 0.387724369764328, Valid Loss: 0.6618345379829407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7468, Train Loss: 0.3877239525318146, Valid Loss: 0.6569492220878601\n",
      "Epoch: 7469, Train Loss: 0.3877231478691101, Valid Loss: 0.6611101031303406\n",
      "Epoch: 7470, Train Loss: 0.3877221643924713, Valid Loss: 0.6579154133796692\n",
      "Epoch: 7471, Train Loss: 0.3877216577529907, Valid Loss: 0.6599440574645996\n",
      "Epoch: 7472, Train Loss: 0.3877212107181549, Valid Loss: 0.6591012477874756\n",
      "Epoch: 7473, Train Loss: 0.3877211809158325, Valid Loss: 0.6589199304580688\n",
      "Epoch: 7474, Train Loss: 0.3877212107181549, Valid Loss: 0.6601206064224243\n",
      "Epoch: 7475, Train Loss: 0.3877214193344116, Valid Loss: 0.6581997871398926\n",
      "Epoch: 7476, Train Loss: 0.38772183656692505, Valid Loss: 0.6606613397598267\n",
      "Epoch: 7477, Train Loss: 0.38772183656692505, Valid Loss: 0.6578353643417358\n",
      "Epoch: 7478, Train Loss: 0.3877218961715698, Valid Loss: 0.6608095765113831\n",
      "Epoch: 7479, Train Loss: 0.3877217471599579, Valid Loss: 0.6578799486160278\n",
      "Epoch: 7480, Train Loss: 0.38772162795066833, Valid Loss: 0.6607142090797424\n",
      "Epoch: 7481, Train Loss: 0.3877214193344116, Valid Loss: 0.6581772565841675\n",
      "Epoch: 7482, Train Loss: 0.3877212405204773, Valid Loss: 0.6603671908378601\n",
      "Epoch: 7483, Train Loss: 0.38772088289260864, Valid Loss: 0.6585849523544312\n",
      "Epoch: 7484, Train Loss: 0.38772052526474, Valid Loss: 0.6599067449569702\n",
      "Epoch: 7485, Train Loss: 0.3877204358577728, Valid Loss: 0.6590676307678223\n",
      "Epoch: 7486, Train Loss: 0.38772037625312805, Valid Loss: 0.6594882011413574\n",
      "Epoch: 7487, Train Loss: 0.3877203166484833, Valid Loss: 0.6595506072044373\n",
      "Epoch: 7488, Train Loss: 0.38772013783454895, Valid Loss: 0.6591036915779114\n",
      "Epoch: 7489, Train Loss: 0.38772058486938477, Valid Loss: 0.6599279046058655\n",
      "Epoch: 7490, Train Loss: 0.3877201974391937, Valid Loss: 0.658781111240387\n",
      "Epoch: 7491, Train Loss: 0.3877204358577728, Valid Loss: 0.6602091789245605\n",
      "Epoch: 7492, Train Loss: 0.38772040605545044, Valid Loss: 0.6585908532142639\n",
      "Epoch: 7493, Train Loss: 0.3877204656600952, Valid Loss: 0.6604218482971191\n",
      "Epoch: 7494, Train Loss: 0.3877202570438385, Valid Loss: 0.658479630947113\n",
      "Epoch: 7495, Train Loss: 0.3877203166484833, Valid Loss: 0.6605113744735718\n",
      "Epoch: 7496, Train Loss: 0.3877200186252594, Valid Loss: 0.6584452986717224\n",
      "Epoch: 7497, Train Loss: 0.38771992921829224, Valid Loss: 0.6605145931243896\n",
      "Epoch: 7498, Train Loss: 0.38771945238113403, Valid Loss: 0.6584936380386353\n",
      "Epoch: 7499, Train Loss: 0.38771960139274597, Valid Loss: 0.6604945659637451\n",
      "Epoch: 7500, Train Loss: 0.38771969079971313, Valid Loss: 0.6585641503334045\n",
      "Epoch: 7501, Train Loss: 0.38771945238113403, Valid Loss: 0.66048264503479\n",
      "Epoch: 7502, Train Loss: 0.3877197802066803, Valid Loss: 0.6585699319839478\n",
      "Epoch: 7503, Train Loss: 0.38771960139274597, Valid Loss: 0.6605053544044495\n",
      "Epoch: 7504, Train Loss: 0.3877197206020355, Valid Loss: 0.6585271954536438\n",
      "Epoch: 7505, Train Loss: 0.3877197802066803, Valid Loss: 0.6606082320213318\n",
      "Epoch: 7506, Train Loss: 0.38771966099739075, Valid Loss: 0.6584489345550537\n",
      "Epoch: 7507, Train Loss: 0.3877195119857788, Valid Loss: 0.6607696413993835\n",
      "Epoch: 7508, Train Loss: 0.3877198398113251, Valid Loss: 0.6582688689231873\n",
      "Epoch: 7509, Train Loss: 0.38771966099739075, Valid Loss: 0.6610159873962402\n",
      "Epoch: 7510, Train Loss: 0.3877197802066803, Valid Loss: 0.6579813361167908\n",
      "Epoch: 7511, Train Loss: 0.3877204954624176, Valid Loss: 0.6613930463790894\n",
      "Epoch: 7512, Train Loss: 0.3877210319042206, Valid Loss: 0.657552182674408\n",
      "Epoch: 7513, Train Loss: 0.38772138953208923, Valid Loss: 0.6619927287101746\n",
      "Epoch: 7514, Train Loss: 0.3877220153808594, Valid Loss: 0.6568509936332703\n",
      "Epoch: 7515, Train Loss: 0.3877231478691101, Valid Loss: 0.6628581881523132\n",
      "Epoch: 7516, Train Loss: 0.3877251446247101, Valid Loss: 0.6558367013931274\n",
      "Epoch: 7517, Train Loss: 0.3877275884151459, Valid Loss: 0.6641342639923096\n",
      "Epoch: 7518, Train Loss: 0.38773173093795776, Valid Loss: 0.6543289422988892\n",
      "Epoch: 7519, Train Loss: 0.3877374231815338, Valid Loss: 0.666095495223999\n",
      "Epoch: 7520, Train Loss: 0.3877468407154083, Valid Loss: 0.6520111560821533\n",
      "Epoch: 7521, Train Loss: 0.387759268283844, Valid Loss: 0.6690965890884399\n",
      "Epoch: 7522, Train Loss: 0.38777920603752136, Valid Loss: 0.6484928131103516\n",
      "Epoch: 7523, Train Loss: 0.3878070116043091, Valid Loss: 0.6737020611763\n",
      "Epoch: 7524, Train Loss: 0.3878523111343384, Valid Loss: 0.6432132124900818\n",
      "Epoch: 7525, Train Loss: 0.3879099488258362, Valid Loss: 0.6806510090827942\n",
      "Epoch: 7526, Train Loss: 0.3880035877227783, Valid Loss: 0.6357479095458984\n",
      "Epoch: 7527, Train Loss: 0.3881043493747711, Valid Loss: 0.6902883648872375\n",
      "Epoch: 7528, Train Loss: 0.3882603943347931, Valid Loss: 0.6265994906425476\n",
      "Epoch: 7529, Train Loss: 0.3883664011955261, Valid Loss: 0.7008672952651978\n",
      "Epoch: 7530, Train Loss: 0.38850778341293335, Valid Loss: 0.6191221475601196\n",
      "Epoch: 7531, Train Loss: 0.38847610354423523, Valid Loss: 0.7056612372398376\n",
      "Epoch: 7532, Train Loss: 0.388418972492218, Valid Loss: 0.6202607154846191\n",
      "Epoch: 7533, Train Loss: 0.3881906270980835, Valid Loss: 0.6958882212638855\n",
      "Epoch: 7534, Train Loss: 0.3879815936088562, Valid Loss: 0.6346682906150818\n",
      "Epoch: 7535, Train Loss: 0.3878033459186554, Valid Loss: 0.6733689904212952\n",
      "Epoch: 7536, Train Loss: 0.3877318203449249, Valid Loss: 0.6576108336448669\n",
      "Epoch: 7537, Train Loss: 0.38776323199272156, Valid Loss: 0.6501843333244324\n",
      "Epoch: 7538, Train Loss: 0.38785749673843384, Valid Loss: 0.6783482432365417\n",
      "Epoch: 7539, Train Loss: 0.3879633843898773, Valid Loss: 0.6356126070022583\n",
      "Epoch: 7540, Train Loss: 0.3879971206188202, Valid Loss: 0.6869380474090576\n",
      "Epoch: 7541, Train Loss: 0.3879719376564026, Valid Loss: 0.6348299980163574\n",
      "Epoch: 7542, Train Loss: 0.3878750205039978, Valid Loss: 0.6795077323913574\n",
      "Epoch: 7543, Train Loss: 0.3877836763858795, Valid Loss: 0.6472526788711548\n",
      "Epoch: 7544, Train Loss: 0.3877297341823578, Valid Loss: 0.6629986763000488\n",
      "Epoch: 7545, Train Loss: 0.3877292573451996, Valid Loss: 0.6637760996818542\n",
      "Epoch: 7546, Train Loss: 0.3877659738063812, Valid Loss: 0.6486684679985046\n",
      "Epoch: 7547, Train Loss: 0.38780704140663147, Valid Loss: 0.674570620059967\n",
      "Epoch: 7548, Train Loss: 0.38783207535743713, Valid Loss: 0.6428996920585632\n",
      "Epoch: 7549, Train Loss: 0.38782307505607605, Valid Loss: 0.6752679347991943\n",
      "Epoch: 7550, Train Loss: 0.38779616355895996, Valid Loss: 0.6468772292137146\n",
      "Epoch: 7551, Train Loss: 0.38775870203971863, Valid Loss: 0.6677312254905701\n",
      "Epoch: 7552, Train Loss: 0.3877306282520294, Valid Loss: 0.6563102602958679\n",
      "Epoch: 7553, Train Loss: 0.38772052526474, Valid Loss: 0.6577253937721252\n",
      "Epoch: 7554, Train Loss: 0.38772985339164734, Valid Loss: 0.664663553237915\n",
      "Epoch: 7555, Train Loss: 0.3877498507499695, Valid Loss: 0.650911271572113\n",
      "Epoch: 7556, Train Loss: 0.38776570558547974, Valid Loss: 0.669097363948822\n",
      "Epoch: 7557, Train Loss: 0.3877700865268707, Valid Loss: 0.6494905948638916\n",
      "Epoch: 7558, Train Loss: 0.38775911927223206, Valid Loss: 0.6686272621154785\n",
      "Epoch: 7559, Train Loss: 0.38774189352989197, Valid Loss: 0.6523943543434143\n",
      "Epoch: 7560, Train Loss: 0.3877255618572235, Valid Loss: 0.6636326313018799\n",
      "Epoch: 7561, Train Loss: 0.3877185881137848, Valid Loss: 0.6577244400978088\n",
      "Epoch: 7562, Train Loss: 0.3877198398113251, Valid Loss: 0.657675564289093\n",
      "Epoch: 7563, Train Loss: 0.387727290391922, Valid Loss: 0.6632046699523926\n",
      "Epoch: 7564, Train Loss: 0.3877350986003876, Valid Loss: 0.6537864804267883\n",
      "Epoch: 7565, Train Loss: 0.3877389430999756, Valid Loss: 0.6663286089897156\n",
      "Epoch: 7566, Train Loss: 0.387738436460495, Valid Loss: 0.6524972319602966\n",
      "Epoch: 7567, Train Loss: 0.38773372769355774, Valid Loss: 0.665865957736969\n",
      "Epoch: 7568, Train Loss: 0.387727826833725, Valid Loss: 0.6540231108665466\n",
      "Epoch: 7569, Train Loss: 0.3877222239971161, Valid Loss: 0.6628537178039551\n",
      "Epoch: 7570, Train Loss: 0.3877183794975281, Valid Loss: 0.6579055786132812\n",
      "Epoch: 7571, Train Loss: 0.3877173960208893, Valid Loss: 0.6590954065322876\n",
      "Epoch: 7572, Train Loss: 0.38771915435791016, Valid Loss: 0.6618193984031677\n",
      "Epoch: 7573, Train Loss: 0.3877222239971161, Valid Loss: 0.6558984518051147\n",
      "Epoch: 7574, Train Loss: 0.3877246677875519, Valid Loss: 0.6639597415924072\n",
      "Epoch: 7575, Train Loss: 0.38772591948509216, Valid Loss: 0.6545579433441162\n",
      "Epoch: 7576, Train Loss: 0.3877251148223877, Valid Loss: 0.6642230749130249\n",
      "Epoch: 7577, Train Loss: 0.38772305846214294, Valid Loss: 0.6554955840110779\n",
      "Epoch: 7578, Train Loss: 0.38772037625312805, Valid Loss: 0.6627670526504517\n",
      "Epoch: 7579, Train Loss: 0.3877185583114624, Valid Loss: 0.6576170921325684\n",
      "Epoch: 7580, Train Loss: 0.38771703839302063, Valid Loss: 0.6604060530662537\n",
      "Epoch: 7581, Train Loss: 0.3877158463001251, Valid Loss: 0.6597270369529724\n",
      "Epoch: 7582, Train Loss: 0.38771671056747437, Valid Loss: 0.6584636569023132\n",
      "Epoch: 7583, Train Loss: 0.38771748542785645, Valid Loss: 0.6613824367523193\n",
      "Epoch: 7584, Train Loss: 0.3877182900905609, Valid Loss: 0.657400369644165\n",
      "Epoch: 7585, Train Loss: 0.38771897554397583, Valid Loss: 0.6622529029846191\n",
      "Epoch: 7586, Train Loss: 0.3877192735671997, Valid Loss: 0.6569867134094238\n",
      "Epoch: 7587, Train Loss: 0.3877193331718445, Valid Loss: 0.6622431874275208\n",
      "Epoch: 7588, Train Loss: 0.3877188563346863, Valid Loss: 0.6572227478027344\n",
      "Epoch: 7589, Train Loss: 0.3877181112766266, Valid Loss: 0.6617845892906189\n",
      "Epoch: 7590, Train Loss: 0.38771727681159973, Valid Loss: 0.6579489707946777\n",
      "Epoch: 7591, Train Loss: 0.387716680765152, Valid Loss: 0.661152720451355\n",
      "Epoch: 7592, Train Loss: 0.38771605491638184, Valid Loss: 0.6587336659431458\n",
      "Epoch: 7593, Train Loss: 0.38771533966064453, Valid Loss: 0.6603199243545532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7594, Train Loss: 0.3877153694629669, Valid Loss: 0.6595176458358765\n",
      "Epoch: 7595, Train Loss: 0.38771581649780273, Valid Loss: 0.65956711769104\n",
      "Epoch: 7596, Train Loss: 0.38771554827690125, Valid Loss: 0.6602778434753418\n",
      "Epoch: 7597, Train Loss: 0.387715607881546, Valid Loss: 0.6590189933776855\n",
      "Epoch: 7598, Train Loss: 0.3877156972885132, Valid Loss: 0.6608477830886841\n",
      "Epoch: 7599, Train Loss: 0.3877159357070923, Valid Loss: 0.6585766673088074\n",
      "Epoch: 7600, Train Loss: 0.3877158761024475, Valid Loss: 0.6611834168434143\n",
      "Epoch: 7601, Train Loss: 0.3877162039279938, Valid Loss: 0.6582930684089661\n",
      "Epoch: 7602, Train Loss: 0.38771599531173706, Valid Loss: 0.6613770127296448\n",
      "Epoch: 7603, Train Loss: 0.3877158463001251, Valid Loss: 0.6582778692245483\n",
      "Epoch: 7604, Train Loss: 0.38771602511405945, Valid Loss: 0.661399781703949\n",
      "Epoch: 7605, Train Loss: 0.38771581649780273, Valid Loss: 0.6583774089813232\n",
      "Epoch: 7606, Train Loss: 0.3877154290676117, Valid Loss: 0.6612719893455505\n",
      "Epoch: 7607, Train Loss: 0.3877153992652893, Valid Loss: 0.6585026383399963\n",
      "Epoch: 7608, Train Loss: 0.38771453499794006, Valid Loss: 0.6611402034759521\n",
      "Epoch: 7609, Train Loss: 0.3877154290676117, Valid Loss: 0.6586927771568298\n",
      "Epoch: 7610, Train Loss: 0.38771525025367737, Valid Loss: 0.6610339283943176\n",
      "Epoch: 7611, Train Loss: 0.38771504163742065, Valid Loss: 0.6588560342788696\n",
      "Epoch: 7612, Train Loss: 0.3877149522304535, Valid Loss: 0.6609327793121338\n",
      "Epoch: 7613, Train Loss: 0.38771510124206543, Valid Loss: 0.658926784992218\n",
      "Epoch: 7614, Train Loss: 0.38771453499794006, Valid Loss: 0.6609207391738892\n",
      "Epoch: 7615, Train Loss: 0.38771480321884155, Valid Loss: 0.6589205265045166\n",
      "Epoch: 7616, Train Loss: 0.3877149820327759, Valid Loss: 0.6610153913497925\n",
      "Epoch: 7617, Train Loss: 0.38771480321884155, Valid Loss: 0.6588466167449951\n",
      "Epoch: 7618, Train Loss: 0.3877145051956177, Valid Loss: 0.6611555218696594\n",
      "Epoch: 7619, Train Loss: 0.3877147436141968, Valid Loss: 0.6586753726005554\n",
      "Epoch: 7620, Train Loss: 0.38771477341651917, Valid Loss: 0.6614022850990295\n",
      "Epoch: 7621, Train Loss: 0.3877148926258087, Valid Loss: 0.6583832502365112\n",
      "Epoch: 7622, Train Loss: 0.38771411776542664, Valid Loss: 0.6617863178253174\n",
      "Epoch: 7623, Train Loss: 0.38771551847457886, Valid Loss: 0.6579834222793579\n",
      "Epoch: 7624, Train Loss: 0.38771623373031616, Valid Loss: 0.6623224020004272\n",
      "Epoch: 7625, Train Loss: 0.3877168893814087, Valid Loss: 0.6573623418807983\n",
      "Epoch: 7626, Train Loss: 0.3877178430557251, Valid Loss: 0.6631125807762146\n",
      "Epoch: 7627, Train Loss: 0.3877192735671997, Valid Loss: 0.6564154028892517\n",
      "Epoch: 7628, Train Loss: 0.3877214193344116, Valid Loss: 0.6643322110176086\n",
      "Epoch: 7629, Train Loss: 0.38772517442703247, Valid Loss: 0.654975414276123\n",
      "Epoch: 7630, Train Loss: 0.3877301812171936, Valid Loss: 0.6662167310714722\n",
      "Epoch: 7631, Train Loss: 0.38773801922798157, Valid Loss: 0.6527162194252014\n",
      "Epoch: 7632, Train Loss: 0.3877493143081665, Valid Loss: 0.6691532731056213\n",
      "Epoch: 7633, Train Loss: 0.3877676725387573, Valid Loss: 0.649217426776886\n",
      "Epoch: 7634, Train Loss: 0.38779357075691223, Valid Loss: 0.6737280488014221\n",
      "Epoch: 7635, Train Loss: 0.3878350853919983, Valid Loss: 0.6439481377601624\n",
      "Epoch: 7636, Train Loss: 0.38789045810699463, Valid Loss: 0.6806711554527283\n",
      "Epoch: 7637, Train Loss: 0.3879820704460144, Valid Loss: 0.6363368034362793\n",
      "Epoch: 7638, Train Loss: 0.3880857229232788, Valid Loss: 0.6905539035797119\n",
      "Epoch: 7639, Train Loss: 0.38825181126594543, Valid Loss: 0.6267196536064148\n",
      "Epoch: 7640, Train Loss: 0.38837864995002747, Valid Loss: 0.7019907236099243\n",
      "Epoch: 7641, Train Loss: 0.38855424523353577, Valid Loss: 0.6183407306671143\n",
      "Epoch: 7642, Train Loss: 0.3885453939437866, Valid Loss: 0.7082780599594116\n",
      "Epoch: 7643, Train Loss: 0.3885076940059662, Valid Loss: 0.6185836791992188\n",
      "Epoch: 7644, Train Loss: 0.3882569372653961, Valid Loss: 0.6992032527923584\n",
      "Epoch: 7645, Train Loss: 0.38801848888397217, Valid Loss: 0.6330905556678772\n",
      "Epoch: 7646, Train Loss: 0.38781070709228516, Valid Loss: 0.6752839684486389\n",
      "Epoch: 7647, Train Loss: 0.38772785663604736, Valid Loss: 0.6573089361190796\n",
      "Epoch: 7648, Train Loss: 0.3877639174461365, Valid Loss: 0.6503307223320007\n",
      "Epoch: 7649, Train Loss: 0.3878701329231262, Valid Loss: 0.6796446442604065\n",
      "Epoch: 7650, Train Loss: 0.3879873752593994, Valid Loss: 0.6350319385528564\n",
      "Epoch: 7651, Train Loss: 0.3880217969417572, Valid Loss: 0.6887807250022888\n",
      "Epoch: 7652, Train Loss: 0.38798969984054565, Valid Loss: 0.6342825889587402\n",
      "Epoch: 7653, Train Loss: 0.38787642121315, Valid Loss: 0.6804730296134949\n",
      "Epoch: 7654, Train Loss: 0.3877730667591095, Valid Loss: 0.6475880146026611\n",
      "Epoch: 7655, Train Loss: 0.38771846890449524, Valid Loss: 0.6623671650886536\n",
      "Epoch: 7656, Train Loss: 0.3877277672290802, Valid Loss: 0.6656526327133179\n",
      "Epoch: 7657, Train Loss: 0.38777828216552734, Valid Loss: 0.647127091884613\n",
      "Epoch: 7658, Train Loss: 0.3878275752067566, Valid Loss: 0.6771864295005798\n",
      "Epoch: 7659, Train Loss: 0.38784971833229065, Valid Loss: 0.6417266726493835\n",
      "Epoch: 7660, Train Loss: 0.3878255784511566, Valid Loss: 0.676608681678772\n",
      "Epoch: 7661, Train Loss: 0.38778263330459595, Valid Loss: 0.6472118496894836\n",
      "Epoch: 7662, Train Loss: 0.38773906230926514, Valid Loss: 0.6667376756668091\n",
      "Epoch: 7663, Train Loss: 0.3877181112766266, Valid Loss: 0.6588336229324341\n",
      "Epoch: 7664, Train Loss: 0.3877221941947937, Valid Loss: 0.6552605628967285\n",
      "Epoch: 7665, Train Loss: 0.3877415359020233, Valid Loss: 0.6683143377304077\n",
      "Epoch: 7666, Train Loss: 0.38776227831840515, Valid Loss: 0.6487862467765808\n",
      "Epoch: 7667, Train Loss: 0.38777077198028564, Valid Loss: 0.6712270975112915\n",
      "Epoch: 7668, Train Loss: 0.3877652883529663, Valid Loss: 0.6494140625\n",
      "Epoch: 7669, Train Loss: 0.38774698972702026, Valid Loss: 0.6679409146308899\n",
      "Epoch: 7670, Train Loss: 0.38772791624069214, Valid Loss: 0.6549015045166016\n",
      "Epoch: 7671, Train Loss: 0.3877154588699341, Valid Loss: 0.6610978841781616\n",
      "Epoch: 7672, Train Loss: 0.3877142369747162, Valid Loss: 0.661510169506073\n",
      "Epoch: 7673, Train Loss: 0.38772159814834595, Valid Loss: 0.6549947261810303\n",
      "Epoch: 7674, Train Loss: 0.3877319097518921, Valid Loss: 0.666130542755127\n",
      "Epoch: 7675, Train Loss: 0.38773879408836365, Valid Loss: 0.6526103019714355\n",
      "Epoch: 7676, Train Loss: 0.3877384066581726, Valid Loss: 0.667000412940979\n",
      "Epoch: 7677, Train Loss: 0.3877314627170563, Valid Loss: 0.6537965536117554\n",
      "Epoch: 7678, Train Loss: 0.3877224326133728, Valid Loss: 0.6642963886260986\n",
      "Epoch: 7679, Train Loss: 0.38771533966064453, Valid Loss: 0.6571652293205261\n",
      "Epoch: 7680, Train Loss: 0.38771259784698486, Valid Loss: 0.6601698398590088\n",
      "Epoch: 7681, Train Loss: 0.387714147567749, Valid Loss: 0.6612492203712463\n",
      "Epoch: 7682, Train Loss: 0.38771775364875793, Valid Loss: 0.6568393111228943\n",
      "Epoch: 7683, Train Loss: 0.38772156834602356, Valid Loss: 0.6641628742218018\n",
      "Epoch: 7684, Train Loss: 0.3877231478691101, Valid Loss: 0.6551661491394043\n",
      "Epoch: 7685, Train Loss: 0.3877224624156952, Valid Loss: 0.6647485494613647\n",
      "Epoch: 7686, Train Loss: 0.38772010803222656, Valid Loss: 0.6554132699966431\n",
      "Epoch: 7687, Train Loss: 0.38771727681159973, Valid Loss: 0.6634567379951477\n",
      "Epoch: 7688, Train Loss: 0.3877140283584595, Valid Loss: 0.6574537754058838\n",
      "Epoch: 7689, Train Loss: 0.3877124488353729, Valid Loss: 0.6611348986625671\n",
      "Epoch: 7690, Train Loss: 0.38771215081214905, Valid Loss: 0.6601675152778625\n",
      "Epoch: 7691, Train Loss: 0.38771259784698486, Valid Loss: 0.6586287021636963\n",
      "Epoch: 7692, Train Loss: 0.3877137303352356, Valid Loss: 0.6622791886329651\n",
      "Epoch: 7693, Train Loss: 0.3877151608467102, Valid Loss: 0.6569766998291016\n",
      "Epoch: 7694, Train Loss: 0.38771575689315796, Valid Loss: 0.6632917523384094\n",
      "Epoch: 7695, Train Loss: 0.38771551847457886, Valid Loss: 0.6567175388336182\n",
      "Epoch: 7696, Train Loss: 0.38771501183509827, Valid Loss: 0.6631110906600952\n",
      "Epoch: 7697, Train Loss: 0.3877137005329132, Valid Loss: 0.6575305461883545\n",
      "Epoch: 7698, Train Loss: 0.3877125680446625, Valid Loss: 0.6619454026222229\n",
      "Epoch: 7699, Train Loss: 0.3877120316028595, Valid Loss: 0.6588941216468811\n",
      "Epoch: 7700, Train Loss: 0.3877113163471222, Valid Loss: 0.6604666113853455\n",
      "Epoch: 7701, Train Loss: 0.3877107501029968, Valid Loss: 0.6603624224662781\n",
      "Epoch: 7702, Train Loss: 0.38771137595176697, Valid Loss: 0.6592648029327393\n",
      "Epoch: 7703, Train Loss: 0.38771164417266846, Valid Loss: 0.6614847779273987\n",
      "Epoch: 7704, Train Loss: 0.3877120316028595, Valid Loss: 0.6584459543228149\n",
      "Epoch: 7705, Train Loss: 0.38771218061447144, Valid Loss: 0.6620351672172546\n",
      "Epoch: 7706, Train Loss: 0.3877122104167938, Valid Loss: 0.6581652760505676\n",
      "Epoch: 7707, Train Loss: 0.3877120316028595, Valid Loss: 0.6621201038360596\n",
      "Epoch: 7708, Train Loss: 0.3877122104167938, Valid Loss: 0.6583625674247742\n",
      "Epoch: 7709, Train Loss: 0.38771194219589233, Valid Loss: 0.6618679761886597\n",
      "Epoch: 7710, Train Loss: 0.387711763381958, Valid Loss: 0.6587573289871216\n",
      "Epoch: 7711, Train Loss: 0.3877112865447998, Valid Loss: 0.6614518761634827\n",
      "Epoch: 7712, Train Loss: 0.3877111077308655, Valid Loss: 0.6591755747795105\n",
      "Epoch: 7713, Train Loss: 0.38771066069602966, Valid Loss: 0.6610368490219116\n",
      "Epoch: 7714, Train Loss: 0.38771048188209534, Valid Loss: 0.6596133708953857\n",
      "Epoch: 7715, Train Loss: 0.3877103924751282, Valid Loss: 0.6606846451759338\n",
      "Epoch: 7716, Train Loss: 0.3877101242542267, Valid Loss: 0.6600092053413391\n",
      "Epoch: 7717, Train Loss: 0.38770997524261475, Valid Loss: 0.660361111164093\n",
      "Epoch: 7718, Train Loss: 0.3877098858356476, Valid Loss: 0.6603183746337891\n",
      "Epoch: 7719, Train Loss: 0.3877100944519043, Valid Loss: 0.6600548624992371\n",
      "Epoch: 7720, Train Loss: 0.387710303068161, Valid Loss: 0.6606537103652954\n",
      "Epoch: 7721, Train Loss: 0.3877103924751282, Valid Loss: 0.6597976088523865\n",
      "Epoch: 7722, Train Loss: 0.3877101540565491, Valid Loss: 0.6609571576118469\n",
      "Epoch: 7723, Train Loss: 0.3877101242542267, Valid Loss: 0.6595824360847473\n",
      "Epoch: 7724, Train Loss: 0.38770997524261475, Valid Loss: 0.6611485481262207\n",
      "Epoch: 7725, Train Loss: 0.3877101242542267, Valid Loss: 0.659430980682373\n",
      "Epoch: 7726, Train Loss: 0.38771000504493713, Valid Loss: 0.6613209247589111\n",
      "Epoch: 7727, Train Loss: 0.3877101242542267, Valid Loss: 0.6592982411384583\n",
      "Epoch: 7728, Train Loss: 0.3877100944519043, Valid Loss: 0.6615153551101685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7729, Train Loss: 0.38771024346351624, Valid Loss: 0.6591485738754272\n",
      "Epoch: 7730, Train Loss: 0.38770952820777893, Valid Loss: 0.6616924405097961\n",
      "Epoch: 7731, Train Loss: 0.387710303068161, Valid Loss: 0.65897536277771\n",
      "Epoch: 7732, Train Loss: 0.38771018385887146, Valid Loss: 0.6619038581848145\n",
      "Epoch: 7733, Train Loss: 0.3877103924751282, Valid Loss: 0.6587674617767334\n",
      "Epoch: 7734, Train Loss: 0.38771042227745056, Valid Loss: 0.6622052788734436\n",
      "Epoch: 7735, Train Loss: 0.38771092891693115, Valid Loss: 0.6584305763244629\n",
      "Epoch: 7736, Train Loss: 0.38771116733551025, Valid Loss: 0.6626553535461426\n",
      "Epoch: 7737, Train Loss: 0.38771194219589233, Valid Loss: 0.6579071879386902\n",
      "Epoch: 7738, Train Loss: 0.387712687253952, Valid Loss: 0.6633349657058716\n",
      "Epoch: 7739, Train Loss: 0.38771429657936096, Valid Loss: 0.6571157574653625\n",
      "Epoch: 7740, Train Loss: 0.3877158463001251, Valid Loss: 0.6643543839454651\n",
      "Epoch: 7741, Train Loss: 0.38771864771842957, Valid Loss: 0.6559320092201233\n",
      "Epoch: 7742, Train Loss: 0.3877220153808594, Valid Loss: 0.6658680438995361\n",
      "Epoch: 7743, Train Loss: 0.3877279460430145, Valid Loss: 0.6541625261306763\n",
      "Epoch: 7744, Train Loss: 0.3877357542514801, Valid Loss: 0.6681199073791504\n",
      "Epoch: 7745, Train Loss: 0.38774821162223816, Valid Loss: 0.6515081524848938\n",
      "Epoch: 7746, Train Loss: 0.3877647817134857, Valid Loss: 0.6715788245201111\n",
      "Epoch: 7747, Train Loss: 0.3877919614315033, Valid Loss: 0.647514820098877\n",
      "Epoch: 7748, Train Loss: 0.3878270387649536, Valid Loss: 0.676791787147522\n",
      "Epoch: 7749, Train Loss: 0.38788336515426636, Valid Loss: 0.6417161822319031\n",
      "Epoch: 7750, Train Loss: 0.3879495859146118, Valid Loss: 0.6843063831329346\n",
      "Epoch: 7751, Train Loss: 0.38805508613586426, Valid Loss: 0.6339696645736694\n",
      "Epoch: 7752, Train Loss: 0.3881523609161377, Valid Loss: 0.6939579248428345\n",
      "Epoch: 7753, Train Loss: 0.38829994201660156, Valid Loss: 0.6254280805587769\n",
      "Epoch: 7754, Train Loss: 0.38836902379989624, Valid Loss: 0.7028764486312866\n",
      "Epoch: 7755, Train Loss: 0.3884551525115967, Valid Loss: 0.6202190518379211\n",
      "Epoch: 7756, Train Loss: 0.3883705735206604, Valid Loss: 0.7038664817810059\n",
      "Epoch: 7757, Train Loss: 0.38826504349708557, Valid Loss: 0.6246643662452698\n",
      "Epoch: 7758, Train Loss: 0.3880479335784912, Valid Loss: 0.6910136342048645\n",
      "Epoch: 7759, Train Loss: 0.3878689110279083, Valid Loss: 0.6408738493919373\n",
      "Epoch: 7760, Train Loss: 0.3877458870410919, Valid Loss: 0.6689935922622681\n",
      "Epoch: 7761, Train Loss: 0.387717068195343, Valid Loss: 0.6625943779945374\n",
      "Epoch: 7762, Train Loss: 0.387769877910614, Valid Loss: 0.6483490467071533\n",
      "Epoch: 7763, Train Loss: 0.38785943388938904, Valid Loss: 0.6803120374679565\n",
      "Epoch: 7764, Train Loss: 0.38794422149658203, Valid Loss: 0.6364847421646118\n",
      "Epoch: 7765, Train Loss: 0.38795897364616394, Valid Loss: 0.686306893825531\n",
      "Epoch: 7766, Train Loss: 0.3879266083240509, Valid Loss: 0.637398362159729\n",
      "Epoch: 7767, Train Loss: 0.38784268498420715, Valid Loss: 0.6786776185035706\n",
      "Epoch: 7768, Train Loss: 0.3877682089805603, Valid Loss: 0.649097740650177\n",
      "Epoch: 7769, Train Loss: 0.38772353529930115, Valid Loss: 0.663970410823822\n",
      "Epoch: 7770, Train Loss: 0.38771870732307434, Valid Loss: 0.6635944247245789\n",
      "Epoch: 7771, Train Loss: 0.3877428472042084, Valid Loss: 0.6511262655258179\n",
      "Epoch: 7772, Train Loss: 0.38777464628219604, Valid Loss: 0.673389196395874\n",
      "Epoch: 7773, Train Loss: 0.3877999484539032, Valid Loss: 0.6453534960746765\n",
      "Epoch: 7774, Train Loss: 0.38780298829078674, Valid Loss: 0.6751738786697388\n",
      "Epoch: 7775, Train Loss: 0.38778945803642273, Valid Loss: 0.6477289795875549\n",
      "Epoch: 7776, Train Loss: 0.38775908946990967, Valid Loss: 0.6698623895645142\n",
      "Epoch: 7777, Train Loss: 0.3877299129962921, Valid Loss: 0.6548977494239807\n",
      "Epoch: 7778, Train Loss: 0.38771188259124756, Valid Loss: 0.6614663004875183\n",
      "Epoch: 7779, Train Loss: 0.3877106308937073, Valid Loss: 0.662355363368988\n",
      "Epoch: 7780, Train Loss: 0.3877227306365967, Valid Loss: 0.6545818448066711\n",
      "Epoch: 7781, Train Loss: 0.3877384066581726, Valid Loss: 0.6677700877189636\n",
      "Epoch: 7782, Train Loss: 0.3877499997615814, Valid Loss: 0.6514235138893127\n",
      "Epoch: 7783, Train Loss: 0.3877498507499695, Valid Loss: 0.6695286631584167\n",
      "Epoch: 7784, Train Loss: 0.3877418041229248, Valid Loss: 0.6518982648849487\n",
      "Epoch: 7785, Train Loss: 0.3877280056476593, Valid Loss: 0.6670500040054321\n",
      "Epoch: 7786, Train Loss: 0.38771674036979675, Valid Loss: 0.6552670001983643\n",
      "Epoch: 7787, Train Loss: 0.3877101540565491, Valid Loss: 0.6623865365982056\n",
      "Epoch: 7788, Train Loss: 0.3877097964286804, Valid Loss: 0.660256028175354\n",
      "Epoch: 7789, Train Loss: 0.3877125680446625, Valid Loss: 0.6578495502471924\n",
      "Epoch: 7790, Train Loss: 0.3877175748348236, Valid Loss: 0.6647406220436096\n",
      "Epoch: 7791, Train Loss: 0.3877219557762146, Valid Loss: 0.6545594930648804\n",
      "Epoch: 7792, Train Loss: 0.38772451877593994, Valid Loss: 0.666786253452301\n",
      "Epoch: 7793, Train Loss: 0.38772401213645935, Valid Loss: 0.6536456346511841\n",
      "Epoch: 7794, Train Loss: 0.3877204656600952, Valid Loss: 0.6661827564239502\n",
      "Epoch: 7795, Train Loss: 0.38771623373031616, Valid Loss: 0.6555004715919495\n",
      "Epoch: 7796, Train Loss: 0.38771119713783264, Valid Loss: 0.6637466549873352\n",
      "Epoch: 7797, Train Loss: 0.38770851492881775, Valid Loss: 0.658705472946167\n",
      "Epoch: 7798, Train Loss: 0.38770726323127747, Valid Loss: 0.6604300737380981\n",
      "Epoch: 7799, Train Loss: 0.38770782947540283, Valid Loss: 0.661715567111969\n",
      "Epoch: 7800, Train Loss: 0.3877096474170685, Valid Loss: 0.6576936841011047\n",
      "Epoch: 7801, Train Loss: 0.3877112865447998, Valid Loss: 0.6638410091400146\n",
      "Epoch: 7802, Train Loss: 0.3877127468585968, Valid Loss: 0.6565072536468506\n",
      "Epoch: 7803, Train Loss: 0.3877131938934326, Valid Loss: 0.6644927263259888\n",
      "Epoch: 7804, Train Loss: 0.3877130150794983, Valid Loss: 0.6566475033760071\n",
      "Epoch: 7805, Train Loss: 0.3877120912075043, Valid Loss: 0.6638469099998474\n",
      "Epoch: 7806, Train Loss: 0.3877108097076416, Valid Loss: 0.6575491428375244\n",
      "Epoch: 7807, Train Loss: 0.38770967721939087, Valid Loss: 0.6626848578453064\n",
      "Epoch: 7808, Train Loss: 0.3877081871032715, Valid Loss: 0.6588742733001709\n",
      "Epoch: 7809, Train Loss: 0.38770702481269836, Valid Loss: 0.6614641547203064\n",
      "Epoch: 7810, Train Loss: 0.38770654797554016, Valid Loss: 0.6601850986480713\n",
      "Epoch: 7811, Train Loss: 0.3877063989639282, Valid Loss: 0.6602781414985657\n",
      "Epoch: 7812, Train Loss: 0.3877066671848297, Valid Loss: 0.6611960530281067\n",
      "Epoch: 7813, Train Loss: 0.3877069652080536, Valid Loss: 0.6593632698059082\n",
      "Epoch: 7814, Train Loss: 0.38770735263824463, Valid Loss: 0.6620268821716309\n",
      "Epoch: 7815, Train Loss: 0.3877081871032715, Valid Loss: 0.6588039994239807\n",
      "Epoch: 7816, Train Loss: 0.3877079486846924, Valid Loss: 0.6625815033912659\n",
      "Epoch: 7817, Train Loss: 0.3877083957195282, Valid Loss: 0.6584744453430176\n",
      "Epoch: 7818, Train Loss: 0.3877076506614685, Valid Loss: 0.6627550721168518\n",
      "Epoch: 7819, Train Loss: 0.3877078890800476, Valid Loss: 0.6584137678146362\n",
      "Epoch: 7820, Train Loss: 0.3877076804637909, Valid Loss: 0.6627135276794434\n",
      "Epoch: 7821, Train Loss: 0.387707382440567, Valid Loss: 0.6586262583732605\n",
      "Epoch: 7822, Train Loss: 0.3877071738243103, Valid Loss: 0.6625320315361023\n",
      "Epoch: 7823, Train Loss: 0.3877071440219879, Valid Loss: 0.6589524149894714\n",
      "Epoch: 7824, Train Loss: 0.3877066373825073, Valid Loss: 0.6622045636177063\n",
      "Epoch: 7825, Train Loss: 0.3877067565917969, Valid Loss: 0.6592799425125122\n",
      "Epoch: 7826, Train Loss: 0.3877066969871521, Valid Loss: 0.6618527770042419\n",
      "Epoch: 7827, Train Loss: 0.38770592212677, Valid Loss: 0.6596395969390869\n",
      "Epoch: 7828, Train Loss: 0.38770586252212524, Valid Loss: 0.6616031527519226\n",
      "Epoch: 7829, Train Loss: 0.38770580291748047, Valid Loss: 0.6599338054656982\n",
      "Epoch: 7830, Train Loss: 0.3877057135105133, Valid Loss: 0.6613766551017761\n",
      "Epoch: 7831, Train Loss: 0.387705534696579, Valid Loss: 0.6601066589355469\n",
      "Epoch: 7832, Train Loss: 0.387705534696579, Valid Loss: 0.661268949508667\n",
      "Epoch: 7833, Train Loss: 0.38770508766174316, Valid Loss: 0.6601800322532654\n",
      "Epoch: 7834, Train Loss: 0.3877052962779999, Valid Loss: 0.6613137125968933\n",
      "Epoch: 7835, Train Loss: 0.3877051770687103, Valid Loss: 0.6601673364639282\n",
      "Epoch: 7836, Train Loss: 0.38770511746406555, Valid Loss: 0.6614024639129639\n",
      "Epoch: 7837, Train Loss: 0.3877049386501312, Valid Loss: 0.6600701212882996\n",
      "Epoch: 7838, Train Loss: 0.38770511746406555, Valid Loss: 0.6615405082702637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7839, Train Loss: 0.38770538568496704, Valid Loss: 0.6599391102790833\n",
      "Epoch: 7840, Train Loss: 0.38770562410354614, Valid Loss: 0.661730945110321\n",
      "Epoch: 7841, Train Loss: 0.38770514726638794, Valid Loss: 0.6597777605056763\n",
      "Epoch: 7842, Train Loss: 0.38770508766174316, Valid Loss: 0.661963701248169\n",
      "Epoch: 7843, Train Loss: 0.3877052366733551, Valid Loss: 0.6595240235328674\n",
      "Epoch: 7844, Train Loss: 0.3877054750919342, Valid Loss: 0.662284791469574\n",
      "Epoch: 7845, Train Loss: 0.3877054750919342, Valid Loss: 0.6591481566429138\n",
      "Epoch: 7846, Train Loss: 0.3877060115337372, Valid Loss: 0.6627975702285767\n",
      "Epoch: 7847, Train Loss: 0.3877064287662506, Valid Loss: 0.6585355997085571\n",
      "Epoch: 7848, Train Loss: 0.38770782947540283, Valid Loss: 0.6636142134666443\n",
      "Epoch: 7849, Train Loss: 0.38770902156829834, Valid Loss: 0.6575721502304077\n",
      "Epoch: 7850, Train Loss: 0.38771137595176697, Valid Loss: 0.6648873686790466\n",
      "Epoch: 7851, Train Loss: 0.3877151608467102, Valid Loss: 0.6560088992118835\n",
      "Epoch: 7852, Train Loss: 0.38772037625312805, Valid Loss: 0.6669403910636902\n",
      "Epoch: 7853, Train Loss: 0.38772886991500854, Valid Loss: 0.6535139679908752\n",
      "Epoch: 7854, Train Loss: 0.3877418637275696, Valid Loss: 0.670235276222229\n",
      "Epoch: 7855, Train Loss: 0.38776227831840515, Valid Loss: 0.6495622396469116\n",
      "Epoch: 7856, Train Loss: 0.38779422640800476, Valid Loss: 0.6754981279373169\n",
      "Epoch: 7857, Train Loss: 0.387846976518631, Valid Loss: 0.6433613300323486\n",
      "Epoch: 7858, Train Loss: 0.38791894912719727, Valid Loss: 0.6837995648384094\n",
      "Epoch: 7859, Train Loss: 0.38804149627685547, Valid Loss: 0.6342368721961975\n",
      "Epoch: 7860, Train Loss: 0.38818082213401794, Valid Loss: 0.6958537101745605\n",
      "Epoch: 7861, Train Loss: 0.3884073793888092, Valid Loss: 0.6227365136146545\n",
      "Epoch: 7862, Train Loss: 0.3885638117790222, Valid Loss: 0.7093965411186218\n",
      "Epoch: 7863, Train Loss: 0.3887707591056824, Valid Loss: 0.6138176918029785\n",
      "Epoch: 7864, Train Loss: 0.3886879086494446, Valid Loss: 0.7142815589904785\n",
      "Epoch: 7865, Train Loss: 0.3885500729084015, Valid Loss: 0.6177083253860474\n",
      "Epoch: 7866, Train Loss: 0.3881855905056, Valid Loss: 0.6978959441184998\n",
      "Epoch: 7867, Train Loss: 0.3878958523273468, Valid Loss: 0.6392841935157776\n",
      "Epoch: 7868, Train Loss: 0.38773590326309204, Valid Loss: 0.6668036580085754\n",
      "Epoch: 7869, Train Loss: 0.3877517879009247, Valid Loss: 0.6689918637275696\n",
      "Epoch: 7870, Train Loss: 0.3878898620605469, Valid Loss: 0.6405521631240845\n",
      "Epoch: 7871, Train Loss: 0.38803377747535706, Valid Loss: 0.6905958652496338\n",
      "Epoch: 7872, Train Loss: 0.38811731338500977, Valid Loss: 0.6299793720245361\n",
      "Epoch: 7873, Train Loss: 0.3880354166030884, Valid Loss: 0.6908574104309082\n",
      "Epoch: 7874, Train Loss: 0.3878953158855438, Valid Loss: 0.6388396620750427\n",
      "Epoch: 7875, Train Loss: 0.38775575160980225, Valid Loss: 0.6715928912162781\n",
      "Epoch: 7876, Train Loss: 0.3877061903476715, Valid Loss: 0.6604229211807251\n",
      "Epoch: 7877, Train Loss: 0.3877478241920471, Valid Loss: 0.6499267816543579\n",
      "Epoch: 7878, Train Loss: 0.38782578706741333, Valid Loss: 0.678702712059021\n",
      "Epoch: 7879, Train Loss: 0.3878840506076813, Valid Loss: 0.6399198174476624\n",
      "Epoch: 7880, Train Loss: 0.3878702223300934, Valid Loss: 0.681416392326355\n",
      "Epoch: 7881, Train Loss: 0.3878139555454254, Valid Loss: 0.6446051597595215\n",
      "Epoch: 7882, Train Loss: 0.3877450227737427, Valid Loss: 0.6695780158042908\n",
      "Epoch: 7883, Train Loss: 0.3877112567424774, Valid Loss: 0.6589363813400269\n",
      "Epoch: 7884, Train Loss: 0.38771888613700867, Valid Loss: 0.6547254920005798\n",
      "Epoch: 7885, Train Loss: 0.38775041699409485, Valid Loss: 0.6716870069503784\n",
      "Epoch: 7886, Train Loss: 0.3877798318862915, Valid Loss: 0.6469733715057373\n",
      "Epoch: 7887, Train Loss: 0.3877842128276825, Valid Loss: 0.6742098331451416\n",
      "Epoch: 7888, Train Loss: 0.38776785135269165, Valid Loss: 0.649290919303894\n",
      "Epoch: 7889, Train Loss: 0.38773614168167114, Valid Loss: 0.6678350567817688\n",
      "Epoch: 7890, Train Loss: 0.3877122402191162, Valid Loss: 0.6577661633491516\n",
      "Epoch: 7891, Train Loss: 0.3877062201499939, Valid Loss: 0.6585843563079834\n",
      "Epoch: 7892, Train Loss: 0.3877170979976654, Valid Loss: 0.6659447550773621\n",
      "Epoch: 7893, Train Loss: 0.3877343237400055, Valid Loss: 0.6522788405418396\n",
      "Epoch: 7894, Train Loss: 0.3877439796924591, Valid Loss: 0.6695904731750488\n",
      "Epoch: 7895, Train Loss: 0.387740820646286, Valid Loss: 0.6520394086837769\n",
      "Epoch: 7896, Train Loss: 0.38772711157798767, Valid Loss: 0.6673658490180969\n",
      "Epoch: 7897, Train Loss: 0.3877122700214386, Valid Loss: 0.6564099192619324\n",
      "Epoch: 7898, Train Loss: 0.38770437240600586, Valid Loss: 0.6615914106369019\n",
      "Epoch: 7899, Train Loss: 0.38770562410354614, Valid Loss: 0.6620503067970276\n",
      "Epoch: 7900, Train Loss: 0.3877130150794983, Valid Loss: 0.6564120650291443\n",
      "Epoch: 7901, Train Loss: 0.38771966099739075, Valid Loss: 0.6661775708198547\n",
      "Epoch: 7902, Train Loss: 0.387722373008728, Valid Loss: 0.6543962359428406\n",
      "Epoch: 7903, Train Loss: 0.38771915435791016, Valid Loss: 0.6667472124099731\n",
      "Epoch: 7904, Train Loss: 0.38771292567253113, Valid Loss: 0.6557379364967346\n",
      "Epoch: 7905, Train Loss: 0.387706995010376, Valid Loss: 0.663788914680481\n",
      "Epoch: 7906, Train Loss: 0.38770484924316406, Valid Loss: 0.6592562794685364\n",
      "Epoch: 7907, Train Loss: 0.38770443201065063, Valid Loss: 0.6597539782524109\n",
      "Epoch: 7908, Train Loss: 0.38770654797554016, Valid Loss: 0.6632363796234131\n",
      "Epoch: 7909, Train Loss: 0.3877102732658386, Valid Loss: 0.6568785905838013\n",
      "Epoch: 7910, Train Loss: 0.38771122694015503, Valid Loss: 0.6653994917869568\n",
      "Epoch: 7911, Train Loss: 0.38771116733551025, Valid Loss: 0.6560654640197754\n",
      "Epoch: 7912, Train Loss: 0.38770925998687744, Valid Loss: 0.6647186875343323\n",
      "Epoch: 7913, Train Loss: 0.3877062499523163, Valid Loss: 0.657641589641571\n",
      "Epoch: 7914, Train Loss: 0.3877037763595581, Valid Loss: 0.6623421311378479\n",
      "Epoch: 7915, Train Loss: 0.38770216703414917, Valid Loss: 0.6605903506278992\n",
      "Epoch: 7916, Train Loss: 0.38770216703414917, Valid Loss: 0.6597179174423218\n",
      "Epoch: 7917, Train Loss: 0.3877042531967163, Valid Loss: 0.6629849076271057\n",
      "Epoch: 7918, Train Loss: 0.38770541548728943, Valid Loss: 0.6579455733299255\n",
      "Epoch: 7919, Train Loss: 0.3877059519290924, Valid Loss: 0.6638940572738647\n",
      "Epoch: 7920, Train Loss: 0.38770610094070435, Valid Loss: 0.6577656269073486\n",
      "Epoch: 7921, Train Loss: 0.3877047598361969, Valid Loss: 0.663463294506073\n",
      "Epoch: 7922, Train Loss: 0.3877040147781372, Valid Loss: 0.6589186191558838\n",
      "Epoch: 7923, Train Loss: 0.387702614068985, Valid Loss: 0.662129819393158\n",
      "Epoch: 7924, Train Loss: 0.387702614068985, Valid Loss: 0.6604304313659668\n",
      "Epoch: 7925, Train Loss: 0.3877021372318268, Valid Loss: 0.6606235504150391\n",
      "Epoch: 7926, Train Loss: 0.38770216703414917, Valid Loss: 0.6617094278335571\n",
      "Epoch: 7927, Train Loss: 0.38770270347595215, Valid Loss: 0.6596166491508484\n",
      "Epoch: 7928, Train Loss: 0.3877028524875641, Valid Loss: 0.6625657081604004\n",
      "Epoch: 7929, Train Loss: 0.38770321011543274, Valid Loss: 0.6592265963554382\n",
      "Epoch: 7930, Train Loss: 0.3877032995223999, Valid Loss: 0.6627423167228699\n",
      "Epoch: 7931, Train Loss: 0.3877030909061432, Valid Loss: 0.6593287587165833\n",
      "Epoch: 7932, Train Loss: 0.3877028226852417, Valid Loss: 0.6623779535293579\n",
      "Epoch: 7933, Train Loss: 0.38770267367362976, Valid Loss: 0.6598098874092102\n",
      "Epoch: 7934, Train Loss: 0.38770216703414917, Valid Loss: 0.661919355392456\n",
      "Epoch: 7935, Train Loss: 0.3877018690109253, Valid Loss: 0.660429835319519\n",
      "Epoch: 7936, Train Loss: 0.3877015709877014, Valid Loss: 0.6613450646400452\n",
      "Epoch: 7937, Train Loss: 0.3877015709877014, Valid Loss: 0.6610095500946045\n",
      "Epoch: 7938, Train Loss: 0.3877016603946686, Valid Loss: 0.6607810854911804\n",
      "Epoch: 7939, Train Loss: 0.38770151138305664, Valid Loss: 0.6615095734596252\n",
      "Epoch: 7940, Train Loss: 0.38770154118537903, Valid Loss: 0.6603710651397705\n",
      "Epoch: 7941, Train Loss: 0.3877018094062805, Valid Loss: 0.6619423627853394\n",
      "Epoch: 7942, Train Loss: 0.3877020478248596, Valid Loss: 0.6601094603538513\n",
      "Epoch: 7943, Train Loss: 0.3877011239528656, Valid Loss: 0.6621890068054199\n",
      "Epoch: 7944, Train Loss: 0.38770177960395813, Valid Loss: 0.6599493622779846\n",
      "Epoch: 7945, Train Loss: 0.38770216703414917, Valid Loss: 0.6622553467750549\n",
      "Epoch: 7946, Train Loss: 0.38770148158073425, Valid Loss: 0.6599894762039185\n",
      "Epoch: 7947, Train Loss: 0.38770154118537903, Valid Loss: 0.6622044444084167\n",
      "Epoch: 7948, Train Loss: 0.3877011239528656, Valid Loss: 0.6601826548576355\n",
      "Epoch: 7949, Train Loss: 0.387701153755188, Valid Loss: 0.6620140671730042\n",
      "Epoch: 7950, Train Loss: 0.3877008259296417, Valid Loss: 0.660430371761322\n",
      "Epoch: 7951, Train Loss: 0.3877008855342865, Valid Loss: 0.6617550849914551\n",
      "Epoch: 7952, Train Loss: 0.38770076632499695, Valid Loss: 0.660693347454071\n",
      "Epoch: 7953, Train Loss: 0.38770145177841187, Valid Loss: 0.6615309119224548\n",
      "Epoch: 7954, Train Loss: 0.3877006471157074, Valid Loss: 0.6609644889831543\n",
      "Epoch: 7955, Train Loss: 0.38770052790641785, Valid Loss: 0.6613283753395081\n",
      "Epoch: 7956, Train Loss: 0.3877004384994507, Valid Loss: 0.6611567139625549\n",
      "Epoch: 7957, Train Loss: 0.3877004086971283, Valid Loss: 0.6611859202384949\n",
      "Epoch: 7958, Train Loss: 0.38770028948783875, Valid Loss: 0.6612900495529175\n",
      "Epoch: 7959, Train Loss: 0.3877008855342865, Valid Loss: 0.6611011624336243\n",
      "Epoch: 7960, Train Loss: 0.38770002126693726, Valid Loss: 0.6614071726799011\n",
      "Epoch: 7961, Train Loss: 0.3877001404762268, Valid Loss: 0.6610439419746399\n",
      "Epoch: 7962, Train Loss: 0.3877002000808716, Valid Loss: 0.6614798903465271\n",
      "Epoch: 7963, Train Loss: 0.3877002000808716, Valid Loss: 0.6610055565834045\n",
      "Epoch: 7964, Train Loss: 0.3876999318599701, Valid Loss: 0.6615312695503235\n",
      "Epoch: 7965, Train Loss: 0.38770025968551636, Valid Loss: 0.6609675884246826\n",
      "Epoch: 7966, Train Loss: 0.38769999146461487, Valid Loss: 0.6616111993789673\n",
      "Epoch: 7967, Train Loss: 0.38770008087158203, Valid Loss: 0.6609137654304504\n",
      "Epoch: 7968, Train Loss: 0.3876997232437134, Valid Loss: 0.6617139577865601\n",
      "Epoch: 7969, Train Loss: 0.38769999146461487, Valid Loss: 0.6608019471168518\n",
      "Epoch: 7970, Train Loss: 0.38769975304603577, Valid Loss: 0.6618797183036804\n",
      "Epoch: 7971, Train Loss: 0.38769960403442383, Valid Loss: 0.660607099533081\n",
      "Epoch: 7972, Train Loss: 0.38770008087158203, Valid Loss: 0.662158191204071\n",
      "Epoch: 7973, Train Loss: 0.38770005106925964, Valid Loss: 0.6603241562843323\n",
      "Epoch: 7974, Train Loss: 0.38770025968551636, Valid Loss: 0.6625245809555054\n",
      "Epoch: 7975, Train Loss: 0.38770025968551636, Valid Loss: 0.6599074006080627\n",
      "Epoch: 7976, Train Loss: 0.3877004384994507, Valid Loss: 0.6630520820617676\n",
      "Epoch: 7977, Train Loss: 0.3877008855342865, Valid Loss: 0.6592910885810852\n",
      "Epoch: 7978, Train Loss: 0.38770201802253723, Valid Loss: 0.663851261138916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7979, Train Loss: 0.3877035975456238, Valid Loss: 0.6583420038223267\n",
      "Epoch: 7980, Train Loss: 0.387705534696579, Valid Loss: 0.6650711894035339\n",
      "Epoch: 7981, Train Loss: 0.38770854473114014, Valid Loss: 0.6568821668624878\n",
      "Epoch: 7982, Train Loss: 0.38771316409111023, Valid Loss: 0.6669830083847046\n",
      "Epoch: 7983, Train Loss: 0.38772132992744446, Valid Loss: 0.6545731425285339\n",
      "Epoch: 7984, Train Loss: 0.3877335488796234, Valid Loss: 0.6700016856193542\n",
      "Epoch: 7985, Train Loss: 0.38775280117988586, Valid Loss: 0.6509088277816772\n",
      "Epoch: 7986, Train Loss: 0.38778144121170044, Valid Loss: 0.6749177575111389\n",
      "Epoch: 7987, Train Loss: 0.38783085346221924, Valid Loss: 0.6451151371002197\n",
      "Epoch: 7988, Train Loss: 0.3878980576992035, Valid Loss: 0.6827621459960938\n",
      "Epoch: 7989, Train Loss: 0.38801276683807373, Valid Loss: 0.6364008188247681\n",
      "Epoch: 7990, Train Loss: 0.38814377784729004, Valid Loss: 0.694434404373169\n",
      "Epoch: 7991, Train Loss: 0.3883568346500397, Valid Loss: 0.6250070333480835\n",
      "Epoch: 7992, Train Loss: 0.3885112702846527, Valid Loss: 0.7083227038383484\n",
      "Epoch: 7993, Train Loss: 0.3887264132499695, Valid Loss: 0.6149929165840149\n",
      "Epoch: 7994, Train Loss: 0.388686865568161, Valid Loss: 0.7152667045593262\n",
      "Epoch: 7995, Train Loss: 0.38860875368118286, Valid Loss: 0.6161680817604065\n",
      "Epoch: 7996, Train Loss: 0.3882744610309601, Valid Loss: 0.7020868062973022\n",
      "Epoch: 7997, Train Loss: 0.38798001408576965, Valid Loss: 0.6355034112930298\n",
      "Epoch: 7998, Train Loss: 0.387765109539032, Valid Loss: 0.6721926927566528\n",
      "Epoch: 7999, Train Loss: 0.3877214193344116, Valid Loss: 0.6653026342391968\n",
      "Epoch: 8000, Train Loss: 0.3878268003463745, Valid Loss: 0.6439527869224548\n",
      "Epoch: 8001, Train Loss: 0.3879823088645935, Valid Loss: 0.6891657114028931\n",
      "Epoch: 8002, Train Loss: 0.38810184597969055, Valid Loss: 0.6301831603050232\n",
      "Epoch: 8003, Train Loss: 0.3880591094493866, Valid Loss: 0.6926613450050354\n",
      "Epoch: 8004, Train Loss: 0.38794004917144775, Valid Loss: 0.6369225382804871\n",
      "Epoch: 8005, Train Loss: 0.38779217004776, Valid Loss: 0.6753802299499512\n",
      "Epoch: 8006, Train Loss: 0.3877185881137848, Valid Loss: 0.6579325199127197\n",
      "Epoch: 8007, Train Loss: 0.3877280652523041, Valid Loss: 0.653669536113739\n",
      "Epoch: 8008, Train Loss: 0.3877861797809601, Valid Loss: 0.6762215495109558\n",
      "Epoch: 8009, Train Loss: 0.3878471255302429, Valid Loss: 0.6421037912368774\n",
      "Epoch: 8010, Train Loss: 0.38785916566848755, Valid Loss: 0.6807242035865784\n",
      "Epoch: 8011, Train Loss: 0.3878350257873535, Valid Loss: 0.6446617841720581\n",
      "Epoch: 8012, Train Loss: 0.38777562975883484, Valid Loss: 0.6724328398704529\n",
      "Epoch: 8013, Train Loss: 0.3877228796482086, Valid Loss: 0.6567332744598389\n",
      "Epoch: 8014, Train Loss: 0.3877027928829193, Valid Loss: 0.6591048240661621\n",
      "Epoch: 8015, Train Loss: 0.387722373008728, Valid Loss: 0.6681951284408569\n",
      "Epoch: 8016, Train Loss: 0.3877607583999634, Valid Loss: 0.6498499512672424\n",
      "Epoch: 8017, Train Loss: 0.38778218626976013, Valid Loss: 0.6732550859451294\n",
      "Epoch: 8018, Train Loss: 0.3877764940261841, Valid Loss: 0.6492036581039429\n",
      "Epoch: 8019, Train Loss: 0.3877454102039337, Valid Loss: 0.6712145209312439\n",
      "Epoch: 8020, Train Loss: 0.3877158761024475, Valid Loss: 0.6546729803085327\n",
      "Epoch: 8021, Train Loss: 0.3877026438713074, Valid Loss: 0.6628990173339844\n",
      "Epoch: 8022, Train Loss: 0.38770756125450134, Valid Loss: 0.6626927852630615\n",
      "Epoch: 8023, Train Loss: 0.38772210478782654, Valid Loss: 0.6545622944831848\n",
      "Epoch: 8024, Train Loss: 0.38773366808891296, Valid Loss: 0.6694610714912415\n",
      "Epoch: 8025, Train Loss: 0.3877367079257965, Valid Loss: 0.6515679359436035\n",
      "Epoch: 8026, Train Loss: 0.3877299427986145, Valid Loss: 0.6702362298965454\n",
      "Epoch: 8027, Train Loss: 0.3877181112766266, Valid Loss: 0.6539475321769714\n",
      "Epoch: 8028, Train Loss: 0.3877059817314148, Valid Loss: 0.6648246049880981\n",
      "Epoch: 8029, Train Loss: 0.3876997232437134, Valid Loss: 0.6600137948989868\n",
      "Epoch: 8030, Train Loss: 0.3877016305923462, Valid Loss: 0.6580938696861267\n",
      "Epoch: 8031, Train Loss: 0.38770943880081177, Valid Loss: 0.6664074659347534\n",
      "Epoch: 8032, Train Loss: 0.3877166509628296, Valid Loss: 0.6544339656829834\n",
      "Epoch: 8033, Train Loss: 0.38771721720695496, Valid Loss: 0.6683483719825745\n",
      "Epoch: 8034, Train Loss: 0.38771286606788635, Valid Loss: 0.6548563241958618\n",
      "Epoch: 8035, Train Loss: 0.3877066969871521, Valid Loss: 0.6653702259063721\n",
      "Epoch: 8036, Train Loss: 0.3877016305923462, Valid Loss: 0.6585516333580017\n",
      "Epoch: 8037, Train Loss: 0.38769927620887756, Valid Loss: 0.661210834980011\n",
      "Epoch: 8038, Train Loss: 0.38769999146461487, Valid Loss: 0.6630734205245972\n",
      "Epoch: 8039, Train Loss: 0.3877021074295044, Valid Loss: 0.6580360531806946\n",
      "Epoch: 8040, Train Loss: 0.3877045512199402, Valid Loss: 0.6652848720550537\n",
      "Epoch: 8041, Train Loss: 0.3877059817314148, Valid Loss: 0.6567600965499878\n",
      "Epoch: 8042, Train Loss: 0.38770580291748047, Valid Loss: 0.664991021156311\n",
      "Epoch: 8043, Train Loss: 0.3877032995223999, Valid Loss: 0.6578565835952759\n",
      "Epoch: 8044, Train Loss: 0.3877013027667999, Valid Loss: 0.6636396646499634\n",
      "Epoch: 8045, Train Loss: 0.3876989483833313, Valid Loss: 0.659969687461853\n",
      "Epoch: 8046, Train Loss: 0.3876979351043701, Valid Loss: 0.661628782749176\n",
      "Epoch: 8047, Train Loss: 0.3876981735229492, Valid Loss: 0.6618379950523376\n",
      "Epoch: 8048, Train Loss: 0.3876993954181671, Valid Loss: 0.6596289873123169\n",
      "Epoch: 8049, Train Loss: 0.3877004384994507, Valid Loss: 0.66336989402771\n",
      "Epoch: 8050, Train Loss: 0.38770100474357605, Valid Loss: 0.6586675047874451\n",
      "Epoch: 8051, Train Loss: 0.3877011835575104, Valid Loss: 0.664170503616333\n",
      "Epoch: 8052, Train Loss: 0.3876999616622925, Valid Loss: 0.6586992144584656\n",
      "Epoch: 8053, Train Loss: 0.3876994848251343, Valid Loss: 0.6636962890625\n",
      "Epoch: 8054, Train Loss: 0.3876986503601074, Valid Loss: 0.6594117879867554\n",
      "Epoch: 8055, Train Loss: 0.3876977562904358, Valid Loss: 0.6624428033828735\n",
      "Epoch: 8056, Train Loss: 0.3876975178718567, Valid Loss: 0.6608761548995972\n",
      "Epoch: 8057, Train Loss: 0.3876969516277313, Valid Loss: 0.6611583232879639\n",
      "Epoch: 8058, Train Loss: 0.3876974880695343, Valid Loss: 0.6623467803001404\n",
      "Epoch: 8059, Train Loss: 0.38769781589508057, Valid Loss: 0.6600689888000488\n",
      "Epoch: 8060, Train Loss: 0.3876977562904358, Valid Loss: 0.6630553603172302\n",
      "Epoch: 8061, Train Loss: 0.38769790530204773, Valid Loss: 0.6595590114593506\n",
      "Epoch: 8062, Train Loss: 0.38769811391830444, Valid Loss: 0.6632232666015625\n",
      "Epoch: 8063, Train Loss: 0.3876979947090149, Valid Loss: 0.6598165035247803\n",
      "Epoch: 8064, Train Loss: 0.38769763708114624, Valid Loss: 0.6629202365875244\n",
      "Epoch: 8065, Train Loss: 0.3876973092556, Valid Loss: 0.6604292988777161\n",
      "Epoch: 8066, Train Loss: 0.38769713044166565, Valid Loss: 0.6622437834739685\n",
      "Epoch: 8067, Train Loss: 0.38769686222076416, Valid Loss: 0.6610174775123596\n",
      "Epoch: 8068, Train Loss: 0.3876965045928955, Valid Loss: 0.6616322994232178\n",
      "Epoch: 8069, Train Loss: 0.38769659399986267, Valid Loss: 0.6615936756134033\n",
      "Epoch: 8070, Train Loss: 0.38769635558128357, Valid Loss: 0.6612467765808105\n",
      "Epoch: 8071, Train Loss: 0.3876964747905731, Valid Loss: 0.6620627641677856\n",
      "Epoch: 8072, Train Loss: 0.38769665360450745, Valid Loss: 0.6608994007110596\n",
      "Epoch: 8073, Train Loss: 0.38769662380218506, Valid Loss: 0.6623235940933228\n",
      "Epoch: 8074, Train Loss: 0.3876967132091522, Valid Loss: 0.6606417298316956\n",
      "Epoch: 8075, Train Loss: 0.38769689202308655, Valid Loss: 0.6625181436538696\n",
      "Epoch: 8076, Train Loss: 0.3876964747905731, Valid Loss: 0.6606036424636841\n",
      "Epoch: 8077, Train Loss: 0.387696236371994, Valid Loss: 0.662627637386322\n",
      "Epoch: 8078, Train Loss: 0.3876965343952179, Valid Loss: 0.6606276631355286\n",
      "Epoch: 8079, Train Loss: 0.38769620656967163, Valid Loss: 0.6625416278839111\n",
      "Epoch: 8080, Train Loss: 0.38769611716270447, Valid Loss: 0.6607277393341064\n",
      "Epoch: 8081, Train Loss: 0.38769614696502686, Valid Loss: 0.6624104380607605\n",
      "Epoch: 8082, Train Loss: 0.3876962661743164, Valid Loss: 0.6609304547309875\n",
      "Epoch: 8083, Train Loss: 0.3876958191394806, Valid Loss: 0.6622810363769531\n",
      "Epoch: 8084, Train Loss: 0.3876960277557373, Valid Loss: 0.6611282229423523\n",
      "Epoch: 8085, Train Loss: 0.38769546151161194, Valid Loss: 0.6621028184890747\n",
      "Epoch: 8086, Train Loss: 0.3876955807209015, Valid Loss: 0.6612747311592102\n",
      "Epoch: 8087, Train Loss: 0.3876957297325134, Valid Loss: 0.6619706153869629\n",
      "Epoch: 8088, Train Loss: 0.3876955807209015, Valid Loss: 0.6614358425140381\n",
      "Epoch: 8089, Train Loss: 0.3876955807209015, Valid Loss: 0.6618852019309998\n",
      "Epoch: 8090, Train Loss: 0.3876953721046448, Valid Loss: 0.6615800261497498\n",
      "Epoch: 8091, Train Loss: 0.38769587874412537, Valid Loss: 0.6617958545684814\n",
      "Epoch: 8092, Train Loss: 0.38769546151161194, Valid Loss: 0.6616544127464294\n",
      "Epoch: 8093, Train Loss: 0.3876953125, Valid Loss: 0.6617273092269897\n",
      "Epoch: 8094, Train Loss: 0.3876954913139343, Valid Loss: 0.6617349982261658\n",
      "Epoch: 8095, Train Loss: 0.3876953721046448, Valid Loss: 0.6617006063461304\n",
      "Epoch: 8096, Train Loss: 0.3876951038837433, Valid Loss: 0.6618194580078125\n",
      "Epoch: 8097, Train Loss: 0.3876951038837433, Valid Loss: 0.661654531955719\n",
      "Epoch: 8098, Train Loss: 0.38769540190696716, Valid Loss: 0.6618842482566833\n",
      "Epoch: 8099, Train Loss: 0.38769540190696716, Valid Loss: 0.6615598797798157\n",
      "Epoch: 8100, Train Loss: 0.38769495487213135, Valid Loss: 0.6620091199874878\n",
      "Epoch: 8101, Train Loss: 0.38769495487213135, Valid Loss: 0.6614721417427063\n",
      "Epoch: 8102, Train Loss: 0.3876950442790985, Valid Loss: 0.6621362566947937\n",
      "Epoch: 8103, Train Loss: 0.38769492506980896, Valid Loss: 0.6613832116127014\n",
      "Epoch: 8104, Train Loss: 0.38769471645355225, Valid Loss: 0.6622456908226013\n",
      "Epoch: 8105, Train Loss: 0.3876948356628418, Valid Loss: 0.6612772941589355\n",
      "Epoch: 8106, Train Loss: 0.38769474625587463, Valid Loss: 0.6623868346214294\n",
      "Epoch: 8107, Train Loss: 0.38769465684890747, Valid Loss: 0.6611382365226746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8108, Train Loss: 0.3876948654651642, Valid Loss: 0.6626044511795044\n",
      "Epoch: 8109, Train Loss: 0.38769492506980896, Valid Loss: 0.6608825922012329\n",
      "Epoch: 8110, Train Loss: 0.38769495487213135, Valid Loss: 0.6629798412322998\n",
      "Epoch: 8111, Train Loss: 0.3876955211162567, Valid Loss: 0.6604107618331909\n",
      "Epoch: 8112, Train Loss: 0.38769567012786865, Valid Loss: 0.6635980010032654\n",
      "Epoch: 8113, Train Loss: 0.387696772813797, Valid Loss: 0.6596719622612\n",
      "Epoch: 8114, Train Loss: 0.3876970410346985, Valid Loss: 0.6645618677139282\n",
      "Epoch: 8115, Train Loss: 0.3876991868019104, Valid Loss: 0.6585017442703247\n",
      "Epoch: 8116, Train Loss: 0.3877018392086029, Valid Loss: 0.6661336421966553\n",
      "Epoch: 8117, Train Loss: 0.3877066671848297, Valid Loss: 0.6565141081809998\n",
      "Epoch: 8118, Train Loss: 0.3877142071723938, Valid Loss: 0.668783962726593\n",
      "Epoch: 8119, Train Loss: 0.38772690296173096, Valid Loss: 0.6532048583030701\n",
      "Epoch: 8120, Train Loss: 0.3877476453781128, Valid Loss: 0.6732468605041504\n",
      "Epoch: 8121, Train Loss: 0.387783944606781, Valid Loss: 0.6477263569831848\n",
      "Epoch: 8122, Train Loss: 0.38783881068229675, Valid Loss: 0.6807664632797241\n",
      "Epoch: 8123, Train Loss: 0.38793808221817017, Valid Loss: 0.6388570070266724\n",
      "Epoch: 8124, Train Loss: 0.388072669506073, Valid Loss: 0.692990243434906\n",
      "Epoch: 8125, Train Loss: 0.388310968875885, Valid Loss: 0.6258517503738403\n",
      "Epoch: 8126, Train Loss: 0.3885512053966522, Valid Loss: 0.7101702690124512\n",
      "Epoch: 8127, Train Loss: 0.38892480731010437, Valid Loss: 0.6116641759872437\n",
      "Epoch: 8128, Train Loss: 0.38901597261428833, Valid Loss: 0.7241552472114563\n",
      "Epoch: 8129, Train Loss: 0.3890632390975952, Valid Loss: 0.608319878578186\n",
      "Epoch: 8130, Train Loss: 0.3886042535305023, Valid Loss: 0.7142226696014404\n",
      "Epoch: 8131, Train Loss: 0.3881514370441437, Valid Loss: 0.6288700699806213\n",
      "Epoch: 8132, Train Loss: 0.38779217004776, Valid Loss: 0.6765848398208618\n",
      "Epoch: 8133, Train Loss: 0.3877285420894623, Valid Loss: 0.6658317446708679\n",
      "Epoch: 8134, Train Loss: 0.38790640234947205, Valid Loss: 0.6400343179702759\n",
      "Epoch: 8135, Train Loss: 0.3881385624408722, Valid Loss: 0.6967146396636963\n",
      "Epoch: 8136, Train Loss: 0.3882856070995331, Valid Loss: 0.6254138350486755\n",
      "Epoch: 8137, Train Loss: 0.38814640045166016, Valid Loss: 0.6976916790008545\n",
      "Epoch: 8138, Train Loss: 0.3879208266735077, Valid Loss: 0.6379272937774658\n",
      "Epoch: 8139, Train Loss: 0.38773083686828613, Valid Loss: 0.670136570930481\n",
      "Epoch: 8140, Train Loss: 0.38771119713783264, Valid Loss: 0.6667574048042297\n",
      "Epoch: 8141, Train Loss: 0.3878249526023865, Valid Loss: 0.6429005265235901\n",
      "Epoch: 8142, Train Loss: 0.387937992811203, Valid Loss: 0.687248706817627\n",
      "Epoch: 8143, Train Loss: 0.38796862959861755, Valid Loss: 0.636325478553772\n",
      "Epoch: 8144, Train Loss: 0.3878711462020874, Valid Loss: 0.6827168464660645\n",
      "Epoch: 8145, Train Loss: 0.3877580761909485, Valid Loss: 0.6501238942146301\n",
      "Epoch: 8146, Train Loss: 0.38770249485969543, Valid Loss: 0.6615147590637207\n",
      "Epoch: 8147, Train Loss: 0.3877287209033966, Valid Loss: 0.6702888607978821\n",
      "Epoch: 8148, Train Loss: 0.38779595494270325, Valid Loss: 0.6453235745429993\n",
      "Epoch: 8149, Train Loss: 0.38782998919487, Valid Loss: 0.6800240874290466\n",
      "Epoch: 8150, Train Loss: 0.38781192898750305, Valid Loss: 0.6456246972084045\n",
      "Epoch: 8151, Train Loss: 0.38775208592414856, Valid Loss: 0.672249436378479\n",
      "Epoch: 8152, Train Loss: 0.38770681619644165, Valid Loss: 0.6579082012176514\n",
      "Epoch: 8153, Train Loss: 0.38770103454589844, Valid Loss: 0.6573905944824219\n",
      "Epoch: 8154, Train Loss: 0.3877284824848175, Valid Loss: 0.6701540350914001\n",
      "Epoch: 8155, Train Loss: 0.38776010274887085, Valid Loss: 0.649262011051178\n",
      "Epoch: 8156, Train Loss: 0.3877646327018738, Valid Loss: 0.6736025810241699\n",
      "Epoch: 8157, Train Loss: 0.38774263858795166, Valid Loss: 0.6517959833145142\n",
      "Epoch: 8158, Train Loss: 0.38771092891693115, Valid Loss: 0.6669856905937195\n",
      "Epoch: 8159, Train Loss: 0.3876951038837433, Valid Loss: 0.6604758501052856\n",
      "Epoch: 8160, Train Loss: 0.38770222663879395, Valid Loss: 0.6571273803710938\n",
      "Epoch: 8161, Train Loss: 0.38772109150886536, Valid Loss: 0.6682658195495605\n",
      "Epoch: 8162, Train Loss: 0.38773250579833984, Valid Loss: 0.6525445580482483\n",
      "Epoch: 8163, Train Loss: 0.387727290391922, Valid Loss: 0.670030951499939\n",
      "Epoch: 8164, Train Loss: 0.38771265745162964, Valid Loss: 0.6550855040550232\n",
      "Epoch: 8165, Train Loss: 0.3876991271972656, Valid Loss: 0.6648128032684326\n",
      "Epoch: 8166, Train Loss: 0.3876953721046448, Valid Loss: 0.6612192392349243\n",
      "Epoch: 8167, Train Loss: 0.3877007067203522, Valid Loss: 0.657856285572052\n",
      "Epoch: 8168, Train Loss: 0.3877090811729431, Valid Loss: 0.6669125556945801\n",
      "Epoch: 8169, Train Loss: 0.3877129554748535, Valid Loss: 0.654966413974762\n",
      "Epoch: 8170, Train Loss: 0.38770970702171326, Valid Loss: 0.667945146560669\n",
      "Epoch: 8171, Train Loss: 0.3877028822898865, Valid Loss: 0.65684974193573\n",
      "Epoch: 8172, Train Loss: 0.387696236371994, Valid Loss: 0.6638065576553345\n",
      "Epoch: 8173, Train Loss: 0.387694388628006, Valid Loss: 0.6613761186599731\n",
      "Epoch: 8174, Train Loss: 0.3876974880695343, Valid Loss: 0.6588638424873352\n",
      "Epoch: 8175, Train Loss: 0.38770052790641785, Valid Loss: 0.6656790375709534\n",
      "Epoch: 8176, Train Loss: 0.3877033293247223, Valid Loss: 0.6567320227622986\n",
      "Epoch: 8177, Train Loss: 0.38770192861557007, Valid Loss: 0.6664459705352783\n",
      "Epoch: 8178, Train Loss: 0.3876987099647522, Valid Loss: 0.6579055786132812\n",
      "Epoch: 8179, Train Loss: 0.3876948058605194, Valid Loss: 0.6634887456893921\n",
      "Epoch: 8180, Train Loss: 0.3876934051513672, Valid Loss: 0.661240816116333\n",
      "Epoch: 8181, Train Loss: 0.38769420981407166, Valid Loss: 0.6600242853164673\n",
      "Epoch: 8182, Train Loss: 0.38769614696502686, Valid Loss: 0.6644627451896667\n",
      "Epoch: 8183, Train Loss: 0.3876972198486328, Valid Loss: 0.658369243144989\n",
      "Epoch: 8184, Train Loss: 0.3876975476741791, Valid Loss: 0.6651707291603088\n",
      "Epoch: 8185, Train Loss: 0.387696236371994, Valid Loss: 0.6587711572647095\n",
      "Epoch: 8186, Train Loss: 0.38769450783729553, Valid Loss: 0.6635212898254395\n",
      "Epoch: 8187, Train Loss: 0.3876934349536896, Valid Loss: 0.660836935043335\n",
      "Epoch: 8188, Train Loss: 0.3876930773258209, Valid Loss: 0.6614237427711487\n",
      "Epoch: 8189, Train Loss: 0.38769352436065674, Valid Loss: 0.6630440354347229\n",
      "Epoch: 8190, Train Loss: 0.38769400119781494, Valid Loss: 0.6599829792976379\n",
      "Epoch: 8191, Train Loss: 0.3876945972442627, Valid Loss: 0.6638797521591187\n",
      "Epoch: 8192, Train Loss: 0.38769546151161194, Valid Loss: 0.6596359014511108\n",
      "Epoch: 8193, Train Loss: 0.38769441843032837, Valid Loss: 0.6635376214981079\n",
      "Epoch: 8194, Train Loss: 0.3876936435699463, Valid Loss: 0.6604827642440796\n",
      "Epoch: 8195, Train Loss: 0.3876930773258209, Valid Loss: 0.6626052260398865\n",
      "Epoch: 8196, Train Loss: 0.3876924514770508, Valid Loss: 0.6617574095726013\n",
      "Epoch: 8197, Train Loss: 0.38769280910491943, Valid Loss: 0.6614213585853577\n",
      "Epoch: 8198, Train Loss: 0.38769277930259705, Valid Loss: 0.662726879119873\n",
      "Epoch: 8199, Train Loss: 0.3876933157444, Valid Loss: 0.6606399416923523\n",
      "Epoch: 8200, Train Loss: 0.38769376277923584, Valid Loss: 0.6632121801376343\n",
      "Epoch: 8201, Train Loss: 0.38769298791885376, Valid Loss: 0.6605998873710632\n",
      "Epoch: 8202, Train Loss: 0.3876928687095642, Valid Loss: 0.6631478667259216\n",
      "Epoch: 8203, Train Loss: 0.38769271969795227, Valid Loss: 0.6610093712806702\n",
      "Epoch: 8204, Train Loss: 0.3876924216747284, Valid Loss: 0.6625038981437683\n",
      "Epoch: 8205, Train Loss: 0.38769227266311646, Valid Loss: 0.6616997718811035\n",
      "Epoch: 8206, Train Loss: 0.38769200444221497, Valid Loss: 0.6617587208747864\n",
      "Epoch: 8207, Train Loss: 0.387692391872406, Valid Loss: 0.6624603867530823\n",
      "Epoch: 8208, Train Loss: 0.3876923620700836, Valid Loss: 0.6612834930419922\n",
      "Epoch: 8209, Train Loss: 0.38769227266311646, Valid Loss: 0.662895679473877\n",
      "Epoch: 8210, Train Loss: 0.38769227266311646, Valid Loss: 0.6610240936279297\n",
      "Epoch: 8211, Train Loss: 0.3876921534538269, Valid Loss: 0.6629363894462585\n",
      "Epoch: 8212, Train Loss: 0.3876922130584717, Valid Loss: 0.6611196398735046\n",
      "Epoch: 8213, Train Loss: 0.3876921534538269, Valid Loss: 0.6627449989318848\n",
      "Epoch: 8214, Train Loss: 0.38769179582595825, Valid Loss: 0.6615468859672546\n",
      "Epoch: 8215, Train Loss: 0.38769155740737915, Valid Loss: 0.6623485684394836\n",
      "Epoch: 8216, Train Loss: 0.38769158720970154, Valid Loss: 0.6620016694068909\n",
      "Epoch: 8217, Train Loss: 0.3876914083957672, Valid Loss: 0.6618791818618774\n",
      "Epoch: 8218, Train Loss: 0.3876914083957672, Valid Loss: 0.6624044179916382\n",
      "Epoch: 8219, Train Loss: 0.38769158720970154, Valid Loss: 0.6615731716156006\n",
      "Epoch: 8220, Train Loss: 0.3876912593841553, Valid Loss: 0.6627063155174255\n",
      "Epoch: 8221, Train Loss: 0.38769158720970154, Valid Loss: 0.6614496111869812\n",
      "Epoch: 8222, Train Loss: 0.3876914978027344, Valid Loss: 0.6627722978591919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8223, Train Loss: 0.3876914978027344, Valid Loss: 0.6614773273468018\n",
      "Epoch: 8224, Train Loss: 0.3876911997795105, Valid Loss: 0.6626551151275635\n",
      "Epoch: 8225, Train Loss: 0.3876912593841553, Valid Loss: 0.6616554856300354\n",
      "Epoch: 8226, Train Loss: 0.3876907229423523, Valid Loss: 0.6625003218650818\n",
      "Epoch: 8227, Train Loss: 0.3876909017562866, Valid Loss: 0.6618910431861877\n",
      "Epoch: 8228, Train Loss: 0.387690931558609, Valid Loss: 0.662315845489502\n",
      "Epoch: 8229, Train Loss: 0.3876909613609314, Valid Loss: 0.6620813012123108\n",
      "Epoch: 8230, Train Loss: 0.387690931558609, Valid Loss: 0.6621497869491577\n",
      "Epoch: 8231, Train Loss: 0.38769102096557617, Valid Loss: 0.6622380018234253\n",
      "Epoch: 8232, Train Loss: 0.38769087195396423, Valid Loss: 0.6620590686798096\n",
      "Epoch: 8233, Train Loss: 0.38769087195396423, Valid Loss: 0.6623538732528687\n",
      "Epoch: 8234, Train Loss: 0.3876909911632538, Valid Loss: 0.6619957089424133\n",
      "Epoch: 8235, Train Loss: 0.38769057393074036, Valid Loss: 0.6624232530593872\n",
      "Epoch: 8236, Train Loss: 0.3876907527446747, Valid Loss: 0.661952793598175\n",
      "Epoch: 8237, Train Loss: 0.3876904547214508, Valid Loss: 0.6624669432640076\n",
      "Epoch: 8238, Train Loss: 0.38769063353538513, Valid Loss: 0.6619514226913452\n",
      "Epoch: 8239, Train Loss: 0.38769036531448364, Valid Loss: 0.6624962687492371\n",
      "Epoch: 8240, Train Loss: 0.38769039511680603, Valid Loss: 0.6619514226913452\n",
      "Epoch: 8241, Train Loss: 0.38769054412841797, Valid Loss: 0.6625328660011292\n",
      "Epoch: 8242, Train Loss: 0.38769036531448364, Valid Loss: 0.6619364023208618\n",
      "Epoch: 8243, Train Loss: 0.3876901865005493, Valid Loss: 0.6625409722328186\n",
      "Epoch: 8244, Train Loss: 0.3876904547214508, Valid Loss: 0.6619532108306885\n",
      "Epoch: 8245, Train Loss: 0.38769033551216125, Valid Loss: 0.6625661253929138\n",
      "Epoch: 8246, Train Loss: 0.38769033551216125, Valid Loss: 0.6619744300842285\n",
      "Epoch: 8247, Train Loss: 0.3876901865005493, Valid Loss: 0.662558376789093\n",
      "Epoch: 8248, Train Loss: 0.3876902759075165, Valid Loss: 0.6620159149169922\n",
      "Epoch: 8249, Train Loss: 0.3876901865005493, Valid Loss: 0.6625246405601501\n",
      "Epoch: 8250, Train Loss: 0.38768988847732544, Valid Loss: 0.6620521545410156\n",
      "Epoch: 8251, Train Loss: 0.38768985867500305, Valid Loss: 0.6625415682792664\n",
      "Epoch: 8252, Train Loss: 0.3876900374889374, Valid Loss: 0.6620606184005737\n",
      "Epoch: 8253, Train Loss: 0.3876899778842926, Valid Loss: 0.6625717878341675\n",
      "Epoch: 8254, Train Loss: 0.3876893222332001, Valid Loss: 0.6620229482650757\n",
      "Epoch: 8255, Train Loss: 0.38768985867500305, Valid Loss: 0.6626480221748352\n",
      "Epoch: 8256, Train Loss: 0.3876900374889374, Valid Loss: 0.6619434952735901\n",
      "Epoch: 8257, Train Loss: 0.3876896798610687, Valid Loss: 0.6627922058105469\n",
      "Epoch: 8258, Train Loss: 0.3876896798610687, Valid Loss: 0.6618130207061768\n",
      "Epoch: 8259, Train Loss: 0.3876895010471344, Valid Loss: 0.6629546880722046\n",
      "Epoch: 8260, Train Loss: 0.38768962025642395, Valid Loss: 0.6616278290748596\n",
      "Epoch: 8261, Train Loss: 0.38768985867500305, Valid Loss: 0.663218080997467\n",
      "Epoch: 8262, Train Loss: 0.3876899182796478, Valid Loss: 0.6613184213638306\n",
      "Epoch: 8263, Train Loss: 0.3876899480819702, Valid Loss: 0.663638174533844\n",
      "Epoch: 8264, Train Loss: 0.3876904547214508, Valid Loss: 0.6608431935310364\n",
      "Epoch: 8265, Train Loss: 0.38769111037254333, Valid Loss: 0.6642666459083557\n",
      "Epoch: 8266, Train Loss: 0.3876917064189911, Valid Loss: 0.6600799560546875\n",
      "Epoch: 8267, Train Loss: 0.3876931369304657, Valid Loss: 0.6652441620826721\n",
      "Epoch: 8268, Train Loss: 0.3876948952674866, Valid Loss: 0.6588962078094482\n",
      "Epoch: 8269, Train Loss: 0.3876982033252716, Valid Loss: 0.6668012738227844\n",
      "Epoch: 8270, Train Loss: 0.387703001499176, Valid Loss: 0.6569995880126953\n",
      "Epoch: 8271, Train Loss: 0.3877115547657013, Valid Loss: 0.6693030595779419\n",
      "Epoch: 8272, Train Loss: 0.3877246677875519, Valid Loss: 0.6539090871810913\n",
      "Epoch: 8273, Train Loss: 0.38774576783180237, Valid Loss: 0.6734594106674194\n",
      "Epoch: 8274, Train Loss: 0.3877822756767273, Valid Loss: 0.64886474609375\n",
      "Epoch: 8275, Train Loss: 0.38783469796180725, Valid Loss: 0.6803691387176514\n",
      "Epoch: 8276, Train Loss: 0.3879264295101166, Valid Loss: 0.6408576369285583\n",
      "Epoch: 8277, Train Loss: 0.3880431652069092, Valid Loss: 0.6913430690765381\n",
      "Epoch: 8278, Train Loss: 0.3882407546043396, Valid Loss: 0.6293443441390991\n",
      "Epoch: 8279, Train Loss: 0.38842442631721497, Valid Loss: 0.7064450979232788\n",
      "Epoch: 8280, Train Loss: 0.388704389333725, Valid Loss: 0.6166261434555054\n",
      "Epoch: 8281, Train Loss: 0.38877975940704346, Valid Loss: 0.7191113233566284\n",
      "Epoch: 8282, Train Loss: 0.38885238766670227, Valid Loss: 0.6117791533470154\n",
      "Epoch: 8283, Train Loss: 0.38855457305908203, Valid Loss: 0.7134981751441956\n",
      "Epoch: 8284, Train Loss: 0.3882336914539337, Valid Loss: 0.6263372302055359\n",
      "Epoch: 8285, Train Loss: 0.3878808617591858, Valid Loss: 0.6843183040618896\n",
      "Epoch: 8286, Train Loss: 0.38771528005599976, Valid Loss: 0.6574525237083435\n",
      "Epoch: 8287, Train Loss: 0.3877526819705963, Valid Loss: 0.6504960656166077\n",
      "Epoch: 8288, Train Loss: 0.38792094588279724, Valid Loss: 0.6874305009841919\n",
      "Epoch: 8289, Train Loss: 0.3881046175956726, Valid Loss: 0.63053959608078\n",
      "Epoch: 8290, Train Loss: 0.38812628388404846, Valid Loss: 0.6974441409111023\n",
      "Epoch: 8291, Train Loss: 0.3880385458469391, Valid Loss: 0.6331801414489746\n",
      "Epoch: 8292, Train Loss: 0.3878563642501831, Valid Loss: 0.6819544434547424\n",
      "Epoch: 8293, Train Loss: 0.38773491978645325, Valid Loss: 0.654481828212738\n",
      "Epoch: 8294, Train Loss: 0.38771215081214905, Valid Loss: 0.6573039889335632\n",
      "Epoch: 8295, Train Loss: 0.3877653181552887, Valid Loss: 0.6758419871330261\n",
      "Epoch: 8296, Train Loss: 0.3878404200077057, Valid Loss: 0.6425866484642029\n",
      "Epoch: 8297, Train Loss: 0.3878730535507202, Valid Loss: 0.6830206513404846\n",
      "Epoch: 8298, Train Loss: 0.38785985112190247, Valid Loss: 0.6439268589019775\n",
      "Epoch: 8299, Train Loss: 0.3877910375595093, Valid Loss: 0.6754665970802307\n",
      "Epoch: 8300, Train Loss: 0.3877220153808594, Valid Loss: 0.6563718318939209\n",
      "Epoch: 8301, Train Loss: 0.387691468000412, Valid Loss: 0.660666823387146\n",
      "Epoch: 8302, Train Loss: 0.3877173066139221, Valid Loss: 0.6691367626190186\n",
      "Epoch: 8303, Train Loss: 0.3877660632133484, Valid Loss: 0.6498527526855469\n",
      "Epoch: 8304, Train Loss: 0.38778936862945557, Valid Loss: 0.6755200028419495\n",
      "Epoch: 8305, Train Loss: 0.3877772092819214, Valid Loss: 0.649130642414093\n",
      "Epoch: 8306, Train Loss: 0.38773757219314575, Valid Loss: 0.6731542348861694\n",
      "Epoch: 8307, Train Loss: 0.3877069652080536, Valid Loss: 0.6555361747741699\n",
      "Epoch: 8308, Train Loss: 0.3876958191394806, Valid Loss: 0.6629554629325867\n",
      "Epoch: 8309, Train Loss: 0.3877047300338745, Valid Loss: 0.6650537252426147\n",
      "Epoch: 8310, Train Loss: 0.3877224326133728, Valid Loss: 0.6534773111343384\n",
      "Epoch: 8311, Train Loss: 0.3877340853214264, Valid Loss: 0.6724069714546204\n",
      "Epoch: 8312, Train Loss: 0.387734591960907, Valid Loss: 0.6511706709861755\n",
      "Epoch: 8313, Train Loss: 0.38772186636924744, Valid Loss: 0.6714065670967102\n",
      "Epoch: 8314, Train Loss: 0.38770437240600586, Valid Loss: 0.6557105779647827\n",
      "Epoch: 8315, Train Loss: 0.38769158720970154, Valid Loss: 0.6636356115341187\n",
      "Epoch: 8316, Train Loss: 0.387690931558609, Valid Loss: 0.6636332869529724\n",
      "Epoch: 8317, Train Loss: 0.3877004384994507, Valid Loss: 0.6563030481338501\n",
      "Epoch: 8318, Train Loss: 0.3877102732658386, Valid Loss: 0.6695981621742249\n",
      "Epoch: 8319, Train Loss: 0.3877132534980774, Valid Loss: 0.6541147828102112\n",
      "Epoch: 8320, Train Loss: 0.38770726323127747, Valid Loss: 0.6690970063209534\n",
      "Epoch: 8321, Train Loss: 0.3876993656158447, Valid Loss: 0.656982421875\n",
      "Epoch: 8322, Train Loss: 0.38769295811653137, Valid Loss: 0.6641688346862793\n",
      "Epoch: 8323, Train Loss: 0.387690007686615, Valid Loss: 0.6622127294540405\n",
      "Epoch: 8324, Train Loss: 0.3876914083957672, Valid Loss: 0.6596737504005432\n",
      "Epoch: 8325, Train Loss: 0.3876945376396179, Valid Loss: 0.6661486029624939\n",
      "Epoch: 8326, Train Loss: 0.3876980245113373, Valid Loss: 0.6573053598403931\n",
      "Epoch: 8327, Train Loss: 0.3876991868019104, Valid Loss: 0.6667777299880981\n",
      "Epoch: 8328, Train Loss: 0.38769757747650146, Valid Loss: 0.6577801704406738\n",
      "Epoch: 8329, Train Loss: 0.3876940906047821, Valid Loss: 0.6652568578720093\n",
      "Epoch: 8330, Train Loss: 0.38769009709358215, Valid Loss: 0.660294771194458\n",
      "Epoch: 8331, Train Loss: 0.3876882791519165, Valid Loss: 0.6627309918403625\n",
      "Epoch: 8332, Train Loss: 0.38768911361694336, Valid Loss: 0.6628943681716919\n",
      "Epoch: 8333, Train Loss: 0.38769078254699707, Valid Loss: 0.6601232886314392\n",
      "Epoch: 8334, Train Loss: 0.38769230246543884, Valid Loss: 0.6648549437522888\n",
      "Epoch: 8335, Train Loss: 0.387692928314209, Valid Loss: 0.658846914768219\n",
      "Epoch: 8336, Train Loss: 0.3876924514770508, Valid Loss: 0.6656414270401001\n",
      "Epoch: 8337, Train Loss: 0.38769131898880005, Valid Loss: 0.6592957377433777\n",
      "Epoch: 8338, Train Loss: 0.38769015669822693, Valid Loss: 0.6645979285240173\n",
      "Epoch: 8339, Train Loss: 0.3876888155937195, Valid Loss: 0.6608189940452576\n",
      "Epoch: 8340, Train Loss: 0.3876878619194031, Valid Loss: 0.6625058054924011\n",
      "Epoch: 8341, Train Loss: 0.3876880407333374, Valid Loss: 0.6628270745277405\n",
      "Epoch: 8342, Train Loss: 0.3876887857913971, Valid Loss: 0.6608079671859741\n",
      "Epoch: 8343, Train Loss: 0.38768941164016724, Valid Loss: 0.6644638776779175\n",
      "Epoch: 8344, Train Loss: 0.3876890540122986, Valid Loss: 0.6600043773651123\n",
      "Epoch: 8345, Train Loss: 0.38768959045410156, Valid Loss: 0.6646888256072998\n",
      "Epoch: 8346, Train Loss: 0.38768914341926575, Valid Loss: 0.6601771712303162\n",
      "Epoch: 8347, Train Loss: 0.38768845796585083, Valid Loss: 0.6639397144317627\n",
      "Epoch: 8348, Train Loss: 0.3876878023147583, Valid Loss: 0.6612318158149719\n",
      "Epoch: 8349, Train Loss: 0.3876877725124359, Valid Loss: 0.6629767417907715\n",
      "Epoch: 8350, Train Loss: 0.38768741488456726, Valid Loss: 0.6624088883399963\n",
      "Epoch: 8351, Train Loss: 0.38768744468688965, Valid Loss: 0.6619939208030701\n",
      "Epoch: 8352, Train Loss: 0.3876875936985016, Valid Loss: 0.6631668210029602\n",
      "Epoch: 8353, Train Loss: 0.3876875936985016, Valid Loss: 0.6613870859146118\n",
      "Epoch: 8354, Train Loss: 0.3876878321170807, Valid Loss: 0.66358482837677\n",
      "Epoch: 8355, Train Loss: 0.38768744468688965, Valid Loss: 0.6612769961357117\n",
      "Epoch: 8356, Train Loss: 0.3876875936985016, Valid Loss: 0.6636573076248169\n",
      "Epoch: 8357, Train Loss: 0.3876875936985016, Valid Loss: 0.6613785028457642\n",
      "Epoch: 8358, Train Loss: 0.38768717646598816, Valid Loss: 0.6634620428085327\n",
      "Epoch: 8359, Train Loss: 0.38768720626831055, Valid Loss: 0.6616714596748352\n",
      "Epoch: 8360, Train Loss: 0.38768625259399414, Valid Loss: 0.6631009578704834\n",
      "Epoch: 8361, Train Loss: 0.38768690824508667, Valid Loss: 0.6621367931365967\n",
      "Epoch: 8362, Train Loss: 0.38768666982650757, Valid Loss: 0.6626839637756348\n",
      "Epoch: 8363, Train Loss: 0.387687087059021, Valid Loss: 0.6626275777816772\n",
      "Epoch: 8364, Train Loss: 0.3876866102218628, Valid Loss: 0.662217378616333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8365, Train Loss: 0.38768690824508667, Valid Loss: 0.663057804107666\n",
      "Epoch: 8366, Train Loss: 0.38768672943115234, Valid Loss: 0.6618824005126953\n",
      "Epoch: 8367, Train Loss: 0.38768666982650757, Valid Loss: 0.6633535623550415\n",
      "Epoch: 8368, Train Loss: 0.3876866102218628, Valid Loss: 0.6617927551269531\n",
      "Epoch: 8369, Train Loss: 0.38768690824508667, Valid Loss: 0.663374662399292\n",
      "Epoch: 8370, Train Loss: 0.38768666982650757, Valid Loss: 0.6618331670761108\n",
      "Epoch: 8371, Train Loss: 0.3876864016056061, Valid Loss: 0.6632553339004517\n",
      "Epoch: 8372, Train Loss: 0.3876863121986389, Valid Loss: 0.6620323061943054\n",
      "Epoch: 8373, Train Loss: 0.3876863718032837, Valid Loss: 0.6631227135658264\n",
      "Epoch: 8374, Train Loss: 0.3876863420009613, Valid Loss: 0.6622278094291687\n",
      "Epoch: 8375, Train Loss: 0.3876860439777374, Valid Loss: 0.6629644632339478\n",
      "Epoch: 8376, Train Loss: 0.3876860737800598, Valid Loss: 0.6623764038085938\n",
      "Epoch: 8377, Train Loss: 0.3876858055591583, Valid Loss: 0.6628145575523376\n",
      "Epoch: 8378, Train Loss: 0.3876860439777374, Valid Loss: 0.6625604033470154\n",
      "Epoch: 8379, Train Loss: 0.3876858949661255, Valid Loss: 0.6626783013343811\n",
      "Epoch: 8380, Train Loss: 0.3876858651638031, Valid Loss: 0.6627603769302368\n",
      "Epoch: 8381, Train Loss: 0.3876858353614807, Valid Loss: 0.6625080108642578\n",
      "Epoch: 8382, Train Loss: 0.3876855969429016, Valid Loss: 0.6629576683044434\n",
      "Epoch: 8383, Train Loss: 0.38768598437309265, Valid Loss: 0.6623178124427795\n",
      "Epoch: 8384, Train Loss: 0.3876856863498688, Valid Loss: 0.6631627678871155\n",
      "Epoch: 8385, Train Loss: 0.3876856565475464, Valid Loss: 0.6621625423431396\n",
      "Epoch: 8386, Train Loss: 0.3876858651638031, Valid Loss: 0.6633264422416687\n",
      "Epoch: 8387, Train Loss: 0.3876859247684479, Valid Loss: 0.6620511412620544\n",
      "Epoch: 8388, Train Loss: 0.3876858055591583, Valid Loss: 0.663480818271637\n",
      "Epoch: 8389, Train Loss: 0.3876858949661255, Valid Loss: 0.6618985533714294\n",
      "Epoch: 8390, Train Loss: 0.387686163187027, Valid Loss: 0.6636506915092468\n",
      "Epoch: 8391, Train Loss: 0.3876855969429016, Valid Loss: 0.6617271304130554\n",
      "Epoch: 8392, Train Loss: 0.38768601417541504, Valid Loss: 0.6638938784599304\n",
      "Epoch: 8393, Train Loss: 0.38768601417541504, Valid Loss: 0.6614879369735718\n",
      "Epoch: 8394, Train Loss: 0.3876856565475464, Valid Loss: 0.6642133593559265\n",
      "Epoch: 8395, Train Loss: 0.3876864016056061, Valid Loss: 0.6611006259918213\n",
      "Epoch: 8396, Train Loss: 0.3876866400241852, Valid Loss: 0.6647183299064636\n",
      "Epoch: 8397, Train Loss: 0.387687623500824, Valid Loss: 0.6605124473571777\n",
      "Epoch: 8398, Train Loss: 0.38768815994262695, Valid Loss: 0.6654884815216064\n",
      "Epoch: 8399, Train Loss: 0.3876892328262329, Valid Loss: 0.6596038937568665\n",
      "Epoch: 8400, Train Loss: 0.3876909613609314, Valid Loss: 0.666625440120697\n",
      "Epoch: 8401, Train Loss: 0.38769376277923584, Valid Loss: 0.6582483649253845\n",
      "Epoch: 8402, Train Loss: 0.3876974880695343, Valid Loss: 0.6683599948883057\n",
      "Epoch: 8403, Train Loss: 0.3877032995223999, Valid Loss: 0.6562094688415527\n",
      "Epoch: 8404, Train Loss: 0.38771164417266846, Valid Loss: 0.6709818840026855\n",
      "Epoch: 8405, Train Loss: 0.38772520422935486, Valid Loss: 0.6530786156654358\n",
      "Epoch: 8406, Train Loss: 0.3877449035644531, Valid Loss: 0.6750231981277466\n",
      "Epoch: 8407, Train Loss: 0.38777580857276917, Valid Loss: 0.6483429074287415\n",
      "Epoch: 8408, Train Loss: 0.3878180980682373, Valid Loss: 0.6812474131584167\n",
      "Epoch: 8409, Train Loss: 0.3878898620605469, Valid Loss: 0.6413451433181763\n",
      "Epoch: 8410, Train Loss: 0.3879770338535309, Valid Loss: 0.6904308795928955\n",
      "Epoch: 8411, Train Loss: 0.38812246918678284, Valid Loss: 0.6317928433418274\n",
      "Epoch: 8412, Train Loss: 0.38826167583465576, Valid Loss: 0.7024364471435547\n",
      "Epoch: 8413, Train Loss: 0.388477087020874, Valid Loss: 0.621502161026001\n",
      "Epoch: 8414, Train Loss: 0.38856419920921326, Valid Loss: 0.7129824757575989\n",
      "Epoch: 8415, Train Loss: 0.38866570591926575, Valid Loss: 0.6167166233062744\n",
      "Epoch: 8416, Train Loss: 0.38848650455474854, Valid Loss: 0.7114521265029907\n",
      "Epoch: 8417, Train Loss: 0.38827571272850037, Valid Loss: 0.6258186101913452\n",
      "Epoch: 8418, Train Loss: 0.38796430826187134, Valid Loss: 0.6909648180007935\n",
      "Epoch: 8419, Train Loss: 0.38775762915611267, Valid Loss: 0.6489461660385132\n",
      "Epoch: 8420, Train Loss: 0.3876890540122986, Valid Loss: 0.6621252298355103\n",
      "Epoch: 8421, Train Loss: 0.3877530097961426, Valid Loss: 0.6755278706550598\n",
      "Epoch: 8422, Train Loss: 0.3878896236419678, Valid Loss: 0.6403952240943909\n",
      "Epoch: 8423, Train Loss: 0.38799598813056946, Valid Loss: 0.6921493411064148\n",
      "Epoch: 8424, Train Loss: 0.3880436420440674, Valid Loss: 0.6334211826324463\n",
      "Epoch: 8425, Train Loss: 0.3879639506340027, Valid Loss: 0.6902116537094116\n",
      "Epoch: 8426, Train Loss: 0.38785070180892944, Valid Loss: 0.6427832841873169\n",
      "Epoch: 8427, Train Loss: 0.38773810863494873, Valid Loss: 0.6732032895088196\n",
      "Epoch: 8428, Train Loss: 0.3876901865005493, Valid Loss: 0.6611409187316895\n",
      "Epoch: 8429, Train Loss: 0.38770821690559387, Valid Loss: 0.6544175148010254\n",
      "Epoch: 8430, Train Loss: 0.38776323199272156, Valid Loss: 0.6767757534980774\n",
      "Epoch: 8431, Train Loss: 0.38781729340553284, Valid Loss: 0.644549548625946\n",
      "Epoch: 8432, Train Loss: 0.3878285884857178, Valid Loss: 0.6816979050636292\n",
      "Epoch: 8433, Train Loss: 0.3878062069416046, Valid Loss: 0.646210253238678\n",
      "Epoch: 8434, Train Loss: 0.387753427028656, Valid Loss: 0.6748133301734924\n",
      "Epoch: 8435, Train Loss: 0.38770750164985657, Valid Loss: 0.6561211347579956\n",
      "Epoch: 8436, Train Loss: 0.3876868784427643, Valid Loss: 0.6623852252960205\n",
      "Epoch: 8437, Train Loss: 0.387696236371994, Valid Loss: 0.6675703525543213\n",
      "Epoch: 8438, Train Loss: 0.38772231340408325, Valid Loss: 0.6529380679130554\n",
      "Epoch: 8439, Train Loss: 0.3877454996109009, Valid Loss: 0.6743924021720886\n",
      "Epoch: 8440, Train Loss: 0.387753963470459, Valid Loss: 0.6504456400871277\n",
      "Epoch: 8441, Train Loss: 0.38773930072784424, Valid Loss: 0.6736995577812195\n",
      "Epoch: 8442, Train Loss: 0.38771623373031616, Valid Loss: 0.6540899872779846\n",
      "Epoch: 8443, Train Loss: 0.3876948058605194, Valid Loss: 0.667121410369873\n",
      "Epoch: 8444, Train Loss: 0.3876851499080658, Valid Loss: 0.6611819267272949\n",
      "Epoch: 8445, Train Loss: 0.38768869638442993, Valid Loss: 0.6596542596817017\n",
      "Epoch: 8446, Train Loss: 0.3876998722553253, Valid Loss: 0.6679866909980774\n",
      "Epoch: 8447, Train Loss: 0.3877106308937073, Valid Loss: 0.6549977660179138\n",
      "Epoch: 8448, Train Loss: 0.3877144753932953, Valid Loss: 0.6709526777267456\n",
      "Epoch: 8449, Train Loss: 0.3877115845680237, Valid Loss: 0.6543976068496704\n",
      "Epoch: 8450, Train Loss: 0.38770249485969543, Valid Loss: 0.6692912578582764\n",
      "Epoch: 8451, Train Loss: 0.38769277930259705, Valid Loss: 0.6576559543609619\n",
      "Epoch: 8452, Train Loss: 0.3876863718032837, Valid Loss: 0.6646682620048523\n",
      "Epoch: 8453, Train Loss: 0.3876848816871643, Valid Loss: 0.6628395318984985\n",
      "Epoch: 8454, Train Loss: 0.3876873850822449, Valid Loss: 0.659843921661377\n",
      "Epoch: 8455, Train Loss: 0.38769176602363586, Valid Loss: 0.6670684814453125\n",
      "Epoch: 8456, Train Loss: 0.38769659399986267, Valid Loss: 0.6570687890052795\n",
      "Epoch: 8457, Train Loss: 0.38769766688346863, Valid Loss: 0.6684563159942627\n",
      "Epoch: 8458, Train Loss: 0.38769569993019104, Valid Loss: 0.6570943593978882\n",
      "Epoch: 8459, Train Loss: 0.3876922130584717, Valid Loss: 0.6670851111412048\n",
      "Epoch: 8460, Train Loss: 0.3876883387565613, Valid Loss: 0.6593998670578003\n",
      "Epoch: 8461, Train Loss: 0.38768523931503296, Valid Loss: 0.6641687154769897\n",
      "Epoch: 8462, Train Loss: 0.38768407702445984, Valid Loss: 0.6625891327857971\n",
      "Epoch: 8463, Train Loss: 0.3876848518848419, Valid Loss: 0.6612522006034851\n",
      "Epoch: 8464, Train Loss: 0.3876861035823822, Valid Loss: 0.6651265025138855\n",
      "Epoch: 8465, Train Loss: 0.3876877725124359, Valid Loss: 0.6594264507293701\n",
      "Epoch: 8466, Train Loss: 0.3876887857913971, Valid Loss: 0.6662267446517944\n",
      "Epoch: 8467, Train Loss: 0.38768893480300903, Valid Loss: 0.6590589880943298\n",
      "Epoch: 8468, Train Loss: 0.38768815994262695, Valid Loss: 0.6659952402114868\n",
      "Epoch: 8469, Train Loss: 0.3876870274543762, Valid Loss: 0.6599487066268921\n",
      "Epoch: 8470, Train Loss: 0.38768571615219116, Valid Loss: 0.6648567914962769\n",
      "Epoch: 8471, Train Loss: 0.3876842260360718, Valid Loss: 0.6614466905593872\n",
      "Epoch: 8472, Train Loss: 0.3876837491989136, Valid Loss: 0.6632845401763916\n",
      "Epoch: 8473, Train Loss: 0.3876834213733673, Valid Loss: 0.6629456877708435\n",
      "Epoch: 8474, Train Loss: 0.3876832127571106, Valid Loss: 0.6619015336036682\n",
      "Epoch: 8475, Train Loss: 0.38768407702445984, Valid Loss: 0.6641949415206909\n",
      "Epoch: 8476, Train Loss: 0.38768482208251953, Valid Loss: 0.6610146164894104\n",
      "Epoch: 8477, Train Loss: 0.38768506050109863, Valid Loss: 0.6649145483970642\n",
      "Epoch: 8478, Train Loss: 0.3876856565475464, Valid Loss: 0.660646378993988\n",
      "Epoch: 8479, Train Loss: 0.3876855969429016, Valid Loss: 0.6650241613388062\n",
      "Epoch: 8480, Train Loss: 0.38768506050109863, Valid Loss: 0.6607769727706909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8481, Train Loss: 0.38768434524536133, Valid Loss: 0.6647162437438965\n",
      "Epoch: 8482, Train Loss: 0.3876844346523285, Valid Loss: 0.6612700819969177\n",
      "Epoch: 8483, Train Loss: 0.3876837491989136, Valid Loss: 0.6641873717308044\n",
      "Epoch: 8484, Train Loss: 0.3876834511756897, Valid Loss: 0.6619369387626648\n",
      "Epoch: 8485, Train Loss: 0.387683242559433, Valid Loss: 0.6635480523109436\n",
      "Epoch: 8486, Train Loss: 0.38768327236175537, Valid Loss: 0.6626235246658325\n",
      "Epoch: 8487, Train Loss: 0.3876829147338867, Valid Loss: 0.6628996133804321\n",
      "Epoch: 8488, Train Loss: 0.3876827359199524, Valid Loss: 0.6632397174835205\n",
      "Epoch: 8489, Train Loss: 0.38768264651298523, Valid Loss: 0.662394106388092\n",
      "Epoch: 8490, Train Loss: 0.38768255710601807, Valid Loss: 0.6637075543403625\n",
      "Epoch: 8491, Train Loss: 0.38768288493156433, Valid Loss: 0.6620686054229736\n",
      "Epoch: 8492, Train Loss: 0.38768327236175537, Valid Loss: 0.6639969348907471\n",
      "Epoch: 8493, Train Loss: 0.3876826763153076, Valid Loss: 0.6618803143501282\n",
      "Epoch: 8494, Train Loss: 0.38768309354782104, Valid Loss: 0.664165735244751\n",
      "Epoch: 8495, Train Loss: 0.38768327236175537, Valid Loss: 0.6617764234542847\n",
      "Epoch: 8496, Train Loss: 0.38768312335014343, Valid Loss: 0.6642695665359497\n",
      "Epoch: 8497, Train Loss: 0.38768330216407776, Valid Loss: 0.6617168188095093\n",
      "Epoch: 8498, Train Loss: 0.3876830041408539, Valid Loss: 0.6643623113632202\n",
      "Epoch: 8499, Train Loss: 0.38768306374549866, Valid Loss: 0.6616908311843872\n",
      "Epoch: 8500, Train Loss: 0.3876830041408539, Valid Loss: 0.6644054651260376\n",
      "Epoch: 8501, Train Loss: 0.3876827359199524, Valid Loss: 0.6616705060005188\n",
      "Epoch: 8502, Train Loss: 0.3876829147338867, Valid Loss: 0.6644630432128906\n",
      "Epoch: 8503, Train Loss: 0.3876829445362091, Valid Loss: 0.6616101861000061\n",
      "Epoch: 8504, Train Loss: 0.38768303394317627, Valid Loss: 0.6645817756652832\n",
      "Epoch: 8505, Train Loss: 0.38768288493156433, Valid Loss: 0.6615092754364014\n",
      "Epoch: 8506, Train Loss: 0.38768330216407776, Valid Loss: 0.6647526621818542\n",
      "Epoch: 8507, Train Loss: 0.38768309354782104, Valid Loss: 0.6613314747810364\n",
      "Epoch: 8508, Train Loss: 0.38768330216407776, Valid Loss: 0.6649937629699707\n",
      "Epoch: 8509, Train Loss: 0.38768360018730164, Valid Loss: 0.6610575914382935\n",
      "Epoch: 8510, Train Loss: 0.38768401741981506, Valid Loss: 0.6653815507888794\n",
      "Epoch: 8511, Train Loss: 0.3876844346523285, Valid Loss: 0.6606014966964722\n",
      "Epoch: 8512, Train Loss: 0.38768500089645386, Valid Loss: 0.6659727692604065\n",
      "Epoch: 8513, Train Loss: 0.3876863121986389, Valid Loss: 0.6599432229995728\n",
      "Epoch: 8514, Train Loss: 0.3876872658729553, Valid Loss: 0.6668125987052917\n",
      "Epoch: 8515, Train Loss: 0.3876893222332001, Valid Loss: 0.6589562892913818\n",
      "Epoch: 8516, Train Loss: 0.3876914083957672, Valid Loss: 0.6680535078048706\n",
      "Epoch: 8517, Train Loss: 0.3876955807209015, Valid Loss: 0.657497227191925\n",
      "Epoch: 8518, Train Loss: 0.3877005875110626, Valid Loss: 0.6699202060699463\n",
      "Epoch: 8519, Train Loss: 0.3877085745334625, Valid Loss: 0.6553260087966919\n",
      "Epoch: 8520, Train Loss: 0.3877193033695221, Valid Loss: 0.6726957559585571\n",
      "Epoch: 8521, Train Loss: 0.38773661851882935, Valid Loss: 0.6520750522613525\n",
      "Epoch: 8522, Train Loss: 0.38775956630706787, Valid Loss: 0.6768966913223267\n",
      "Epoch: 8523, Train Loss: 0.3877958655357361, Valid Loss: 0.647290050983429\n",
      "Epoch: 8524, Train Loss: 0.38784152269363403, Valid Loss: 0.6830925941467285\n",
      "Epoch: 8525, Train Loss: 0.38791608810424805, Valid Loss: 0.6405500769615173\n",
      "Epoch: 8526, Train Loss: 0.38799774646759033, Valid Loss: 0.6917161345481873\n",
      "Epoch: 8527, Train Loss: 0.38812893629074097, Valid Loss: 0.6320332884788513\n",
      "Epoch: 8528, Train Loss: 0.3882341682910919, Valid Loss: 0.7019222974777222\n",
      "Epoch: 8529, Train Loss: 0.38838991522789, Valid Loss: 0.6238965392112732\n",
      "Epoch: 8530, Train Loss: 0.3884198069572449, Valid Loss: 0.7091988921165466\n",
      "Epoch: 8531, Train Loss: 0.38845300674438477, Valid Loss: 0.6215538382530212\n",
      "Epoch: 8532, Train Loss: 0.3882922828197479, Valid Loss: 0.7055171132087708\n",
      "Epoch: 8533, Train Loss: 0.388121634721756, Valid Loss: 0.6306657195091248\n",
      "Epoch: 8534, Train Loss: 0.3878978490829468, Valid Loss: 0.6877302527427673\n",
      "Epoch: 8535, Train Loss: 0.38774701952934265, Valid Loss: 0.6502458453178406\n",
      "Epoch: 8536, Train Loss: 0.38768714666366577, Valid Loss: 0.6642181873321533\n",
      "Epoch: 8537, Train Loss: 0.3877175748348236, Valid Loss: 0.6721429228782654\n",
      "Epoch: 8538, Train Loss: 0.3878052830696106, Valid Loss: 0.645495593547821\n",
      "Epoch: 8539, Train Loss: 0.38789209723472595, Valid Loss: 0.6870931386947632\n",
      "Epoch: 8540, Train Loss: 0.3879531919956207, Valid Loss: 0.6372628211975098\n",
      "Epoch: 8541, Train Loss: 0.3879314959049225, Valid Loss: 0.6890914440155029\n",
      "Epoch: 8542, Train Loss: 0.3878723978996277, Valid Loss: 0.6414375901222229\n",
      "Epoch: 8543, Train Loss: 0.38778284192085266, Valid Loss: 0.6786623597145081\n",
      "Epoch: 8544, Train Loss: 0.38771575689315796, Valid Loss: 0.654428243637085\n",
      "Epoch: 8545, Train Loss: 0.3876875638961792, Valid Loss: 0.6634712815284729\n",
      "Epoch: 8546, Train Loss: 0.3876968324184418, Valid Loss: 0.668666660785675\n",
      "Epoch: 8547, Train Loss: 0.387730211019516, Valid Loss: 0.6516628265380859\n",
      "Epoch: 8548, Train Loss: 0.3877633213996887, Valid Loss: 0.6775848269462585\n",
      "Epoch: 8549, Train Loss: 0.3877843916416168, Valid Loss: 0.6471450328826904\n",
      "Epoch: 8550, Train Loss: 0.3877774477005005, Valid Loss: 0.6781904101371765\n",
      "Epoch: 8551, Train Loss: 0.3877545893192291, Valid Loss: 0.650407075881958\n",
      "Epoch: 8552, Train Loss: 0.38772037625312805, Valid Loss: 0.6718245148658752\n",
      "Epoch: 8553, Train Loss: 0.38769301772117615, Valid Loss: 0.6582716107368469\n",
      "Epoch: 8554, Train Loss: 0.38768190145492554, Valid Loss: 0.6630018353462219\n",
      "Epoch: 8555, Train Loss: 0.3876868188381195, Valid Loss: 0.6663148403167725\n",
      "Epoch: 8556, Train Loss: 0.38770100474357605, Valid Loss: 0.6561502814292908\n",
      "Epoch: 8557, Train Loss: 0.3877158463001251, Valid Loss: 0.6715301275253296\n",
      "Epoch: 8558, Train Loss: 0.3877250552177429, Valid Loss: 0.6532543301582336\n",
      "Epoch: 8559, Train Loss: 0.3877229392528534, Valid Loss: 0.672511875629425\n",
      "Epoch: 8560, Train Loss: 0.38771334290504456, Valid Loss: 0.6543353199958801\n",
      "Epoch: 8561, Train Loss: 0.38770008087158203, Valid Loss: 0.6696626543998718\n",
      "Epoch: 8562, Train Loss: 0.3876889646053314, Valid Loss: 0.6582183837890625\n",
      "Epoch: 8563, Train Loss: 0.3876825273036957, Valid Loss: 0.66481614112854\n",
      "Epoch: 8564, Train Loss: 0.38768240809440613, Valid Loss: 0.6632347106933594\n",
      "Epoch: 8565, Train Loss: 0.3876854479312897, Valid Loss: 0.660094141960144\n",
      "Epoch: 8566, Train Loss: 0.3876904845237732, Valid Loss: 0.6676092743873596\n",
      "Epoch: 8567, Train Loss: 0.3876955807209015, Valid Loss: 0.6569783687591553\n",
      "Epoch: 8568, Train Loss: 0.3876980245113373, Valid Loss: 0.6696370840072632\n",
      "Epoch: 8569, Train Loss: 0.38769736886024475, Valid Loss: 0.6563164591789246\n",
      "Epoch: 8570, Train Loss: 0.3876941204071045, Valid Loss: 0.6689452528953552\n",
      "Epoch: 8571, Train Loss: 0.38768962025642395, Valid Loss: 0.6580524444580078\n",
      "Epoch: 8572, Train Loss: 0.3876848518848419, Valid Loss: 0.6664543747901917\n",
      "Epoch: 8573, Train Loss: 0.38768213987350464, Valid Loss: 0.6610673666000366\n",
      "Epoch: 8574, Train Loss: 0.38768061995506287, Valid Loss: 0.6633404493331909\n",
      "Epoch: 8575, Train Loss: 0.3876810073852539, Valid Loss: 0.6640907526016235\n",
      "Epoch: 8576, Train Loss: 0.3876822888851166, Valid Loss: 0.6607203483581543\n",
      "Epoch: 8577, Train Loss: 0.3876843750476837, Valid Loss: 0.6661384105682373\n",
      "Epoch: 8578, Train Loss: 0.3876858353614807, Valid Loss: 0.6592941880226135\n",
      "Epoch: 8579, Train Loss: 0.3876863718032837, Valid Loss: 0.6669549345970154\n",
      "Epoch: 8580, Train Loss: 0.38768646121025085, Valid Loss: 0.6591499447822571\n",
      "Epoch: 8581, Train Loss: 0.3876858651638031, Valid Loss: 0.6667448282241821\n",
      "Epoch: 8582, Train Loss: 0.3876849114894867, Valid Loss: 0.659865140914917\n",
      "Epoch: 8583, Train Loss: 0.3876835107803345, Valid Loss: 0.6658158898353577\n",
      "Epoch: 8584, Train Loss: 0.38768211007118225, Valid Loss: 0.6609519124031067\n",
      "Epoch: 8585, Train Loss: 0.38768115639686584, Valid Loss: 0.6646324396133423\n",
      "Epoch: 8586, Train Loss: 0.3876805007457733, Valid Loss: 0.662199854850769\n",
      "Epoch: 8587, Train Loss: 0.3876801133155823, Valid Loss: 0.663531482219696\n",
      "Epoch: 8588, Train Loss: 0.3876801133155823, Valid Loss: 0.6633126139640808\n",
      "Epoch: 8589, Train Loss: 0.38767990469932556, Valid Loss: 0.6625990271568298\n",
      "Epoch: 8590, Train Loss: 0.3876801133155823, Valid Loss: 0.664171576499939\n",
      "Epoch: 8591, Train Loss: 0.38768070936203003, Valid Loss: 0.6618515253067017\n",
      "Epoch: 8592, Train Loss: 0.3876810073852539, Valid Loss: 0.6648212671279907\n",
      "Epoch: 8593, Train Loss: 0.38768139481544495, Valid Loss: 0.6613616347312927\n",
      "Epoch: 8594, Train Loss: 0.38768136501312256, Valid Loss: 0.6652519702911377\n",
      "Epoch: 8595, Train Loss: 0.38768142461776733, Valid Loss: 0.6611083745956421\n",
      "Epoch: 8596, Train Loss: 0.3876814842224121, Valid Loss: 0.6654685139656067\n",
      "Epoch: 8597, Train Loss: 0.38768118619918823, Valid Loss: 0.6610170602798462\n",
      "Epoch: 8598, Train Loss: 0.38768136501312256, Valid Loss: 0.6654762029647827\n",
      "Epoch: 8599, Train Loss: 0.3876809775829315, Valid Loss: 0.6611315011978149\n",
      "Epoch: 8600, Train Loss: 0.3876807987689972, Valid Loss: 0.6653375029563904\n",
      "Epoch: 8601, Train Loss: 0.3876812160015106, Valid Loss: 0.6613664031028748\n",
      "Epoch: 8602, Train Loss: 0.38768041133880615, Valid Loss: 0.6651666760444641\n",
      "Epoch: 8603, Train Loss: 0.38768064975738525, Valid Loss: 0.6615760922431946\n",
      "Epoch: 8604, Train Loss: 0.3876805007457733, Valid Loss: 0.6650374531745911\n",
      "Epoch: 8605, Train Loss: 0.3876805603504181, Valid Loss: 0.6616823077201843\n",
      "Epoch: 8606, Train Loss: 0.3876803517341614, Valid Loss: 0.6649670600891113\n",
      "Epoch: 8607, Train Loss: 0.38768085837364197, Valid Loss: 0.6617435216903687\n",
      "Epoch: 8608, Train Loss: 0.38768017292022705, Valid Loss: 0.6650006175041199\n",
      "Epoch: 8609, Train Loss: 0.3876801133155823, Valid Loss: 0.6616874933242798\n",
      "Epoch: 8610, Train Loss: 0.3876805305480957, Valid Loss: 0.6651695966720581\n",
      "Epoch: 8611, Train Loss: 0.387680321931839, Valid Loss: 0.661500096321106\n",
      "Epoch: 8612, Train Loss: 0.3876805603504181, Valid Loss: 0.6654497385025024\n",
      "Epoch: 8613, Train Loss: 0.3876808285713196, Valid Loss: 0.6611435413360596\n",
      "Epoch: 8614, Train Loss: 0.38768136501312256, Valid Loss: 0.6659205555915833\n",
      "Epoch: 8615, Train Loss: 0.3876819908618927, Valid Loss: 0.6606197953224182\n",
      "Epoch: 8616, Train Loss: 0.3876829147338867, Valid Loss: 0.6666095852851868\n",
      "Epoch: 8617, Train Loss: 0.3876842260360718, Valid Loss: 0.6598381996154785\n",
      "Epoch: 8618, Train Loss: 0.38768595457077026, Valid Loss: 0.6676222085952759\n",
      "Epoch: 8619, Train Loss: 0.387688547372818, Valid Loss: 0.6586260199546814\n",
      "Epoch: 8620, Train Loss: 0.3876917064189911, Valid Loss: 0.6691693067550659\n",
      "Epoch: 8621, Train Loss: 0.3876974582672119, Valid Loss: 0.6567995548248291\n",
      "Epoch: 8622, Train Loss: 0.3877047896385193, Valid Loss: 0.6714968681335449\n",
      "Epoch: 8623, Train Loss: 0.38771694898605347, Valid Loss: 0.654081404209137\n",
      "Epoch: 8624, Train Loss: 0.38773220777511597, Valid Loss: 0.6750019788742065\n",
      "Epoch: 8625, Train Loss: 0.3877578377723694, Valid Loss: 0.6500245928764343\n",
      "Epoch: 8626, Train Loss: 0.3877907991409302, Valid Loss: 0.6802517175674438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8627, Train Loss: 0.38784506916999817, Valid Loss: 0.644136905670166\n",
      "Epoch: 8628, Train Loss: 0.3879101276397705, Valid Loss: 0.6878558993339539\n",
      "Epoch: 8629, Train Loss: 0.38801634311676025, Valid Loss: 0.636186420917511\n",
      "Epoch: 8630, Train Loss: 0.38812023401260376, Valid Loss: 0.697831392288208\n",
      "Epoch: 8631, Train Loss: 0.3882831335067749, Valid Loss: 0.6271559596061707\n",
      "Epoch: 8632, Train Loss: 0.3883739709854126, Valid Loss: 0.7077311873435974\n",
      "Epoch: 8633, Train Loss: 0.38849887251853943, Valid Loss: 0.6209847331047058\n",
      "Epoch: 8634, Train Loss: 0.38843226432800293, Valid Loss: 0.7105113863945007\n",
      "Epoch: 8635, Train Loss: 0.3883456885814667, Valid Loss: 0.6242390275001526\n",
      "Epoch: 8636, Train Loss: 0.38810497522354126, Valid Loss: 0.6987261772155762\n",
      "Epoch: 8637, Train Loss: 0.3878965377807617, Valid Loss: 0.6400124430656433\n",
      "Epoch: 8638, Train Loss: 0.38773855566978455, Valid Loss: 0.6756020188331604\n",
      "Epoch: 8639, Train Loss: 0.38768452405929565, Valid Loss: 0.6627322435379028\n",
      "Epoch: 8640, Train Loss: 0.3877255618572235, Valid Loss: 0.6529312133789062\n",
      "Epoch: 8641, Train Loss: 0.38781777024269104, Valid Loss: 0.6825804114341736\n",
      "Epoch: 8642, Train Loss: 0.3879189193248749, Valid Loss: 0.6391130685806274\n",
      "Epoch: 8643, Train Loss: 0.3879561126232147, Valid Loss: 0.6911044120788574\n",
      "Epoch: 8644, Train Loss: 0.38794469833374023, Valid Loss: 0.6378351449966431\n",
      "Epoch: 8645, Train Loss: 0.387859046459198, Valid Loss: 0.6851599216461182\n",
      "Epoch: 8646, Train Loss: 0.3877701461315155, Valid Loss: 0.6482418179512024\n",
      "Epoch: 8647, Train Loss: 0.3877027630805969, Valid Loss: 0.6700360178947449\n",
      "Epoch: 8648, Train Loss: 0.3876822590827942, Valid Loss: 0.6636600494384766\n",
      "Epoch: 8649, Train Loss: 0.387702077627182, Valid Loss: 0.6554480791091919\n",
      "Epoch: 8650, Train Loss: 0.3877401053905487, Valid Loss: 0.675977349281311\n",
      "Epoch: 8651, Train Loss: 0.38777610659599304, Valid Loss: 0.6474974155426025\n",
      "Epoch: 8652, Train Loss: 0.3877866268157959, Valid Loss: 0.6799352765083313\n",
      "Epoch: 8653, Train Loss: 0.38777533173561096, Valid Loss: 0.6481454372406006\n",
      "Epoch: 8654, Train Loss: 0.38774189352989197, Valid Loss: 0.6752316355705261\n",
      "Epoch: 8655, Train Loss: 0.3877081573009491, Valid Loss: 0.6555377840995789\n",
      "Epoch: 8656, Train Loss: 0.38768452405929565, Valid Loss: 0.6659532785415649\n",
      "Epoch: 8657, Train Loss: 0.38767966628074646, Valid Loss: 0.664692223072052\n",
      "Epoch: 8658, Train Loss: 0.3876902163028717, Valid Loss: 0.6575576663017273\n",
      "Epoch: 8659, Train Loss: 0.3877071738243103, Valid Loss: 0.6713695526123047\n",
      "Epoch: 8660, Train Loss: 0.38772231340408325, Valid Loss: 0.6533019542694092\n",
      "Epoch: 8661, Train Loss: 0.3877255618572235, Valid Loss: 0.673478901386261\n",
      "Epoch: 8662, Train Loss: 0.3877195715904236, Valid Loss: 0.6536598205566406\n",
      "Epoch: 8663, Train Loss: 0.3877061605453491, Valid Loss: 0.6710853576660156\n",
      "Epoch: 8664, Train Loss: 0.3876916766166687, Valid Loss: 0.6574506163597107\n",
      "Epoch: 8665, Train Loss: 0.3876815140247345, Valid Loss: 0.6661134362220764\n",
      "Epoch: 8666, Train Loss: 0.3876785337924957, Valid Loss: 0.6626740097999573\n",
      "Epoch: 8667, Train Loss: 0.3876814544200897, Valid Loss: 0.660950243473053\n",
      "Epoch: 8668, Train Loss: 0.38768741488456726, Valid Loss: 0.6674157977104187\n",
      "Epoch: 8669, Train Loss: 0.38769304752349854, Valid Loss: 0.6574142575263977\n",
      "Epoch: 8670, Train Loss: 0.38769564032554626, Valid Loss: 0.6700066328048706\n",
      "Epoch: 8671, Train Loss: 0.38769638538360596, Valid Loss: 0.6563919186592102\n",
      "Epoch: 8672, Train Loss: 0.3876930773258209, Valid Loss: 0.669606626033783\n",
      "Epoch: 8673, Train Loss: 0.3876882791519165, Valid Loss: 0.6579436659812927\n",
      "Epoch: 8674, Train Loss: 0.38768357038497925, Valid Loss: 0.667034387588501\n",
      "Epoch: 8675, Train Loss: 0.3876796066761017, Valid Loss: 0.6611214280128479\n",
      "Epoch: 8676, Train Loss: 0.3876776397228241, Valid Loss: 0.6637140512466431\n",
      "Epoch: 8677, Train Loss: 0.3876782953739166, Valid Loss: 0.6644343733787537\n",
      "Epoch: 8678, Train Loss: 0.387679785490036, Valid Loss: 0.6608349680900574\n",
      "Epoch: 8679, Train Loss: 0.38768187165260315, Valid Loss: 0.6667265295982361\n",
      "Epoch: 8680, Train Loss: 0.38768377900123596, Valid Loss: 0.659243106842041\n",
      "Epoch: 8681, Train Loss: 0.38768383860588074, Valid Loss: 0.6675671339035034\n",
      "Epoch: 8682, Train Loss: 0.387684166431427, Valid Loss: 0.6591207385063171\n",
      "Epoch: 8683, Train Loss: 0.38768336176872253, Valid Loss: 0.6671896576881409\n",
      "Epoch: 8684, Train Loss: 0.38768184185028076, Valid Loss: 0.6600919961929321\n",
      "Epoch: 8685, Train Loss: 0.3876804709434509, Valid Loss: 0.6659669280052185\n",
      "Epoch: 8686, Train Loss: 0.3876785635948181, Valid Loss: 0.6615809798240662\n",
      "Epoch: 8687, Train Loss: 0.3876779079437256, Valid Loss: 0.6643609404563904\n",
      "Epoch: 8688, Train Loss: 0.3876773715019226, Valid Loss: 0.6631529331207275\n",
      "Epoch: 8689, Train Loss: 0.3876773715019226, Valid Loss: 0.6629871129989624\n",
      "Epoch: 8690, Train Loss: 0.3876771926879883, Valid Loss: 0.6644667983055115\n",
      "Epoch: 8691, Train Loss: 0.3876781761646271, Valid Loss: 0.6619846224784851\n",
      "Epoch: 8692, Train Loss: 0.38767847418785095, Valid Loss: 0.6653342247009277\n",
      "Epoch: 8693, Train Loss: 0.387678861618042, Valid Loss: 0.6613545417785645\n",
      "Epoch: 8694, Train Loss: 0.38767945766448975, Valid Loss: 0.6657868027687073\n",
      "Epoch: 8695, Train Loss: 0.38767945766448975, Valid Loss: 0.6611089110374451\n",
      "Epoch: 8696, Train Loss: 0.38767942786216736, Valid Loss: 0.6659011840820312\n",
      "Epoch: 8697, Train Loss: 0.387678861618042, Valid Loss: 0.6611782908439636\n",
      "Epoch: 8698, Train Loss: 0.3876791298389435, Valid Loss: 0.6658080220222473\n",
      "Epoch: 8699, Train Loss: 0.3876782953739166, Valid Loss: 0.661426842212677\n",
      "Epoch: 8700, Train Loss: 0.3876783847808838, Valid Loss: 0.6655145287513733\n",
      "Epoch: 8701, Train Loss: 0.38767778873443604, Valid Loss: 0.6617684364318848\n",
      "Epoch: 8702, Train Loss: 0.38767755031585693, Valid Loss: 0.6651497483253479\n",
      "Epoch: 8703, Train Loss: 0.3876771330833435, Valid Loss: 0.6621949076652527\n",
      "Epoch: 8704, Train Loss: 0.3876773416996002, Valid Loss: 0.664813220500946\n",
      "Epoch: 8705, Train Loss: 0.3876771330833435, Valid Loss: 0.6625661253929138\n",
      "Epoch: 8706, Train Loss: 0.3876771330833435, Valid Loss: 0.6645455956459045\n",
      "Epoch: 8707, Train Loss: 0.3876768946647644, Valid Loss: 0.6628230810165405\n",
      "Epoch: 8708, Train Loss: 0.3876764476299286, Valid Loss: 0.6643052697181702\n",
      "Epoch: 8709, Train Loss: 0.3876762390136719, Valid Loss: 0.6630764603614807\n",
      "Epoch: 8710, Train Loss: 0.3876765966415405, Valid Loss: 0.6641291975975037\n",
      "Epoch: 8711, Train Loss: 0.3876764178276062, Valid Loss: 0.6632611751556396\n",
      "Epoch: 8712, Train Loss: 0.3876761496067047, Valid Loss: 0.6640148162841797\n",
      "Epoch: 8713, Train Loss: 0.3876761198043823, Valid Loss: 0.663383424282074\n",
      "Epoch: 8714, Train Loss: 0.38767606019973755, Valid Loss: 0.663954496383667\n",
      "Epoch: 8715, Train Loss: 0.3876762092113495, Valid Loss: 0.6634254455566406\n",
      "Epoch: 8716, Train Loss: 0.3876759707927704, Valid Loss: 0.6639410257339478\n",
      "Epoch: 8717, Train Loss: 0.38767609000205994, Valid Loss: 0.6634666919708252\n",
      "Epoch: 8718, Train Loss: 0.3876759707927704, Valid Loss: 0.6639593243598938\n",
      "Epoch: 8719, Train Loss: 0.38767579197883606, Valid Loss: 0.6634653210639954\n",
      "Epoch: 8720, Train Loss: 0.3876756429672241, Valid Loss: 0.664015531539917\n",
      "Epoch: 8721, Train Loss: 0.38767555356025696, Valid Loss: 0.6634025573730469\n",
      "Epoch: 8722, Train Loss: 0.3876758813858032, Valid Loss: 0.6641358137130737\n",
      "Epoch: 8723, Train Loss: 0.38767579197883606, Valid Loss: 0.6632769703865051\n",
      "Epoch: 8724, Train Loss: 0.38767558336257935, Valid Loss: 0.6643116474151611\n",
      "Epoch: 8725, Train Loss: 0.3876756429672241, Valid Loss: 0.6631143093109131\n",
      "Epoch: 8726, Train Loss: 0.3876759111881256, Valid Loss: 0.6645494699478149\n",
      "Epoch: 8727, Train Loss: 0.3876759707927704, Valid Loss: 0.6628590226173401\n",
      "Epoch: 8728, Train Loss: 0.38767603039741516, Valid Loss: 0.6649088859558105\n",
      "Epoch: 8729, Train Loss: 0.3876760005950928, Valid Loss: 0.6624038219451904\n",
      "Epoch: 8730, Train Loss: 0.3876765966415405, Valid Loss: 0.6654975414276123\n",
      "Epoch: 8731, Train Loss: 0.38767725229263306, Valid Loss: 0.6617235541343689\n",
      "Epoch: 8732, Train Loss: 0.38767769932746887, Valid Loss: 0.6663897037506104\n",
      "Epoch: 8733, Train Loss: 0.3876793682575226, Valid Loss: 0.6606625318527222\n",
      "Epoch: 8734, Train Loss: 0.3876815736293793, Valid Loss: 0.6677707433700562\n",
      "Epoch: 8735, Train Loss: 0.3876851499080658, Valid Loss: 0.6589472889900208\n",
      "Epoch: 8736, Train Loss: 0.38769105076789856, Valid Loss: 0.670036256313324\n",
      "Epoch: 8737, Train Loss: 0.38770097494125366, Valid Loss: 0.6561252474784851\n",
      "Epoch: 8738, Train Loss: 0.38771653175354004, Valid Loss: 0.6738156080245972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8739, Train Loss: 0.387742817401886, Valid Loss: 0.6514928936958313\n",
      "Epoch: 8740, Train Loss: 0.3877831697463989, Valid Loss: 0.6800880432128906\n",
      "Epoch: 8741, Train Loss: 0.3878540098667145, Valid Loss: 0.6440342664718628\n",
      "Epoch: 8742, Train Loss: 0.3879531919956207, Valid Loss: 0.6903360486030579\n",
      "Epoch: 8743, Train Loss: 0.38812801241874695, Valid Loss: 0.632705569267273\n",
      "Epoch: 8744, Train Loss: 0.3883250653743744, Valid Loss: 0.7055967450141907\n",
      "Epoch: 8745, Train Loss: 0.3886507749557495, Valid Loss: 0.6185725927352905\n",
      "Epoch: 8746, Train Loss: 0.38883766531944275, Valid Loss: 0.722108781337738\n",
      "Epoch: 8747, Train Loss: 0.3890751600265503, Valid Loss: 0.6093153357505798\n",
      "Epoch: 8748, Train Loss: 0.3888487219810486, Valid Loss: 0.7242178320884705\n",
      "Epoch: 8749, Train Loss: 0.3885558843612671, Valid Loss: 0.618864119052887\n",
      "Epoch: 8750, Train Loss: 0.38806915283203125, Valid Loss: 0.6974071264266968\n",
      "Epoch: 8751, Train Loss: 0.38777029514312744, Valid Loss: 0.6494958400726318\n",
      "Epoch: 8752, Train Loss: 0.38771292567253113, Valid Loss: 0.6581621766090393\n",
      "Epoch: 8753, Train Loss: 0.38786059617996216, Valid Loss: 0.684744656085968\n",
      "Epoch: 8754, Train Loss: 0.38809555768966675, Valid Loss: 0.6321325898170471\n",
      "Epoch: 8755, Train Loss: 0.3881964385509491, Valid Loss: 0.7029152512550354\n",
      "Epoch: 8756, Train Loss: 0.3881550431251526, Valid Loss: 0.6299970149993896\n",
      "Epoch: 8757, Train Loss: 0.3879241943359375, Valid Loss: 0.6901651620864868\n",
      "Epoch: 8758, Train Loss: 0.38773593306541443, Valid Loss: 0.6508045792579651\n",
      "Epoch: 8759, Train Loss: 0.3876844346523285, Valid Loss: 0.6602480411529541\n",
      "Epoch: 8760, Train Loss: 0.387759268283844, Valid Loss: 0.6774575114250183\n",
      "Epoch: 8761, Train Loss: 0.3878704607486725, Valid Loss: 0.6405966877937317\n",
      "Epoch: 8762, Train Loss: 0.38791438937187195, Valid Loss: 0.6890690326690674\n",
      "Epoch: 8763, Train Loss: 0.3878861367702484, Valid Loss: 0.6419955492019653\n",
      "Epoch: 8764, Train Loss: 0.38778671622276306, Valid Loss: 0.6789212226867676\n",
      "Epoch: 8765, Train Loss: 0.38770535588264465, Valid Loss: 0.6574410796165466\n",
      "Epoch: 8766, Train Loss: 0.38768500089645386, Valid Loss: 0.6593006253242493\n",
      "Epoch: 8767, Train Loss: 0.38772401213645935, Valid Loss: 0.6738488078117371\n",
      "Epoch: 8768, Train Loss: 0.38777896761894226, Valid Loss: 0.6474260091781616\n",
      "Epoch: 8769, Train Loss: 0.3877981901168823, Valid Loss: 0.6798837184906006\n",
      "Epoch: 8770, Train Loss: 0.387774795293808, Valid Loss: 0.6497788429260254\n",
      "Epoch: 8771, Train Loss: 0.3877184987068176, Valid Loss: 0.6729861497879028\n",
      "Epoch: 8772, Train Loss: 0.3876801133155823, Valid Loss: 0.6602491140365601\n",
      "Epoch: 8773, Train Loss: 0.3876824975013733, Valid Loss: 0.6601415276527405\n",
      "Epoch: 8774, Train Loss: 0.3877107501029968, Valid Loss: 0.6705261468887329\n",
      "Epoch: 8775, Train Loss: 0.38773655891418457, Valid Loss: 0.6517300605773926\n",
      "Epoch: 8776, Train Loss: 0.387737900018692, Valid Loss: 0.6752270460128784\n",
      "Epoch: 8777, Train Loss: 0.38771986961364746, Valid Loss: 0.652961015701294\n",
      "Epoch: 8778, Train Loss: 0.38769450783729553, Valid Loss: 0.6706818342208862\n",
      "Epoch: 8779, Train Loss: 0.3876798748970032, Valid Loss: 0.6607571244239807\n",
      "Epoch: 8780, Train Loss: 0.3876810073852539, Valid Loss: 0.6608045697212219\n",
      "Epoch: 8781, Train Loss: 0.3876926302909851, Valid Loss: 0.6688719391822815\n",
      "Epoch: 8782, Train Loss: 0.38770508766174316, Valid Loss: 0.6543338894844055\n",
      "Epoch: 8783, Train Loss: 0.38770753145217896, Valid Loss: 0.6724696159362793\n",
      "Epoch: 8784, Train Loss: 0.38770022988319397, Valid Loss: 0.655351996421814\n",
      "Epoch: 8785, Train Loss: 0.38768696784973145, Valid Loss: 0.6691766381263733\n",
      "Epoch: 8786, Train Loss: 0.38767731189727783, Valid Loss: 0.6613755822181702\n",
      "Epoch: 8787, Train Loss: 0.38767606019973755, Valid Loss: 0.6618532538414001\n",
      "Epoch: 8788, Train Loss: 0.3876817226409912, Valid Loss: 0.6673079133033752\n",
      "Epoch: 8789, Train Loss: 0.3876887261867523, Valid Loss: 0.657092273235321\n",
      "Epoch: 8790, Train Loss: 0.3876912295818329, Valid Loss: 0.6698974370956421\n",
      "Epoch: 8791, Train Loss: 0.38768866658210754, Valid Loss: 0.657705545425415\n",
      "Epoch: 8792, Train Loss: 0.3876829147338867, Valid Loss: 0.667941153049469\n",
      "Epoch: 8793, Train Loss: 0.3876773416996002, Valid Loss: 0.6614099144935608\n",
      "Epoch: 8794, Train Loss: 0.38767552375793457, Valid Loss: 0.6632431149482727\n",
      "Epoch: 8795, Train Loss: 0.38767683506011963, Valid Loss: 0.6653134226799011\n",
      "Epoch: 8796, Train Loss: 0.38767969608306885, Valid Loss: 0.6597774028778076\n",
      "Epoch: 8797, Train Loss: 0.38768187165260315, Valid Loss: 0.6675638556480408\n",
      "Epoch: 8798, Train Loss: 0.3876822292804718, Valid Loss: 0.6593820452690125\n",
      "Epoch: 8799, Train Loss: 0.38768118619918823, Valid Loss: 0.6672540903091431\n",
      "Epoch: 8800, Train Loss: 0.3876781165599823, Valid Loss: 0.6610168218612671\n",
      "Epoch: 8801, Train Loss: 0.3876757025718689, Valid Loss: 0.6648832559585571\n",
      "Epoch: 8802, Train Loss: 0.38767489790916443, Valid Loss: 0.6633605360984802\n",
      "Epoch: 8803, Train Loss: 0.3876751661300659, Valid Loss: 0.6622523665428162\n",
      "Epoch: 8804, Train Loss: 0.38767653703689575, Valid Loss: 0.6656128764152527\n",
      "Epoch: 8805, Train Loss: 0.3876775801181793, Valid Loss: 0.6609781384468079\n",
      "Epoch: 8806, Train Loss: 0.38767826557159424, Valid Loss: 0.6666067242622375\n",
      "Epoch: 8807, Train Loss: 0.38767629861831665, Valid Loss: 0.6610579490661621\n",
      "Epoch: 8808, Train Loss: 0.38767603039741516, Valid Loss: 0.6658381819725037\n",
      "Epoch: 8809, Train Loss: 0.38767507672309875, Valid Loss: 0.6621235013008118\n",
      "Epoch: 8810, Train Loss: 0.38767480850219727, Valid Loss: 0.664161205291748\n",
      "Epoch: 8811, Train Loss: 0.3876746594905853, Valid Loss: 0.6639248728752136\n",
      "Epoch: 8812, Train Loss: 0.3876747190952301, Valid Loss: 0.6626842617988586\n",
      "Epoch: 8813, Train Loss: 0.38767552375793457, Valid Loss: 0.6654061079025269\n",
      "Epoch: 8814, Train Loss: 0.38767579197883606, Valid Loss: 0.6618283987045288\n",
      "Epoch: 8815, Train Loss: 0.3876758813858032, Valid Loss: 0.665809154510498\n",
      "Epoch: 8816, Train Loss: 0.3876756429672241, Valid Loss: 0.6617805361747742\n",
      "Epoch: 8817, Train Loss: 0.38767513632774353, Valid Loss: 0.6653074622154236\n",
      "Epoch: 8818, Train Loss: 0.3876744508743286, Valid Loss: 0.6625878810882568\n",
      "Epoch: 8819, Train Loss: 0.3876737654209137, Valid Loss: 0.6644142866134644\n",
      "Epoch: 8820, Train Loss: 0.3876742720603943, Valid Loss: 0.6638093590736389\n",
      "Epoch: 8821, Train Loss: 0.3876740634441376, Valid Loss: 0.6634281873703003\n",
      "Epoch: 8822, Train Loss: 0.3876742720603943, Valid Loss: 0.6646688580513\n",
      "Epoch: 8823, Train Loss: 0.3876744210720062, Valid Loss: 0.6627129912376404\n",
      "Epoch: 8824, Train Loss: 0.3876742422580719, Valid Loss: 0.6650359630584717\n",
      "Epoch: 8825, Train Loss: 0.38767459988594055, Valid Loss: 0.6625831723213196\n",
      "Epoch: 8826, Train Loss: 0.38767459988594055, Valid Loss: 0.6650949716567993\n",
      "Epoch: 8827, Train Loss: 0.3876740634441376, Valid Loss: 0.6628782153129578\n",
      "Epoch: 8828, Train Loss: 0.3876739740371704, Valid Loss: 0.6647598147392273\n",
      "Epoch: 8829, Train Loss: 0.387673556804657, Valid Loss: 0.6633323431015015\n",
      "Epoch: 8830, Train Loss: 0.38767343759536743, Valid Loss: 0.6642112731933594\n",
      "Epoch: 8831, Train Loss: 0.38767364621162415, Valid Loss: 0.6638057231903076\n",
      "Epoch: 8832, Train Loss: 0.38767340779304504, Valid Loss: 0.663766622543335\n",
      "Epoch: 8833, Train Loss: 0.387673556804657, Valid Loss: 0.6642915606498718\n",
      "Epoch: 8834, Train Loss: 0.3876733183860779, Valid Loss: 0.663451075553894\n",
      "Epoch: 8835, Train Loss: 0.38767343759536743, Valid Loss: 0.6646305322647095\n",
      "Epoch: 8836, Train Loss: 0.387673556804657, Valid Loss: 0.6632291674613953\n",
      "Epoch: 8837, Train Loss: 0.38767358660697937, Valid Loss: 0.6647328734397888\n",
      "Epoch: 8838, Train Loss: 0.38767358660697937, Valid Loss: 0.663168728351593\n",
      "Epoch: 8839, Train Loss: 0.3876733183860779, Valid Loss: 0.6647293567657471\n",
      "Epoch: 8840, Train Loss: 0.38767334818840027, Valid Loss: 0.6632940769195557\n",
      "Epoch: 8841, Train Loss: 0.3876733183860779, Valid Loss: 0.6646657586097717\n",
      "Epoch: 8842, Train Loss: 0.38767296075820923, Valid Loss: 0.6634535193443298\n",
      "Epoch: 8843, Train Loss: 0.3876732587814331, Valid Loss: 0.6645155549049377\n",
      "Epoch: 8844, Train Loss: 0.38767313957214355, Valid Loss: 0.6635971069335938\n",
      "Epoch: 8845, Train Loss: 0.3876730799674988, Valid Loss: 0.6643526554107666\n",
      "Epoch: 8846, Train Loss: 0.38767358660697937, Valid Loss: 0.6637794375419617\n",
      "Epoch: 8847, Train Loss: 0.38767313957214355, Valid Loss: 0.6642184257507324\n",
      "Epoch: 8848, Train Loss: 0.38767296075820923, Valid Loss: 0.6639904975891113\n",
      "Epoch: 8849, Train Loss: 0.38767287135124207, Valid Loss: 0.6640689373016357\n",
      "Epoch: 8850, Train Loss: 0.38767263293266296, Valid Loss: 0.6641384959220886\n",
      "Epoch: 8851, Train Loss: 0.3876725733280182, Valid Loss: 0.6639472842216492\n",
      "Epoch: 8852, Train Loss: 0.3876728117465973, Valid Loss: 0.6642328500747681\n",
      "Epoch: 8853, Train Loss: 0.387672483921051, Valid Loss: 0.6638668775558472\n",
      "Epoch: 8854, Train Loss: 0.387672483921051, Valid Loss: 0.66436767578125\n",
      "Epoch: 8855, Train Loss: 0.3876725733280182, Valid Loss: 0.6637790203094482\n",
      "Epoch: 8856, Train Loss: 0.3876725733280182, Valid Loss: 0.6645078063011169\n",
      "Epoch: 8857, Train Loss: 0.38767263293266296, Valid Loss: 0.6636723279953003\n",
      "Epoch: 8858, Train Loss: 0.3876725435256958, Valid Loss: 0.6646098494529724\n",
      "Epoch: 8859, Train Loss: 0.3876726031303406, Valid Loss: 0.663555383682251\n",
      "Epoch: 8860, Train Loss: 0.3876722455024719, Valid Loss: 0.6647546291351318\n",
      "Epoch: 8861, Train Loss: 0.38767296075820923, Valid Loss: 0.6634485721588135\n",
      "Epoch: 8862, Train Loss: 0.387672483921051, Valid Loss: 0.6649150252342224\n",
      "Epoch: 8863, Train Loss: 0.3876726031303406, Valid Loss: 0.6633060574531555\n",
      "Epoch: 8864, Train Loss: 0.38767269253730774, Valid Loss: 0.6650930643081665\n",
      "Epoch: 8865, Train Loss: 0.38767287135124207, Valid Loss: 0.6631098389625549\n",
      "Epoch: 8866, Train Loss: 0.3876727819442749, Valid Loss: 0.6653362512588501\n",
      "Epoch: 8867, Train Loss: 0.38767296075820923, Valid Loss: 0.6628426313400269\n",
      "Epoch: 8868, Train Loss: 0.38767313957214355, Valid Loss: 0.6656857132911682\n",
      "Epoch: 8869, Train Loss: 0.3876730501651764, Valid Loss: 0.6624788045883179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8870, Train Loss: 0.38767382502555847, Valid Loss: 0.6661607623100281\n",
      "Epoch: 8871, Train Loss: 0.3876747190952301, Valid Loss: 0.6619191765785217\n",
      "Epoch: 8872, Train Loss: 0.387675017118454, Valid Loss: 0.666860044002533\n",
      "Epoch: 8873, Train Loss: 0.387675940990448, Valid Loss: 0.6610848307609558\n",
      "Epoch: 8874, Train Loss: 0.38767728209495544, Valid Loss: 0.6679200530052185\n",
      "Epoch: 8875, Train Loss: 0.3876800835132599, Valid Loss: 0.6598266363143921\n",
      "Epoch: 8876, Train Loss: 0.387683629989624, Valid Loss: 0.6695541143417358\n",
      "Epoch: 8877, Train Loss: 0.38768890500068665, Valid Loss: 0.6578870415687561\n",
      "Epoch: 8878, Train Loss: 0.3876964747905731, Valid Loss: 0.6720216870307922\n",
      "Epoch: 8879, Train Loss: 0.3877090513706207, Valid Loss: 0.654944896697998\n",
      "Epoch: 8880, Train Loss: 0.3877266049385071, Valid Loss: 0.6758268475532532\n",
      "Epoch: 8881, Train Loss: 0.38775435090065, Valid Loss: 0.6504887342453003\n",
      "Epoch: 8882, Train Loss: 0.3877928555011749, Valid Loss: 0.6816806793212891\n",
      "Epoch: 8883, Train Loss: 0.38785725831985474, Valid Loss: 0.6438373327255249\n",
      "Epoch: 8884, Train Loss: 0.3879367411136627, Valid Loss: 0.6904493570327759\n",
      "Epoch: 8885, Train Loss: 0.38806986808776855, Valid Loss: 0.6345802545547485\n",
      "Epoch: 8886, Train Loss: 0.3882032036781311, Valid Loss: 0.7022925615310669\n",
      "Epoch: 8887, Train Loss: 0.3884143829345703, Valid Loss: 0.6239907741546631\n",
      "Epoch: 8888, Train Loss: 0.3885232210159302, Valid Loss: 0.7138803005218506\n",
      "Epoch: 8889, Train Loss: 0.38866710662841797, Valid Loss: 0.6174584627151489\n",
      "Epoch: 8890, Train Loss: 0.388541579246521, Valid Loss: 0.7154636383056641\n",
      "Epoch: 8891, Train Loss: 0.3883852958679199, Valid Loss: 0.6235259771347046\n",
      "Epoch: 8892, Train Loss: 0.38806650042533875, Valid Loss: 0.6981750726699829\n",
      "Epoch: 8893, Train Loss: 0.38782164454460144, Valid Loss: 0.6444789171218872\n",
      "Epoch: 8894, Train Loss: 0.38768869638442993, Valid Loss: 0.6694700121879578\n",
      "Epoch: 8895, Train Loss: 0.3876992166042328, Valid Loss: 0.6714949011802673\n",
      "Epoch: 8896, Train Loss: 0.38781148195266724, Valid Loss: 0.6452980637550354\n",
      "Epoch: 8897, Train Loss: 0.38793879747390747, Valid Loss: 0.6916029453277588\n",
      "Epoch: 8898, Train Loss: 0.38802918791770935, Valid Loss: 0.6345872282981873\n",
      "Epoch: 8899, Train Loss: 0.3879953622817993, Valid Loss: 0.6942323446273804\n",
      "Epoch: 8900, Train Loss: 0.3879069983959198, Valid Loss: 0.6402223110198975\n",
      "Epoch: 8901, Train Loss: 0.38777878880500793, Valid Loss: 0.6798298358917236\n",
      "Epoch: 8902, Train Loss: 0.387696772813797, Valid Loss: 0.6572045683860779\n",
      "Epoch: 8903, Train Loss: 0.38767942786216736, Valid Loss: 0.660567045211792\n",
      "Epoch: 8904, Train Loss: 0.3877149224281311, Valid Loss: 0.6743384599685669\n",
      "Epoch: 8905, Train Loss: 0.38777145743370056, Valid Loss: 0.6479589939117432\n",
      "Epoch: 8906, Train Loss: 0.38780632615089417, Valid Loss: 0.6825656294822693\n",
      "Epoch: 8907, Train Loss: 0.3878108859062195, Valid Loss: 0.6460883617401123\n",
      "Epoch: 8908, Train Loss: 0.38777315616607666, Valid Loss: 0.6790867447853088\n",
      "Epoch: 8909, Train Loss: 0.38772448897361755, Valid Loss: 0.6536967754364014\n",
      "Epoch: 8910, Train Loss: 0.38768482208251953, Valid Loss: 0.6681624054908752\n",
      "Epoch: 8911, Train Loss: 0.38767293095588684, Valid Loss: 0.6649677157402039\n",
      "Epoch: 8912, Train Loss: 0.38768815994262695, Valid Loss: 0.6573900580406189\n",
      "Epoch: 8913, Train Loss: 0.3877151906490326, Valid Loss: 0.6735504269599915\n",
      "Epoch: 8914, Train Loss: 0.38773584365844727, Valid Loss: 0.6521367430686951\n",
      "Epoch: 8915, Train Loss: 0.3877352774143219, Valid Loss: 0.6759639978408813\n",
      "Epoch: 8916, Train Loss: 0.38771992921829224, Valid Loss: 0.6534074544906616\n",
      "Epoch: 8917, Train Loss: 0.38769662380218506, Valid Loss: 0.6717180013656616\n",
      "Epoch: 8918, Train Loss: 0.3876795470714569, Valid Loss: 0.6592058539390564\n",
      "Epoch: 8919, Train Loss: 0.38767313957214355, Valid Loss: 0.6642523407936096\n",
      "Epoch: 8920, Train Loss: 0.3876773416996002, Valid Loss: 0.6663911938667297\n",
      "Epoch: 8921, Train Loss: 0.38768720626831055, Valid Loss: 0.6580200791358948\n",
      "Epoch: 8922, Train Loss: 0.38769596815109253, Valid Loss: 0.6714890003204346\n",
      "Epoch: 8923, Train Loss: 0.3877003490924835, Valid Loss: 0.6554197072982788\n",
      "Epoch: 8924, Train Loss: 0.38769689202308655, Valid Loss: 0.6721917986869812\n",
      "Epoch: 8925, Train Loss: 0.38768965005874634, Valid Loss: 0.6568818092346191\n",
      "Epoch: 8926, Train Loss: 0.3876805603504181, Valid Loss: 0.6686418652534485\n",
      "Epoch: 8927, Train Loss: 0.387673556804657, Valid Loss: 0.6613720059394836\n",
      "Epoch: 8928, Train Loss: 0.38767147064208984, Valid Loss: 0.6635759472846985\n",
      "Epoch: 8929, Train Loss: 0.3876737952232361, Valid Loss: 0.6664305329322815\n",
      "Epoch: 8930, Train Loss: 0.3876780569553375, Valid Loss: 0.659780740737915\n",
      "Epoch: 8931, Train Loss: 0.3876807391643524, Valid Loss: 0.6693118214607239\n",
      "Epoch: 8932, Train Loss: 0.3876832127571106, Valid Loss: 0.6583030819892883\n",
      "Epoch: 8933, Train Loss: 0.38768184185028076, Valid Loss: 0.669241189956665\n",
      "Epoch: 8934, Train Loss: 0.387679785490036, Valid Loss: 0.6593813896179199\n",
      "Epoch: 8935, Train Loss: 0.38767528533935547, Valid Loss: 0.6671637892723083\n",
      "Epoch: 8936, Train Loss: 0.38767293095588684, Valid Loss: 0.6621267199516296\n",
      "Epoch: 8937, Train Loss: 0.38767170906066895, Valid Loss: 0.6644573211669922\n",
      "Epoch: 8938, Train Loss: 0.38767150044441223, Valid Loss: 0.6648023724555969\n",
      "Epoch: 8939, Train Loss: 0.38767245411872864, Valid Loss: 0.6621531844139099\n",
      "Epoch: 8940, Train Loss: 0.3876737952232361, Valid Loss: 0.6665205359458923\n",
      "Epoch: 8941, Train Loss: 0.3876749277114868, Valid Loss: 0.6609169840812683\n",
      "Epoch: 8942, Train Loss: 0.38767510652542114, Valid Loss: 0.667235255241394\n",
      "Epoch: 8943, Train Loss: 0.3876756429672241, Valid Loss: 0.6608782410621643\n",
      "Epoch: 8944, Train Loss: 0.3876746892929077, Valid Loss: 0.6670417785644531\n",
      "Epoch: 8945, Train Loss: 0.3876737058162689, Valid Loss: 0.6616102457046509\n",
      "Epoch: 8946, Train Loss: 0.3876722455024719, Valid Loss: 0.666073203086853\n",
      "Epoch: 8947, Train Loss: 0.3876713812351227, Valid Loss: 0.6626997590065002\n",
      "Epoch: 8948, Train Loss: 0.38767099380493164, Valid Loss: 0.6648073792457581\n",
      "Epoch: 8949, Train Loss: 0.38767075538635254, Valid Loss: 0.664021372795105\n",
      "Epoch: 8950, Train Loss: 0.3876708745956421, Valid Loss: 0.663653552532196\n",
      "Epoch: 8951, Train Loss: 0.3876711428165436, Valid Loss: 0.6652200222015381\n",
      "Epoch: 8952, Train Loss: 0.3876713812351227, Valid Loss: 0.6627223491668701\n",
      "Epoch: 8953, Train Loss: 0.3876718282699585, Valid Loss: 0.665957510471344\n",
      "Epoch: 8954, Train Loss: 0.38767197728157043, Valid Loss: 0.6621819138526917\n",
      "Epoch: 8955, Train Loss: 0.38767197728157043, Valid Loss: 0.6662555932998657\n",
      "Epoch: 8956, Train Loss: 0.38767194747924805, Valid Loss: 0.6621241569519043\n",
      "Epoch: 8957, Train Loss: 0.3876718282699585, Valid Loss: 0.6661844849586487\n",
      "Epoch: 8958, Train Loss: 0.3876713812351227, Valid Loss: 0.6624816060066223\n",
      "Epoch: 8959, Train Loss: 0.387670636177063, Valid Loss: 0.6657843589782715\n",
      "Epoch: 8960, Train Loss: 0.3876709043979645, Valid Loss: 0.6629828810691833\n",
      "Epoch: 8961, Train Loss: 0.3876705467700958, Valid Loss: 0.665239691734314\n",
      "Epoch: 8962, Train Loss: 0.3876701593399048, Valid Loss: 0.6635403633117676\n",
      "Epoch: 8963, Train Loss: 0.38767024874687195, Valid Loss: 0.6647202372550964\n",
      "Epoch: 8964, Train Loss: 0.3876698911190033, Valid Loss: 0.6641172170639038\n",
      "Epoch: 8965, Train Loss: 0.3876703381538391, Valid Loss: 0.6642889380455017\n",
      "Epoch: 8966, Train Loss: 0.3876700699329376, Valid Loss: 0.6645528674125671\n",
      "Epoch: 8967, Train Loss: 0.3876704275608063, Valid Loss: 0.6639211177825928\n",
      "Epoch: 8968, Train Loss: 0.3876700699329376, Valid Loss: 0.6648579239845276\n",
      "Epoch: 8969, Train Loss: 0.3876699209213257, Valid Loss: 0.6636831760406494\n",
      "Epoch: 8970, Train Loss: 0.38767004013061523, Valid Loss: 0.6650934815406799\n",
      "Epoch: 8971, Train Loss: 0.3876701593399048, Valid Loss: 0.6635076403617859\n",
      "Epoch: 8972, Train Loss: 0.3876698315143585, Valid Loss: 0.6653265953063965\n",
      "Epoch: 8973, Train Loss: 0.3876703381538391, Valid Loss: 0.6633174419403076\n",
      "Epoch: 8974, Train Loss: 0.3876701891422272, Valid Loss: 0.6655107140541077\n",
      "Epoch: 8975, Train Loss: 0.3876701891422272, Valid Loss: 0.6631684303283691\n",
      "Epoch: 8976, Train Loss: 0.3876700699329376, Valid Loss: 0.665662407875061\n",
      "Epoch: 8977, Train Loss: 0.38767021894454956, Valid Loss: 0.6630309820175171\n",
      "Epoch: 8978, Train Loss: 0.3876703977584839, Valid Loss: 0.6658700704574585\n",
      "Epoch: 8979, Train Loss: 0.3876703977584839, Valid Loss: 0.6628562808036804\n",
      "Epoch: 8980, Train Loss: 0.38767051696777344, Valid Loss: 0.6661202311515808\n",
      "Epoch: 8981, Train Loss: 0.3876694440841675, Valid Loss: 0.6625749468803406\n",
      "Epoch: 8982, Train Loss: 0.38767099380493164, Valid Loss: 0.6664509773254395\n",
      "Epoch: 8983, Train Loss: 0.38767141103744507, Valid Loss: 0.6622225046157837\n",
      "Epoch: 8984, Train Loss: 0.3876713514328003, Valid Loss: 0.6669001579284668\n",
      "Epoch: 8985, Train Loss: 0.38767293095588684, Valid Loss: 0.6617326140403748\n",
      "Epoch: 8986, Train Loss: 0.387673020362854, Valid Loss: 0.6675360202789307\n",
      "Epoch: 8987, Train Loss: 0.3876742720603943, Valid Loss: 0.6610140800476074\n",
      "Epoch: 8988, Train Loss: 0.38767561316490173, Valid Loss: 0.6684427857398987\n",
      "Epoch: 8989, Train Loss: 0.38767775893211365, Valid Loss: 0.659939706325531\n",
      "Epoch: 8990, Train Loss: 0.3876809775829315, Valid Loss: 0.6698117256164551\n",
      "Epoch: 8991, Train Loss: 0.38768500089645386, Valid Loss: 0.6583189368247986\n",
      "Epoch: 8992, Train Loss: 0.3876911401748657, Valid Loss: 0.671905517578125\n",
      "Epoch: 8993, Train Loss: 0.38770079612731934, Valid Loss: 0.655845582485199\n",
      "Epoch: 8994, Train Loss: 0.38771411776542664, Valid Loss: 0.6750819683074951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8995, Train Loss: 0.38773486018180847, Valid Loss: 0.652113139629364\n",
      "Epoch: 8996, Train Loss: 0.3877628445625305, Valid Loss: 0.6799247860908508\n",
      "Epoch: 8997, Train Loss: 0.3878084123134613, Valid Loss: 0.6466073393821716\n",
      "Epoch: 8998, Train Loss: 0.38786518573760986, Valid Loss: 0.6870878338813782\n",
      "Epoch: 8999, Train Loss: 0.3879581391811371, Valid Loss: 0.6389495134353638\n",
      "Epoch: 9000, Train Loss: 0.388057142496109, Valid Loss: 0.6968284845352173\n",
      "Epoch: 9001, Train Loss: 0.3882150650024414, Valid Loss: 0.6296966075897217\n",
      "Epoch: 9002, Train Loss: 0.38832712173461914, Valid Loss: 0.7076132893562317\n",
      "Epoch: 9003, Train Loss: 0.3884904086589813, Valid Loss: 0.6219305396080017\n",
      "Epoch: 9004, Train Loss: 0.38848137855529785, Valid Loss: 0.7135106921195984\n",
      "Epoch: 9005, Train Loss: 0.3884630501270294, Valid Loss: 0.622058629989624\n",
      "Epoch: 9006, Train Loss: 0.38823774456977844, Valid Loss: 0.705634593963623\n",
      "Epoch: 9007, Train Loss: 0.3880213797092438, Valid Loss: 0.6350391507148743\n",
      "Epoch: 9008, Train Loss: 0.38780394196510315, Valid Loss: 0.6836223006248474\n",
      "Epoch: 9009, Train Loss: 0.3876897096633911, Valid Loss: 0.6574229598045349\n",
      "Epoch: 9010, Train Loss: 0.38768479228019714, Valid Loss: 0.6589646935462952\n",
      "Epoch: 9011, Train Loss: 0.3877606987953186, Valid Loss: 0.6796896457672119\n",
      "Epoch: 9012, Train Loss: 0.387870728969574, Valid Loss: 0.6420591473579407\n",
      "Epoch: 9013, Train Loss: 0.3879409432411194, Valid Loss: 0.6920483112335205\n",
      "Epoch: 9014, Train Loss: 0.3879671096801758, Valid Loss: 0.6374409198760986\n",
      "Epoch: 9015, Train Loss: 0.38790109753608704, Valid Loss: 0.6893872618675232\n",
      "Epoch: 9016, Train Loss: 0.3878137469291687, Valid Loss: 0.6454780697822571\n",
      "Epoch: 9017, Train Loss: 0.3877231478691101, Valid Loss: 0.6754188537597656\n",
      "Epoch: 9018, Train Loss: 0.38767632842063904, Valid Loss: 0.6605992913246155\n",
      "Epoch: 9019, Train Loss: 0.38767772912979126, Valid Loss: 0.6595834493637085\n",
      "Epoch: 9020, Train Loss: 0.38771316409111023, Valid Loss: 0.6746557354927063\n",
      "Epoch: 9021, Train Loss: 0.3877570927143097, Valid Loss: 0.6493532657623291\n",
      "Epoch: 9022, Train Loss: 0.3877801299095154, Valid Loss: 0.681313693523407\n",
      "Epoch: 9023, Train Loss: 0.3877808749675751, Valid Loss: 0.6476731896400452\n",
      "Epoch: 9024, Train Loss: 0.38775235414505005, Valid Loss: 0.6785571575164795\n",
      "Epoch: 9025, Train Loss: 0.38771602511405945, Valid Loss: 0.6538713574409485\n",
      "Epoch: 9026, Train Loss: 0.3876848518848419, Valid Loss: 0.6695685386657715\n",
      "Epoch: 9027, Train Loss: 0.3876703083515167, Valid Loss: 0.6634570360183716\n",
      "Epoch: 9028, Train Loss: 0.387675017118454, Valid Loss: 0.6600074768066406\n",
      "Epoch: 9029, Train Loss: 0.3876912295818329, Valid Loss: 0.6715318560600281\n",
      "Epoch: 9030, Train Loss: 0.38770902156829834, Valid Loss: 0.6543527841567993\n",
      "Epoch: 9031, Train Loss: 0.38771724700927734, Valid Loss: 0.6749544739723206\n",
      "Epoch: 9032, Train Loss: 0.3877159655094147, Valid Loss: 0.6538164019584656\n",
      "Epoch: 9033, Train Loss: 0.3877032995223999, Valid Loss: 0.6730601787567139\n",
      "Epoch: 9034, Train Loss: 0.38768813014030457, Valid Loss: 0.657406747341156\n",
      "Epoch: 9035, Train Loss: 0.3876759111881256, Valid Loss: 0.668038010597229\n",
      "Epoch: 9036, Train Loss: 0.38766956329345703, Valid Loss: 0.6627979278564453\n",
      "Epoch: 9037, Train Loss: 0.38767051696777344, Valid Loss: 0.662596583366394\n",
      "Epoch: 9038, Train Loss: 0.38767561316490173, Valid Loss: 0.667802631855011\n",
      "Epoch: 9039, Train Loss: 0.38768234848976135, Valid Loss: 0.6587145924568176\n",
      "Epoch: 9040, Train Loss: 0.38768646121025085, Valid Loss: 0.6708247661590576\n",
      "Epoch: 9041, Train Loss: 0.38768815994262695, Valid Loss: 0.6572616100311279\n",
      "Epoch: 9042, Train Loss: 0.38768550753593445, Valid Loss: 0.6708886623382568\n",
      "Epoch: 9043, Train Loss: 0.3876808285713196, Valid Loss: 0.658494770526886\n",
      "Epoch: 9044, Train Loss: 0.387675404548645, Valid Loss: 0.6685047745704651\n",
      "Epoch: 9045, Train Loss: 0.3876711130142212, Valid Loss: 0.6616140007972717\n",
      "Epoch: 9046, Train Loss: 0.3876688778400421, Valid Loss: 0.6650711297988892\n",
      "Epoch: 9047, Train Loss: 0.3876688778400421, Valid Loss: 0.6651493310928345\n",
      "Epoch: 9048, Train Loss: 0.3876705765724182, Valid Loss: 0.6619540452957153\n",
      "Epoch: 9049, Train Loss: 0.38767269253730774, Valid Loss: 0.6676881313323975\n",
      "Epoch: 9050, Train Loss: 0.3876746892929077, Valid Loss: 0.6601409912109375\n",
      "Epoch: 9051, Train Loss: 0.3876758813858032, Valid Loss: 0.6686801314353943\n",
      "Epoch: 9052, Train Loss: 0.38767579197883606, Valid Loss: 0.6599260568618774\n",
      "Epoch: 9053, Train Loss: 0.38767483830451965, Valid Loss: 0.6683281660079956\n",
      "Epoch: 9054, Train Loss: 0.38767293095588684, Valid Loss: 0.6608714461326599\n",
      "Epoch: 9055, Train Loss: 0.3876712918281555, Valid Loss: 0.6670753359794617\n",
      "Epoch: 9056, Train Loss: 0.3876696825027466, Valid Loss: 0.6624126434326172\n",
      "Epoch: 9057, Train Loss: 0.38766834139823914, Valid Loss: 0.6654175519943237\n",
      "Epoch: 9058, Train Loss: 0.3876681625843048, Valid Loss: 0.6640591621398926\n",
      "Epoch: 9059, Train Loss: 0.3876681327819824, Valid Loss: 0.6639163494110107\n",
      "Epoch: 9060, Train Loss: 0.3876684010028839, Valid Loss: 0.6654940843582153\n",
      "Epoch: 9061, Train Loss: 0.3876687288284302, Valid Loss: 0.662822425365448\n",
      "Epoch: 9062, Train Loss: 0.38766974210739136, Valid Loss: 0.6664431691169739\n",
      "Epoch: 9063, Train Loss: 0.3876700699329376, Valid Loss: 0.6621513366699219\n",
      "Epoch: 9064, Train Loss: 0.38767024874687195, Valid Loss: 0.6668782234191895\n",
      "Epoch: 9065, Train Loss: 0.3876703381538391, Valid Loss: 0.6619933843612671\n",
      "Epoch: 9066, Train Loss: 0.3876700699329376, Valid Loss: 0.6668750643730164\n",
      "Epoch: 9067, Train Loss: 0.3876698613166809, Valid Loss: 0.662203848361969\n",
      "Epoch: 9068, Train Loss: 0.3876694142818451, Valid Loss: 0.6666121482849121\n",
      "Epoch: 9069, Train Loss: 0.38767021894454956, Valid Loss: 0.6625767350196838\n",
      "Epoch: 9070, Train Loss: 0.3876688778400421, Valid Loss: 0.6662507057189941\n",
      "Epoch: 9071, Train Loss: 0.38766801357269287, Valid Loss: 0.6629742383956909\n",
      "Epoch: 9072, Train Loss: 0.38766780495643616, Valid Loss: 0.6658377647399902\n",
      "Epoch: 9073, Train Loss: 0.3876678943634033, Valid Loss: 0.6634197235107422\n",
      "Epoch: 9074, Train Loss: 0.3876677453517914, Valid Loss: 0.6654560565948486\n",
      "Epoch: 9075, Train Loss: 0.3876676559448242, Valid Loss: 0.6638679504394531\n",
      "Epoch: 9076, Train Loss: 0.3876675069332123, Valid Loss: 0.6650747656822205\n",
      "Epoch: 9077, Train Loss: 0.38766735792160034, Valid Loss: 0.6642666459083557\n",
      "Epoch: 9078, Train Loss: 0.38766732811927795, Valid Loss: 0.6647423505783081\n",
      "Epoch: 9079, Train Loss: 0.38766729831695557, Valid Loss: 0.6645771861076355\n",
      "Epoch: 9080, Train Loss: 0.3876672387123108, Valid Loss: 0.6645156741142273\n",
      "Epoch: 9081, Train Loss: 0.38766729831695557, Valid Loss: 0.6648125648498535\n",
      "Epoch: 9082, Train Loss: 0.38766714930534363, Valid Loss: 0.6643629670143127\n",
      "Epoch: 9083, Train Loss: 0.38766708970069885, Valid Loss: 0.6649844646453857\n",
      "Epoch: 9084, Train Loss: 0.38766738772392273, Valid Loss: 0.6642226576805115\n",
      "Epoch: 9085, Train Loss: 0.3876670002937317, Valid Loss: 0.6651537418365479\n",
      "Epoch: 9086, Train Loss: 0.38766711950302124, Valid Loss: 0.664063572883606\n",
      "Epoch: 9087, Train Loss: 0.38766738772392273, Valid Loss: 0.6653303503990173\n",
      "Epoch: 9088, Train Loss: 0.38766738772392273, Valid Loss: 0.6639207601547241\n",
      "Epoch: 9089, Train Loss: 0.3876672387123108, Valid Loss: 0.6655204892158508\n",
      "Epoch: 9090, Train Loss: 0.38766708970069885, Valid Loss: 0.6637322902679443\n",
      "Epoch: 9091, Train Loss: 0.38766729831695557, Valid Loss: 0.6657903790473938\n",
      "Epoch: 9092, Train Loss: 0.38766729831695557, Valid Loss: 0.6634290814399719\n",
      "Epoch: 9093, Train Loss: 0.3876681625843048, Valid Loss: 0.6661444902420044\n",
      "Epoch: 9094, Train Loss: 0.38766801357269287, Valid Loss: 0.6630679368972778\n",
      "Epoch: 9095, Train Loss: 0.38766801357269287, Valid Loss: 0.6666189432144165\n",
      "Epoch: 9096, Train Loss: 0.3876686692237854, Valid Loss: 0.6625430583953857\n",
      "Epoch: 9097, Train Loss: 0.38766905665397644, Valid Loss: 0.6672964692115784\n",
      "Epoch: 9098, Train Loss: 0.38766995072364807, Valid Loss: 0.6617196798324585\n",
      "Epoch: 9099, Train Loss: 0.38767215609550476, Valid Loss: 0.6683727502822876\n",
      "Epoch: 9100, Train Loss: 0.38767436146736145, Valid Loss: 0.6604249477386475\n",
      "Epoch: 9101, Train Loss: 0.3876781165599823, Valid Loss: 0.6700621247291565\n",
      "Epoch: 9102, Train Loss: 0.3876838982105255, Valid Loss: 0.6583647727966309\n",
      "Epoch: 9103, Train Loss: 0.38769227266311646, Valid Loss: 0.6727393865585327\n",
      "Epoch: 9104, Train Loss: 0.3877061605453491, Valid Loss: 0.6551514267921448\n",
      "Epoch: 9105, Train Loss: 0.3877258002758026, Valid Loss: 0.6769634485244751\n",
      "Epoch: 9106, Train Loss: 0.3877590596675873, Valid Loss: 0.6501489877700806\n",
      "Epoch: 9107, Train Loss: 0.38780543208122253, Valid Loss: 0.6835927367210388\n",
      "Epoch: 9108, Train Loss: 0.38788318634033203, Valid Loss: 0.6426159739494324\n",
      "Epoch: 9109, Train Loss: 0.3879818916320801, Valid Loss: 0.6936293244361877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9110, Train Loss: 0.3881474733352661, Valid Loss: 0.6321718096733093\n",
      "Epoch: 9111, Train Loss: 0.3883092999458313, Valid Loss: 0.7070391774177551\n",
      "Epoch: 9112, Train Loss: 0.38856393098831177, Valid Loss: 0.6207248568534851\n",
      "Epoch: 9113, Train Loss: 0.38866499066352844, Valid Loss: 0.7191044092178345\n",
      "Epoch: 9114, Train Loss: 0.3887880742549896, Valid Loss: 0.6153209209442139\n",
      "Epoch: 9115, Train Loss: 0.38857102394104004, Valid Loss: 0.7174308896064758\n",
      "Epoch: 9116, Train Loss: 0.3883237838745117, Valid Loss: 0.6254944205284119\n",
      "Epoch: 9117, Train Loss: 0.38796600699424744, Valid Loss: 0.6940335035324097\n",
      "Epoch: 9118, Train Loss: 0.3877430856227875, Valid Loss: 0.6509889364242554\n",
      "Epoch: 9119, Train Loss: 0.38768503069877625, Valid Loss: 0.6622067093849182\n",
      "Epoch: 9120, Train Loss: 0.38777148723602295, Valid Loss: 0.6798838973045349\n",
      "Epoch: 9121, Train Loss: 0.3879290521144867, Valid Loss: 0.6396028995513916\n",
      "Epoch: 9122, Train Loss: 0.3880361020565033, Valid Loss: 0.6972222328186035\n",
      "Epoch: 9123, Train Loss: 0.3880724310874939, Valid Loss: 0.6336351037025452\n",
      "Epoch: 9124, Train Loss: 0.3879593014717102, Valid Loss: 0.693183958530426\n",
      "Epoch: 9125, Train Loss: 0.3878175914287567, Valid Loss: 0.6451157927513123\n",
      "Epoch: 9126, Train Loss: 0.38769951462745667, Valid Loss: 0.6728804111480713\n",
      "Epoch: 9127, Train Loss: 0.3876701593399048, Valid Loss: 0.6656737327575684\n",
      "Epoch: 9128, Train Loss: 0.3877183496952057, Valid Loss: 0.6526365876197815\n",
      "Epoch: 9129, Train Loss: 0.38778847455978394, Valid Loss: 0.6822898983955383\n",
      "Epoch: 9130, Train Loss: 0.38783836364746094, Valid Loss: 0.6438872814178467\n",
      "Epoch: 9131, Train Loss: 0.3878267705440521, Valid Loss: 0.6852626800537109\n",
      "Epoch: 9132, Train Loss: 0.38778069615364075, Valid Loss: 0.6480761170387268\n",
      "Epoch: 9133, Train Loss: 0.38771647214889526, Valid Loss: 0.6744714379310608\n",
      "Epoch: 9134, Train Loss: 0.3876751959323883, Valid Loss: 0.6608546376228333\n",
      "Epoch: 9135, Train Loss: 0.3876723647117615, Valid Loss: 0.6601570844650269\n",
      "Epoch: 9136, Train Loss: 0.3876996338367462, Valid Loss: 0.6733155846595764\n",
      "Epoch: 9137, Train Loss: 0.38773298263549805, Valid Loss: 0.6517601609230042\n",
      "Epoch: 9138, Train Loss: 0.3877459466457367, Valid Loss: 0.6782084107398987\n",
      "Epoch: 9139, Train Loss: 0.3877377212047577, Valid Loss: 0.6518849730491638\n",
      "Epoch: 9140, Train Loss: 0.38770952820777893, Valid Loss: 0.6742788553237915\n",
      "Epoch: 9141, Train Loss: 0.3876815140247345, Valid Loss: 0.6582319140434265\n",
      "Epoch: 9142, Train Loss: 0.3876678943634033, Valid Loss: 0.6654510498046875\n",
      "Epoch: 9143, Train Loss: 0.38767120242118835, Valid Loss: 0.6666738390922546\n",
      "Epoch: 9144, Train Loss: 0.38768547773361206, Valid Loss: 0.6579208374023438\n",
      "Epoch: 9145, Train Loss: 0.38769829273223877, Valid Loss: 0.6727900505065918\n",
      "Epoch: 9146, Train Loss: 0.38770338892936707, Valid Loss: 0.654999852180481\n",
      "Epoch: 9147, Train Loss: 0.387697696685791, Valid Loss: 0.6734269857406616\n",
      "Epoch: 9148, Train Loss: 0.38768693804740906, Valid Loss: 0.6569740772247314\n",
      "Epoch: 9149, Train Loss: 0.38767459988594055, Valid Loss: 0.6688507795333862\n",
      "Epoch: 9150, Train Loss: 0.38766756653785706, Valid Loss: 0.6624864935874939\n",
      "Epoch: 9151, Train Loss: 0.38766732811927795, Valid Loss: 0.662738561630249\n",
      "Epoch: 9152, Train Loss: 0.3876729905605316, Valid Loss: 0.6683627963066101\n",
      "Epoch: 9153, Train Loss: 0.3876790404319763, Valid Loss: 0.65868079662323\n",
      "Epoch: 9154, Train Loss: 0.3876824975013733, Valid Loss: 0.6711012125015259\n",
      "Epoch: 9155, Train Loss: 0.38768208026885986, Valid Loss: 0.6580319404602051\n",
      "Epoch: 9156, Train Loss: 0.3876780569553375, Valid Loss: 0.6698670983314514\n",
      "Epoch: 9157, Train Loss: 0.38767269253730774, Valid Loss: 0.6603279113769531\n",
      "Epoch: 9158, Train Loss: 0.3876681625843048, Valid Loss: 0.6664381623268127\n",
      "Epoch: 9159, Train Loss: 0.3876664936542511, Valid Loss: 0.6641930937767029\n",
      "Epoch: 9160, Train Loss: 0.38766732811927795, Valid Loss: 0.6629987955093384\n",
      "Epoch: 9161, Train Loss: 0.38766908645629883, Valid Loss: 0.6673374772071838\n",
      "Epoch: 9162, Train Loss: 0.38767147064208984, Valid Loss: 0.6607853174209595\n",
      "Epoch: 9163, Train Loss: 0.3876725733280182, Valid Loss: 0.6684784889221191\n",
      "Epoch: 9164, Train Loss: 0.38767287135124207, Valid Loss: 0.6604019999504089\n",
      "Epoch: 9165, Train Loss: 0.3876712918281555, Valid Loss: 0.6680134534835815\n",
      "Epoch: 9166, Train Loss: 0.38766926527023315, Valid Loss: 0.6616619825363159\n",
      "Epoch: 9167, Train Loss: 0.3876674473285675, Valid Loss: 0.6664565205574036\n",
      "Epoch: 9168, Train Loss: 0.3876660466194153, Valid Loss: 0.6636732220649719\n",
      "Epoch: 9169, Train Loss: 0.3876660466194153, Valid Loss: 0.6644880771636963\n",
      "Epoch: 9170, Train Loss: 0.3876664638519287, Valid Loss: 0.665473222732544\n",
      "Epoch: 9171, Train Loss: 0.3876669108867645, Valid Loss: 0.6628875136375427\n",
      "Epoch: 9172, Train Loss: 0.38766735792160034, Valid Loss: 0.6667413115501404\n",
      "Epoch: 9173, Train Loss: 0.387668251991272, Valid Loss: 0.6621153354644775\n",
      "Epoch: 9174, Train Loss: 0.38766810297966003, Valid Loss: 0.6672512888908386\n",
      "Epoch: 9175, Train Loss: 0.3876679837703705, Valid Loss: 0.6622055172920227\n",
      "Epoch: 9176, Train Loss: 0.38766735792160034, Valid Loss: 0.6668345928192139\n",
      "Epoch: 9177, Train Loss: 0.38766705989837646, Valid Loss: 0.6629053354263306\n",
      "Epoch: 9178, Train Loss: 0.3876660168170929, Valid Loss: 0.6658462285995483\n",
      "Epoch: 9179, Train Loss: 0.3876655697822571, Valid Loss: 0.6639859676361084\n",
      "Epoch: 9180, Train Loss: 0.3876652121543884, Valid Loss: 0.664787232875824\n",
      "Epoch: 9181, Train Loss: 0.38766545057296753, Valid Loss: 0.6651385426521301\n",
      "Epoch: 9182, Train Loss: 0.3876655697822571, Valid Loss: 0.6639026403427124\n",
      "Epoch: 9183, Train Loss: 0.3876652419567108, Valid Loss: 0.6658851504325867\n",
      "Epoch: 9184, Train Loss: 0.3876660168170929, Valid Loss: 0.6633633375167847\n",
      "Epoch: 9185, Train Loss: 0.3876658082008362, Valid Loss: 0.6661966443061829\n",
      "Epoch: 9186, Train Loss: 0.3876659572124481, Valid Loss: 0.6632428765296936\n",
      "Epoch: 9187, Train Loss: 0.387666255235672, Valid Loss: 0.6662439703941345\n",
      "Epoch: 9188, Train Loss: 0.38766607642173767, Valid Loss: 0.6634117364883423\n",
      "Epoch: 9189, Train Loss: 0.38766559958457947, Valid Loss: 0.6661075353622437\n",
      "Epoch: 9190, Train Loss: 0.387665718793869, Valid Loss: 0.6636467576026917\n",
      "Epoch: 9191, Train Loss: 0.38766545057296753, Valid Loss: 0.6658308506011963\n",
      "Epoch: 9192, Train Loss: 0.38766518235206604, Valid Loss: 0.6639471650123596\n",
      "Epoch: 9193, Train Loss: 0.3876652717590332, Valid Loss: 0.6655030846595764\n",
      "Epoch: 9194, Train Loss: 0.38766539096832275, Valid Loss: 0.6643570065498352\n",
      "Epoch: 9195, Train Loss: 0.3876647651195526, Valid Loss: 0.6651513576507568\n",
      "Epoch: 9196, Train Loss: 0.3876647651195526, Valid Loss: 0.664771556854248\n",
      "Epoch: 9197, Train Loss: 0.3876652121543884, Valid Loss: 0.6647768616676331\n",
      "Epoch: 9198, Train Loss: 0.3876645267009735, Valid Loss: 0.6651403903961182\n",
      "Epoch: 9199, Train Loss: 0.3876650035381317, Valid Loss: 0.6644306778907776\n",
      "Epoch: 9200, Train Loss: 0.3876648247241974, Valid Loss: 0.6654422283172607\n",
      "Epoch: 9201, Train Loss: 0.38766494393348694, Valid Loss: 0.6642178297042847\n",
      "Epoch: 9202, Train Loss: 0.3876650631427765, Valid Loss: 0.6656810641288757\n",
      "Epoch: 9203, Train Loss: 0.3876650631427765, Valid Loss: 0.6640703082084656\n",
      "Epoch: 9204, Train Loss: 0.38766446709632874, Valid Loss: 0.6658262014389038\n",
      "Epoch: 9205, Train Loss: 0.38766443729400635, Valid Loss: 0.6639564037322998\n",
      "Epoch: 9206, Train Loss: 0.38766470551490784, Valid Loss: 0.6659417748451233\n",
      "Epoch: 9207, Train Loss: 0.38766536116600037, Valid Loss: 0.6638438701629639\n",
      "Epoch: 9208, Train Loss: 0.3876650631427765, Valid Loss: 0.6661320328712463\n",
      "Epoch: 9209, Train Loss: 0.387664794921875, Valid Loss: 0.6636581420898438\n",
      "Epoch: 9210, Train Loss: 0.387664794921875, Valid Loss: 0.6664015054702759\n",
      "Epoch: 9211, Train Loss: 0.3876652717590332, Valid Loss: 0.6634006500244141\n",
      "Epoch: 9212, Train Loss: 0.387665331363678, Valid Loss: 0.6666932702064514\n",
      "Epoch: 9213, Train Loss: 0.38766583800315857, Valid Loss: 0.6630565524101257\n",
      "Epoch: 9214, Train Loss: 0.38766616582870483, Valid Loss: 0.6671342253684998\n",
      "Epoch: 9215, Train Loss: 0.3876664638519287, Valid Loss: 0.6625655889511108\n",
      "Epoch: 9216, Train Loss: 0.38766711950302124, Valid Loss: 0.6677687764167786\n",
      "Epoch: 9217, Train Loss: 0.3876681625843048, Valid Loss: 0.6618505716323853\n",
      "Epoch: 9218, Train Loss: 0.38766929507255554, Valid Loss: 0.6686654090881348\n",
      "Epoch: 9219, Train Loss: 0.3876711428165436, Valid Loss: 0.6608105301856995\n",
      "Epoch: 9220, Train Loss: 0.38767358660697937, Valid Loss: 0.6699432134628296\n",
      "Epoch: 9221, Train Loss: 0.38767820596694946, Valid Loss: 0.6593061089515686\n",
      "Epoch: 9222, Train Loss: 0.38768240809440613, Valid Loss: 0.6718469858169556\n",
      "Epoch: 9223, Train Loss: 0.38769033551216125, Valid Loss: 0.6571087837219238\n",
      "Epoch: 9224, Train Loss: 0.387701153755188, Valid Loss: 0.6746910810470581\n",
      "Epoch: 9225, Train Loss: 0.38771793246269226, Valid Loss: 0.6537786722183228\n",
      "Epoch: 9226, Train Loss: 0.38774049282073975, Valid Loss: 0.6789604425430298\n",
      "Epoch: 9227, Train Loss: 0.38777586817741394, Valid Loss: 0.6488983631134033\n",
      "Epoch: 9228, Train Loss: 0.38782215118408203, Valid Loss: 0.6853132843971252\n",
      "Epoch: 9229, Train Loss: 0.3878971338272095, Valid Loss: 0.641958475112915\n",
      "Epoch: 9230, Train Loss: 0.38798221945762634, Valid Loss: 0.6943052411079407\n",
      "Epoch: 9231, Train Loss: 0.38812074065208435, Valid Loss: 0.6330304145812988\n",
      "Epoch: 9232, Train Loss: 0.38823655247688293, Valid Loss: 0.7051793932914734\n",
      "Epoch: 9233, Train Loss: 0.38841482996940613, Valid Loss: 0.6242882013320923\n",
      "Epoch: 9234, Train Loss: 0.38846254348754883, Valid Loss: 0.7135170102119446\n",
      "Epoch: 9235, Train Loss: 0.3885238766670227, Valid Loss: 0.621199905872345\n",
      "Epoch: 9236, Train Loss: 0.38835835456848145, Valid Loss: 0.7106941342353821\n",
      "Epoch: 9237, Train Loss: 0.38818123936653137, Valid Loss: 0.6299631595611572\n",
      "Epoch: 9238, Train Loss: 0.38792455196380615, Valid Loss: 0.692340075969696\n",
      "Epoch: 9239, Train Loss: 0.38774704933166504, Valid Loss: 0.6500579118728638\n",
      "Epoch: 9240, Train Loss: 0.3876689076423645, Valid Loss: 0.6671283841133118\n",
      "Epoch: 9241, Train Loss: 0.3876955807209015, Valid Loss: 0.6734153032302856\n",
      "Epoch: 9242, Train Loss: 0.3877894878387451, Valid Loss: 0.6470238566398621\n",
      "Epoch: 9243, Train Loss: 0.3878867030143738, Valid Loss: 0.6899402141571045\n",
      "Epoch: 9244, Train Loss: 0.3879575729370117, Valid Loss: 0.6381137371063232\n",
      "Epoch: 9245, Train Loss: 0.3879378139972687, Valid Loss: 0.6923937797546387\n",
      "Epoch: 9246, Train Loss: 0.3878784775733948, Valid Loss: 0.6421552896499634\n",
      "Epoch: 9247, Train Loss: 0.38777920603752136, Valid Loss: 0.6815495491027832\n",
      "Epoch: 9248, Train Loss: 0.3877028822898865, Valid Loss: 0.6554586291313171\n",
      "Epoch: 9249, Train Loss: 0.38766810297966003, Valid Loss: 0.6656339168548584\n",
      "Epoch: 9250, Train Loss: 0.3876783549785614, Valid Loss: 0.6702967882156372\n",
      "Epoch: 9251, Train Loss: 0.3877168297767639, Valid Loss: 0.6531051397323608\n",
      "Epoch: 9252, Train Loss: 0.38775521516799927, Valid Loss: 0.6799848675727844\n",
      "Epoch: 9253, Train Loss: 0.3877783417701721, Valid Loss: 0.6481165885925293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9254, Train Loss: 0.38776856660842896, Valid Loss: 0.68100905418396\n",
      "Epoch: 9255, Train Loss: 0.38774165511131287, Valid Loss: 0.6513050198554993\n",
      "Epoch: 9256, Train Loss: 0.3877033293247223, Valid Loss: 0.6742675304412842\n",
      "Epoch: 9257, Train Loss: 0.3876744508743286, Valid Loss: 0.6597166657447815\n",
      "Epoch: 9258, Train Loss: 0.3876643478870392, Valid Loss: 0.6644272804260254\n",
      "Epoch: 9259, Train Loss: 0.38767141103744507, Valid Loss: 0.6687563061714172\n",
      "Epoch: 9260, Train Loss: 0.3876893222332001, Valid Loss: 0.6568304300308228\n",
      "Epoch: 9261, Train Loss: 0.3877050578594208, Valid Loss: 0.6746467351913452\n",
      "Epoch: 9262, Train Loss: 0.3877127170562744, Valid Loss: 0.6539492011070251\n",
      "Epoch: 9263, Train Loss: 0.3877081274986267, Valid Loss: 0.6751526594161987\n",
      "Epoch: 9264, Train Loss: 0.3876965641975403, Valid Loss: 0.6557134389877319\n",
      "Epoch: 9265, Train Loss: 0.38768187165260315, Valid Loss: 0.6712209582328796\n",
      "Epoch: 9266, Train Loss: 0.38767045736312866, Valid Loss: 0.6605111956596375\n",
      "Epoch: 9267, Train Loss: 0.3876644968986511, Valid Loss: 0.6656827330589294\n",
      "Epoch: 9268, Train Loss: 0.3876652717590332, Valid Loss: 0.6660948991775513\n",
      "Epoch: 9269, Train Loss: 0.38767051696777344, Valid Loss: 0.6608293652534485\n",
      "Epoch: 9270, Train Loss: 0.3876766860485077, Valid Loss: 0.6703221201896667\n",
      "Epoch: 9271, Train Loss: 0.38768118619918823, Valid Loss: 0.6580461859703064\n",
      "Epoch: 9272, Train Loss: 0.38768258690834045, Valid Loss: 0.6718094348907471\n",
      "Epoch: 9273, Train Loss: 0.3876807391643524, Valid Loss: 0.6580050587654114\n",
      "Epoch: 9274, Train Loss: 0.3876754641532898, Valid Loss: 0.6704552173614502\n",
      "Epoch: 9275, Train Loss: 0.3876706063747406, Valid Loss: 0.6603963971138\n",
      "Epoch: 9276, Train Loss: 0.3876661956310272, Valid Loss: 0.667448103427887\n",
      "Epoch: 9277, Train Loss: 0.387663871049881, Valid Loss: 0.6638486981391907\n",
      "Epoch: 9278, Train Loss: 0.3876635432243347, Valid Loss: 0.6641051769256592\n",
      "Epoch: 9279, Train Loss: 0.3876650035381317, Valid Loss: 0.6668261885643005\n",
      "Epoch: 9280, Train Loss: 0.3876669108867645, Valid Loss: 0.6616389751434326\n",
      "Epoch: 9281, Train Loss: 0.38766875863075256, Valid Loss: 0.6685605645179749\n",
      "Epoch: 9282, Train Loss: 0.3876698911190033, Valid Loss: 0.6606771945953369\n",
      "Epoch: 9283, Train Loss: 0.38767024874687195, Valid Loss: 0.6689419746398926\n",
      "Epoch: 9284, Train Loss: 0.3876698315143585, Valid Loss: 0.6609345078468323\n",
      "Epoch: 9285, Train Loss: 0.3876684010028839, Valid Loss: 0.668331503868103\n",
      "Epoch: 9286, Train Loss: 0.38766661286354065, Valid Loss: 0.6619229316711426\n",
      "Epoch: 9287, Train Loss: 0.3876650631427765, Valid Loss: 0.6670918464660645\n",
      "Epoch: 9288, Train Loss: 0.3876642882823944, Valid Loss: 0.6632933616638184\n",
      "Epoch: 9289, Train Loss: 0.38766345381736755, Valid Loss: 0.6656696796417236\n",
      "Epoch: 9290, Train Loss: 0.3876631557941437, Valid Loss: 0.6647791862487793\n",
      "Epoch: 9291, Train Loss: 0.387663334608078, Valid Loss: 0.6643857359886169\n",
      "Epoch: 9292, Train Loss: 0.38766348361968994, Valid Loss: 0.6660551428794861\n",
      "Epoch: 9293, Train Loss: 0.38766416907310486, Valid Loss: 0.6633268594741821\n",
      "Epoch: 9294, Train Loss: 0.38766470551490784, Valid Loss: 0.6669292449951172\n",
      "Epoch: 9295, Train Loss: 0.3876648545265198, Valid Loss: 0.6627011895179749\n",
      "Epoch: 9296, Train Loss: 0.3876650929450989, Valid Loss: 0.6673547625541687\n",
      "Epoch: 9297, Train Loss: 0.38766515254974365, Valid Loss: 0.6625478863716125\n",
      "Epoch: 9298, Train Loss: 0.38766494393348694, Valid Loss: 0.6673970222473145\n",
      "Epoch: 9299, Train Loss: 0.3876648545265198, Valid Loss: 0.6626824736595154\n",
      "Epoch: 9300, Train Loss: 0.38766491413116455, Valid Loss: 0.6672143340110779\n",
      "Epoch: 9301, Train Loss: 0.3876650631427765, Valid Loss: 0.6629600524902344\n",
      "Epoch: 9302, Train Loss: 0.3876640200614929, Valid Loss: 0.6668922901153564\n",
      "Epoch: 9303, Train Loss: 0.38766372203826904, Valid Loss: 0.6633341908454895\n",
      "Epoch: 9304, Train Loss: 0.38766297698020935, Valid Loss: 0.666543185710907\n",
      "Epoch: 9305, Train Loss: 0.38766297698020935, Valid Loss: 0.6637495160102844\n",
      "Epoch: 9306, Train Loss: 0.38766300678253174, Valid Loss: 0.6661943197250366\n",
      "Epoch: 9307, Train Loss: 0.3876629173755646, Valid Loss: 0.6641381978988647\n",
      "Epoch: 9308, Train Loss: 0.38766273856163025, Valid Loss: 0.665855884552002\n",
      "Epoch: 9309, Train Loss: 0.3876626193523407, Valid Loss: 0.664469838142395\n",
      "Epoch: 9310, Train Loss: 0.38766270875930786, Valid Loss: 0.6655885577201843\n",
      "Epoch: 9311, Train Loss: 0.3876623511314392, Valid Loss: 0.6647500395774841\n",
      "Epoch: 9312, Train Loss: 0.3876621127128601, Valid Loss: 0.6653895378112793\n",
      "Epoch: 9313, Train Loss: 0.3876621127128601, Valid Loss: 0.6649678945541382\n",
      "Epoch: 9314, Train Loss: 0.3876621425151825, Valid Loss: 0.6652207374572754\n",
      "Epoch: 9315, Train Loss: 0.38766205310821533, Valid Loss: 0.6651384234428406\n",
      "Epoch: 9316, Train Loss: 0.3876623511314392, Valid Loss: 0.6650764346122742\n",
      "Epoch: 9317, Train Loss: 0.3876621127128601, Valid Loss: 0.6652963161468506\n",
      "Epoch: 9318, Train Loss: 0.3876625597476959, Valid Loss: 0.6649467349052429\n",
      "Epoch: 9319, Train Loss: 0.3876616358757019, Valid Loss: 0.665444016456604\n",
      "Epoch: 9320, Train Loss: 0.3876619338989258, Valid Loss: 0.6648411750793457\n",
      "Epoch: 9321, Train Loss: 0.3876619338989258, Valid Loss: 0.6656004190444946\n",
      "Epoch: 9322, Train Loss: 0.387661874294281, Valid Loss: 0.6647067070007324\n",
      "Epoch: 9323, Train Loss: 0.38766196370124817, Valid Loss: 0.6657586693763733\n",
      "Epoch: 9324, Train Loss: 0.38766172528266907, Valid Loss: 0.6645472049713135\n",
      "Epoch: 9325, Train Loss: 0.387661874294281, Valid Loss: 0.6659805178642273\n",
      "Epoch: 9326, Train Loss: 0.38766199350357056, Valid Loss: 0.6643175482749939\n",
      "Epoch: 9327, Train Loss: 0.38766229152679443, Valid Loss: 0.6662853956222534\n",
      "Epoch: 9328, Train Loss: 0.38766220211982727, Valid Loss: 0.6639865040779114\n",
      "Epoch: 9329, Train Loss: 0.3876625597476959, Valid Loss: 0.666731595993042\n",
      "Epoch: 9330, Train Loss: 0.38766297698020935, Valid Loss: 0.663471519947052\n",
      "Epoch: 9331, Train Loss: 0.38766348361968994, Valid Loss: 0.6673908233642578\n",
      "Epoch: 9332, Train Loss: 0.3876642882823944, Valid Loss: 0.6626448035240173\n",
      "Epoch: 9333, Train Loss: 0.3876657485961914, Valid Loss: 0.668495774269104\n",
      "Epoch: 9334, Train Loss: 0.38766753673553467, Valid Loss: 0.661297619342804\n",
      "Epoch: 9335, Train Loss: 0.38767147064208984, Valid Loss: 0.6702789068222046\n",
      "Epoch: 9336, Train Loss: 0.3876774311065674, Valid Loss: 0.6591057777404785\n",
      "Epoch: 9337, Train Loss: 0.387686550617218, Valid Loss: 0.6731515526771545\n",
      "Epoch: 9338, Train Loss: 0.38770121335983276, Valid Loss: 0.6555740237236023\n",
      "Epoch: 9339, Train Loss: 0.38772347569465637, Valid Loss: 0.6778472065925598\n",
      "Epoch: 9340, Train Loss: 0.38776227831840515, Valid Loss: 0.6499366760253906\n",
      "Epoch: 9341, Train Loss: 0.38781848549842834, Valid Loss: 0.6855085492134094\n",
      "Epoch: 9342, Train Loss: 0.3879185616970062, Valid Loss: 0.6411293148994446\n",
      "Epoch: 9343, Train Loss: 0.38804689049720764, Valid Loss: 0.6975558400154114\n",
      "Epoch: 9344, Train Loss: 0.3882724642753601, Valid Loss: 0.6286236643791199\n",
      "Epoch: 9345, Train Loss: 0.38849014043807983, Valid Loss: 0.7139726877212524\n",
      "Epoch: 9346, Train Loss: 0.38883596658706665, Valid Loss: 0.6152392029762268\n",
      "Epoch: 9347, Train Loss: 0.3889296352863312, Valid Loss: 0.7274987697601318\n",
      "Epoch: 9348, Train Loss: 0.38901686668395996, Valid Loss: 0.6113474369049072\n",
      "Epoch: 9349, Train Loss: 0.38862454891204834, Valid Loss: 0.7201611399650574\n",
      "Epoch: 9350, Train Loss: 0.38822320103645325, Valid Loss: 0.6286680698394775\n",
      "Epoch: 9351, Train Loss: 0.3878263533115387, Valid Loss: 0.6861897110939026\n",
      "Epoch: 9352, Train Loss: 0.38767924904823303, Valid Loss: 0.6621227264404297\n",
      "Epoch: 9353, Train Loss: 0.38776952028274536, Valid Loss: 0.6494964361190796\n",
      "Epoch: 9354, Train Loss: 0.3879743814468384, Valid Loss: 0.6938775777816772\n",
      "Epoch: 9355, Train Loss: 0.3881679177284241, Valid Loss: 0.6308721303939819\n",
      "Epoch: 9356, Train Loss: 0.38815590739250183, Valid Loss: 0.7033630609512329\n",
      "Epoch: 9357, Train Loss: 0.38803359866142273, Valid Loss: 0.6359818577766418\n",
      "Epoch: 9358, Train Loss: 0.387816846370697, Valid Loss: 0.6847134232521057\n",
      "Epoch: 9359, Train Loss: 0.387682169675827, Valid Loss: 0.6584148406982422\n",
      "Epoch: 9360, Train Loss: 0.3876803517341614, Valid Loss: 0.6569139957427979\n",
      "Epoch: 9361, Train Loss: 0.38777878880500793, Valid Loss: 0.6812798380851746\n",
      "Epoch: 9362, Train Loss: 0.38788914680480957, Valid Loss: 0.6414577960968018\n",
      "Epoch: 9363, Train Loss: 0.3879035711288452, Valid Loss: 0.6903899908065796\n",
      "Epoch: 9364, Train Loss: 0.38784539699554443, Valid Loss: 0.6446184515953064\n",
      "Epoch: 9365, Train Loss: 0.38774144649505615, Valid Loss: 0.6791837811470032\n",
      "Epoch: 9366, Train Loss: 0.3876756727695465, Valid Loss: 0.6599251627922058\n",
      "Epoch: 9367, Train Loss: 0.3876740634441376, Valid Loss: 0.6591037511825562\n",
      "Epoch: 9368, Train Loss: 0.38772088289260864, Valid Loss: 0.6761922240257263\n",
      "Epoch: 9369, Train Loss: 0.38777509331703186, Valid Loss: 0.6477227210998535\n",
      "Epoch: 9370, Train Loss: 0.387783408164978, Valid Loss: 0.6823321580886841\n",
      "Epoch: 9371, Train Loss: 0.38775017857551575, Valid Loss: 0.6509162187576294\n",
      "Epoch: 9372, Train Loss: 0.3876979947090149, Valid Loss: 0.6745285987854004\n",
      "Epoch: 9373, Train Loss: 0.3876674473285675, Valid Loss: 0.6618000268936157\n",
      "Epoch: 9374, Train Loss: 0.38766956329345703, Valid Loss: 0.6605428457260132\n",
      "Epoch: 9375, Train Loss: 0.3876937925815582, Valid Loss: 0.6725180745124817\n",
      "Epoch: 9376, Train Loss: 0.3877192437648773, Valid Loss: 0.6526117920875549\n",
      "Epoch: 9377, Train Loss: 0.38772374391555786, Valid Loss: 0.6769232749938965\n",
      "Epoch: 9378, Train Loss: 0.38770875334739685, Valid Loss: 0.6544292569160461\n",
      "Epoch: 9379, Train Loss: 0.38768279552459717, Valid Loss: 0.672492265701294\n",
      "Epoch: 9380, Train Loss: 0.3876657485961914, Valid Loss: 0.661777675151825\n",
      "Epoch: 9381, Train Loss: 0.3876647651195526, Valid Loss: 0.6627506017684937\n",
      "Epoch: 9382, Train Loss: 0.38767489790916443, Valid Loss: 0.6694795489311218\n",
      "Epoch: 9383, Train Loss: 0.3876878619194031, Valid Loss: 0.6560596227645874\n",
      "Epoch: 9384, Train Loss: 0.3876933455467224, Valid Loss: 0.6738556027412415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9385, Train Loss: 0.38768863677978516, Valid Loss: 0.6567927002906799\n",
      "Epoch: 9386, Train Loss: 0.3876761496067047, Valid Loss: 0.6712997555732727\n",
      "Epoch: 9387, Train Loss: 0.38766589760780334, Valid Loss: 0.6617678999900818\n",
      "Epoch: 9388, Train Loss: 0.38766229152679443, Valid Loss: 0.6644822955131531\n",
      "Epoch: 9389, Train Loss: 0.3876652121543884, Valid Loss: 0.667369544506073\n",
      "Epoch: 9390, Train Loss: 0.38767164945602417, Valid Loss: 0.6594153046607971\n",
      "Epoch: 9391, Train Loss: 0.3876761496067047, Valid Loss: 0.6708493232727051\n",
      "Epoch: 9392, Train Loss: 0.3876761496067047, Valid Loss: 0.6589053273200989\n",
      "Epoch: 9393, Train Loss: 0.38767221570014954, Valid Loss: 0.6703407764434814\n",
      "Epoch: 9394, Train Loss: 0.38766688108444214, Valid Loss: 0.661465048789978\n",
      "Epoch: 9395, Train Loss: 0.38766270875930786, Valid Loss: 0.6663006544113159\n",
      "Epoch: 9396, Train Loss: 0.38766205310821533, Valid Loss: 0.6649823784828186\n",
      "Epoch: 9397, Train Loss: 0.38766366243362427, Valid Loss: 0.662384033203125\n",
      "Epoch: 9398, Train Loss: 0.3876664638519287, Valid Loss: 0.6682172417640686\n",
      "Epoch: 9399, Train Loss: 0.38766831159591675, Valid Loss: 0.6608335971832275\n",
      "Epoch: 9400, Train Loss: 0.3876686096191406, Valid Loss: 0.6693207025527954\n",
      "Epoch: 9401, Train Loss: 0.3876669704914093, Valid Loss: 0.6613906025886536\n",
      "Epoch: 9402, Train Loss: 0.387664258480072, Valid Loss: 0.6676194071769714\n",
      "Epoch: 9403, Train Loss: 0.3876623809337616, Valid Loss: 0.6632801294326782\n",
      "Epoch: 9404, Train Loss: 0.3876613974571228, Valid Loss: 0.6649492383003235\n",
      "Epoch: 9405, Train Loss: 0.38766157627105713, Valid Loss: 0.6658411622047424\n",
      "Epoch: 9406, Train Loss: 0.3876630365848541, Valid Loss: 0.6631759405136108\n",
      "Epoch: 9407, Train Loss: 0.38766369223594666, Valid Loss: 0.6676607728004456\n",
      "Epoch: 9408, Train Loss: 0.38766446709632874, Valid Loss: 0.6623451113700867\n",
      "Epoch: 9409, Train Loss: 0.3876641094684601, Valid Loss: 0.6677793264389038\n",
      "Epoch: 9410, Train Loss: 0.38766345381736755, Valid Loss: 0.6626062989234924\n",
      "Epoch: 9411, Train Loss: 0.38766223192214966, Valid Loss: 0.6666861176490784\n",
      "Epoch: 9412, Train Loss: 0.3876613676548004, Valid Loss: 0.6639633774757385\n",
      "Epoch: 9413, Train Loss: 0.38766106963157654, Valid Loss: 0.665327250957489\n",
      "Epoch: 9414, Train Loss: 0.3876608908176422, Valid Loss: 0.665711522102356\n",
      "Epoch: 9415, Train Loss: 0.38766130805015564, Valid Loss: 0.6640530228614807\n",
      "Epoch: 9416, Train Loss: 0.3876618444919586, Valid Loss: 0.6667091250419617\n",
      "Epoch: 9417, Train Loss: 0.3876619040966034, Valid Loss: 0.663219153881073\n",
      "Epoch: 9418, Train Loss: 0.38766247034072876, Valid Loss: 0.6669182777404785\n",
      "Epoch: 9419, Train Loss: 0.38766220211982727, Valid Loss: 0.6633982062339783\n",
      "Epoch: 9420, Train Loss: 0.38766154646873474, Valid Loss: 0.6666201949119568\n",
      "Epoch: 9421, Train Loss: 0.3876616060733795, Valid Loss: 0.664151132106781\n",
      "Epoch: 9422, Train Loss: 0.38766035437583923, Valid Loss: 0.665954053401947\n",
      "Epoch: 9423, Train Loss: 0.38766080141067505, Valid Loss: 0.6649082899093628\n",
      "Epoch: 9424, Train Loss: 0.3876606822013855, Valid Loss: 0.6651249527931213\n",
      "Epoch: 9425, Train Loss: 0.38766077160835266, Valid Loss: 0.6655462384223938\n",
      "Epoch: 9426, Train Loss: 0.3876606822013855, Valid Loss: 0.6645246148109436\n",
      "Epoch: 9427, Train Loss: 0.3876606523990631, Valid Loss: 0.6661373972892761\n",
      "Epoch: 9428, Train Loss: 0.38766101002693176, Valid Loss: 0.6643005609512329\n",
      "Epoch: 9429, Train Loss: 0.38766106963157654, Valid Loss: 0.6663508415222168\n",
      "Epoch: 9430, Train Loss: 0.3876607120037079, Valid Loss: 0.6642543077468872\n",
      "Epoch: 9431, Train Loss: 0.3876606822013855, Valid Loss: 0.6662126779556274\n",
      "Epoch: 9432, Train Loss: 0.38766083121299744, Valid Loss: 0.6644089221954346\n",
      "Epoch: 9433, Train Loss: 0.3876604735851288, Valid Loss: 0.6659437417984009\n",
      "Epoch: 9434, Train Loss: 0.38766056299209595, Valid Loss: 0.6647941470146179\n",
      "Epoch: 9435, Train Loss: 0.38766029477119446, Valid Loss: 0.6656853556632996\n",
      "Epoch: 9436, Train Loss: 0.3876602053642273, Valid Loss: 0.6651830077171326\n",
      "Epoch: 9437, Train Loss: 0.38766005635261536, Valid Loss: 0.6653263568878174\n",
      "Epoch: 9438, Train Loss: 0.3876601755619049, Valid Loss: 0.6654584407806396\n",
      "Epoch: 9439, Train Loss: 0.3876602053642273, Valid Loss: 0.6650271415710449\n",
      "Epoch: 9440, Train Loss: 0.38766002655029297, Valid Loss: 0.665723443031311\n",
      "Epoch: 9441, Train Loss: 0.3876603841781616, Valid Loss: 0.6648870706558228\n",
      "Epoch: 9442, Train Loss: 0.3876601755619049, Valid Loss: 0.6659117937088013\n",
      "Epoch: 9443, Train Loss: 0.3876599967479706, Valid Loss: 0.6648277044296265\n",
      "Epoch: 9444, Train Loss: 0.38766005635261536, Valid Loss: 0.6659559011459351\n",
      "Epoch: 9445, Train Loss: 0.38765987753868103, Valid Loss: 0.6648184061050415\n",
      "Epoch: 9446, Train Loss: 0.38766002655029297, Valid Loss: 0.6658892631530762\n",
      "Epoch: 9447, Train Loss: 0.3876597285270691, Valid Loss: 0.6648783683776855\n",
      "Epoch: 9448, Train Loss: 0.3876597285270691, Valid Loss: 0.6658856272697449\n",
      "Epoch: 9449, Train Loss: 0.3876597285270691, Valid Loss: 0.664976179599762\n",
      "Epoch: 9450, Train Loss: 0.3876599669456482, Valid Loss: 0.6658470034599304\n",
      "Epoch: 9451, Train Loss: 0.38765981793403625, Valid Loss: 0.6650222539901733\n",
      "Epoch: 9452, Train Loss: 0.3876599073410034, Valid Loss: 0.6658085584640503\n",
      "Epoch: 9453, Train Loss: 0.38765889406204224, Valid Loss: 0.6650340557098389\n",
      "Epoch: 9454, Train Loss: 0.3876594603061676, Valid Loss: 0.6658152937889099\n",
      "Epoch: 9455, Train Loss: 0.3876601755619049, Valid Loss: 0.6650664806365967\n",
      "Epoch: 9456, Train Loss: 0.3876596987247467, Valid Loss: 0.6658473014831543\n",
      "Epoch: 9457, Train Loss: 0.38765949010849, Valid Loss: 0.6650726795196533\n",
      "Epoch: 9458, Train Loss: 0.38765960931777954, Valid Loss: 0.6658583283424377\n",
      "Epoch: 9459, Train Loss: 0.38765960931777954, Valid Loss: 0.6650352478027344\n",
      "Epoch: 9460, Train Loss: 0.38765937089920044, Valid Loss: 0.6659080982208252\n",
      "Epoch: 9461, Train Loss: 0.3876596689224243, Valid Loss: 0.6650000810623169\n",
      "Epoch: 9462, Train Loss: 0.3876594603061676, Valid Loss: 0.6660096645355225\n",
      "Epoch: 9463, Train Loss: 0.3876595199108124, Valid Loss: 0.6649117469787598\n",
      "Epoch: 9464, Train Loss: 0.38765931129455566, Valid Loss: 0.6661614179611206\n",
      "Epoch: 9465, Train Loss: 0.3876595199108124, Valid Loss: 0.6647306084632874\n",
      "Epoch: 9466, Train Loss: 0.38765963912010193, Valid Loss: 0.6663826107978821\n",
      "Epoch: 9467, Train Loss: 0.3876596689224243, Valid Loss: 0.6644801497459412\n",
      "Epoch: 9468, Train Loss: 0.38765957951545715, Valid Loss: 0.6667047142982483\n",
      "Epoch: 9469, Train Loss: 0.38765984773635864, Valid Loss: 0.6641488671302795\n",
      "Epoch: 9470, Train Loss: 0.3876602053642273, Valid Loss: 0.6671241521835327\n",
      "Epoch: 9471, Train Loss: 0.3876601755619049, Valid Loss: 0.6636773943901062\n",
      "Epoch: 9472, Train Loss: 0.3876609206199646, Valid Loss: 0.6677404642105103\n",
      "Epoch: 9473, Train Loss: 0.38766202330589294, Valid Loss: 0.6629071235656738\n",
      "Epoch: 9474, Train Loss: 0.38766294717788696, Valid Loss: 0.668723464012146\n",
      "Epoch: 9475, Train Loss: 0.38766470551490784, Valid Loss: 0.661712110042572\n",
      "Epoch: 9476, Train Loss: 0.3876679539680481, Valid Loss: 0.6702766418457031\n",
      "Epoch: 9477, Train Loss: 0.38767269253730774, Valid Loss: 0.659848690032959\n",
      "Epoch: 9478, Train Loss: 0.38767918944358826, Valid Loss: 0.6727197766304016\n",
      "Epoch: 9479, Train Loss: 0.38769108057022095, Valid Loss: 0.6568663120269775\n",
      "Epoch: 9480, Train Loss: 0.3877078890800476, Valid Loss: 0.6766360402107239\n",
      "Epoch: 9481, Train Loss: 0.3877358138561249, Valid Loss: 0.6521949172019958\n",
      "Epoch: 9482, Train Loss: 0.3877762258052826, Valid Loss: 0.6828858852386475\n",
      "Epoch: 9483, Train Loss: 0.3878459632396698, Valid Loss: 0.6449944376945496\n",
      "Epoch: 9484, Train Loss: 0.3879367709159851, Valid Loss: 0.6926430463790894\n",
      "Epoch: 9485, Train Loss: 0.3880942463874817, Valid Loss: 0.634570837020874\n",
      "Epoch: 9486, Train Loss: 0.3882609009742737, Valid Loss: 0.7064737677574158\n",
      "Epoch: 9487, Train Loss: 0.3885352909564972, Valid Loss: 0.6221191883087158\n",
      "Epoch: 9488, Train Loss: 0.3886866867542267, Valid Loss: 0.7208327651023865\n",
      "Epoch: 9489, Train Loss: 0.38889285922050476, Valid Loss: 0.6140505075454712\n",
      "Epoch: 9490, Train Loss: 0.3887232542037964, Valid Loss: 0.7230873703956604\n",
      "Epoch: 9491, Train Loss: 0.3885098099708557, Valid Loss: 0.621445894241333\n",
      "Epoch: 9492, Train Loss: 0.38808727264404297, Valid Loss: 0.7012040615081787\n",
      "Epoch: 9493, Train Loss: 0.38778725266456604, Valid Loss: 0.6469081044197083\n",
      "Epoch: 9494, Train Loss: 0.38766539096832275, Valid Loss: 0.6662731766700745\n",
      "Epoch: 9495, Train Loss: 0.38773438334465027, Valid Loss: 0.6786924004554749\n",
      "Epoch: 9496, Train Loss: 0.38791412115097046, Valid Loss: 0.6399964094161987\n",
      "Epoch: 9497, Train Loss: 0.38805657625198364, Valid Loss: 0.6995548009872437\n",
      "Epoch: 9498, Train Loss: 0.3881186544895172, Valid Loss: 0.6324898600578308\n",
      "Epoch: 9499, Train Loss: 0.38800033926963806, Valid Loss: 0.6962994933128357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9500, Train Loss: 0.38784512877464294, Valid Loss: 0.644713282585144\n",
      "Epoch: 9501, Train Loss: 0.38770583271980286, Valid Loss: 0.6744884252548218\n",
      "Epoch: 9502, Train Loss: 0.3876632750034332, Valid Loss: 0.6664178967475891\n",
      "Epoch: 9503, Train Loss: 0.3877117931842804, Valid Loss: 0.6528176069259644\n",
      "Epoch: 9504, Train Loss: 0.38779371976852417, Valid Loss: 0.6833812594413757\n",
      "Epoch: 9505, Train Loss: 0.3878563642501831, Valid Loss: 0.6438741087913513\n",
      "Epoch: 9506, Train Loss: 0.3878422975540161, Valid Loss: 0.6867378950119019\n",
      "Epoch: 9507, Train Loss: 0.3877837657928467, Valid Loss: 0.6487889289855957\n",
      "Epoch: 9508, Train Loss: 0.3877076208591461, Valid Loss: 0.6756243705749512\n",
      "Epoch: 9509, Train Loss: 0.3876655697822571, Valid Loss: 0.6618622541427612\n",
      "Epoch: 9510, Train Loss: 0.3876700699329376, Valid Loss: 0.6599306464195251\n",
      "Epoch: 9511, Train Loss: 0.38770633935928345, Valid Loss: 0.6749809980392456\n",
      "Epoch: 9512, Train Loss: 0.387745201587677, Valid Loss: 0.6507462859153748\n",
      "Epoch: 9513, Train Loss: 0.3877532184123993, Valid Loss: 0.6805665493011475\n",
      "Epoch: 9514, Train Loss: 0.3877342939376831, Valid Loss: 0.6520208120346069\n",
      "Epoch: 9515, Train Loss: 0.38769546151161194, Valid Loss: 0.6751226186752319\n",
      "Epoch: 9516, Train Loss: 0.38766759634017944, Valid Loss: 0.6601831912994385\n",
      "Epoch: 9517, Train Loss: 0.3876619040966034, Valid Loss: 0.6636987924575806\n",
      "Epoch: 9518, Train Loss: 0.3876737654209137, Valid Loss: 0.6699305176734924\n",
      "Epoch: 9519, Train Loss: 0.3876911401748657, Valid Loss: 0.6558012366294861\n",
      "Epoch: 9520, Train Loss: 0.3877027928829193, Valid Loss: 0.6756365299224854\n",
      "Epoch: 9521, Train Loss: 0.3877026438713074, Valid Loss: 0.6549135446548462\n",
      "Epoch: 9522, Train Loss: 0.3876890242099762, Valid Loss: 0.6740205883979797\n",
      "Epoch: 9523, Train Loss: 0.387673020362854, Valid Loss: 0.6591982841491699\n",
      "Epoch: 9524, Train Loss: 0.3876611888408661, Valid Loss: 0.6671005487442017\n",
      "Epoch: 9525, Train Loss: 0.3876602351665497, Valid Loss: 0.6657534241676331\n",
      "Epoch: 9526, Train Loss: 0.38766711950302124, Valid Loss: 0.6604921817779541\n",
      "Epoch: 9527, Train Loss: 0.38767480850219727, Valid Loss: 0.6714479327201843\n",
      "Epoch: 9528, Train Loss: 0.38767972588539124, Valid Loss: 0.6580225229263306\n",
      "Epoch: 9529, Train Loss: 0.3876783549785614, Valid Loss: 0.6725118160247803\n",
      "Epoch: 9530, Train Loss: 0.3876729905605316, Valid Loss: 0.6593221426010132\n",
      "Epoch: 9531, Train Loss: 0.3876660466194153, Valid Loss: 0.668977677822113\n",
      "Epoch: 9532, Train Loss: 0.3876607418060303, Valid Loss: 0.6632155776023865\n",
      "Epoch: 9533, Train Loss: 0.38765934109687805, Valid Loss: 0.6643205881118774\n",
      "Epoch: 9534, Train Loss: 0.3876614272594452, Valid Loss: 0.667592465877533\n",
      "Epoch: 9535, Train Loss: 0.38766494393348694, Valid Loss: 0.6613791584968567\n",
      "Epoch: 9536, Train Loss: 0.38766732811927795, Valid Loss: 0.6699342131614685\n",
      "Epoch: 9537, Train Loss: 0.3876681625843048, Valid Loss: 0.6606162190437317\n",
      "Epoch: 9538, Train Loss: 0.3876667618751526, Valid Loss: 0.6693505048751831\n",
      "Epoch: 9539, Train Loss: 0.38766372203826904, Valid Loss: 0.6616189479827881\n",
      "Epoch: 9540, Train Loss: 0.3876608908176422, Valid Loss: 0.667315661907196\n",
      "Epoch: 9541, Train Loss: 0.3876589834690094, Valid Loss: 0.6640717387199402\n",
      "Epoch: 9542, Train Loss: 0.3876575827598572, Valid Loss: 0.6650769710540771\n",
      "Epoch: 9543, Train Loss: 0.38765889406204224, Valid Loss: 0.6666496992111206\n",
      "Epoch: 9544, Train Loss: 0.3876609802246094, Valid Loss: 0.6630551815032959\n",
      "Epoch: 9545, Train Loss: 0.3876621127128601, Valid Loss: 0.6681323051452637\n",
      "Epoch: 9546, Train Loss: 0.38766223192214966, Valid Loss: 0.6620364189147949\n",
      "Epoch: 9547, Train Loss: 0.38766205310821533, Valid Loss: 0.6682807803153992\n",
      "Epoch: 9548, Train Loss: 0.38766154646873474, Valid Loss: 0.6625614762306213\n",
      "Epoch: 9549, Train Loss: 0.38765960931777954, Valid Loss: 0.6674072742462158\n",
      "Epoch: 9550, Train Loss: 0.3876589834690094, Valid Loss: 0.6641305685043335\n",
      "Epoch: 9551, Train Loss: 0.38765856623649597, Valid Loss: 0.665860116481781\n",
      "Epoch: 9552, Train Loss: 0.38765856623649597, Valid Loss: 0.6656590104103088\n",
      "Epoch: 9553, Train Loss: 0.38765862584114075, Valid Loss: 0.6643561720848083\n",
      "Epoch: 9554, Train Loss: 0.3876592516899109, Valid Loss: 0.6667182445526123\n",
      "Epoch: 9555, Train Loss: 0.3876591622829437, Valid Loss: 0.6636466383934021\n",
      "Epoch: 9556, Train Loss: 0.3876594305038452, Valid Loss: 0.6672335863113403\n",
      "Epoch: 9557, Train Loss: 0.3876597583293915, Valid Loss: 0.6636080741882324\n",
      "Epoch: 9558, Train Loss: 0.38766005635261536, Valid Loss: 0.6672056317329407\n",
      "Epoch: 9559, Train Loss: 0.38765913248062134, Valid Loss: 0.66388338804245\n",
      "Epoch: 9560, Train Loss: 0.38765889406204224, Valid Loss: 0.6666842103004456\n",
      "Epoch: 9561, Train Loss: 0.3876584768295288, Valid Loss: 0.66441810131073\n",
      "Epoch: 9562, Train Loss: 0.38765838742256165, Valid Loss: 0.6660671234130859\n",
      "Epoch: 9563, Train Loss: 0.38765791058540344, Valid Loss: 0.6651723980903625\n",
      "Epoch: 9564, Train Loss: 0.38765794038772583, Valid Loss: 0.6654736399650574\n",
      "Epoch: 9565, Train Loss: 0.3876578211784363, Valid Loss: 0.6658895611763\n",
      "Epoch: 9566, Train Loss: 0.38765811920166016, Valid Loss: 0.6648662090301514\n",
      "Epoch: 9567, Train Loss: 0.38765811920166016, Valid Loss: 0.666378378868103\n",
      "Epoch: 9568, Train Loss: 0.3876577615737915, Valid Loss: 0.664452314376831\n",
      "Epoch: 9569, Train Loss: 0.3876577913761139, Valid Loss: 0.6666463613510132\n",
      "Epoch: 9570, Train Loss: 0.38765817880630493, Valid Loss: 0.6643714308738708\n",
      "Epoch: 9571, Train Loss: 0.3876579999923706, Valid Loss: 0.6667381525039673\n",
      "Epoch: 9572, Train Loss: 0.38765817880630493, Valid Loss: 0.6644668579101562\n",
      "Epoch: 9573, Train Loss: 0.38765794038772583, Valid Loss: 0.6666291952133179\n",
      "Epoch: 9574, Train Loss: 0.3876580595970154, Valid Loss: 0.6645729541778564\n",
      "Epoch: 9575, Train Loss: 0.38765770196914673, Valid Loss: 0.6664347648620605\n",
      "Epoch: 9576, Train Loss: 0.3876577615737915, Valid Loss: 0.6648036241531372\n",
      "Epoch: 9577, Train Loss: 0.38765794038772583, Valid Loss: 0.6662452816963196\n",
      "Epoch: 9578, Train Loss: 0.38765767216682434, Valid Loss: 0.6650614738464355\n",
      "Epoch: 9579, Train Loss: 0.3876572251319885, Valid Loss: 0.6660650372505188\n",
      "Epoch: 9580, Train Loss: 0.3876574635505676, Valid Loss: 0.6652560234069824\n",
      "Epoch: 9581, Train Loss: 0.3876573145389557, Valid Loss: 0.6658856272697449\n",
      "Epoch: 9582, Train Loss: 0.3876570761203766, Valid Loss: 0.6654111742973328\n",
      "Epoch: 9583, Train Loss: 0.3876575231552124, Valid Loss: 0.6657499074935913\n",
      "Epoch: 9584, Train Loss: 0.38765743374824524, Valid Loss: 0.6655790209770203\n",
      "Epoch: 9585, Train Loss: 0.38765716552734375, Valid Loss: 0.665666401386261\n",
      "Epoch: 9586, Train Loss: 0.38765737414360046, Valid Loss: 0.6656930446624756\n",
      "Epoch: 9587, Train Loss: 0.3876570761203766, Valid Loss: 0.6655930876731873\n",
      "Epoch: 9588, Train Loss: 0.3876575529575348, Valid Loss: 0.6657639145851135\n",
      "Epoch: 9589, Train Loss: 0.387657105922699, Valid Loss: 0.6655369400978088\n",
      "Epoch: 9590, Train Loss: 0.38765695691108704, Valid Loss: 0.6658229231834412\n",
      "Epoch: 9591, Train Loss: 0.3876568078994751, Valid Loss: 0.6655141711235046\n",
      "Epoch: 9592, Train Loss: 0.3876570463180542, Valid Loss: 0.665860116481781\n",
      "Epoch: 9593, Train Loss: 0.38765695691108704, Valid Loss: 0.6655483245849609\n",
      "Epoch: 9594, Train Loss: 0.3876568078994751, Valid Loss: 0.6658536791801453\n",
      "Epoch: 9595, Train Loss: 0.3876569867134094, Valid Loss: 0.6655347347259521\n",
      "Epoch: 9596, Train Loss: 0.3876568675041199, Valid Loss: 0.6658797264099121\n",
      "Epoch: 9597, Train Loss: 0.38765713572502136, Valid Loss: 0.6655198931694031\n",
      "Epoch: 9598, Train Loss: 0.38765695691108704, Valid Loss: 0.6659284234046936\n",
      "Epoch: 9599, Train Loss: 0.38765689730644226, Valid Loss: 0.6654930114746094\n",
      "Epoch: 9600, Train Loss: 0.38765665888786316, Valid Loss: 0.6660031676292419\n",
      "Epoch: 9601, Train Loss: 0.38765668869018555, Valid Loss: 0.6654199957847595\n",
      "Epoch: 9602, Train Loss: 0.38765671849250793, Valid Loss: 0.6661049127578735\n",
      "Epoch: 9603, Train Loss: 0.38765716552734375, Valid Loss: 0.6653112769126892\n",
      "Epoch: 9604, Train Loss: 0.3876567482948303, Valid Loss: 0.6662657856941223\n",
      "Epoch: 9605, Train Loss: 0.3876568377017975, Valid Loss: 0.6651394367218018\n",
      "Epoch: 9606, Train Loss: 0.3876565396785736, Valid Loss: 0.6665111780166626\n",
      "Epoch: 9607, Train Loss: 0.3876568078994751, Valid Loss: 0.664857804775238\n",
      "Epoch: 9608, Train Loss: 0.38765695691108704, Valid Loss: 0.6668792963027954\n",
      "Epoch: 9609, Train Loss: 0.38765740394592285, Valid Loss: 0.6644302606582642\n",
      "Epoch: 9610, Train Loss: 0.38765785098075867, Valid Loss: 0.6674454212188721\n",
      "Epoch: 9611, Train Loss: 0.3876584768295288, Valid Loss: 0.6637189388275146\n",
      "Epoch: 9612, Train Loss: 0.3876591920852661, Valid Loss: 0.6683749556541443\n",
      "Epoch: 9613, Train Loss: 0.3876606523990631, Valid Loss: 0.6625657677650452\n",
      "Epoch: 9614, Train Loss: 0.3876631557941437, Valid Loss: 0.6699163317680359\n",
      "Epoch: 9615, Train Loss: 0.38766756653785706, Valid Loss: 0.6606364250183105\n",
      "Epoch: 9616, Train Loss: 0.3876747190952301, Valid Loss: 0.6724785566329956\n",
      "Epoch: 9617, Train Loss: 0.3876860737800598, Valid Loss: 0.6574311852455139\n",
      "Epoch: 9618, Train Loss: 0.38770434260368347, Valid Loss: 0.6768081784248352\n",
      "Epoch: 9619, Train Loss: 0.3877370357513428, Valid Loss: 0.6520838141441345\n",
      "Epoch: 9620, Train Loss: 0.3877871036529541, Valid Loss: 0.684203028678894\n",
      "Epoch: 9621, Train Loss: 0.38787856698036194, Valid Loss: 0.6432993412017822\n",
      "Epoch: 9622, Train Loss: 0.3880067467689514, Valid Loss: 0.6964796185493469\n",
      "Epoch: 9623, Train Loss: 0.3882388174533844, Valid Loss: 0.6300004720687866\n",
      "Epoch: 9624, Train Loss: 0.3884914219379425, Valid Loss: 0.714662492275238\n",
      "Epoch: 9625, Train Loss: 0.3889161944389343, Valid Loss: 0.6141979694366455\n",
      "Epoch: 9626, Train Loss: 0.3890993893146515, Valid Loss: 0.7325061559677124\n",
      "Epoch: 9627, Train Loss: 0.3893132209777832, Valid Loss: 0.6069241166114807\n",
      "Epoch: 9628, Train Loss: 0.38888826966285706, Valid Loss: 0.7285478711128235\n",
      "Epoch: 9629, Train Loss: 0.388413667678833, Valid Loss: 0.6240196228027344\n",
      "Epoch: 9630, Train Loss: 0.38788121938705444, Valid Loss: 0.6907978653907776\n",
      "Epoch: 9631, Train Loss: 0.3876695930957794, Valid Loss: 0.6616584658622742\n",
      "Epoch: 9632, Train Loss: 0.3877843916416168, Valid Loss: 0.647246778011322\n",
      "Epoch: 9633, Train Loss: 0.38806143403053284, Valid Loss: 0.6986525654792786\n",
      "Epoch: 9634, Train Loss: 0.388313889503479, Valid Loss: 0.626690685749054\n",
      "Epoch: 9635, Train Loss: 0.3882521390914917, Valid Loss: 0.7081823945045471\n",
      "Epoch: 9636, Train Loss: 0.38804367184638977, Valid Loss: 0.6362491846084595\n",
      "Epoch: 9637, Train Loss: 0.38777410984039307, Valid Loss: 0.6823585033416748\n",
      "Epoch: 9638, Train Loss: 0.38766464591026306, Valid Loss: 0.6646072864532471\n",
      "Epoch: 9639, Train Loss: 0.38773468136787415, Valid Loss: 0.6499022841453552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9640, Train Loss: 0.38788262009620667, Valid Loss: 0.6884002685546875\n",
      "Epoch: 9641, Train Loss: 0.38799113035202026, Valid Loss: 0.6375069618225098\n",
      "Epoch: 9642, Train Loss: 0.38793399930000305, Valid Loss: 0.6919070482254028\n",
      "Epoch: 9643, Train Loss: 0.38780248165130615, Valid Loss: 0.6484690308570862\n",
      "Epoch: 9644, Train Loss: 0.3876815140247345, Valid Loss: 0.6736928820610046\n",
      "Epoch: 9645, Train Loss: 0.3876689076423645, Valid Loss: 0.6684199571609497\n",
      "Epoch: 9646, Train Loss: 0.3877403438091278, Valid Loss: 0.6510007381439209\n",
      "Epoch: 9647, Train Loss: 0.3878089487552643, Valid Loss: 0.6830276250839233\n",
      "Epoch: 9648, Train Loss: 0.3878254294395447, Valid Loss: 0.6443758606910706\n",
      "Epoch: 9649, Train Loss: 0.38776737451553345, Valid Loss: 0.6828195452690125\n",
      "Epoch: 9650, Train Loss: 0.3876977562904358, Valid Loss: 0.6560615301132202\n",
      "Epoch: 9651, Train Loss: 0.3876611888408661, Valid Loss: 0.6670627593994141\n",
      "Epoch: 9652, Train Loss: 0.3876783549785614, Valid Loss: 0.6719875931739807\n",
      "Epoch: 9653, Train Loss: 0.3877238929271698, Valid Loss: 0.6513699889183044\n",
      "Epoch: 9654, Train Loss: 0.3877469301223755, Valid Loss: 0.6796427965164185\n",
      "Epoch: 9655, Train Loss: 0.387733519077301, Valid Loss: 0.6503933668136597\n",
      "Epoch: 9656, Train Loss: 0.3876940906047821, Valid Loss: 0.6748027205467224\n",
      "Epoch: 9657, Train Loss: 0.3876655101776123, Valid Loss: 0.6619791984558105\n",
      "Epoch: 9658, Train Loss: 0.3876616656780243, Valid Loss: 0.6630644798278809\n",
      "Epoch: 9659, Train Loss: 0.3876778185367584, Valid Loss: 0.672514021396637\n",
      "Epoch: 9660, Train Loss: 0.38769766688346863, Valid Loss: 0.6545504927635193\n",
      "Epoch: 9661, Train Loss: 0.3877027928829193, Valid Loss: 0.6747913360595703\n",
      "Epoch: 9662, Train Loss: 0.387690931558609, Valid Loss: 0.6557908058166504\n",
      "Epoch: 9663, Train Loss: 0.38767048716545105, Valid Loss: 0.6705788969993591\n",
      "Epoch: 9664, Train Loss: 0.3876584768295288, Valid Loss: 0.664009690284729\n",
      "Epoch: 9665, Train Loss: 0.38766053318977356, Valid Loss: 0.6631771326065063\n",
      "Epoch: 9666, Train Loss: 0.3876704275608063, Valid Loss: 0.6708238124847412\n",
      "Epoch: 9667, Train Loss: 0.387678861618042, Valid Loss: 0.6577281355857849\n",
      "Epoch: 9668, Train Loss: 0.3876783549785614, Valid Loss: 0.6722060441970825\n",
      "Epoch: 9669, Train Loss: 0.3876717686653137, Valid Loss: 0.6586644053459167\n",
      "Epoch: 9670, Train Loss: 0.3876626193523407, Valid Loss: 0.6689200401306152\n",
      "Epoch: 9671, Train Loss: 0.38765743374824524, Valid Loss: 0.6646530032157898\n",
      "Epoch: 9672, Train Loss: 0.3876587450504303, Valid Loss: 0.6634357571601868\n",
      "Epoch: 9673, Train Loss: 0.3876638412475586, Valid Loss: 0.6697268486022949\n",
      "Epoch: 9674, Train Loss: 0.3876682221889496, Valid Loss: 0.6597104668617249\n",
      "Epoch: 9675, Train Loss: 0.3876684010028839, Valid Loss: 0.6704134345054626\n",
      "Epoch: 9676, Train Loss: 0.38766494393348694, Valid Loss: 0.6605700850486755\n",
      "Epoch: 9677, Train Loss: 0.3876599967479706, Valid Loss: 0.6677876114845276\n",
      "Epoch: 9678, Train Loss: 0.38765743374824524, Valid Loss: 0.6646445989608765\n",
      "Epoch: 9679, Train Loss: 0.38765719532966614, Valid Loss: 0.6643597483634949\n",
      "Epoch: 9680, Train Loss: 0.38765949010849, Valid Loss: 0.6680101752281189\n",
      "Epoch: 9681, Train Loss: 0.38766124844551086, Valid Loss: 0.6618976593017578\n",
      "Epoch: 9682, Train Loss: 0.38766229152679443, Valid Loss: 0.668764054775238\n",
      "Epoch: 9683, Train Loss: 0.3876608908176422, Valid Loss: 0.6618587374687195\n",
      "Epoch: 9684, Train Loss: 0.3876588046550751, Valid Loss: 0.6677526235580444\n",
      "Epoch: 9685, Train Loss: 0.3876572549343109, Valid Loss: 0.6640561819076538\n",
      "Epoch: 9686, Train Loss: 0.38765648007392883, Valid Loss: 0.6657401919364929\n",
      "Epoch: 9687, Train Loss: 0.38765713572502136, Valid Loss: 0.6664692759513855\n",
      "Epoch: 9688, Train Loss: 0.3876579701900482, Valid Loss: 0.6636061072349548\n",
      "Epoch: 9689, Train Loss: 0.38765883445739746, Valid Loss: 0.6678147315979004\n",
      "Epoch: 9690, Train Loss: 0.38765889406204224, Valid Loss: 0.6627126932144165\n",
      "Epoch: 9691, Train Loss: 0.3876582980155945, Valid Loss: 0.667771577835083\n",
      "Epoch: 9692, Train Loss: 0.38765761256217957, Valid Loss: 0.6636914610862732\n",
      "Epoch: 9693, Train Loss: 0.3876568675041199, Valid Loss: 0.6665990948677063\n",
      "Epoch: 9694, Train Loss: 0.3876565098762512, Valid Loss: 0.6654573678970337\n",
      "Epoch: 9695, Train Loss: 0.38765668869018555, Valid Loss: 0.664925217628479\n",
      "Epoch: 9696, Train Loss: 0.3876568675041199, Valid Loss: 0.6666963696479797\n",
      "Epoch: 9697, Train Loss: 0.38765642046928406, Valid Loss: 0.6638426780700684\n",
      "Epoch: 9698, Train Loss: 0.38765761256217957, Valid Loss: 0.6671974658966064\n",
      "Epoch: 9699, Train Loss: 0.38765648007392883, Valid Loss: 0.6639382839202881\n",
      "Epoch: 9700, Train Loss: 0.38765671849250793, Valid Loss: 0.6669760346412659\n",
      "Epoch: 9701, Train Loss: 0.3876563608646393, Valid Loss: 0.664715588092804\n",
      "Epoch: 9702, Train Loss: 0.3876568675041199, Valid Loss: 0.6661376953125\n",
      "Epoch: 9703, Train Loss: 0.3876561224460602, Valid Loss: 0.6655195355415344\n",
      "Epoch: 9704, Train Loss: 0.38765570521354675, Valid Loss: 0.6652286052703857\n",
      "Epoch: 9705, Train Loss: 0.3876555263996124, Valid Loss: 0.6662971377372742\n",
      "Epoch: 9706, Train Loss: 0.38765618205070496, Valid Loss: 0.6646566987037659\n",
      "Epoch: 9707, Train Loss: 0.3876560628414154, Valid Loss: 0.6668227314949036\n",
      "Epoch: 9708, Train Loss: 0.38765618205070496, Valid Loss: 0.6645921468734741\n",
      "Epoch: 9709, Train Loss: 0.387656033039093, Valid Loss: 0.6667682528495789\n",
      "Epoch: 9710, Train Loss: 0.38765600323677063, Valid Loss: 0.6648357510566711\n",
      "Epoch: 9711, Train Loss: 0.38765570521354675, Valid Loss: 0.6662442684173584\n",
      "Epoch: 9712, Train Loss: 0.38765570521354675, Valid Loss: 0.6653668284416199\n",
      "Epoch: 9713, Train Loss: 0.387655645608902, Valid Loss: 0.6657059192657471\n",
      "Epoch: 9714, Train Loss: 0.38765576481819153, Valid Loss: 0.6659788489341736\n",
      "Epoch: 9715, Train Loss: 0.3876555860042572, Valid Loss: 0.6653386950492859\n",
      "Epoch: 9716, Train Loss: 0.38765576481819153, Valid Loss: 0.6663291454315186\n",
      "Epoch: 9717, Train Loss: 0.387655645608902, Valid Loss: 0.6651095747947693\n",
      "Epoch: 9718, Train Loss: 0.3876558542251587, Valid Loss: 0.6663652658462524\n",
      "Epoch: 9719, Train Loss: 0.3876555562019348, Valid Loss: 0.6651056408882141\n",
      "Epoch: 9720, Train Loss: 0.38765543699264526, Valid Loss: 0.6663360595703125\n",
      "Epoch: 9721, Train Loss: 0.38765522837638855, Valid Loss: 0.6652587056159973\n",
      "Epoch: 9722, Train Loss: 0.3876553475856781, Valid Loss: 0.6662698984146118\n",
      "Epoch: 9723, Train Loss: 0.3876555263996124, Valid Loss: 0.6654455661773682\n",
      "Epoch: 9724, Train Loss: 0.3876551687717438, Valid Loss: 0.6660579442977905\n",
      "Epoch: 9725, Train Loss: 0.387655109167099, Valid Loss: 0.6656572222709656\n",
      "Epoch: 9726, Train Loss: 0.38765501976013184, Valid Loss: 0.665795087814331\n",
      "Epoch: 9727, Train Loss: 0.3876553475856781, Valid Loss: 0.6659088730812073\n",
      "Epoch: 9728, Train Loss: 0.3876551687717438, Valid Loss: 0.6656192541122437\n",
      "Epoch: 9729, Train Loss: 0.3876549303531647, Valid Loss: 0.6661645770072937\n",
      "Epoch: 9730, Train Loss: 0.3876551389694214, Valid Loss: 0.6654713153839111\n",
      "Epoch: 9731, Train Loss: 0.38765498995780945, Valid Loss: 0.6662757396697998\n",
      "Epoch: 9732, Train Loss: 0.3876551687717438, Valid Loss: 0.6653952598571777\n",
      "Epoch: 9733, Train Loss: 0.3876549005508423, Valid Loss: 0.666286289691925\n",
      "Epoch: 9734, Train Loss: 0.38765475153923035, Valid Loss: 0.6654178500175476\n",
      "Epoch: 9735, Train Loss: 0.3876551687717438, Valid Loss: 0.6662728786468506\n",
      "Epoch: 9736, Train Loss: 0.387655109167099, Valid Loss: 0.6655085682868958\n",
      "Epoch: 9737, Train Loss: 0.3876550495624542, Valid Loss: 0.666217029094696\n",
      "Epoch: 9738, Train Loss: 0.3876548707485199, Valid Loss: 0.6656272411346436\n",
      "Epoch: 9739, Train Loss: 0.3876548707485199, Valid Loss: 0.6660846471786499\n",
      "Epoch: 9740, Train Loss: 0.3876549303531647, Valid Loss: 0.6657423377037048\n",
      "Epoch: 9741, Train Loss: 0.3876549005508423, Valid Loss: 0.6659656763076782\n",
      "Epoch: 9742, Train Loss: 0.38765501976013184, Valid Loss: 0.6658965349197388\n",
      "Epoch: 9743, Train Loss: 0.38765472173690796, Valid Loss: 0.6658531427383423\n",
      "Epoch: 9744, Train Loss: 0.3876546621322632, Valid Loss: 0.666049063205719\n",
      "Epoch: 9745, Train Loss: 0.38765472173690796, Valid Loss: 0.6657392978668213\n",
      "Epoch: 9746, Train Loss: 0.387654572725296, Valid Loss: 0.666151762008667\n",
      "Epoch: 9747, Train Loss: 0.3876546025276184, Valid Loss: 0.6656579375267029\n",
      "Epoch: 9748, Train Loss: 0.3876544237136841, Valid Loss: 0.6662103533744812\n",
      "Epoch: 9749, Train Loss: 0.38765451312065125, Valid Loss: 0.6656513214111328\n",
      "Epoch: 9750, Train Loss: 0.38765451312065125, Valid Loss: 0.6662628650665283\n",
      "Epoch: 9751, Train Loss: 0.38765472173690796, Valid Loss: 0.6656031608581543\n",
      "Epoch: 9752, Train Loss: 0.3876544237136841, Valid Loss: 0.6663451194763184\n",
      "Epoch: 9753, Train Loss: 0.38765430450439453, Valid Loss: 0.6655333638191223\n",
      "Epoch: 9754, Train Loss: 0.38765448331832886, Valid Loss: 0.6664380431175232\n",
      "Epoch: 9755, Train Loss: 0.3876543939113617, Valid Loss: 0.6654269695281982\n",
      "Epoch: 9756, Train Loss: 0.38765430450439453, Valid Loss: 0.66657555103302\n",
      "Epoch: 9757, Train Loss: 0.38765448331832886, Valid Loss: 0.6653093695640564\n",
      "Epoch: 9758, Train Loss: 0.38765430450439453, Valid Loss: 0.6667394042015076\n",
      "Epoch: 9759, Train Loss: 0.3876543939113617, Valid Loss: 0.6651520729064941\n",
      "Epoch: 9760, Train Loss: 0.38765430450439453, Valid Loss: 0.6669450402259827\n",
      "Epoch: 9761, Train Loss: 0.38765472173690796, Valid Loss: 0.6649012565612793\n",
      "Epoch: 9762, Train Loss: 0.3876546621322632, Valid Loss: 0.667266845703125\n",
      "Epoch: 9763, Train Loss: 0.3876546621322632, Valid Loss: 0.6645238995552063\n",
      "Epoch: 9764, Train Loss: 0.387655645608902, Valid Loss: 0.6677758693695068\n",
      "Epoch: 9765, Train Loss: 0.38765570521354675, Valid Loss: 0.6639153361320496\n",
      "Epoch: 9766, Train Loss: 0.3876568377017975, Valid Loss: 0.6685584783554077\n",
      "Epoch: 9767, Train Loss: 0.3876577317714691, Valid Loss: 0.6629914045333862\n",
      "Epoch: 9768, Train Loss: 0.38765960931777954, Valid Loss: 0.6697141528129578\n",
      "Epoch: 9769, Train Loss: 0.38766220211982727, Valid Loss: 0.6616038680076599\n",
      "Epoch: 9770, Train Loss: 0.38766586780548096, Valid Loss: 0.6714990139007568\n",
      "Epoch: 9771, Train Loss: 0.3876720368862152, Valid Loss: 0.65944504737854\n",
      "Epoch: 9772, Train Loss: 0.3876810669898987, Valid Loss: 0.6743060350418091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9773, Train Loss: 0.3876957893371582, Valid Loss: 0.656080961227417\n",
      "Epoch: 9774, Train Loss: 0.38771697878837585, Valid Loss: 0.6787412762641907\n",
      "Epoch: 9775, Train Loss: 0.38775312900543213, Valid Loss: 0.6508268713951111\n",
      "Epoch: 9776, Train Loss: 0.38780340552330017, Valid Loss: 0.6857872009277344\n",
      "Epoch: 9777, Train Loss: 0.3878903388977051, Valid Loss: 0.6428209543228149\n",
      "Epoch: 9778, Train Loss: 0.3879988491535187, Valid Loss: 0.6965858340263367\n",
      "Epoch: 9779, Train Loss: 0.3881852626800537, Valid Loss: 0.6317148804664612\n",
      "Epoch: 9780, Train Loss: 0.3883607089519501, Valid Loss: 0.7109761834144592\n",
      "Epoch: 9781, Train Loss: 0.3886432647705078, Valid Loss: 0.6197569966316223\n",
      "Epoch: 9782, Train Loss: 0.38874027132987976, Valid Loss: 0.7234358787536621\n",
      "Epoch: 9783, Train Loss: 0.38886111974716187, Valid Loss: 0.6148470044136047\n",
      "Epoch: 9784, Train Loss: 0.3885951042175293, Valid Loss: 0.7201341986656189\n",
      "Epoch: 9785, Train Loss: 0.3883046805858612, Valid Loss: 0.6269948482513428\n",
      "Epoch: 9786, Train Loss: 0.38792183995246887, Valid Loss: 0.6936721801757812\n",
      "Epoch: 9787, Train Loss: 0.38770076632499695, Valid Loss: 0.6546573042869568\n",
      "Epoch: 9788, Train Loss: 0.38767024874687195, Valid Loss: 0.6598752737045288\n",
      "Epoch: 9789, Train Loss: 0.3877922296524048, Valid Loss: 0.6845681667327881\n",
      "Epoch: 9790, Train Loss: 0.38797426223754883, Valid Loss: 0.6378080248832703\n",
      "Epoch: 9791, Train Loss: 0.3880694806575775, Valid Loss: 0.7005942463874817\n",
      "Epoch: 9792, Train Loss: 0.3880769908428192, Valid Loss: 0.634660542011261\n",
      "Epoch: 9793, Train Loss: 0.3879336416721344, Valid Loss: 0.6934143304824829\n",
      "Epoch: 9794, Train Loss: 0.3877822458744049, Valid Loss: 0.6488279104232788\n",
      "Epoch: 9795, Train Loss: 0.3876754343509674, Valid Loss: 0.6713518500328064\n",
      "Epoch: 9796, Train Loss: 0.387663334608078, Valid Loss: 0.6694044470787048\n",
      "Epoch: 9797, Train Loss: 0.3877272605895996, Valid Loss: 0.6516251564025879\n",
      "Epoch: 9798, Train Loss: 0.3878065347671509, Valid Loss: 0.6846646666526794\n",
      "Epoch: 9799, Train Loss: 0.3878560960292816, Valid Loss: 0.6444286108016968\n",
      "Epoch: 9800, Train Loss: 0.3878254294395447, Valid Loss: 0.6870678067207336\n",
      "Epoch: 9801, Train Loss: 0.3877590596675873, Valid Loss: 0.649890124797821\n",
      "Epoch: 9802, Train Loss: 0.3876890540122986, Valid Loss: 0.6753123998641968\n",
      "Epoch: 9803, Train Loss: 0.38765761256217957, Valid Loss: 0.6627864241600037\n",
      "Epoch: 9804, Train Loss: 0.3876696527004242, Valid Loss: 0.6595041751861572\n",
      "Epoch: 9805, Train Loss: 0.38770562410354614, Valid Loss: 0.6762039661407471\n",
      "Epoch: 9806, Train Loss: 0.38773900270462036, Valid Loss: 0.6507012844085693\n",
      "Epoch: 9807, Train Loss: 0.3877444863319397, Valid Loss: 0.6817482113838196\n",
      "Epoch: 9808, Train Loss: 0.3877251148223877, Valid Loss: 0.6522284150123596\n",
      "Epoch: 9809, Train Loss: 0.3876894414424896, Valid Loss: 0.6755419969558716\n",
      "Epoch: 9810, Train Loss: 0.3876623511314392, Valid Loss: 0.6607568264007568\n",
      "Epoch: 9811, Train Loss: 0.3876558542251587, Valid Loss: 0.6637632846832275\n",
      "Epoch: 9812, Train Loss: 0.38766688108444214, Valid Loss: 0.6706939935684204\n",
      "Epoch: 9813, Train Loss: 0.38768407702445984, Valid Loss: 0.656190037727356\n",
      "Epoch: 9814, Train Loss: 0.38769498467445374, Valid Loss: 0.6761193871498108\n",
      "Epoch: 9815, Train Loss: 0.3876956105232239, Valid Loss: 0.6557554602622986\n",
      "Epoch: 9816, Train Loss: 0.3876838684082031, Valid Loss: 0.6741459369659424\n",
      "Epoch: 9817, Train Loss: 0.3876693844795227, Valid Loss: 0.6597879528999329\n",
      "Epoch: 9818, Train Loss: 0.38765770196914673, Valid Loss: 0.6677013635635376\n",
      "Epoch: 9819, Train Loss: 0.3876551389694214, Valid Loss: 0.6657140254974365\n",
      "Epoch: 9820, Train Loss: 0.3876591920852661, Valid Loss: 0.6618995070457458\n",
      "Epoch: 9821, Train Loss: 0.38766711950302124, Valid Loss: 0.6709725260734558\n",
      "Epoch: 9822, Train Loss: 0.38767269253730774, Valid Loss: 0.659208357334137\n",
      "Epoch: 9823, Train Loss: 0.38767319917678833, Valid Loss: 0.6727313995361328\n",
      "Epoch: 9824, Train Loss: 0.38766899704933167, Valid Loss: 0.6595152020454407\n",
      "Epoch: 9825, Train Loss: 0.38766273856163025, Valid Loss: 0.6703436374664307\n",
      "Epoch: 9826, Train Loss: 0.38765689730644226, Valid Loss: 0.6624918580055237\n",
      "Epoch: 9827, Train Loss: 0.38765454292297363, Valid Loss: 0.6660662889480591\n",
      "Epoch: 9828, Train Loss: 0.3876550793647766, Valid Loss: 0.6670023202896118\n",
      "Epoch: 9829, Train Loss: 0.3876578211784363, Valid Loss: 0.662557065486908\n",
      "Epoch: 9830, Train Loss: 0.3876603841781616, Valid Loss: 0.6701324582099915\n",
      "Epoch: 9831, Train Loss: 0.3876616656780243, Valid Loss: 0.6610004901885986\n",
      "Epoch: 9832, Train Loss: 0.38766172528266907, Valid Loss: 0.6702393889427185\n",
      "Epoch: 9833, Train Loss: 0.38766002655029297, Valid Loss: 0.661583662033081\n",
      "Epoch: 9834, Train Loss: 0.3876572251319885, Valid Loss: 0.6683977246284485\n",
      "Epoch: 9835, Train Loss: 0.3876558244228363, Valid Loss: 0.6638931035995483\n",
      "Epoch: 9836, Train Loss: 0.3876541554927826, Valid Loss: 0.6662098169326782\n",
      "Epoch: 9837, Train Loss: 0.38765376806259155, Valid Loss: 0.6664219498634338\n",
      "Epoch: 9838, Train Loss: 0.3876546025276184, Valid Loss: 0.6642906069755554\n",
      "Epoch: 9839, Train Loss: 0.387655645608902, Valid Loss: 0.6679118275642395\n",
      "Epoch: 9840, Train Loss: 0.3876565396785736, Valid Loss: 0.6630673408508301\n",
      "Epoch: 9841, Train Loss: 0.38765692710876465, Valid Loss: 0.6684690117835999\n",
      "Epoch: 9842, Train Loss: 0.38765665888786316, Valid Loss: 0.6629562973976135\n",
      "Epoch: 9843, Train Loss: 0.38765600323677063, Valid Loss: 0.6683306097984314\n",
      "Epoch: 9844, Train Loss: 0.3876546621322632, Valid Loss: 0.6638302803039551\n",
      "Epoch: 9845, Train Loss: 0.3876543343067169, Valid Loss: 0.667330801486969\n",
      "Epoch: 9846, Train Loss: 0.38765332102775574, Valid Loss: 0.6651012301445007\n",
      "Epoch: 9847, Train Loss: 0.38765329122543335, Valid Loss: 0.6658418774604797\n",
      "Epoch: 9848, Train Loss: 0.3876534402370453, Valid Loss: 0.6663563251495361\n",
      "Epoch: 9849, Train Loss: 0.38765430450439453, Valid Loss: 0.6646934747695923\n",
      "Epoch: 9850, Train Loss: 0.3876539170742035, Valid Loss: 0.667357861995697\n",
      "Epoch: 9851, Train Loss: 0.38765430450439453, Valid Loss: 0.6642109155654907\n",
      "Epoch: 9852, Train Loss: 0.3876543641090393, Valid Loss: 0.6677310466766357\n",
      "Epoch: 9853, Train Loss: 0.387654572725296, Valid Loss: 0.6641486883163452\n",
      "Epoch: 9854, Train Loss: 0.3876541256904602, Valid Loss: 0.6675026416778564\n",
      "Epoch: 9855, Train Loss: 0.38765403628349304, Valid Loss: 0.6644390821456909\n",
      "Epoch: 9856, Train Loss: 0.38765349984169006, Valid Loss: 0.6670817732810974\n",
      "Epoch: 9857, Train Loss: 0.38765376806259155, Valid Loss: 0.664988100528717\n",
      "Epoch: 9858, Train Loss: 0.3876532018184662, Valid Loss: 0.6666252613067627\n",
      "Epoch: 9859, Train Loss: 0.3876529932022095, Valid Loss: 0.665626585483551\n",
      "Epoch: 9860, Train Loss: 0.38765355944633484, Valid Loss: 0.6660775542259216\n",
      "Epoch: 9861, Train Loss: 0.3876529633998871, Valid Loss: 0.666121244430542\n",
      "Epoch: 9862, Train Loss: 0.3876531422138214, Valid Loss: 0.6655736565589905\n",
      "Epoch: 9863, Train Loss: 0.38765278458595276, Valid Loss: 0.6665583848953247\n",
      "Epoch: 9864, Train Loss: 0.38765284419059753, Valid Loss: 0.6652357578277588\n",
      "Epoch: 9865, Train Loss: 0.3876532316207886, Valid Loss: 0.6669226288795471\n",
      "Epoch: 9866, Train Loss: 0.387653112411499, Valid Loss: 0.6650540828704834\n",
      "Epoch: 9867, Train Loss: 0.38765308260917664, Valid Loss: 0.6670653820037842\n",
      "Epoch: 9868, Train Loss: 0.3876529633998871, Valid Loss: 0.6649802327156067\n",
      "Epoch: 9869, Train Loss: 0.3876529037952423, Valid Loss: 0.6670582294464111\n",
      "Epoch: 9870, Train Loss: 0.3876531720161438, Valid Loss: 0.6649925112724304\n",
      "Epoch: 9871, Train Loss: 0.38765302300453186, Valid Loss: 0.6670415997505188\n",
      "Epoch: 9872, Train Loss: 0.3876529037952423, Valid Loss: 0.6650902032852173\n",
      "Epoch: 9873, Train Loss: 0.38765284419059753, Valid Loss: 0.6670213937759399\n",
      "Epoch: 9874, Train Loss: 0.3876526653766632, Valid Loss: 0.6651676893234253\n",
      "Epoch: 9875, Train Loss: 0.3876528739929199, Valid Loss: 0.6669492125511169\n",
      "Epoch: 9876, Train Loss: 0.38765257596969604, Valid Loss: 0.6652361154556274\n",
      "Epoch: 9877, Train Loss: 0.38765254616737366, Valid Loss: 0.6668607592582703\n",
      "Epoch: 9878, Train Loss: 0.38765275478363037, Valid Loss: 0.6653565764427185\n",
      "Epoch: 9879, Train Loss: 0.38765308260917664, Valid Loss: 0.666789710521698\n",
      "Epoch: 9880, Train Loss: 0.3876524865627289, Valid Loss: 0.6654636859893799\n",
      "Epoch: 9881, Train Loss: 0.3876531720161438, Valid Loss: 0.6667638421058655\n",
      "Epoch: 9882, Train Loss: 0.3876522183418274, Valid Loss: 0.6654602885246277\n",
      "Epoch: 9883, Train Loss: 0.38765352964401245, Valid Loss: 0.6668103933334351\n",
      "Epoch: 9884, Train Loss: 0.3876526653766632, Valid Loss: 0.6653740406036377\n",
      "Epoch: 9885, Train Loss: 0.38765233755111694, Valid Loss: 0.66695237159729\n",
      "Epoch: 9886, Train Loss: 0.38765230774879456, Valid Loss: 0.6652478575706482\n",
      "Epoch: 9887, Train Loss: 0.38765275478363037, Valid Loss: 0.6671556830406189\n",
      "Epoch: 9888, Train Loss: 0.3876522183418274, Valid Loss: 0.6650249361991882\n",
      "Epoch: 9889, Train Loss: 0.38765278458595276, Valid Loss: 0.667448878288269\n",
      "Epoch: 9890, Train Loss: 0.38765284419059753, Valid Loss: 0.6646600961685181\n",
      "Epoch: 9891, Train Loss: 0.38765326142311096, Valid Loss: 0.6679074168205261\n",
      "Epoch: 9892, Train Loss: 0.38765373826026917, Valid Loss: 0.6641050577163696\n",
      "Epoch: 9893, Train Loss: 0.38765445351600647, Valid Loss: 0.6686253547668457\n",
      "Epoch: 9894, Train Loss: 0.387655645608902, Valid Loss: 0.663280189037323\n",
      "Epoch: 9895, Train Loss: 0.387657105922699, Valid Loss: 0.6696805357933044\n",
      "Epoch: 9896, Train Loss: 0.3876591622829437, Valid Loss: 0.6620222330093384\n",
      "Epoch: 9897, Train Loss: 0.3876621127128601, Valid Loss: 0.6712802052497864\n",
      "Epoch: 9898, Train Loss: 0.387666791677475, Valid Loss: 0.6600946187973022\n",
      "Epoch: 9899, Train Loss: 0.387673944234848, Valid Loss: 0.6737282276153564\n",
      "Epoch: 9900, Train Loss: 0.387685090303421, Valid Loss: 0.6571898460388184\n",
      "Epoch: 9901, Train Loss: 0.3877011239528656, Valid Loss: 0.6775111556053162\n",
      "Epoch: 9902, Train Loss: 0.38772714138031006, Valid Loss: 0.652768611907959\n",
      "Epoch: 9903, Train Loss: 0.3877631425857544, Valid Loss: 0.6833127737045288\n",
      "Epoch: 9904, Train Loss: 0.3878236711025238, Valid Loss: 0.646145224571228\n",
      "Epoch: 9905, Train Loss: 0.38790005445480347, Valid Loss: 0.6921177506446838\n",
      "Epoch: 9906, Train Loss: 0.3880313038825989, Valid Loss: 0.6367628574371338\n",
      "Epoch: 9907, Train Loss: 0.3881691098213196, Valid Loss: 0.7043921947479248\n",
      "Epoch: 9908, Train Loss: 0.38839802145957947, Valid Loss: 0.6255188584327698\n",
      "Epoch: 9909, Train Loss: 0.3885394036769867, Valid Loss: 0.7175421714782715\n",
      "Epoch: 9910, Train Loss: 0.3887473940849304, Valid Loss: 0.617262601852417\n",
      "Epoch: 9911, Train Loss: 0.38866207003593445, Valid Loss: 0.7220356464385986\n",
      "Epoch: 9912, Train Loss: 0.3885512053966522, Valid Loss: 0.6210792660713196\n",
      "Epoch: 9913, Train Loss: 0.38819268345832825, Valid Loss: 0.7065851092338562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9914, Train Loss: 0.38789716362953186, Valid Loss: 0.6412103176116943\n",
      "Epoch: 9915, Train Loss: 0.387698233127594, Valid Loss: 0.6761687994003296\n",
      "Epoch: 9916, Train Loss: 0.3876670300960541, Valid Loss: 0.6696075201034546\n",
      "Epoch: 9917, Train Loss: 0.3877693712711334, Valid Loss: 0.6489409804344177\n",
      "Epoch: 9918, Train Loss: 0.3879130184650421, Valid Loss: 0.6926941871643066\n",
      "Epoch: 9919, Train Loss: 0.3880343735218048, Valid Loss: 0.6360327005386353\n",
      "Epoch: 9920, Train Loss: 0.3880225419998169, Valid Loss: 0.6983358263969421\n",
      "Epoch: 9921, Train Loss: 0.3879452645778656, Valid Loss: 0.640187680721283\n",
      "Epoch: 9922, Train Loss: 0.38780081272125244, Valid Loss: 0.6851241588592529\n",
      "Epoch: 9923, Train Loss: 0.387693852186203, Valid Loss: 0.6564696431159973\n",
      "Epoch: 9924, Train Loss: 0.3876556158065796, Valid Loss: 0.6646305322647095\n",
      "Epoch: 9925, Train Loss: 0.38768845796585083, Valid Loss: 0.6742619276046753\n",
      "Epoch: 9926, Train Loss: 0.38775768876075745, Valid Loss: 0.6499732136726379\n",
      "Epoch: 9927, Train Loss: 0.38780805468559265, Valid Loss: 0.6852958798408508\n",
      "Epoch: 9928, Train Loss: 0.3878220021724701, Valid Loss: 0.6463995575904846\n",
      "Epoch: 9929, Train Loss: 0.3877769410610199, Valid Loss: 0.6843847632408142\n",
      "Epoch: 9930, Train Loss: 0.3877187669277191, Valid Loss: 0.652700662612915\n",
      "Epoch: 9931, Train Loss: 0.3876711130142212, Valid Loss: 0.6724995970726013\n",
      "Epoch: 9932, Train Loss: 0.3876558840274811, Valid Loss: 0.6648371815681458\n",
      "Epoch: 9933, Train Loss: 0.3876704275608063, Valid Loss: 0.6590000987052917\n",
      "Epoch: 9934, Train Loss: 0.3876996338367462, Valid Loss: 0.6765398383140564\n",
      "Epoch: 9935, Train Loss: 0.38772499561309814, Valid Loss: 0.6520566344261169\n",
      "Epoch: 9936, Train Loss: 0.3877283036708832, Valid Loss: 0.6805821061134338\n",
      "Epoch: 9937, Train Loss: 0.387710303068161, Valid Loss: 0.6535019874572754\n",
      "Epoch: 9938, Train Loss: 0.3876825273036957, Valid Loss: 0.6746900081634521\n",
      "Epoch: 9939, Train Loss: 0.3876609206199646, Valid Loss: 0.6608630418777466\n",
      "Epoch: 9940, Train Loss: 0.3876535892486572, Valid Loss: 0.6648507714271545\n",
      "Epoch: 9941, Train Loss: 0.3876592516899109, Valid Loss: 0.6696019172668457\n",
      "Epoch: 9942, Train Loss: 0.387671560049057, Valid Loss: 0.6583962440490723\n",
      "Epoch: 9943, Train Loss: 0.3876822292804718, Valid Loss: 0.6747615933418274\n",
      "Epoch: 9944, Train Loss: 0.38768622279167175, Valid Loss: 0.656868577003479\n",
      "Epoch: 9945, Train Loss: 0.38768038153648376, Valid Loss: 0.6740499138832092\n",
      "Epoch: 9946, Train Loss: 0.38767048716545105, Valid Loss: 0.6591250896453857\n",
      "Epoch: 9947, Train Loss: 0.38765957951545715, Valid Loss: 0.6695825457572937\n",
      "Epoch: 9948, Train Loss: 0.38765349984169006, Valid Loss: 0.6639450192451477\n",
      "Epoch: 9949, Train Loss: 0.3876529037952423, Valid Loss: 0.664654552936554\n",
      "Epoch: 9950, Train Loss: 0.3876572251319885, Valid Loss: 0.6690360307693481\n",
      "Epoch: 9951, Train Loss: 0.3876621425151825, Valid Loss: 0.6610918641090393\n",
      "Epoch: 9952, Train Loss: 0.38766542077064514, Valid Loss: 0.6718370914459229\n",
      "Epoch: 9953, Train Loss: 0.387666255235672, Valid Loss: 0.6597316265106201\n",
      "Epoch: 9954, Train Loss: 0.38766348361968994, Valid Loss: 0.6713383197784424\n",
      "Epoch: 9955, Train Loss: 0.38765960931777954, Valid Loss: 0.6611742377281189\n",
      "Epoch: 9956, Train Loss: 0.38765522837638855, Valid Loss: 0.6686670780181885\n",
      "Epoch: 9957, Train Loss: 0.38765257596969604, Valid Loss: 0.6646414995193481\n",
      "Epoch: 9958, Train Loss: 0.3876522183418274, Valid Loss: 0.665473461151123\n",
      "Epoch: 9959, Train Loss: 0.38765326142311096, Valid Loss: 0.667798638343811\n",
      "Epoch: 9960, Train Loss: 0.38765496015548706, Valid Loss: 0.6629722714424133\n",
      "Epoch: 9961, Train Loss: 0.38765639066696167, Valid Loss: 0.6693281531333923\n",
      "Epoch: 9962, Train Loss: 0.3876575827598572, Valid Loss: 0.6619850397109985\n",
      "Epoch: 9963, Train Loss: 0.38765716552734375, Valid Loss: 0.6694784760475159\n",
      "Epoch: 9964, Train Loss: 0.38765645027160645, Valid Loss: 0.6625891327857971\n",
      "Epoch: 9965, Train Loss: 0.3876549005508423, Valid Loss: 0.6686851382255554\n",
      "Epoch: 9966, Train Loss: 0.3876533508300781, Valid Loss: 0.6640106439590454\n",
      "Epoch: 9967, Train Loss: 0.3876524269580841, Valid Loss: 0.6671634912490845\n",
      "Epoch: 9968, Train Loss: 0.3876517117023468, Valid Loss: 0.6655400991439819\n",
      "Epoch: 9969, Train Loss: 0.387651652097702, Valid Loss: 0.665473222732544\n",
      "Epoch: 9970, Train Loss: 0.38765212893486023, Valid Loss: 0.6670275926589966\n",
      "Epoch: 9971, Train Loss: 0.38765275478363037, Valid Loss: 0.6642791628837585\n",
      "Epoch: 9972, Train Loss: 0.38765305280685425, Valid Loss: 0.6681689620018005\n",
      "Epoch: 9973, Train Loss: 0.38765355944633484, Valid Loss: 0.6637265086174011\n",
      "Epoch: 9974, Train Loss: 0.38765326142311096, Valid Loss: 0.6684765815734863\n",
      "Epoch: 9975, Train Loss: 0.38765278458595276, Valid Loss: 0.6637301445007324\n",
      "Epoch: 9976, Train Loss: 0.38765284419059753, Valid Loss: 0.6680570244789124\n",
      "Epoch: 9977, Train Loss: 0.3876523971557617, Valid Loss: 0.6642875671386719\n",
      "Epoch: 9978, Train Loss: 0.38765203952789307, Valid Loss: 0.6673628091812134\n",
      "Epoch: 9979, Train Loss: 0.3876515328884125, Valid Loss: 0.6651809811592102\n",
      "Epoch: 9980, Train Loss: 0.3876514732837677, Valid Loss: 0.6666142344474792\n",
      "Epoch: 9981, Train Loss: 0.3876512348651886, Valid Loss: 0.6659993529319763\n",
      "Epoch: 9982, Train Loss: 0.3876514136791229, Valid Loss: 0.6658869981765747\n",
      "Epoch: 9983, Train Loss: 0.3876512944698334, Valid Loss: 0.6665957570075989\n",
      "Epoch: 9984, Train Loss: 0.3876512944698334, Valid Loss: 0.6652991771697998\n",
      "Epoch: 9985, Train Loss: 0.3876515328884125, Valid Loss: 0.6671249270439148\n",
      "Epoch: 9986, Train Loss: 0.38765162229537964, Valid Loss: 0.6649284362792969\n",
      "Epoch: 9987, Train Loss: 0.38765156269073486, Valid Loss: 0.6675496101379395\n",
      "Epoch: 9988, Train Loss: 0.3876511752605438, Valid Loss: 0.6647181510925293\n",
      "Epoch: 9989, Train Loss: 0.38765183091163635, Valid Loss: 0.6676994562149048\n",
      "Epoch: 9990, Train Loss: 0.3876517713069916, Valid Loss: 0.6646484136581421\n",
      "Epoch: 9991, Train Loss: 0.38765183091163635, Valid Loss: 0.6676291823387146\n",
      "Epoch: 9992, Train Loss: 0.3876514434814453, Valid Loss: 0.6647824645042419\n",
      "Epoch: 9993, Train Loss: 0.3876512944698334, Valid Loss: 0.6675108075141907\n",
      "Epoch: 9994, Train Loss: 0.38765066862106323, Valid Loss: 0.6650044918060303\n",
      "Epoch: 9995, Train Loss: 0.38765135407447815, Valid Loss: 0.667378842830658\n",
      "Epoch: 9996, Train Loss: 0.3876512348651886, Valid Loss: 0.6651589274406433\n",
      "Epoch: 9997, Train Loss: 0.3876514732837677, Valid Loss: 0.6672349572181702\n",
      "Epoch: 9998, Train Loss: 0.3876512348651886, Valid Loss: 0.6652237176895142\n",
      "Epoch: 9999, Train Loss: 0.38765111565589905, Valid Loss: 0.6671931743621826\n"
     ]
    }
   ],
   "source": [
    "model.train(train_x, train_y)\n",
    "t2v_train_loss = pd.Series(model.train_loss)\n",
    "t2v_valid_loss = pd.Series(model.valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a6323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(test_x) >= 0.5).numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96245a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11eae387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.745"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((model.predict(test_x) >= 0.5).numpy().astype(int) == test_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e808fa3",
   "metadata": {},
   "source": [
    "# Date2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6376c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_dataset(\n",
    "    feature=['year', 'dayofyear', 'month', 'dayofmonth','week', 'dayofweek'], split_loc=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f850b317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateNet(nn.Module):\n",
    "    def __init__(self, linear_channel, period_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_fc = nn.Linear(6, linear_channel)\n",
    "        self.period_fc = nn.Linear(6, period_channel)\n",
    "        \n",
    "        self.fc = nn.Linear(linear_channel + period_channel, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def d2v_forward(self, x):\n",
    "        linear_output = self.linear_fc(x)\n",
    "        period_output = torch.sin(self.period_fc(x))\n",
    "        return torch.cat([linear_output, period_output], 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.d2v_forward(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26c0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network = DateNet(1, 16)\n",
    "model = Model(network, max_epoch=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7371c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.525292694568634, Valid Loss: 0.6324706077575684\n",
      "Epoch: 1, Train Loss: 0.5210200548171997, Valid Loss: 0.6259492635726929\n",
      "Epoch: 2, Train Loss: 0.516995370388031, Valid Loss: 0.6191476583480835\n",
      "Epoch: 3, Train Loss: 0.5131736993789673, Valid Loss: 0.6121880412101746\n",
      "Epoch: 4, Train Loss: 0.5094984173774719, Valid Loss: 0.605127215385437\n",
      "Epoch: 5, Train Loss: 0.5059183239936829, Valid Loss: 0.5979436635971069\n",
      "Epoch: 6, Train Loss: 0.502441942691803, Valid Loss: 0.5906006693840027\n",
      "Epoch: 7, Train Loss: 0.49913346767425537, Valid Loss: 0.5831502676010132\n",
      "Epoch: 8, Train Loss: 0.4960729479789734, Valid Loss: 0.5757371783256531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/bb77p1fj09d0s_0z7g249tchjddcwy/T/ipykernel_92856/3253151976.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(array).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Loss: 0.4933132529258728, Valid Loss: 0.5684820413589478\n",
      "Epoch: 10, Train Loss: 0.49085885286331177, Valid Loss: 0.5614067912101746\n",
      "Epoch: 11, Train Loss: 0.48870187997817993, Valid Loss: 0.5545615553855896\n",
      "Epoch: 12, Train Loss: 0.48685476183891296, Valid Loss: 0.5481453537940979\n",
      "Epoch: 13, Train Loss: 0.4853242039680481, Valid Loss: 0.5424088835716248\n",
      "Epoch: 14, Train Loss: 0.48407816886901855, Valid Loss: 0.5375028252601624\n",
      "Epoch: 15, Train Loss: 0.4830513596534729, Valid Loss: 0.5334164500236511\n",
      "Epoch: 16, Train Loss: 0.4821787476539612, Valid Loss: 0.5300261974334717\n",
      "Epoch: 17, Train Loss: 0.4814201891422272, Valid Loss: 0.5271838903427124\n",
      "Epoch: 18, Train Loss: 0.4807514548301697, Valid Loss: 0.5247626900672913\n",
      "Epoch: 19, Train Loss: 0.4801395535469055, Valid Loss: 0.5226520895957947\n",
      "Epoch: 20, Train Loss: 0.4795401990413666, Valid Loss: 0.5207495093345642\n",
      "Epoch: 21, Train Loss: 0.4789198338985443, Valid Loss: 0.518975555896759\n",
      "Epoch: 22, Train Loss: 0.4782665967941284, Valid Loss: 0.5172898769378662\n",
      "Epoch: 23, Train Loss: 0.47758305072784424, Valid Loss: 0.5156904458999634\n",
      "Epoch: 24, Train Loss: 0.4768761098384857, Valid Loss: 0.5141972303390503\n",
      "Epoch: 25, Train Loss: 0.4761500954627991, Valid Loss: 0.5128358602523804\n",
      "Epoch: 26, Train Loss: 0.47540462017059326, Valid Loss: 0.5116193294525146\n",
      "Epoch: 27, Train Loss: 0.4746325612068176, Valid Loss: 0.5105321407318115\n",
      "Epoch: 28, Train Loss: 0.4738210439682007, Valid Loss: 0.509524941444397\n",
      "Epoch: 29, Train Loss: 0.4729565978050232, Valid Loss: 0.5085275173187256\n",
      "Epoch: 30, Train Loss: 0.4720362722873688, Valid Loss: 0.5074849128723145\n",
      "Epoch: 31, Train Loss: 0.4710731506347656, Valid Loss: 0.5063890814781189\n",
      "Epoch: 32, Train Loss: 0.47009196877479553, Valid Loss: 0.5052765011787415\n",
      "Epoch: 33, Train Loss: 0.4691241383552551, Valid Loss: 0.5042104721069336\n",
      "Epoch: 34, Train Loss: 0.468205064535141, Valid Loss: 0.5032615065574646\n",
      "Epoch: 35, Train Loss: 0.467369019985199, Valid Loss: 0.5024898052215576\n",
      "Epoch: 36, Train Loss: 0.46663981676101685, Valid Loss: 0.5019281506538391\n",
      "Epoch: 37, Train Loss: 0.4660215675830841, Valid Loss: 0.5015747547149658\n",
      "Epoch: 38, Train Loss: 0.46549591422080994, Valid Loss: 0.5013961791992188\n",
      "Epoch: 39, Train Loss: 0.4650280177593231, Valid Loss: 0.5013403296470642\n",
      "Epoch: 40, Train Loss: 0.4645785093307495, Valid Loss: 0.5013497471809387\n",
      "Epoch: 41, Train Loss: 0.4641134738922119, Valid Loss: 0.5013744831085205\n",
      "Epoch: 42, Train Loss: 0.4636141061782837, Valid Loss: 0.5013797879219055\n",
      "Epoch: 43, Train Loss: 0.463079571723938, Valid Loss: 0.5013452768325806\n",
      "Epoch: 44, Train Loss: 0.4625205397605896, Valid Loss: 0.5012537240982056\n",
      "Epoch: 45, Train Loss: 0.4619499146938324, Valid Loss: 0.5010827779769897\n",
      "Epoch: 46, Train Loss: 0.461378276348114, Valid Loss: 0.5008057355880737\n",
      "Epoch: 47, Train Loss: 0.4608151316642761, Valid Loss: 0.5004014372825623\n",
      "Epoch: 48, Train Loss: 0.46027064323425293, Valid Loss: 0.49986347556114197\n",
      "Epoch: 49, Train Loss: 0.4597548544406891, Valid Loss: 0.4992072582244873\n",
      "Epoch: 50, Train Loss: 0.45927444100379944, Valid Loss: 0.4984685480594635\n",
      "Epoch: 51, Train Loss: 0.4588279128074646, Valid Loss: 0.4976913332939148\n",
      "Epoch: 52, Train Loss: 0.45840322971343994, Valid Loss: 0.4969104826450348\n",
      "Epoch: 53, Train Loss: 0.4579819142818451, Valid Loss: 0.4961419999599457\n",
      "Epoch: 54, Train Loss: 0.4575483798980713, Valid Loss: 0.49538668990135193\n",
      "Epoch: 55, Train Loss: 0.45709654688835144, Valid Loss: 0.4946419596672058\n",
      "Epoch: 56, Train Loss: 0.4566311240196228, Valid Loss: 0.49391013383865356\n",
      "Epoch: 57, Train Loss: 0.4561612010002136, Valid Loss: 0.49319449067115784\n",
      "Epoch: 58, Train Loss: 0.4556935727596283, Valid Loss: 0.49248772859573364\n",
      "Epoch: 59, Train Loss: 0.4552304446697235, Valid Loss: 0.4917653203010559\n",
      "Epoch: 60, Train Loss: 0.45477214455604553, Valid Loss: 0.4909910559654236\n",
      "Epoch: 61, Train Loss: 0.45431992411613464, Valid Loss: 0.4901314675807953\n",
      "Epoch: 62, Train Loss: 0.45387589931488037, Valid Loss: 0.48917222023010254\n",
      "Epoch: 63, Train Loss: 0.4534420371055603, Valid Loss: 0.48812544345855713\n",
      "Epoch: 64, Train Loss: 0.45301932096481323, Valid Loss: 0.4870256185531616\n",
      "Epoch: 65, Train Loss: 0.4526077210903168, Valid Loss: 0.4859180152416229\n",
      "Epoch: 66, Train Loss: 0.4522058069705963, Valid Loss: 0.48484504222869873\n",
      "Epoch: 67, Train Loss: 0.4518097937107086, Valid Loss: 0.48383796215057373\n",
      "Epoch: 68, Train Loss: 0.4514150619506836, Valid Loss: 0.48291563987731934\n",
      "Epoch: 69, Train Loss: 0.45101869106292725, Valid Loss: 0.4820879399776459\n",
      "Epoch: 70, Train Loss: 0.4506206810474396, Valid Loss: 0.48135852813720703\n",
      "Epoch: 71, Train Loss: 0.45022347569465637, Valid Loss: 0.4807225465774536\n",
      "Epoch: 72, Train Loss: 0.44983038306236267, Valid Loss: 0.48016566038131714\n",
      "Epoch: 73, Train Loss: 0.44944268465042114, Valid Loss: 0.4796662926673889\n",
      "Epoch: 74, Train Loss: 0.4490599036216736, Valid Loss: 0.4792005121707916\n",
      "Epoch: 75, Train Loss: 0.4486810266971588, Valid Loss: 0.47874733805656433\n",
      "Epoch: 76, Train Loss: 0.44830575585365295, Valid Loss: 0.4782905876636505\n",
      "Epoch: 77, Train Loss: 0.4479345679283142, Valid Loss: 0.47782039642333984\n",
      "Epoch: 78, Train Loss: 0.4475677013397217, Valid Loss: 0.47733473777770996\n",
      "Epoch: 79, Train Loss: 0.4472041726112366, Valid Loss: 0.47684165835380554\n",
      "Epoch: 80, Train Loss: 0.4468434154987335, Valid Loss: 0.4763592481613159\n",
      "Epoch: 81, Train Loss: 0.44648513197898865, Valid Loss: 0.47590798139572144\n",
      "Epoch: 82, Train Loss: 0.4461295008659363, Valid Loss: 0.47549888491630554\n",
      "Epoch: 83, Train Loss: 0.4457760751247406, Valid Loss: 0.47512638568878174\n",
      "Epoch: 84, Train Loss: 0.44542405009269714, Valid Loss: 0.4747699797153473\n",
      "Epoch: 85, Train Loss: 0.44507333636283875, Valid Loss: 0.47440382838249207\n",
      "Epoch: 86, Train Loss: 0.44472452998161316, Valid Loss: 0.47400614619255066\n",
      "Epoch: 87, Train Loss: 0.4443785548210144, Valid Loss: 0.4735645353794098\n",
      "Epoch: 88, Train Loss: 0.44403553009033203, Valid Loss: 0.47307834029197693\n",
      "Epoch: 89, Train Loss: 0.4436950087547302, Valid Loss: 0.4725595712661743\n",
      "Epoch: 90, Train Loss: 0.44335678219795227, Valid Loss: 0.4720304012298584\n",
      "Epoch: 91, Train Loss: 0.4430207908153534, Valid Loss: 0.4715164303779602\n",
      "Epoch: 92, Train Loss: 0.4426872730255127, Valid Loss: 0.47103509306907654\n",
      "Epoch: 93, Train Loss: 0.4423556923866272, Valid Loss: 0.47058799862861633\n",
      "Epoch: 94, Train Loss: 0.4420255422592163, Valid Loss: 0.4701627492904663\n",
      "Epoch: 95, Train Loss: 0.4416966140270233, Valid Loss: 0.4697420597076416\n",
      "Epoch: 96, Train Loss: 0.44136926531791687, Valid Loss: 0.4693143367767334\n",
      "Epoch: 97, Train Loss: 0.441043496131897, Valid Loss: 0.46887972950935364\n",
      "Epoch: 98, Train Loss: 0.4407193064689636, Valid Loss: 0.46845000982284546\n",
      "Epoch: 99, Train Loss: 0.44039681553840637, Valid Loss: 0.46804070472717285\n",
      "Epoch: 100, Train Loss: 0.44007614254951477, Valid Loss: 0.4676612615585327\n",
      "Epoch: 101, Train Loss: 0.43975743651390076, Valid Loss: 0.4673062264919281\n",
      "Epoch: 102, Train Loss: 0.4394407570362091, Valid Loss: 0.46695613861083984\n",
      "Epoch: 103, Train Loss: 0.4391259253025055, Valid Loss: 0.4665878713130951\n",
      "Epoch: 104, Train Loss: 0.4388126730918884, Valid Loss: 0.4661884307861328\n",
      "Epoch: 105, Train Loss: 0.43850117921829224, Valid Loss: 0.46576201915740967\n",
      "Epoch: 106, Train Loss: 0.43819111585617065, Valid Loss: 0.4653269946575165\n",
      "Epoch: 107, Train Loss: 0.4378824234008789, Valid Loss: 0.46490392088890076\n",
      "Epoch: 108, Train Loss: 0.4375750720500946, Valid Loss: 0.46450501680374146\n",
      "Epoch: 109, Train Loss: 0.4372691214084625, Valid Loss: 0.46412813663482666\n",
      "Epoch: 110, Train Loss: 0.43696457147598267, Valid Loss: 0.46376052498817444\n",
      "Epoch: 111, Train Loss: 0.4366612732410431, Valid Loss: 0.46338844299316406\n",
      "Epoch: 112, Train Loss: 0.43635913729667664, Valid Loss: 0.46300604939460754\n",
      "Epoch: 113, Train Loss: 0.43605831265449524, Valid Loss: 0.46261832118034363\n",
      "Epoch: 114, Train Loss: 0.43575868010520935, Valid Loss: 0.4622363746166229\n",
      "Epoch: 115, Train Loss: 0.43546009063720703, Valid Loss: 0.4618692696094513\n",
      "Epoch: 116, Train Loss: 0.43516260385513306, Valid Loss: 0.46151936054229736\n",
      "Epoch: 117, Train Loss: 0.43486613035202026, Valid Loss: 0.4611819386482239\n",
      "Epoch: 118, Train Loss: 0.4345707297325134, Valid Loss: 0.46084898710250854\n",
      "Epoch: 119, Train Loss: 0.434276282787323, Valid Loss: 0.4605141580104828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120, Train Loss: 0.433982789516449, Valid Loss: 0.46017515659332275\n",
      "Epoch: 121, Train Loss: 0.43369027972221375, Valid Loss: 0.45983460545539856\n",
      "Epoch: 122, Train Loss: 0.4333987534046173, Valid Loss: 0.45949721336364746\n",
      "Epoch: 123, Train Loss: 0.43310821056365967, Valid Loss: 0.45916807651519775\n",
      "Epoch: 124, Train Loss: 0.43281856179237366, Valid Loss: 0.45885002613067627\n",
      "Epoch: 125, Train Loss: 0.43252986669540405, Valid Loss: 0.4585416316986084\n",
      "Epoch: 126, Train Loss: 0.4322420656681061, Valid Loss: 0.45823776721954346\n",
      "Epoch: 127, Train Loss: 0.43195515871047974, Valid Loss: 0.45793142914772034\n",
      "Epoch: 128, Train Loss: 0.4316692650318146, Valid Loss: 0.45761844515800476\n",
      "Epoch: 129, Train Loss: 0.4313841164112091, Valid Loss: 0.4573011100292206\n",
      "Epoch: 130, Train Loss: 0.43109995126724243, Valid Loss: 0.4569869637489319\n",
      "Epoch: 131, Train Loss: 0.430816650390625, Valid Loss: 0.4566839337348938\n",
      "Epoch: 132, Train Loss: 0.43053415417671204, Valid Loss: 0.45639389753341675\n",
      "Epoch: 133, Train Loss: 0.4302525222301483, Valid Loss: 0.4561106860637665\n",
      "Epoch: 134, Train Loss: 0.4299718737602234, Valid Loss: 0.4558243453502655\n",
      "Epoch: 135, Train Loss: 0.429691880941391, Valid Loss: 0.45552918314933777\n",
      "Epoch: 136, Train Loss: 0.429412841796875, Valid Loss: 0.4552282989025116\n",
      "Epoch: 137, Train Loss: 0.4291345179080963, Valid Loss: 0.4549304246902466\n",
      "Epoch: 138, Train Loss: 0.4288570284843445, Valid Loss: 0.4546416401863098\n",
      "Epoch: 139, Train Loss: 0.42858028411865234, Valid Loss: 0.45435965061187744\n",
      "Epoch: 140, Train Loss: 0.4283043444156647, Valid Loss: 0.45407649874687195\n",
      "Epoch: 141, Train Loss: 0.4280291199684143, Valid Loss: 0.45378634333610535\n",
      "Epoch: 142, Train Loss: 0.42775458097457886, Valid Loss: 0.45349061489105225\n",
      "Epoch: 143, Train Loss: 0.4274807870388031, Valid Loss: 0.45319655537605286\n",
      "Epoch: 144, Train Loss: 0.4272076487541199, Valid Loss: 0.45291072130203247\n",
      "Epoch: 145, Train Loss: 0.4269351661205292, Valid Loss: 0.45263272523880005\n",
      "Epoch: 146, Train Loss: 0.426663339138031, Valid Loss: 0.4523582458496094\n",
      "Epoch: 147, Train Loss: 0.4263920485973358, Valid Loss: 0.4520822763442993\n",
      "Epoch: 148, Train Loss: 0.4261213541030884, Valid Loss: 0.45180466771125793\n",
      "Epoch: 149, Train Loss: 0.4258512258529663, Valid Loss: 0.4515286386013031\n",
      "Epoch: 150, Train Loss: 0.42558160424232483, Valid Loss: 0.45125702023506165\n",
      "Epoch: 151, Train Loss: 0.42531251907348633, Valid Loss: 0.450990229845047\n",
      "Epoch: 152, Train Loss: 0.42504388093948364, Valid Loss: 0.45072659850120544\n",
      "Epoch: 153, Train Loss: 0.42477574944496155, Valid Loss: 0.45046401023864746\n",
      "Epoch: 154, Train Loss: 0.42450791597366333, Valid Loss: 0.450201153755188\n",
      "Epoch: 155, Train Loss: 0.4242405295372009, Valid Loss: 0.4499378502368927\n",
      "Epoch: 156, Train Loss: 0.42397353053092957, Valid Loss: 0.44967591762542725\n",
      "Epoch: 157, Train Loss: 0.4237067699432373, Valid Loss: 0.44941747188568115\n",
      "Epoch: 158, Train Loss: 0.4234403371810913, Valid Loss: 0.449163019657135\n",
      "Epoch: 159, Train Loss: 0.4231741726398468, Valid Loss: 0.44890984892845154\n",
      "Epoch: 160, Train Loss: 0.42290830612182617, Valid Loss: 0.4486543536186218\n",
      "Epoch: 161, Train Loss: 0.4226425886154175, Valid Loss: 0.4483954608440399\n",
      "Epoch: 162, Train Loss: 0.4223770201206207, Valid Loss: 0.44813674688339233\n",
      "Epoch: 163, Train Loss: 0.4221116602420807, Valid Loss: 0.4478819668292999\n",
      "Epoch: 164, Train Loss: 0.42184633016586304, Valid Loss: 0.44763174653053284\n",
      "Epoch: 165, Train Loss: 0.4215812087059021, Valid Loss: 0.4473825693130493\n",
      "Epoch: 166, Train Loss: 0.42131611704826355, Valid Loss: 0.4471316635608673\n",
      "Epoch: 167, Train Loss: 0.4210509955883026, Valid Loss: 0.446880042552948\n",
      "Epoch: 168, Train Loss: 0.4207859933376312, Valid Loss: 0.446630597114563\n",
      "Epoch: 169, Train Loss: 0.4205208718776703, Valid Loss: 0.4463841915130615\n",
      "Epoch: 170, Train Loss: 0.42025575041770935, Valid Loss: 0.44613876938819885\n",
      "Epoch: 171, Train Loss: 0.419990599155426, Valid Loss: 0.44589194655418396\n",
      "Epoch: 172, Train Loss: 0.41972529888153076, Valid Loss: 0.4456442594528198\n",
      "Epoch: 173, Train Loss: 0.4194599390029907, Valid Loss: 0.44539767503738403\n",
      "Epoch: 174, Train Loss: 0.41919440031051636, Valid Loss: 0.4451528787612915\n",
      "Epoch: 175, Train Loss: 0.41892874240875244, Valid Loss: 0.4449089765548706\n",
      "Epoch: 176, Train Loss: 0.4186629056930542, Valid Loss: 0.4446651339530945\n",
      "Epoch: 177, Train Loss: 0.41839686036109924, Valid Loss: 0.4444212019443512\n",
      "Epoch: 178, Train Loss: 0.4181306064128876, Valid Loss: 0.4441777467727661\n",
      "Epoch: 179, Train Loss: 0.417864054441452, Valid Loss: 0.4439350962638855\n",
      "Epoch: 180, Train Loss: 0.4175972640514374, Valid Loss: 0.4436943531036377\n",
      "Epoch: 181, Train Loss: 0.41733023524284363, Valid Loss: 0.4434552490711212\n",
      "Epoch: 182, Train Loss: 0.4170628786087036, Valid Loss: 0.443217009305954\n",
      "Epoch: 183, Train Loss: 0.41679519414901733, Valid Loss: 0.44297894835472107\n",
      "Epoch: 184, Train Loss: 0.4165271818637848, Valid Loss: 0.44274163246154785\n",
      "Epoch: 185, Train Loss: 0.416258841753006, Valid Loss: 0.4425062835216522\n",
      "Epoch: 186, Train Loss: 0.41599008440971375, Valid Loss: 0.4422728717327118\n",
      "Epoch: 187, Train Loss: 0.41572102904319763, Valid Loss: 0.44204002618789673\n",
      "Epoch: 188, Train Loss: 0.4154515266418457, Valid Loss: 0.4418076276779175\n",
      "Epoch: 189, Train Loss: 0.41518157720565796, Valid Loss: 0.44157645106315613\n",
      "Epoch: 190, Train Loss: 0.4149112403392792, Valid Loss: 0.44134750962257385\n",
      "Epoch: 191, Train Loss: 0.4146404564380646, Valid Loss: 0.44112011790275574\n",
      "Epoch: 192, Train Loss: 0.414369136095047, Valid Loss: 0.44089362025260925\n",
      "Epoch: 193, Train Loss: 0.41409745812416077, Valid Loss: 0.44066891074180603\n",
      "Epoch: 194, Train Loss: 0.4138251841068268, Valid Loss: 0.4404464364051819\n",
      "Epoch: 195, Train Loss: 0.41355234384536743, Valid Loss: 0.44022616744041443\n",
      "Epoch: 196, Train Loss: 0.4132790267467499, Valid Loss: 0.44000789523124695\n",
      "Epoch: 197, Train Loss: 0.41300517320632935, Valid Loss: 0.4397915303707123\n",
      "Epoch: 198, Train Loss: 0.41273069381713867, Valid Loss: 0.43957749009132385\n",
      "Epoch: 199, Train Loss: 0.41245555877685547, Valid Loss: 0.43936577439308167\n",
      "Epoch: 200, Train Loss: 0.4121798276901245, Valid Loss: 0.4391566514968872\n",
      "Epoch: 201, Train Loss: 0.411903440952301, Valid Loss: 0.4389503598213196\n",
      "Epoch: 202, Train Loss: 0.411626398563385, Valid Loss: 0.4387464225292206\n",
      "Epoch: 203, Train Loss: 0.41134870052337646, Valid Loss: 0.43854430317878723\n",
      "Epoch: 204, Train Loss: 0.41107043623924255, Valid Loss: 0.4383438527584076\n",
      "Epoch: 205, Train Loss: 0.4107915163040161, Valid Loss: 0.4381447732448578\n",
      "Epoch: 206, Train Loss: 0.41051214933395386, Valid Loss: 0.4379461407661438\n",
      "Epoch: 207, Train Loss: 0.41023221611976624, Valid Loss: 0.43774697184562683\n",
      "Epoch: 208, Train Loss: 0.40995198488235474, Valid Loss: 0.4375460743904114\n",
      "Epoch: 209, Train Loss: 0.40967148542404175, Valid Loss: 0.43734318017959595\n",
      "Epoch: 210, Train Loss: 0.40939074754714966, Valid Loss: 0.4371376037597656\n",
      "Epoch: 211, Train Loss: 0.409109890460968, Valid Loss: 0.43692904710769653\n",
      "Epoch: 212, Train Loss: 0.4088289439678192, Valid Loss: 0.43671754002571106\n",
      "Epoch: 213, Train Loss: 0.4085480868816376, Valid Loss: 0.43650370836257935\n",
      "Epoch: 214, Train Loss: 0.4082672894001007, Valid Loss: 0.43628764152526855\n",
      "Epoch: 215, Train Loss: 0.40798649191856384, Valid Loss: 0.43606939911842346\n",
      "Epoch: 216, Train Loss: 0.40770575404167175, Valid Loss: 0.43584904074668884\n",
      "Epoch: 217, Train Loss: 0.40742501616477966, Valid Loss: 0.43562600016593933\n",
      "Epoch: 218, Train Loss: 0.407144159078598, Valid Loss: 0.43540114164352417\n",
      "Epoch: 219, Train Loss: 0.4068632125854492, Valid Loss: 0.43517521023750305\n",
      "Epoch: 220, Train Loss: 0.40658193826675415, Valid Loss: 0.43494895100593567\n",
      "Epoch: 221, Train Loss: 0.40630021691322327, Valid Loss: 0.43472281098365784\n",
      "Epoch: 222, Train Loss: 0.40601804852485657, Valid Loss: 0.4344976544380188\n",
      "Epoch: 223, Train Loss: 0.4057352840900421, Valid Loss: 0.434273362159729\n",
      "Epoch: 224, Train Loss: 0.40545180439949036, Valid Loss: 0.43404924869537354\n",
      "Epoch: 225, Train Loss: 0.40516749024391174, Valid Loss: 0.4338252544403076\n",
      "Epoch: 226, Train Loss: 0.4048823416233063, Valid Loss: 0.4336009919643402\n",
      "Epoch: 227, Train Loss: 0.4045962393283844, Valid Loss: 0.4333765506744385\n",
      "Epoch: 228, Train Loss: 0.4043092429637909, Valid Loss: 0.43315255641937256\n",
      "Epoch: 229, Train Loss: 0.40402114391326904, Valid Loss: 0.43292921781539917\n",
      "Epoch: 230, Train Loss: 0.403732031583786, Valid Loss: 0.43270665407180786\n",
      "Epoch: 231, Train Loss: 0.4034419357776642, Valid Loss: 0.43248477578163147\n",
      "Epoch: 232, Train Loss: 0.4031507670879364, Valid Loss: 0.4322631359100342\n",
      "Epoch: 233, Train Loss: 0.40285855531692505, Valid Loss: 0.4320404827594757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 234, Train Loss: 0.40256527066230774, Valid Loss: 0.43181687593460083\n",
      "Epoch: 235, Train Loss: 0.40227100253105164, Valid Loss: 0.4315924048423767\n",
      "Epoch: 236, Train Loss: 0.4019755423069, Valid Loss: 0.4313666820526123\n",
      "Epoch: 237, Train Loss: 0.40167906880378723, Valid Loss: 0.43114033341407776\n",
      "Epoch: 238, Train Loss: 0.4013814628124237, Valid Loss: 0.43091315031051636\n",
      "Epoch: 239, Train Loss: 0.4010826349258423, Valid Loss: 0.4306846857070923\n",
      "Epoch: 240, Train Loss: 0.40078267455101013, Valid Loss: 0.430454820394516\n",
      "Epoch: 241, Train Loss: 0.40048152208328247, Valid Loss: 0.430223286151886\n",
      "Epoch: 242, Train Loss: 0.40017902851104736, Valid Loss: 0.42998942732810974\n",
      "Epoch: 243, Train Loss: 0.39987534284591675, Valid Loss: 0.42975372076034546\n",
      "Epoch: 244, Train Loss: 0.3995702266693115, Valid Loss: 0.4295162260532379\n",
      "Epoch: 245, Train Loss: 0.39926382899284363, Valid Loss: 0.4292769134044647\n",
      "Epoch: 246, Train Loss: 0.39895591139793396, Valid Loss: 0.429035484790802\n",
      "Epoch: 247, Train Loss: 0.3986465036869049, Valid Loss: 0.42879238724708557\n",
      "Epoch: 248, Train Loss: 0.39833563566207886, Valid Loss: 0.4285465478897095\n",
      "Epoch: 249, Train Loss: 0.3980231285095215, Valid Loss: 0.4282981753349304\n",
      "Epoch: 250, Train Loss: 0.3977090120315552, Valid Loss: 0.4280470013618469\n",
      "Epoch: 251, Train Loss: 0.39739322662353516, Valid Loss: 0.4277929961681366\n",
      "Epoch: 252, Train Loss: 0.3970758020877838, Valid Loss: 0.4275365471839905\n",
      "Epoch: 253, Train Loss: 0.39675667881965637, Valid Loss: 0.4272771179676056\n",
      "Epoch: 254, Train Loss: 0.3964357078075409, Valid Loss: 0.42701447010040283\n",
      "Epoch: 255, Train Loss: 0.3961128890514374, Valid Loss: 0.4267485737800598\n",
      "Epoch: 256, Train Loss: 0.3957882225513458, Valid Loss: 0.4264795184135437\n",
      "Epoch: 257, Train Loss: 0.39546167850494385, Valid Loss: 0.42620670795440674\n",
      "Epoch: 258, Train Loss: 0.39513319730758667, Valid Loss: 0.42593085765838623\n",
      "Epoch: 259, Train Loss: 0.39480268955230713, Valid Loss: 0.42565208673477173\n",
      "Epoch: 260, Train Loss: 0.39447012543678284, Valid Loss: 0.4253695607185364\n",
      "Epoch: 261, Train Loss: 0.3941355049610138, Valid Loss: 0.42508381605148315\n",
      "Epoch: 262, Train Loss: 0.39379873871803284, Valid Loss: 0.42479461431503296\n",
      "Epoch: 263, Train Loss: 0.39345991611480713, Valid Loss: 0.4245012402534485\n",
      "Epoch: 264, Train Loss: 0.3931187391281128, Valid Loss: 0.4242039620876312\n",
      "Epoch: 265, Train Loss: 0.39277535676956177, Valid Loss: 0.42390331625938416\n",
      "Epoch: 266, Train Loss: 0.3924296796321869, Valid Loss: 0.4235987961292267\n",
      "Epoch: 267, Train Loss: 0.3920815587043762, Valid Loss: 0.42329075932502747\n",
      "Epoch: 268, Train Loss: 0.3917311131954193, Valid Loss: 0.42297911643981934\n",
      "Epoch: 269, Train Loss: 0.39137813448905945, Valid Loss: 0.42266297340393066\n",
      "Epoch: 270, Train Loss: 0.3910226821899414, Valid Loss: 0.42234307527542114\n",
      "Epoch: 271, Train Loss: 0.3906647264957428, Valid Loss: 0.42201876640319824\n",
      "Epoch: 272, Train Loss: 0.3903041183948517, Valid Loss: 0.4216892719268799\n",
      "Epoch: 273, Train Loss: 0.3899409770965576, Valid Loss: 0.4213566184043884\n",
      "Epoch: 274, Train Loss: 0.38957521319389343, Valid Loss: 0.4210186302661896\n",
      "Epoch: 275, Train Loss: 0.3892067074775696, Valid Loss: 0.42067578434944153\n",
      "Epoch: 276, Train Loss: 0.38883543014526367, Valid Loss: 0.42032891511917114\n",
      "Epoch: 277, Train Loss: 0.3884614109992981, Valid Loss: 0.4199758768081665\n",
      "Epoch: 278, Train Loss: 0.38808462023735046, Valid Loss: 0.41961756348609924\n",
      "Epoch: 279, Train Loss: 0.387704998254776, Valid Loss: 0.4192544221878052\n",
      "Epoch: 280, Train Loss: 0.3873225748538971, Valid Loss: 0.41888535022735596\n",
      "Epoch: 281, Train Loss: 0.3869372606277466, Valid Loss: 0.41851097345352173\n",
      "Epoch: 282, Train Loss: 0.3865490257740021, Valid Loss: 0.41813111305236816\n",
      "Epoch: 283, Train Loss: 0.38615792989730835, Valid Loss: 0.4177452027797699\n",
      "Epoch: 284, Train Loss: 0.385763943195343, Valid Loss: 0.4173537790775299\n",
      "Epoch: 285, Train Loss: 0.3853670358657837, Valid Loss: 0.41695618629455566\n",
      "Epoch: 286, Train Loss: 0.3849670886993408, Valid Loss: 0.41655242443084717\n",
      "Epoch: 287, Train Loss: 0.3845643103122711, Valid Loss: 0.4161433279514313\n",
      "Epoch: 288, Train Loss: 0.38415852189064026, Valid Loss: 0.4157274663448334\n",
      "Epoch: 289, Train Loss: 0.38374990224838257, Valid Loss: 0.41530632972717285\n",
      "Epoch: 290, Train Loss: 0.38333824276924133, Valid Loss: 0.4148789644241333\n",
      "Epoch: 291, Train Loss: 0.3829236328601837, Valid Loss: 0.41444605588912964\n",
      "Epoch: 292, Train Loss: 0.38250619173049927, Valid Loss: 0.4140070974826813\n",
      "Epoch: 293, Train Loss: 0.38208577036857605, Valid Loss: 0.4135627746582031\n",
      "Epoch: 294, Train Loss: 0.381662517786026, Valid Loss: 0.4131125509738922\n",
      "Epoch: 295, Train Loss: 0.38123631477355957, Valid Loss: 0.41265669465065\n",
      "Epoch: 296, Train Loss: 0.3808072507381439, Valid Loss: 0.41219547390937805\n",
      "Epoch: 297, Train Loss: 0.3803754150867462, Valid Loss: 0.41172897815704346\n",
      "Epoch: 298, Train Loss: 0.3799406886100769, Valid Loss: 0.41125771403312683\n",
      "Epoch: 299, Train Loss: 0.37950319051742554, Valid Loss: 0.4107801020145416\n",
      "Epoch: 300, Train Loss: 0.3790629804134369, Valid Loss: 0.4102998375892639\n",
      "Epoch: 301, Train Loss: 0.3786199986934662, Valid Loss: 0.4098115861415863\n",
      "Epoch: 302, Train Loss: 0.3781742453575134, Valid Loss: 0.4093233346939087\n",
      "Epoch: 303, Train Loss: 0.3777258098125458, Valid Loss: 0.40882328152656555\n",
      "Epoch: 304, Train Loss: 0.3772747218608856, Valid Loss: 0.4083303213119507\n",
      "Epoch: 305, Train Loss: 0.37682104110717773, Valid Loss: 0.40781310200691223\n",
      "Epoch: 306, Train Loss: 0.3763647973537445, Valid Loss: 0.40732911229133606\n",
      "Epoch: 307, Train Loss: 0.3759060800075531, Valid Loss: 0.4067702889442444\n",
      "Epoch: 308, Train Loss: 0.3754451870918274, Valid Loss: 0.4063434600830078\n",
      "Epoch: 309, Train Loss: 0.3749830722808838, Valid Loss: 0.4056520164012909\n",
      "Epoch: 310, Train Loss: 0.37452375888824463, Valid Loss: 0.4054822027683258\n",
      "Epoch: 311, Train Loss: 0.37407827377319336, Valid Loss: 0.4043094217777252\n",
      "Epoch: 312, Train Loss: 0.3736630082130432, Valid Loss: 0.4050619900226593\n",
      "Epoch: 313, Train Loss: 0.3732062876224518, Valid Loss: 0.4027958810329437\n",
      "Epoch: 314, Train Loss: 0.37266987562179565, Valid Loss: 0.4038606286048889\n",
      "Epoch: 315, Train Loss: 0.37217023968696594, Valid Loss: 0.4026326835155487\n",
      "Epoch: 316, Train Loss: 0.3717224597930908, Valid Loss: 0.4013657867908478\n",
      "Epoch: 317, Train Loss: 0.37123826146125793, Valid Loss: 0.40241318941116333\n",
      "Epoch: 318, Train Loss: 0.37072402238845825, Valid Loss: 0.4009544253349304\n",
      "Epoch: 319, Train Loss: 0.3702567219734192, Valid Loss: 0.3996756076812744\n",
      "Epoch: 320, Train Loss: 0.3697778582572937, Valid Loss: 0.40077054500579834\n",
      "Epoch: 321, Train Loss: 0.3692561984062195, Valid Loss: 0.39934930205345154\n",
      "Epoch: 322, Train Loss: 0.3687923550605774, Valid Loss: 0.39816710352897644\n",
      "Epoch: 323, Train Loss: 0.3682902753353119, Valid Loss: 0.3987067937850952\n",
      "Epoch: 324, Train Loss: 0.3677861988544464, Valid Loss: 0.39773690700531006\n",
      "Epoch: 325, Train Loss: 0.36730191111564636, Valid Loss: 0.39676886796951294\n",
      "Epoch: 326, Train Loss: 0.36679860949516296, Valid Loss: 0.39672261476516724\n",
      "Epoch: 327, Train Loss: 0.3662973940372467, Valid Loss: 0.3960728347301483\n",
      "Epoch: 328, Train Loss: 0.3657953143119812, Valid Loss: 0.39506804943084717\n",
      "Epoch: 329, Train Loss: 0.36530056595802307, Valid Loss: 0.39506226778030396\n",
      "Epoch: 330, Train Loss: 0.36478516459465027, Valid Loss: 0.3942624628543854\n",
      "Epoch: 331, Train Loss: 0.36428651213645935, Valid Loss: 0.39341139793395996\n",
      "Epoch: 332, Train Loss: 0.3637818694114685, Valid Loss: 0.3933553397655487\n",
      "Epoch: 333, Train Loss: 0.36326703429222107, Valid Loss: 0.3923989236354828\n",
      "Epoch: 334, Train Loss: 0.3627629280090332, Valid Loss: 0.391874223947525\n",
      "Epoch: 335, Train Loss: 0.3622525632381439, Valid Loss: 0.3915213644504547\n",
      "Epoch: 336, Train Loss: 0.3617388606071472, Valid Loss: 0.3906813859939575\n",
      "Epoch: 337, Train Loss: 0.3612266480922699, Valid Loss: 0.3900938332080841\n",
      "Epoch: 338, Train Loss: 0.3607151508331299, Valid Loss: 0.3898499608039856\n",
      "Epoch: 339, Train Loss: 0.36019963026046753, Valid Loss: 0.3888872563838959\n",
      "Epoch: 340, Train Loss: 0.3596823215484619, Valid Loss: 0.3884115517139435\n",
      "Epoch: 341, Train Loss: 0.35916873812675476, Valid Loss: 0.3880942165851593\n",
      "Epoch: 342, Train Loss: 0.3586517572402954, Valid Loss: 0.38706761598587036\n",
      "Epoch: 343, Train Loss: 0.3581312596797943, Valid Loss: 0.3868085443973541\n",
      "Epoch: 344, Train Loss: 0.3576148748397827, Valid Loss: 0.38622811436653137\n",
      "Epoch: 345, Train Loss: 0.3570960760116577, Valid Loss: 0.3853742480278015\n",
      "Epoch: 346, Train Loss: 0.3565749228000641, Valid Loss: 0.38499152660369873\n",
      "Epoch: 347, Train Loss: 0.3560551404953003, Valid Loss: 0.38452789187431335\n",
      "Epoch: 348, Train Loss: 0.35553422570228577, Valid Loss: 0.3836061954498291\n",
      "Epoch: 349, Train Loss: 0.3550143539905548, Valid Loss: 0.38334259390830994\n",
      "Epoch: 350, Train Loss: 0.3544914722442627, Valid Loss: 0.38255560398101807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 351, Train Loss: 0.3539693355560303, Valid Loss: 0.382112592458725\n",
      "Epoch: 352, Train Loss: 0.3534488379955292, Valid Loss: 0.38148263096809387\n",
      "Epoch: 353, Train Loss: 0.3529259264469147, Valid Loss: 0.3808394968509674\n",
      "Epoch: 354, Train Loss: 0.3524033725261688, Valid Loss: 0.38033050298690796\n",
      "Epoch: 355, Train Loss: 0.35188090801239014, Valid Loss: 0.3798603415489197\n",
      "Epoch: 356, Train Loss: 0.3513587415218353, Valid Loss: 0.3789623975753784\n",
      "Epoch: 357, Train Loss: 0.35083675384521484, Valid Loss: 0.37879958748817444\n",
      "Epoch: 358, Train Loss: 0.35031434893608093, Valid Loss: 0.377829372882843\n",
      "Epoch: 359, Train Loss: 0.34979191422462463, Valid Loss: 0.3776141405105591\n",
      "Epoch: 360, Train Loss: 0.34927043318748474, Valid Loss: 0.3767082691192627\n",
      "Epoch: 361, Train Loss: 0.3487492501735687, Valid Loss: 0.37643635272979736\n",
      "Epoch: 362, Train Loss: 0.34822776913642883, Valid Loss: 0.3755917251110077\n",
      "Epoch: 363, Train Loss: 0.3477064073085785, Valid Loss: 0.3753246068954468\n",
      "Epoch: 364, Train Loss: 0.34718501567840576, Valid Loss: 0.37440451979637146\n",
      "Epoch: 365, Train Loss: 0.3466639816761017, Valid Loss: 0.37420690059661865\n",
      "Epoch: 366, Train Loss: 0.34614381194114685, Valid Loss: 0.3732982873916626\n",
      "Epoch: 367, Train Loss: 0.3456243872642517, Valid Loss: 0.3730168640613556\n",
      "Epoch: 368, Train Loss: 0.34510529041290283, Valid Loss: 0.3722606301307678\n",
      "Epoch: 369, Train Loss: 0.3445870578289032, Valid Loss: 0.3717723786830902\n",
      "Epoch: 370, Train Loss: 0.34406933188438416, Valid Loss: 0.3712824881076813\n",
      "Epoch: 371, Train Loss: 0.34355229139328003, Valid Loss: 0.3705478012561798\n",
      "Epoch: 372, Train Loss: 0.3430361747741699, Valid Loss: 0.37023308873176575\n",
      "Epoch: 373, Train Loss: 0.34252089262008667, Valid Loss: 0.3694053590297699\n",
      "Epoch: 374, Train Loss: 0.34200650453567505, Valid Loss: 0.36917224526405334\n",
      "Epoch: 375, Train Loss: 0.3414929211139679, Valid Loss: 0.368246853351593\n",
      "Epoch: 376, Train Loss: 0.3409803807735443, Valid Loss: 0.36813002824783325\n",
      "Epoch: 377, Train Loss: 0.3404686748981476, Valid Loss: 0.3671203553676605\n",
      "Epoch: 378, Train Loss: 0.33995816111564636, Valid Loss: 0.36707618832588196\n",
      "Epoch: 379, Train Loss: 0.3394487500190735, Valid Loss: 0.3659724295139313\n",
      "Epoch: 380, Train Loss: 0.3389410078525543, Valid Loss: 0.36611035466194153\n",
      "Epoch: 381, Train Loss: 0.33843496441841125, Valid Loss: 0.3647376596927643\n",
      "Epoch: 382, Train Loss: 0.3379312753677368, Valid Loss: 0.3652511537075043\n",
      "Epoch: 383, Train Loss: 0.33743050694465637, Valid Loss: 0.36342018842697144\n",
      "Epoch: 384, Train Loss: 0.3369329869747162, Valid Loss: 0.3645164370536804\n",
      "Epoch: 385, Train Loss: 0.3364366590976715, Valid Loss: 0.3620619475841522\n",
      "Epoch: 386, Train Loss: 0.33593857288360596, Valid Loss: 0.3636946380138397\n",
      "Epoch: 387, Train Loss: 0.33543315529823303, Valid Loss: 0.36101993918418884\n",
      "Epoch: 388, Train Loss: 0.33492082357406616, Valid Loss: 0.3622894287109375\n",
      "Epoch: 389, Train Loss: 0.33441001176834106, Valid Loss: 0.36062562465667725\n",
      "Epoch: 390, Train Loss: 0.33390897512435913, Valid Loss: 0.360380083322525\n",
      "Epoch: 391, Train Loss: 0.3334183692932129, Valid Loss: 0.36042821407318115\n",
      "Epoch: 392, Train Loss: 0.3329320549964905, Valid Loss: 0.3587617874145508\n",
      "Epoch: 393, Train Loss: 0.332442969083786, Valid Loss: 0.3597324788570404\n",
      "Epoch: 394, Train Loss: 0.33194753527641296, Valid Loss: 0.35773321986198425\n",
      "Epoch: 395, Train Loss: 0.33144906163215637, Valid Loss: 0.3583981990814209\n",
      "Epoch: 396, Train Loss: 0.3309539258480072, Valid Loss: 0.35724472999572754\n",
      "Epoch: 397, Train Loss: 0.33046600222587585, Valid Loss: 0.35673192143440247\n",
      "Epoch: 398, Train Loss: 0.32998377084732056, Valid Loss: 0.3568459749221802\n",
      "Epoch: 399, Train Loss: 0.3295028805732727, Valid Loss: 0.35534244775772095\n",
      "Epoch: 400, Train Loss: 0.3290202021598816, Valid Loss: 0.35603150725364685\n",
      "Epoch: 401, Train Loss: 0.32853490114212036, Valid Loss: 0.35440748929977417\n",
      "Epoch: 402, Train Loss: 0.3280493915081024, Valid Loss: 0.3547686040401459\n",
      "Epoch: 403, Train Loss: 0.32756656408309937, Valid Loss: 0.35382750630378723\n",
      "Epoch: 404, Train Loss: 0.32708799839019775, Valid Loss: 0.353335976600647\n",
      "Epoch: 405, Train Loss: 0.32661306858062744, Valid Loss: 0.353261262178421\n",
      "Epoch: 406, Train Loss: 0.32614001631736755, Valid Loss: 0.3520902693271637\n",
      "Epoch: 407, Train Loss: 0.32566750049591064, Valid Loss: 0.3524863123893738\n",
      "Epoch: 408, Train Loss: 0.32519474625587463, Valid Loss: 0.3510652184486389\n",
      "Epoch: 409, Train Loss: 0.3247218430042267, Valid Loss: 0.35147586464881897\n",
      "Epoch: 410, Train Loss: 0.32424962520599365, Valid Loss: 0.35026809573173523\n",
      "Epoch: 411, Train Loss: 0.32377904653549194, Valid Loss: 0.35029837489128113\n",
      "Epoch: 412, Train Loss: 0.3233104944229126, Valid Loss: 0.3495703935623169\n",
      "Epoch: 413, Train Loss: 0.32284414768218994, Valid Loss: 0.34912222623825073\n",
      "Epoch: 414, Train Loss: 0.3223797380924225, Valid Loss: 0.34886670112609863\n",
      "Epoch: 415, Train Loss: 0.32191717624664307, Valid Loss: 0.3479962944984436\n",
      "Epoch: 416, Train Loss: 0.32145631313323975, Valid Loss: 0.3480977714061737\n",
      "Epoch: 417, Train Loss: 0.32099688053131104, Valid Loss: 0.3469562530517578\n",
      "Epoch: 418, Train Loss: 0.3205391466617584, Valid Loss: 0.3472784459590912\n",
      "Epoch: 419, Train Loss: 0.32008302211761475, Valid Loss: 0.3459463119506836\n",
      "Epoch: 420, Train Loss: 0.3196289539337158, Valid Loss: 0.34647873044013977\n",
      "Epoch: 421, Train Loss: 0.3191770315170288, Valid Loss: 0.34494656324386597\n",
      "Epoch: 422, Train Loss: 0.3187270164489746, Valid Loss: 0.34569069743156433\n",
      "Epoch: 423, Train Loss: 0.31827831268310547, Valid Loss: 0.34395405650138855\n",
      "Epoch: 424, Train Loss: 0.31782910227775574, Valid Loss: 0.3449126183986664\n",
      "Epoch: 425, Train Loss: 0.31737756729125977, Valid Loss: 0.34296515583992004\n",
      "Epoch: 426, Train Loss: 0.31692343950271606, Valid Loss: 0.3440719544887543\n",
      "Epoch: 427, Train Loss: 0.3164689838886261, Valid Loss: 0.34210026264190674\n",
      "Epoch: 428, Train Loss: 0.3160170316696167, Valid Loss: 0.3430095314979553\n",
      "Epoch: 429, Train Loss: 0.3155686557292938, Valid Loss: 0.3415343761444092\n",
      "Epoch: 430, Train Loss: 0.3151237666606903, Valid Loss: 0.3416993319988251\n",
      "Epoch: 431, Train Loss: 0.31468120217323303, Valid Loss: 0.3411704897880554\n",
      "Epoch: 432, Train Loss: 0.3142406940460205, Valid Loss: 0.3403097987174988\n",
      "Epoch: 433, Train Loss: 0.3138023614883423, Valid Loss: 0.34079307317733765\n",
      "Epoch: 434, Train Loss: 0.3133658766746521, Valid Loss: 0.3390366733074188\n",
      "Epoch: 435, Train Loss: 0.3129304051399231, Valid Loss: 0.3402389883995056\n",
      "Epoch: 436, Train Loss: 0.3124944269657135, Valid Loss: 0.3380131125450134\n",
      "Epoch: 437, Train Loss: 0.3120573163032532, Valid Loss: 0.33940932154655457\n",
      "Epoch: 438, Train Loss: 0.31161901354789734, Valid Loss: 0.3372911810874939\n",
      "Epoch: 439, Train Loss: 0.31118080019950867, Valid Loss: 0.33829057216644287\n",
      "Epoch: 440, Train Loss: 0.31074410676956177, Valid Loss: 0.3368009626865387\n",
      "Epoch: 441, Train Loss: 0.31030982732772827, Valid Loss: 0.33703938126564026\n",
      "Epoch: 442, Train Loss: 0.30987784266471863, Valid Loss: 0.33636343479156494\n",
      "Epoch: 443, Train Loss: 0.309447705745697, Valid Loss: 0.335828959941864\n",
      "Epoch: 444, Train Loss: 0.3090190589427948, Valid Loss: 0.33585605025291443\n",
      "Epoch: 445, Train Loss: 0.30859169363975525, Valid Loss: 0.3347201943397522\n",
      "Epoch: 446, Train Loss: 0.3081657290458679, Valid Loss: 0.33527499437332153\n",
      "Epoch: 447, Train Loss: 0.3077412545681, Valid Loss: 0.3336735963821411\n",
      "Epoch: 448, Train Loss: 0.30731868743896484, Valid Loss: 0.3346759080886841\n",
      "Epoch: 449, Train Loss: 0.3068980276584625, Valid Loss: 0.3326295018196106\n",
      "Epoch: 450, Train Loss: 0.306479275226593, Valid Loss: 0.33411499857902527\n",
      "Epoch: 451, Train Loss: 0.3060618042945862, Valid Loss: 0.3315548002719879\n",
      "Epoch: 452, Train Loss: 0.30564403533935547, Valid Loss: 0.33356425166130066\n",
      "Epoch: 453, Train Loss: 0.3052237033843994, Valid Loss: 0.330567866563797\n",
      "Epoch: 454, Train Loss: 0.30479931831359863, Valid Loss: 0.3327789306640625\n",
      "Epoch: 455, Train Loss: 0.3043726980686188, Valid Loss: 0.32992127537727356\n",
      "Epoch: 456, Train Loss: 0.30394789576530457, Valid Loss: 0.33158543705940247\n",
      "Epoch: 457, Train Loss: 0.3035261631011963, Valid Loss: 0.3296513855457306\n",
      "Epoch: 458, Train Loss: 0.3031068444252014, Valid Loss: 0.330122172832489\n",
      "Epoch: 459, Train Loss: 0.30268681049346924, Valid Loss: 0.3296010494232178\n",
      "Epoch: 460, Train Loss: 0.3022710382938385, Valid Loss: 0.32853028178215027\n",
      "Epoch: 461, Train Loss: 0.3018609583377838, Valid Loss: 0.3295236825942993\n",
      "Epoch: 462, Train Loss: 0.30145183205604553, Valid Loss: 0.3272019922733307\n",
      "Epoch: 463, Train Loss: 0.3010382652282715, Valid Loss: 0.32897353172302246\n",
      "Epoch: 464, Train Loss: 0.3006189167499542, Valid Loss: 0.32652777433395386\n",
      "Epoch: 465, Train Loss: 0.3002004623413086, Valid Loss: 0.3276725709438324\n",
      "Epoch: 466, Train Loss: 0.29978683590888977, Valid Loss: 0.3264067471027374\n",
      "Epoch: 467, Train Loss: 0.2993752062320709, Valid Loss: 0.3262300491333008\n",
      "Epoch: 468, Train Loss: 0.2989625334739685, Valid Loss: 0.3260832130908966\n",
      "Epoch: 469, Train Loss: 0.2985498607158661, Valid Loss: 0.3252111077308655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 470, Train Loss: 0.2981405258178711, Valid Loss: 0.32533401250839233\n",
      "Epoch: 471, Train Loss: 0.29773443937301636, Valid Loss: 0.3244476020336151\n",
      "Epoch: 472, Train Loss: 0.2973286211490631, Valid Loss: 0.324625164270401\n",
      "Epoch: 473, Train Loss: 0.2969212532043457, Valid Loss: 0.3234608471393585\n",
      "Epoch: 474, Train Loss: 0.29651403427124023, Valid Loss: 0.32418519258499146\n",
      "Epoch: 475, Train Loss: 0.2961084246635437, Valid Loss: 0.3222992718219757\n",
      "Epoch: 476, Train Loss: 0.2957046627998352, Valid Loss: 0.32374417781829834\n",
      "Epoch: 477, Train Loss: 0.2953013479709625, Valid Loss: 0.32128676772117615\n",
      "Epoch: 478, Train Loss: 0.2948974072933197, Valid Loss: 0.3230917453765869\n",
      "Epoch: 479, Train Loss: 0.294492244720459, Valid Loss: 0.32049521803855896\n",
      "Epoch: 480, Train Loss: 0.29408660531044006, Valid Loss: 0.3222333490848541\n",
      "Epoch: 481, Train Loss: 0.29368096590042114, Valid Loss: 0.31987395882606506\n",
      "Epoch: 482, Train Loss: 0.29327479004859924, Valid Loss: 0.3212418258190155\n",
      "Epoch: 483, Train Loss: 0.2928675711154938, Valid Loss: 0.31936219334602356\n",
      "Epoch: 484, Train Loss: 0.29246002435684204, Valid Loss: 0.3201550543308258\n",
      "Epoch: 485, Train Loss: 0.2920536398887634, Valid Loss: 0.31889593601226807\n",
      "Epoch: 486, Train Loss: 0.2916494607925415, Valid Loss: 0.31908321380615234\n",
      "Epoch: 487, Train Loss: 0.2912473976612091, Valid Loss: 0.31838276982307434\n",
      "Epoch: 488, Train Loss: 0.2908467650413513, Valid Loss: 0.3180832266807556\n",
      "Epoch: 489, Train Loss: 0.2904466688632965, Valid Loss: 0.3178444802761078\n",
      "Epoch: 490, Train Loss: 0.2900468409061432, Valid Loss: 0.31707629561424255\n",
      "Epoch: 491, Train Loss: 0.2896474599838257, Valid Loss: 0.3173424303531647\n",
      "Epoch: 492, Train Loss: 0.2892489731311798, Valid Loss: 0.31600818037986755\n",
      "Epoch: 493, Train Loss: 0.28885212540626526, Valid Loss: 0.31690800189971924\n",
      "Epoch: 494, Train Loss: 0.2884574234485626, Valid Loss: 0.3148716390132904\n",
      "Epoch: 495, Train Loss: 0.28806591033935547, Valid Loss: 0.31658047437667847\n",
      "Epoch: 496, Train Loss: 0.28767821192741394, Valid Loss: 0.31363770365715027\n",
      "Epoch: 497, Train Loss: 0.28729379177093506, Valid Loss: 0.31638872623443604\n",
      "Epoch: 498, Train Loss: 0.28690779209136963, Valid Loss: 0.31241440773010254\n",
      "Epoch: 499, Train Loss: 0.28651493787765503, Valid Loss: 0.3159336745738983\n",
      "Epoch: 500, Train Loss: 0.28611207008361816, Valid Loss: 0.3117714822292328\n",
      "Epoch: 501, Train Loss: 0.2856982350349426, Valid Loss: 0.3144945800304413\n",
      "Epoch: 502, Train Loss: 0.2852805554866791, Valid Loss: 0.31208765506744385\n",
      "Epoch: 503, Train Loss: 0.2848717272281647, Valid Loss: 0.3122860789299011\n",
      "Epoch: 504, Train Loss: 0.2844787538051605, Valid Loss: 0.31263303756713867\n",
      "Epoch: 505, Train Loss: 0.28409647941589355, Valid Loss: 0.3105647563934326\n",
      "Epoch: 506, Train Loss: 0.28371304273605347, Valid Loss: 0.3124140501022339\n",
      "Epoch: 507, Train Loss: 0.28331872820854187, Valid Loss: 0.30977436900138855\n",
      "Epoch: 508, Train Loss: 0.28291264176368713, Valid Loss: 0.3113028109073639\n",
      "Epoch: 509, Train Loss: 0.2825057804584503, Valid Loss: 0.309587299823761\n",
      "Epoch: 510, Train Loss: 0.28210827708244324, Valid Loss: 0.30977028608322144\n",
      "Epoch: 511, Train Loss: 0.28172028064727783, Valid Loss: 0.3095976710319519\n",
      "Epoch: 512, Train Loss: 0.281333863735199, Valid Loss: 0.308357298374176\n",
      "Epoch: 513, Train Loss: 0.2809428870677948, Valid Loss: 0.3093700706958771\n",
      "Epoch: 514, Train Loss: 0.2805478870868683, Valid Loss: 0.3072955012321472\n",
      "Epoch: 515, Train Loss: 0.2801523208618164, Valid Loss: 0.30857744812965393\n",
      "Epoch: 516, Train Loss: 0.27975860238075256, Valid Loss: 0.30685386061668396\n",
      "Epoch: 517, Train Loss: 0.279366672039032, Valid Loss: 0.307257741689682\n",
      "Epoch: 518, Train Loss: 0.27897441387176514, Valid Loss: 0.3067117929458618\n",
      "Epoch: 519, Train Loss: 0.27858197689056396, Valid Loss: 0.3059498965740204\n",
      "Epoch: 520, Train Loss: 0.27819088101387024, Valid Loss: 0.30635371804237366\n",
      "Epoch: 521, Train Loss: 0.2778022289276123, Valid Loss: 0.3049682676792145\n",
      "Epoch: 522, Train Loss: 0.27741459012031555, Valid Loss: 0.3056771755218506\n",
      "Epoch: 523, Train Loss: 0.2770250737667084, Valid Loss: 0.3042483925819397\n",
      "Epoch: 524, Train Loss: 0.2766331434249878, Valid Loss: 0.30480220913887024\n",
      "Epoch: 525, Train Loss: 0.2762405276298523, Valid Loss: 0.30368223786354065\n",
      "Epoch: 526, Train Loss: 0.2758498787879944, Valid Loss: 0.3037467896938324\n",
      "Epoch: 527, Train Loss: 0.27546191215515137, Valid Loss: 0.30327022075653076\n",
      "Epoch: 528, Train Loss: 0.2750750184059143, Valid Loss: 0.30263713002204895\n",
      "Epoch: 529, Train Loss: 0.2746877670288086, Valid Loss: 0.30278387665748596\n",
      "Epoch: 530, Train Loss: 0.2742992639541626, Valid Loss: 0.3017185926437378\n",
      "Epoch: 531, Train Loss: 0.27391067147254944, Valid Loss: 0.30205902457237244\n",
      "Epoch: 532, Train Loss: 0.2735232412815094, Valid Loss: 0.30100563168525696\n",
      "Epoch: 533, Train Loss: 0.2731373608112335, Valid Loss: 0.301238089799881\n",
      "Epoch: 534, Train Loss: 0.272752046585083, Valid Loss: 0.3002780079841614\n",
      "Epoch: 535, Train Loss: 0.2723665237426758, Valid Loss: 0.30053943395614624\n",
      "Epoch: 536, Train Loss: 0.27198055386543274, Valid Loss: 0.2993921935558319\n",
      "Epoch: 537, Train Loss: 0.2715948224067688, Valid Loss: 0.2999550402164459\n",
      "Epoch: 538, Train Loss: 0.27120986580848694, Valid Loss: 0.29844221472740173\n",
      "Epoch: 539, Train Loss: 0.2708263099193573, Valid Loss: 0.29940274357795715\n",
      "Epoch: 540, Train Loss: 0.27044442296028137, Valid Loss: 0.29746052622795105\n",
      "Epoch: 541, Train Loss: 0.2700650095939636, Valid Loss: 0.29892632365226746\n",
      "Epoch: 542, Train Loss: 0.26968756318092346, Valid Loss: 0.2963807284832001\n",
      "Epoch: 543, Train Loss: 0.2693118751049042, Valid Loss: 0.2985782325267792\n",
      "Epoch: 544, Train Loss: 0.2689370810985565, Valid Loss: 0.29523009061813354\n",
      "Epoch: 545, Train Loss: 0.268561452627182, Valid Loss: 0.29818421602249146\n",
      "Epoch: 546, Train Loss: 0.26818323135375977, Valid Loss: 0.2943209707736969\n",
      "Epoch: 547, Train Loss: 0.2677970826625824, Valid Loss: 0.2973034679889679\n",
      "Epoch: 548, Train Loss: 0.26740187406539917, Valid Loss: 0.29403990507125854\n",
      "Epoch: 549, Train Loss: 0.26700127124786377, Valid Loss: 0.29566463828086853\n",
      "Epoch: 550, Train Loss: 0.2666056454181671, Valid Loss: 0.294287770986557\n",
      "Epoch: 551, Train Loss: 0.26622146368026733, Valid Loss: 0.293844074010849\n",
      "Epoch: 552, Train Loss: 0.2658475935459137, Valid Loss: 0.29439255595207214\n",
      "Epoch: 553, Train Loss: 0.26547756791114807, Valid Loss: 0.2925211787223816\n",
      "Epoch: 554, Train Loss: 0.26510342955589294, Valid Loss: 0.2940007448196411\n",
      "Epoch: 555, Train Loss: 0.26472166180610657, Valid Loss: 0.29167208075523376\n",
      "Epoch: 556, Train Loss: 0.26433414220809937, Valid Loss: 0.2931169271469116\n",
      "Epoch: 557, Train Loss: 0.26394709944725037, Valid Loss: 0.2912059724330902\n",
      "Epoch: 558, Train Loss: 0.2635647654533386, Valid Loss: 0.2918749749660492\n",
      "Epoch: 559, Train Loss: 0.2631867229938507, Valid Loss: 0.291034460067749\n",
      "Epoch: 560, Train Loss: 0.26281020045280457, Valid Loss: 0.2905066907405853\n",
      "Epoch: 561, Train Loss: 0.2624332308769226, Valid Loss: 0.2908379137516022\n",
      "Epoch: 562, Train Loss: 0.262055367231369, Valid Loss: 0.28932735323905945\n",
      "Epoch: 563, Train Loss: 0.26167774200439453, Valid Loss: 0.2902912497520447\n",
      "Epoch: 564, Train Loss: 0.2613011300563812, Valid Loss: 0.28853848576545715\n",
      "Epoch: 565, Train Loss: 0.26092496514320374, Valid Loss: 0.28940457105636597\n",
      "Epoch: 566, Train Loss: 0.26054754853248596, Valid Loss: 0.28801944851875305\n",
      "Epoch: 567, Train Loss: 0.26016905903816223, Valid Loss: 0.2883526086807251\n",
      "Epoch: 568, Train Loss: 0.259790301322937, Valid Loss: 0.2876097559928894\n",
      "Epoch: 569, Train Loss: 0.2594135105609894, Valid Loss: 0.2872321307659149\n",
      "Epoch: 570, Train Loss: 0.25903916358947754, Valid Loss: 0.2872115969657898\n",
      "Epoch: 571, Train Loss: 0.2586665451526642, Valid Loss: 0.28617358207702637\n",
      "Epoch: 572, Train Loss: 0.25829413533210754, Valid Loss: 0.28668802976608276\n",
      "Epoch: 573, Train Loss: 0.25792062282562256, Valid Loss: 0.285302996635437\n",
      "Epoch: 574, Train Loss: 0.2575460374355316, Valid Loss: 0.285940021276474\n",
      "Epoch: 575, Train Loss: 0.2571708559989929, Valid Loss: 0.28462889790534973\n",
      "Epoch: 576, Train Loss: 0.25679662823677063, Valid Loss: 0.285033643245697\n",
      "Epoch: 577, Train Loss: 0.25642383098602295, Valid Loss: 0.28402408957481384\n",
      "Epoch: 578, Train Loss: 0.256052166223526, Valid Loss: 0.2841397821903229\n",
      "Epoch: 579, Train Loss: 0.25568079948425293, Valid Loss: 0.28336867690086365\n",
      "Epoch: 580, Train Loss: 0.25530925393104553, Valid Loss: 0.28333646059036255\n",
      "Epoch: 581, Train Loss: 0.25493746995925903, Valid Loss: 0.28263944387435913\n",
      "Epoch: 582, Train Loss: 0.25456559658050537, Valid Loss: 0.2825934588909149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 583, Train Loss: 0.25419414043426514, Valid Loss: 0.2818682789802551\n",
      "Epoch: 584, Train Loss: 0.25382348895072937, Valid Loss: 0.28187429904937744\n",
      "Epoch: 585, Train Loss: 0.25345370173454285, Valid Loss: 0.281061589717865\n",
      "Epoch: 586, Train Loss: 0.2530846893787384, Valid Loss: 0.281207799911499\n",
      "Epoch: 587, Train Loss: 0.25271642208099365, Valid Loss: 0.2801854908466339\n",
      "Epoch: 588, Train Loss: 0.25234878063201904, Valid Loss: 0.28062722086906433\n",
      "Epoch: 589, Train Loss: 0.25198206305503845, Valid Loss: 0.2792230546474457\n",
      "Epoch: 590, Train Loss: 0.25161656737327576, Valid Loss: 0.28013867139816284\n",
      "Epoch: 591, Train Loss: 0.25125277042388916, Valid Loss: 0.27816399931907654\n",
      "Epoch: 592, Train Loss: 0.2508919835090637, Valid Loss: 0.2797822058200836\n",
      "Epoch: 593, Train Loss: 0.2505356967449188, Valid Loss: 0.27695855498313904\n",
      "Epoch: 594, Train Loss: 0.250185489654541, Valid Loss: 0.27963656187057495\n",
      "Epoch: 595, Train Loss: 0.24984194338321686, Valid Loss: 0.27563294768333435\n",
      "Epoch: 596, Train Loss: 0.2494976818561554, Valid Loss: 0.27948907017707825\n",
      "Epoch: 597, Train Loss: 0.24914060533046722, Valid Loss: 0.2747025191783905\n",
      "Epoch: 598, Train Loss: 0.24875420331954956, Valid Loss: 0.2783440053462982\n",
      "Epoch: 599, Train Loss: 0.2483508288860321, Valid Loss: 0.275007426738739\n",
      "Epoch: 600, Train Loss: 0.24795781075954437, Valid Loss: 0.27583467960357666\n",
      "Epoch: 601, Train Loss: 0.24759504199028015, Valid Loss: 0.27601122856140137\n",
      "Epoch: 602, Train Loss: 0.24725346267223358, Valid Loss: 0.2736620306968689\n",
      "Epoch: 603, Train Loss: 0.2469075471162796, Valid Loss: 0.2760933041572571\n",
      "Epoch: 604, Train Loss: 0.24654071033000946, Valid Loss: 0.2729499340057373\n",
      "Epoch: 605, Train Loss: 0.24615725874900818, Valid Loss: 0.2745879888534546\n",
      "Epoch: 606, Train Loss: 0.24577957391738892, Valid Loss: 0.27335646748542786\n",
      "Epoch: 607, Train Loss: 0.24542129039764404, Valid Loss: 0.2725781500339508\n",
      "Epoch: 608, Train Loss: 0.24507492780685425, Valid Loss: 0.27359986305236816\n",
      "Epoch: 609, Train Loss: 0.2447219043970108, Valid Loss: 0.2714416980743408\n",
      "Epoch: 610, Train Loss: 0.2443537414073944, Valid Loss: 0.27279019355773926\n",
      "Epoch: 611, Train Loss: 0.24398140609264374, Valid Loss: 0.27111396193504333\n",
      "Epoch: 612, Train Loss: 0.24361927807331085, Valid Loss: 0.27132290601730347\n",
      "Epoch: 613, Train Loss: 0.24326764047145844, Valid Loss: 0.2711375951766968\n",
      "Epoch: 614, Train Loss: 0.24291513860225677, Valid Loss: 0.26994702219963074\n",
      "Epoch: 615, Train Loss: 0.24255472421646118, Valid Loss: 0.2707722783088684\n",
      "Epoch: 616, Train Loss: 0.2421906739473343, Valid Loss: 0.2691848576068878\n",
      "Epoch: 617, Train Loss: 0.24182993173599243, Valid Loss: 0.26966023445129395\n",
      "Epoch: 618, Train Loss: 0.24147476255893707, Valid Loss: 0.2690504789352417\n",
      "Epoch: 619, Train Loss: 0.24112212657928467, Valid Loss: 0.2683054506778717\n",
      "Epoch: 620, Train Loss: 0.2407682090997696, Valid Loss: 0.26873719692230225\n",
      "Epoch: 621, Train Loss: 0.2404116839170456, Valid Loss: 0.2674943208694458\n",
      "Epoch: 622, Train Loss: 0.24005356431007385, Valid Loss: 0.2677608132362366\n",
      "Epoch: 623, Train Loss: 0.2396964281797409, Valid Loss: 0.26720014214515686\n",
      "Epoch: 624, Train Loss: 0.23934194445610046, Valid Loss: 0.26651865243911743\n",
      "Epoch: 625, Train Loss: 0.23899005353450775, Valid Loss: 0.2668904662132263\n",
      "Epoch: 626, Train Loss: 0.23863838613033295, Valid Loss: 0.26553189754486084\n",
      "Epoch: 627, Train Loss: 0.2382849156856537, Valid Loss: 0.2662053406238556\n",
      "Epoch: 628, Train Loss: 0.23792989552021027, Valid Loss: 0.2649534046649933\n",
      "Epoch: 629, Train Loss: 0.23757585883140564, Valid Loss: 0.265159010887146\n",
      "Epoch: 630, Train Loss: 0.23722396790981293, Valid Loss: 0.26460206508636475\n",
      "Epoch: 631, Train Loss: 0.23687349259853363, Valid Loss: 0.2640700936317444\n",
      "Epoch: 632, Train Loss: 0.23652340471744537, Valid Loss: 0.26412108540534973\n",
      "Epoch: 633, Train Loss: 0.23617315292358398, Valid Loss: 0.26324111223220825\n",
      "Epoch: 634, Train Loss: 0.2358226776123047, Valid Loss: 0.26334044337272644\n",
      "Epoch: 635, Train Loss: 0.23547238111495972, Valid Loss: 0.2626858353614807\n",
      "Epoch: 636, Train Loss: 0.23512257635593414, Valid Loss: 0.26235252618789673\n",
      "Epoch: 637, Train Loss: 0.23477409780025482, Valid Loss: 0.2622646391391754\n",
      "Epoch: 638, Train Loss: 0.23442740738391876, Valid Loss: 0.2613190710544586\n",
      "Epoch: 639, Train Loss: 0.2340829223394394, Valid Loss: 0.2618354856967926\n",
      "Epoch: 640, Train Loss: 0.23374058306217194, Valid Loss: 0.26033562421798706\n",
      "Epoch: 641, Train Loss: 0.2334011346101761, Valid Loss: 0.2613810896873474\n",
      "Epoch: 642, Train Loss: 0.2330622375011444, Valid Loss: 0.2594103515148163\n",
      "Epoch: 643, Train Loss: 0.23272110521793365, Valid Loss: 0.2608083188533783\n",
      "Epoch: 644, Train Loss: 0.23236994445323944, Valid Loss: 0.25874871015548706\n",
      "Epoch: 645, Train Loss: 0.23201125860214233, Valid Loss: 0.2597300410270691\n",
      "Epoch: 646, Train Loss: 0.23165321350097656, Valid Loss: 0.2586110830307007\n",
      "Epoch: 647, Train Loss: 0.23130488395690918, Valid Loss: 0.2582067549228668\n",
      "Epoch: 648, Train Loss: 0.23096659779548645, Valid Loss: 0.25862255692481995\n",
      "Epoch: 649, Train Loss: 0.2306310534477234, Valid Loss: 0.2569551169872284\n",
      "Epoch: 650, Train Loss: 0.23028945922851562, Valid Loss: 0.25817739963531494\n",
      "Epoch: 651, Train Loss: 0.22994038462638855, Valid Loss: 0.2562866508960724\n",
      "Epoch: 652, Train Loss: 0.22958923876285553, Valid Loss: 0.25713175535202026\n",
      "Epoch: 653, Train Loss: 0.22924308478832245, Valid Loss: 0.25607025623321533\n",
      "Epoch: 654, Train Loss: 0.2289036065340042, Valid Loss: 0.25582626461982727\n",
      "Epoch: 655, Train Loss: 0.2285667210817337, Valid Loss: 0.2558715045452118\n",
      "Epoch: 656, Train Loss: 0.22822700440883636, Valid Loss: 0.2547994554042816\n",
      "Epoch: 657, Train Loss: 0.22788314521312714, Valid Loss: 0.25520390272140503\n",
      "Epoch: 658, Train Loss: 0.22753801941871643, Valid Loss: 0.2542773187160492\n",
      "Epoch: 659, Train Loss: 0.22719553112983704, Valid Loss: 0.2541347146034241\n",
      "Epoch: 660, Train Loss: 0.2268570512533188, Valid Loss: 0.2539011240005493\n",
      "Epoch: 661, Train Loss: 0.22652064263820648, Valid Loss: 0.25319477915763855\n",
      "Epoch: 662, Train Loss: 0.22618332505226135, Valid Loss: 0.25328701734542847\n",
      "Epoch: 663, Train Loss: 0.22584378719329834, Valid Loss: 0.25253191590309143\n",
      "Epoch: 664, Train Loss: 0.2255033552646637, Valid Loss: 0.2524127662181854\n",
      "Epoch: 665, Train Loss: 0.22516411542892456, Valid Loss: 0.2520829737186432\n",
      "Epoch: 666, Train Loss: 0.2248270958662033, Valid Loss: 0.251361608505249\n",
      "Epoch: 667, Train Loss: 0.22449208796024323, Valid Loss: 0.25171998143196106\n",
      "Epoch: 668, Train Loss: 0.22415779531002045, Valid Loss: 0.2503511309623718\n",
      "Epoch: 669, Train Loss: 0.223823681473732, Valid Loss: 0.25125446915626526\n",
      "Epoch: 670, Train Loss: 0.2234901636838913, Valid Loss: 0.24947400391101837\n",
      "Epoch: 671, Train Loss: 0.22315888106822968, Valid Loss: 0.250739187002182\n",
      "Epoch: 672, Train Loss: 0.22283226251602173, Valid Loss: 0.2485288381576538\n",
      "Epoch: 673, Train Loss: 0.22251319885253906, Valid Loss: 0.2504458427429199\n",
      "Epoch: 674, Train Loss: 0.2222033143043518, Valid Loss: 0.24736930429935455\n",
      "Epoch: 675, Train Loss: 0.22190116345882416, Valid Loss: 0.2503809928894043\n",
      "Epoch: 676, Train Loss: 0.22159390151500702, Valid Loss: 0.24628521502017975\n",
      "Epoch: 677, Train Loss: 0.22125953435897827, Valid Loss: 0.24981091916561127\n",
      "Epoch: 678, Train Loss: 0.22088834643363953, Valid Loss: 0.2460917830467224\n",
      "Epoch: 679, Train Loss: 0.220505490899086, Valid Loss: 0.24773624539375305\n",
      "Epoch: 680, Train Loss: 0.22015391290187836, Valid Loss: 0.24700260162353516\n",
      "Epoch: 681, Train Loss: 0.21984070539474487, Valid Loss: 0.24535755813121796\n",
      "Epoch: 682, Train Loss: 0.21953673660755157, Valid Loss: 0.24748694896697998\n",
      "Epoch: 683, Train Loss: 0.21921157836914062, Valid Loss: 0.2443828582763672\n",
      "Epoch: 684, Train Loss: 0.21886242926120758, Valid Loss: 0.2461666315793991\n",
      "Epoch: 685, Train Loss: 0.218515545129776, Valid Loss: 0.24496635794639587\n",
      "Epoch: 686, Train Loss: 0.2181871235370636, Valid Loss: 0.24393410980701447\n",
      "Epoch: 687, Train Loss: 0.21786873042583466, Valid Loss: 0.24547654390335083\n",
      "Epoch: 688, Train Loss: 0.21754369139671326, Valid Loss: 0.24279643595218658\n",
      "Epoch: 689, Train Loss: 0.2172084003686905, Valid Loss: 0.24441330134868622\n",
      "Epoch: 690, Train Loss: 0.2168741375207901, Valid Loss: 0.2430763989686966\n",
      "Epoch: 691, Train Loss: 0.2165490984916687, Valid Loss: 0.24243156611919403\n",
      "Epoch: 692, Train Loss: 0.21622878313064575, Valid Loss: 0.2434868961572647\n",
      "Epoch: 693, Train Loss: 0.21590372920036316, Valid Loss: 0.2411937266588211\n",
      "Epoch: 694, Train Loss: 0.21557189524173737, Valid Loss: 0.24264684319496155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 695, Train Loss: 0.21524104475975037, Valid Loss: 0.24125829339027405\n",
      "Epoch: 696, Train Loss: 0.21491765975952148, Valid Loss: 0.24090339243412018\n",
      "Epoch: 697, Train Loss: 0.21459946036338806, Valid Loss: 0.24151381850242615\n",
      "Epoch: 698, Train Loss: 0.21427860856056213, Valid Loss: 0.2396720051765442\n",
      "Epoch: 699, Train Loss: 0.21395111083984375, Valid Loss: 0.2408517301082611\n",
      "Epoch: 700, Train Loss: 0.21362213790416718, Valid Loss: 0.23945461213588715\n",
      "Epoch: 701, Train Loss: 0.21329841017723083, Valid Loss: 0.2393774390220642\n",
      "Epoch: 702, Train Loss: 0.21298018097877502, Valid Loss: 0.23956400156021118\n",
      "Epoch: 703, Train Loss: 0.21266216039657593, Valid Loss: 0.23816414177417755\n",
      "Epoch: 704, Train Loss: 0.21234022080898285, Valid Loss: 0.23903712630271912\n",
      "Epoch: 705, Train Loss: 0.2120160162448883, Valid Loss: 0.23771320283412933\n",
      "Epoch: 706, Train Loss: 0.21169306337833405, Valid Loss: 0.23784679174423218\n",
      "Epoch: 707, Train Loss: 0.2113731950521469, Valid Loss: 0.2376137524843216\n",
      "Epoch: 708, Train Loss: 0.2110554575920105, Valid Loss: 0.23668202757835388\n",
      "Epoch: 709, Train Loss: 0.21073773503303528, Valid Loss: 0.2372039258480072\n",
      "Epoch: 710, Train Loss: 0.21041865646839142, Valid Loss: 0.23599964380264282\n",
      "Epoch: 711, Train Loss: 0.2100984752178192, Valid Loss: 0.23631416261196136\n",
      "Epoch: 712, Train Loss: 0.20977887511253357, Valid Loss: 0.2356753796339035\n",
      "Epoch: 713, Train Loss: 0.20946113765239716, Valid Loss: 0.23525115847587585\n",
      "Epoch: 714, Train Loss: 0.2091449350118637, Valid Loss: 0.23531369864940643\n",
      "Epoch: 715, Train Loss: 0.20882901549339294, Valid Loss: 0.23437152802944183\n",
      "Epoch: 716, Train Loss: 0.2085122913122177, Valid Loss: 0.23471030592918396\n",
      "Epoch: 717, Train Loss: 0.20819519460201263, Valid Loss: 0.23375722765922546\n",
      "Epoch: 718, Train Loss: 0.20787864923477173, Valid Loss: 0.23385661840438843\n",
      "Epoch: 719, Train Loss: 0.20756299793720245, Valid Loss: 0.23334819078445435\n",
      "Epoch: 720, Train Loss: 0.2072482854127884, Valid Loss: 0.23289991915225983\n",
      "Epoch: 721, Train Loss: 0.20693424344062805, Valid Loss: 0.23292867839336395\n",
      "Epoch: 722, Train Loss: 0.20662043988704681, Valid Loss: 0.23205581307411194\n",
      "Epoch: 723, Train Loss: 0.2063065618276596, Valid Loss: 0.23232178390026093\n",
      "Epoch: 724, Train Loss: 0.20599277317523956, Valid Loss: 0.23142653703689575\n",
      "Epoch: 725, Train Loss: 0.20567913353443146, Valid Loss: 0.23151668906211853\n",
      "Epoch: 726, Train Loss: 0.2053661346435547, Valid Loss: 0.23094488680362701\n",
      "Epoch: 727, Train Loss: 0.20505379140377045, Valid Loss: 0.23065178096294403\n",
      "Epoch: 728, Train Loss: 0.20474207401275635, Valid Loss: 0.2304450422525406\n",
      "Epoch: 729, Train Loss: 0.2044306993484497, Valid Loss: 0.22987285256385803\n",
      "Epoch: 730, Train Loss: 0.20411962270736694, Valid Loss: 0.22983482480049133\n",
      "Epoch: 731, Train Loss: 0.2038087546825409, Valid Loss: 0.229198157787323\n",
      "Epoch: 732, Train Loss: 0.20349818468093872, Valid Loss: 0.22913189232349396\n",
      "Epoch: 733, Train Loss: 0.20318791270256042, Valid Loss: 0.2285977154970169\n",
      "Epoch: 734, Train Loss: 0.2028779834508896, Valid Loss: 0.2283814251422882\n",
      "Epoch: 735, Train Loss: 0.2025686353445053, Valid Loss: 0.22802884876728058\n",
      "Epoch: 736, Train Loss: 0.20225971937179565, Valid Loss: 0.22761660814285278\n",
      "Epoch: 737, Train Loss: 0.20195142924785614, Valid Loss: 0.2274736911058426\n",
      "Epoch: 738, Train Loss: 0.20164363086223602, Valid Loss: 0.22684364020824432\n",
      "Epoch: 739, Train Loss: 0.20133644342422485, Valid Loss: 0.22692100703716278\n",
      "Epoch: 740, Train Loss: 0.20103022456169128, Valid Loss: 0.22607421875\n",
      "Epoch: 741, Train Loss: 0.2007252275943756, Valid Loss: 0.2263800948858261\n",
      "Epoch: 742, Train Loss: 0.2004225254058838, Valid Loss: 0.22528770565986633\n",
      "Epoch: 743, Train Loss: 0.20012372732162476, Valid Loss: 0.2259070724248886\n",
      "Epoch: 744, Train Loss: 0.19983235001564026, Valid Loss: 0.22442789375782013\n",
      "Epoch: 745, Train Loss: 0.19955335557460785, Valid Loss: 0.22562235593795776\n",
      "Epoch: 746, Train Loss: 0.19929587841033936, Valid Loss: 0.22344344854354858\n",
      "Epoch: 747, Train Loss: 0.1990564465522766, Valid Loss: 0.2256731390953064\n",
      "Epoch: 748, Train Loss: 0.19882561266422272, Valid Loss: 0.22236700356006622\n",
      "Epoch: 749, Train Loss: 0.19852058589458466, Valid Loss: 0.22562295198440552\n",
      "Epoch: 750, Train Loss: 0.19813090562820435, Valid Loss: 0.22158418595790863\n",
      "Epoch: 751, Train Loss: 0.1977086365222931, Valid Loss: 0.22391492128372192\n",
      "Epoch: 752, Train Loss: 0.1973780244588852, Valid Loss: 0.22230663895606995\n",
      "Epoch: 753, Train Loss: 0.19714239239692688, Valid Loss: 0.22131118178367615\n",
      "Epoch: 754, Train Loss: 0.1968945562839508, Valid Loss: 0.22342251241207123\n",
      "Epoch: 755, Train Loss: 0.1965644508600235, Valid Loss: 0.2199733704328537\n",
      "Epoch: 756, Train Loss: 0.19618992507457733, Valid Loss: 0.22212371230125427\n",
      "Epoch: 757, Train Loss: 0.19587279856204987, Valid Loss: 0.22084738314151764\n",
      "Epoch: 758, Train Loss: 0.19561955332756042, Valid Loss: 0.2196047157049179\n",
      "Epoch: 759, Train Loss: 0.19534535706043243, Valid Loss: 0.2216317355632782\n",
      "Epoch: 760, Train Loss: 0.19501163065433502, Valid Loss: 0.21873554587364197\n",
      "Epoch: 761, Train Loss: 0.19467324018478394, Valid Loss: 0.21983063220977783\n",
      "Epoch: 762, Train Loss: 0.19438691437244415, Valid Loss: 0.21970076858997345\n",
      "Epoch: 763, Train Loss: 0.19412146508693695, Valid Loss: 0.21779344975948334\n",
      "Epoch: 764, Train Loss: 0.1938197761774063, Valid Loss: 0.21961385011672974\n",
      "Epoch: 765, Train Loss: 0.19349168241024017, Valid Loss: 0.2177094668149948\n",
      "Epoch: 766, Train Loss: 0.19318591058254242, Valid Loss: 0.2176167517900467\n",
      "Epoch: 767, Train Loss: 0.1929093450307846, Valid Loss: 0.21838024258613586\n",
      "Epoch: 768, Train Loss: 0.1926240175962448, Valid Loss: 0.21636997163295746\n",
      "Epoch: 769, Train Loss: 0.1923135370016098, Valid Loss: 0.2173929065465927\n",
      "Epoch: 770, Train Loss: 0.1920035481452942, Valid Loss: 0.21661362051963806\n",
      "Epoch: 771, Train Loss: 0.19171370565891266, Valid Loss: 0.2157161682844162\n",
      "Epoch: 772, Train Loss: 0.19143089652061462, Valid Loss: 0.2165934443473816\n",
      "Epoch: 773, Train Loss: 0.19113613665103912, Valid Loss: 0.2151472121477127\n",
      "Epoch: 774, Train Loss: 0.19083154201507568, Valid Loss: 0.21536724269390106\n",
      "Epoch: 775, Train Loss: 0.1905333548784256, Valid Loss: 0.2152126282453537\n",
      "Epoch: 776, Train Loss: 0.19024576246738434, Valid Loss: 0.21421684324741364\n",
      "Epoch: 777, Train Loss: 0.18995870649814606, Valid Loss: 0.2146783024072647\n",
      "Epoch: 778, Train Loss: 0.18966399133205414, Valid Loss: 0.21378973126411438\n",
      "Epoch: 779, Train Loss: 0.18936531245708466, Valid Loss: 0.21363244950771332\n",
      "Epoch: 780, Train Loss: 0.18907180428504944, Valid Loss: 0.2135150283575058\n",
      "Epoch: 781, Train Loss: 0.18878482282161713, Valid Loss: 0.21279405057430267\n",
      "Epoch: 782, Train Loss: 0.18849726021289825, Valid Loss: 0.21289512515068054\n",
      "Epoch: 783, Train Loss: 0.18820446729660034, Valid Loss: 0.21227502822875977\n",
      "Epoch: 784, Train Loss: 0.18790987133979797, Valid Loss: 0.2120995968580246\n",
      "Epoch: 785, Train Loss: 0.18761934340000153, Valid Loss: 0.21175618469715118\n",
      "Epoch: 786, Train Loss: 0.18733273446559906, Valid Loss: 0.21132497489452362\n",
      "Epoch: 787, Train Loss: 0.18704558908939362, Valid Loss: 0.21122074127197266\n",
      "Epoch: 788, Train Loss: 0.18675540387630463, Valid Loss: 0.21061524748802185\n",
      "Epoch: 789, Train Loss: 0.18646453320980072, Valid Loss: 0.21061331033706665\n",
      "Epoch: 790, Train Loss: 0.18617573380470276, Valid Loss: 0.21002942323684692\n",
      "Epoch: 791, Train Loss: 0.18588925898075104, Valid Loss: 0.20980656147003174\n",
      "Epoch: 792, Train Loss: 0.18560314178466797, Valid Loss: 0.20963411033153534\n",
      "Epoch: 793, Train Loss: 0.18531621992588043, Valid Loss: 0.20893512666225433\n",
      "Epoch: 794, Train Loss: 0.18502861261367798, Valid Loss: 0.20909157395362854\n",
      "Epoch: 795, Train Loss: 0.18474124372005463, Valid Loss: 0.2083589881658554\n",
      "Epoch: 796, Train Loss: 0.1844550520181656, Valid Loss: 0.20823152363300323\n",
      "Epoch: 797, Train Loss: 0.1841701865196228, Valid Loss: 0.20802150666713715\n",
      "Epoch: 798, Train Loss: 0.18388575315475464, Valid Loss: 0.20733968913555145\n",
      "Epoch: 799, Train Loss: 0.1836009919643402, Valid Loss: 0.20750588178634644\n",
      "Epoch: 800, Train Loss: 0.18331573903560638, Valid Loss: 0.2067495584487915\n",
      "Epoch: 801, Train Loss: 0.18303082883358002, Valid Loss: 0.20668171346187592\n",
      "Epoch: 802, Train Loss: 0.18274691700935364, Valid Loss: 0.20634523034095764\n",
      "Epoch: 803, Train Loss: 0.1824638694524765, Valid Loss: 0.20583093166351318\n",
      "Epoch: 804, Train Loss: 0.18218111991882324, Valid Loss: 0.20583492517471313\n",
      "Epoch: 805, Train Loss: 0.18189853429794312, Valid Loss: 0.20518474280834198\n",
      "Epoch: 806, Train Loss: 0.18161596357822418, Valid Loss: 0.2051295042037964\n",
      "Epoch: 807, Train Loss: 0.18133364617824554, Valid Loss: 0.20466478168964386\n",
      "Epoch: 808, Train Loss: 0.1810515969991684, Valid Loss: 0.20438255369663239\n",
      "Epoch: 809, Train Loss: 0.18077009916305542, Valid Loss: 0.2041037231683731\n",
      "Epoch: 810, Train Loss: 0.18048927187919617, Valid Loss: 0.20370401442050934\n",
      "Epoch: 811, Train Loss: 0.18020886182785034, Valid Loss: 0.20348571240901947\n",
      "Epoch: 812, Train Loss: 0.1799287348985672, Valid Loss: 0.20305854082107544\n",
      "Epoch: 813, Train Loss: 0.1796487718820572, Valid Loss: 0.20287549495697021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 814, Train Loss: 0.17936910688877106, Valid Loss: 0.20240148901939392\n",
      "Epoch: 815, Train Loss: 0.1790897250175476, Valid Loss: 0.20225928723812103\n",
      "Epoch: 816, Train Loss: 0.1788107007741928, Valid Loss: 0.20177283883094788\n",
      "Epoch: 817, Train Loss: 0.17853210866451263, Valid Loss: 0.20158803462982178\n",
      "Epoch: 818, Train Loss: 0.1782538741827011, Valid Loss: 0.20120666921138763\n",
      "Epoch: 819, Train Loss: 0.17797613143920898, Valid Loss: 0.20087386667728424\n",
      "Epoch: 820, Train Loss: 0.17769867181777954, Valid Loss: 0.20065398514270782\n",
      "Epoch: 821, Train Loss: 0.17742161452770233, Valid Loss: 0.20018665492534637\n",
      "Epoch: 822, Train Loss: 0.17714495956897736, Valid Loss: 0.20005762577056885\n",
      "Epoch: 823, Train Loss: 0.17686857283115387, Valid Loss: 0.1995537132024765\n",
      "Epoch: 824, Train Loss: 0.17659254372119904, Valid Loss: 0.19941166043281555\n",
      "Epoch: 825, Train Loss: 0.17631687223911285, Valid Loss: 0.19894662499427795\n",
      "Epoch: 826, Train Loss: 0.17604143917560577, Valid Loss: 0.19876615703105927\n",
      "Epoch: 827, Train Loss: 0.1757664680480957, Valid Loss: 0.1983225792646408\n",
      "Epoch: 828, Train Loss: 0.1754918396472931, Valid Loss: 0.19814832508563995\n",
      "Epoch: 829, Train Loss: 0.17521756887435913, Valid Loss: 0.19767791032791138\n",
      "Epoch: 830, Train Loss: 0.17494359612464905, Valid Loss: 0.1975450962781906\n",
      "Epoch: 831, Train Loss: 0.1746700257062912, Valid Loss: 0.19703593850135803\n",
      "Epoch: 832, Train Loss: 0.17439687252044678, Valid Loss: 0.19692660868167877\n",
      "Epoch: 833, Train Loss: 0.17412406206130981, Valid Loss: 0.19640634953975677\n",
      "Epoch: 834, Train Loss: 0.1738516390323639, Valid Loss: 0.1963091641664505\n",
      "Epoch: 835, Train Loss: 0.17357969284057617, Valid Loss: 0.1957656890153885\n",
      "Epoch: 836, Train Loss: 0.17330826818943024, Valid Loss: 0.19572535157203674\n",
      "Epoch: 837, Train Loss: 0.17303739488124847, Valid Loss: 0.19508063793182373\n",
      "Epoch: 838, Train Loss: 0.1727672517299652, Valid Loss: 0.1952020227909088\n",
      "Epoch: 839, Train Loss: 0.17249822616577148, Valid Loss: 0.19433170557022095\n",
      "Epoch: 840, Train Loss: 0.17223066091537476, Valid Loss: 0.19476284086704254\n",
      "Epoch: 841, Train Loss: 0.17196586728096008, Valid Loss: 0.19349166750907898\n",
      "Epoch: 842, Train Loss: 0.17170551419258118, Valid Loss: 0.19446945190429688\n",
      "Epoch: 843, Train Loss: 0.17145290970802307, Valid Loss: 0.19250495731830597\n",
      "Epoch: 844, Train Loss: 0.17121249437332153, Valid Loss: 0.19444607198238373\n",
      "Epoch: 845, Train Loss: 0.170990452170372, Valid Loss: 0.19133800268173218\n",
      "Epoch: 846, Train Loss: 0.17078383266925812, Valid Loss: 0.19471487402915955\n",
      "Epoch: 847, Train Loss: 0.17057722806930542, Valid Loss: 0.19028419256210327\n",
      "Epoch: 848, Train Loss: 0.170314222574234, Valid Loss: 0.19439907371997833\n",
      "Epoch: 849, Train Loss: 0.16997557878494263, Valid Loss: 0.1901766061782837\n",
      "Epoch: 850, Train Loss: 0.16959628462791443, Valid Loss: 0.19213280081748962\n",
      "Epoch: 851, Train Loss: 0.16927897930145264, Valid Loss: 0.19116145372390747\n",
      "Epoch: 852, Train Loss: 0.16905148327350616, Valid Loss: 0.1897408366203308\n",
      "Epoch: 853, Train Loss: 0.16885225474834442, Valid Loss: 0.19176845252513885\n",
      "Epoch: 854, Train Loss: 0.1686037927865982, Valid Loss: 0.18894802033901215\n",
      "Epoch: 855, Train Loss: 0.1682826727628708, Valid Loss: 0.19070544838905334\n",
      "Epoch: 856, Train Loss: 0.16796286404132843, Valid Loss: 0.18922238051891327\n",
      "Epoch: 857, Train Loss: 0.1677038073539734, Valid Loss: 0.1888650357723236\n",
      "Epoch: 858, Train Loss: 0.16748346388339996, Valid Loss: 0.18971864879131317\n",
      "Epoch: 859, Train Loss: 0.16723912954330444, Valid Loss: 0.18762096762657166\n",
      "Epoch: 860, Train Loss: 0.16694675385951996, Valid Loss: 0.1891423761844635\n",
      "Epoch: 861, Train Loss: 0.1666502058506012, Valid Loss: 0.18745537102222443\n",
      "Epoch: 862, Train Loss: 0.16638925671577454, Valid Loss: 0.18746007978916168\n",
      "Epoch: 863, Train Loss: 0.16615302860736847, Valid Loss: 0.1880524605512619\n",
      "Epoch: 864, Train Loss: 0.16590392589569092, Valid Loss: 0.18614666163921356\n",
      "Epoch: 865, Train Loss: 0.16562679409980774, Valid Loss: 0.1876116544008255\n",
      "Epoch: 866, Train Loss: 0.16534534096717834, Valid Loss: 0.1860801875591278\n",
      "Epoch: 867, Train Loss: 0.1650855988264084, Valid Loss: 0.18589244782924652\n",
      "Epoch: 868, Train Loss: 0.16484209895133972, Valid Loss: 0.18651828169822693\n",
      "Epoch: 869, Train Loss: 0.1645907610654831, Valid Loss: 0.184719517827034\n",
      "Epoch: 870, Train Loss: 0.16432200372219086, Valid Loss: 0.18585443496704102\n",
      "Epoch: 871, Train Loss: 0.1640506237745285, Valid Loss: 0.18473483622074127\n",
      "Epoch: 872, Train Loss: 0.16379204392433167, Valid Loss: 0.18438197672367096\n",
      "Epoch: 873, Train Loss: 0.16354361176490784, Valid Loss: 0.18489594757556915\n",
      "Epoch: 874, Train Loss: 0.1632918119430542, Valid Loss: 0.18349212408065796\n",
      "Epoch: 875, Train Loss: 0.1630304753780365, Valid Loss: 0.18416538834571838\n",
      "Epoch: 876, Train Loss: 0.16276586055755615, Valid Loss: 0.1832953691482544\n",
      "Epoch: 877, Train Loss: 0.16250747442245483, Valid Loss: 0.18302717804908752\n",
      "Epoch: 878, Train Loss: 0.16225631535053253, Valid Loss: 0.1831485778093338\n",
      "Epoch: 879, Train Loss: 0.16200558841228485, Valid Loss: 0.18221519887447357\n",
      "Epoch: 880, Train Loss: 0.16174955666065216, Valid Loss: 0.1826322227716446\n",
      "Epoch: 881, Train Loss: 0.16149011254310608, Valid Loss: 0.18173734843730927\n",
      "Epoch: 882, Train Loss: 0.1612328141927719, Valid Loss: 0.1817743331193924\n",
      "Epoch: 883, Train Loss: 0.1609800010919571, Valid Loss: 0.18148531019687653\n",
      "Epoch: 884, Train Loss: 0.1607295423746109, Valid Loss: 0.18083716928958893\n",
      "Epoch: 885, Train Loss: 0.16047753393650055, Valid Loss: 0.1811569184064865\n",
      "Epoch: 886, Train Loss: 0.16022302210330963, Valid Loss: 0.18018020689487457\n",
      "Epoch: 887, Train Loss: 0.15996788442134857, Valid Loss: 0.18043185770511627\n",
      "Epoch: 888, Train Loss: 0.1597144603729248, Valid Loss: 0.17991980910301208\n",
      "Epoch: 889, Train Loss: 0.15946358442306519, Valid Loss: 0.17949111759662628\n",
      "Epoch: 890, Train Loss: 0.15921373665332794, Valid Loss: 0.1796381026506424\n",
      "Epoch: 891, Train Loss: 0.1589631587266922, Valid Loss: 0.17876788973808289\n",
      "Epoch: 892, Train Loss: 0.15871138870716095, Valid Loss: 0.17900843918323517\n",
      "Epoch: 893, Train Loss: 0.15845945477485657, Valid Loss: 0.17836549878120422\n",
      "Epoch: 894, Train Loss: 0.15820856392383575, Valid Loss: 0.17818786203861237\n",
      "Epoch: 895, Train Loss: 0.15795904397964478, Valid Loss: 0.17801330983638763\n",
      "Epoch: 896, Train Loss: 0.157710462808609, Valid Loss: 0.17746058106422424\n",
      "Epoch: 897, Train Loss: 0.15746192634105682, Valid Loss: 0.17752093076705933\n",
      "Epoch: 898, Train Loss: 0.1572129726409912, Valid Loss: 0.17688333988189697\n",
      "Epoch: 899, Train Loss: 0.15696388483047485, Valid Loss: 0.17690084874629974\n",
      "Epoch: 900, Train Loss: 0.15671509504318237, Valid Loss: 0.17638492584228516\n",
      "Epoch: 901, Train Loss: 0.1564670354127884, Valid Loss: 0.17621280252933502\n",
      "Epoch: 902, Train Loss: 0.15621978044509888, Valid Loss: 0.17594625055789948\n",
      "Epoch: 903, Train Loss: 0.15597306191921234, Valid Loss: 0.1755112111568451\n",
      "Epoch: 904, Train Loss: 0.15572665631771088, Valid Loss: 0.17549201846122742\n",
      "Epoch: 905, Train Loss: 0.15548017621040344, Valid Loss: 0.1748846173286438\n",
      "Epoch: 906, Train Loss: 0.1552339494228363, Valid Loss: 0.17491790652275085\n",
      "Epoch: 907, Train Loss: 0.15498779714107513, Valid Loss: 0.17438580095767975\n",
      "Epoch: 908, Train Loss: 0.1547420471906662, Valid Loss: 0.17424529790878296\n",
      "Epoch: 909, Train Loss: 0.15449684858322144, Valid Loss: 0.17393100261688232\n",
      "Epoch: 910, Train Loss: 0.15425214171409607, Valid Loss: 0.1735847145318985\n",
      "Epoch: 911, Train Loss: 0.1540079265832901, Valid Loss: 0.17343464493751526\n",
      "Epoch: 912, Train Loss: 0.15376399457454681, Valid Loss: 0.17298731207847595\n",
      "Epoch: 913, Train Loss: 0.15352033078670502, Valid Loss: 0.17289741337299347\n",
      "Epoch: 914, Train Loss: 0.15327690541744232, Valid Loss: 0.17241716384887695\n",
      "Epoch: 915, Train Loss: 0.15303367376327515, Valid Loss: 0.1723368614912033\n",
      "Epoch: 916, Train Loss: 0.15279076993465424, Valid Loss: 0.17186838388442993\n",
      "Epoch: 917, Train Loss: 0.15254825353622437, Valid Loss: 0.17174825072288513\n",
      "Epoch: 918, Train Loss: 0.15230603516101837, Valid Loss: 0.17135502398014069\n",
      "Epoch: 919, Train Loss: 0.15206417441368103, Valid Loss: 0.17113439738750458\n",
      "Epoch: 920, Train Loss: 0.15182267129421234, Valid Loss: 0.17085696756839752\n",
      "Epoch: 921, Train Loss: 0.15158163011074066, Valid Loss: 0.17053216695785522\n",
      "Epoch: 922, Train Loss: 0.15134090185165405, Valid Loss: 0.17034128308296204\n",
      "Epoch: 923, Train Loss: 0.1511005163192749, Valid Loss: 0.16995660960674286\n",
      "Epoch: 924, Train Loss: 0.15086036920547485, Valid Loss: 0.16980203986167908\n",
      "Epoch: 925, Train Loss: 0.15062065422534943, Valid Loss: 0.16939039528369904\n",
      "Epoch: 926, Train Loss: 0.15038122236728668, Valid Loss: 0.169265478849411\n",
      "Epoch: 927, Train Loss: 0.15014207363128662, Valid Loss: 0.16882272064685822\n",
      "Epoch: 928, Train Loss: 0.1499033421278, Valid Loss: 0.1687358021736145\n",
      "Epoch: 929, Train Loss: 0.14966481924057007, Valid Loss: 0.16825757920742035\n",
      "Epoch: 930, Train Loss: 0.14942675828933716, Valid Loss: 0.1682019829750061\n",
      "Epoch: 931, Train Loss: 0.1491890251636505, Valid Loss: 0.1677004098892212\n",
      "Epoch: 932, Train Loss: 0.14895159006118774, Valid Loss: 0.16766995191574097\n",
      "Epoch: 933, Train Loss: 0.14871451258659363, Valid Loss: 0.16713398694992065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 934, Train Loss: 0.1484779417514801, Valid Loss: 0.1671580672264099\n",
      "Epoch: 935, Train Loss: 0.14824174344539642, Valid Loss: 0.16654299199581146\n",
      "Epoch: 936, Train Loss: 0.14800599217414856, Valid Loss: 0.166681706905365\n",
      "Epoch: 937, Train Loss: 0.14777091145515442, Valid Loss: 0.1659223586320877\n",
      "Epoch: 938, Train Loss: 0.14753662049770355, Valid Loss: 0.16624711453914642\n",
      "Epoch: 939, Train Loss: 0.14730344712734222, Valid Loss: 0.16525569558143616\n",
      "Epoch: 940, Train Loss: 0.1470719426870346, Valid Loss: 0.16588565707206726\n",
      "Epoch: 941, Train Loss: 0.14684292674064636, Valid Loss: 0.16450661420822144\n",
      "Epoch: 942, Train Loss: 0.1466178447008133, Valid Loss: 0.1656639128923416\n",
      "Epoch: 943, Train Loss: 0.14639875292778015, Valid Loss: 0.16362538933753967\n",
      "Epoch: 944, Train Loss: 0.14618827402591705, Valid Loss: 0.16565778851509094\n",
      "Epoch: 945, Train Loss: 0.14598894119262695, Valid Loss: 0.16261829435825348\n",
      "Epoch: 946, Train Loss: 0.14579814672470093, Valid Loss: 0.16582699120044708\n",
      "Epoch: 947, Train Loss: 0.14560577273368835, Valid Loss: 0.1617136001586914\n",
      "Epoch: 948, Train Loss: 0.14538469910621643, Valid Loss: 0.16558969020843506\n",
      "Epoch: 949, Train Loss: 0.14511798322200775, Valid Loss: 0.16144904494285583\n",
      "Epoch: 950, Train Loss: 0.14481250941753387, Valid Loss: 0.16402627527713776\n",
      "Epoch: 951, Train Loss: 0.1445188671350479, Valid Loss: 0.16204304993152618\n",
      "Epoch: 952, Train Loss: 0.14427512884140015, Valid Loss: 0.16189426183700562\n",
      "Epoch: 953, Train Loss: 0.14407779276371002, Valid Loss: 0.16279900074005127\n",
      "Epoch: 954, Train Loss: 0.14388954639434814, Valid Loss: 0.16059623658657074\n",
      "Epoch: 955, Train Loss: 0.14366993308067322, Valid Loss: 0.16275420784950256\n",
      "Epoch: 956, Train Loss: 0.14341233670711517, Valid Loss: 0.16025680303573608\n",
      "Epoch: 957, Train Loss: 0.14314283430576324, Valid Loss: 0.16151297092437744\n",
      "Epoch: 958, Train Loss: 0.14289823174476624, Valid Loss: 0.16062089800834656\n",
      "Epoch: 959, Train Loss: 0.14268554747104645, Valid Loss: 0.15990740060806274\n",
      "Epoch: 960, Train Loss: 0.14248213171958923, Valid Loss: 0.1609867513179779\n",
      "Epoch: 961, Train Loss: 0.14226192235946655, Valid Loss: 0.15891915559768677\n",
      "Epoch: 962, Train Loss: 0.14201854169368744, Valid Loss: 0.1604274958372116\n",
      "Epoch: 963, Train Loss: 0.14176957309246063, Valid Loss: 0.15888161957263947\n",
      "Epoch: 964, Train Loss: 0.14153510332107544, Valid Loss: 0.15904594957828522\n",
      "Epoch: 965, Train Loss: 0.14131863415241241, Valid Loss: 0.1592952013015747\n",
      "Epoch: 966, Train Loss: 0.14110630750656128, Valid Loss: 0.15787924826145172\n",
      "Epoch: 967, Train Loss: 0.14088349044322968, Valid Loss: 0.15907424688339233\n",
      "Epoch: 968, Train Loss: 0.14064867794513702, Valid Loss: 0.1574876755475998\n",
      "Epoch: 969, Train Loss: 0.140411838889122, Valid Loss: 0.15802200138568878\n",
      "Epoch: 970, Train Loss: 0.14018350839614868, Valid Loss: 0.1576063334941864\n",
      "Epoch: 971, Train Loss: 0.139964759349823, Valid Loss: 0.15693393349647522\n",
      "Epoch: 972, Train Loss: 0.13974805176258087, Valid Loss: 0.15753823518753052\n",
      "Epoch: 973, Train Loss: 0.13952617347240448, Valid Loss: 0.15628580749034882\n",
      "Epoch: 974, Train Loss: 0.1392979621887207, Valid Loss: 0.15691536664962769\n",
      "Epoch: 975, Train Loss: 0.1390683352947235, Valid Loss: 0.15603265166282654\n",
      "Epoch: 976, Train Loss: 0.1388428956270218, Valid Loss: 0.15600264072418213\n",
      "Epoch: 977, Train Loss: 0.1386227160692215, Valid Loss: 0.15593910217285156\n",
      "Epoch: 978, Train Loss: 0.13840478658676147, Valid Loss: 0.1551916003227234\n",
      "Epoch: 979, Train Loss: 0.13818477094173431, Valid Loss: 0.1556583195924759\n",
      "Epoch: 980, Train Loss: 0.1379617303609848, Valid Loss: 0.15465526282787323\n",
      "Epoch: 981, Train Loss: 0.13773705065250397, Valid Loss: 0.1550210565328598\n",
      "Epoch: 982, Train Loss: 0.13751372694969177, Valid Loss: 0.1543959379196167\n",
      "Epoch: 983, Train Loss: 0.13729308545589447, Valid Loss: 0.15418796241283417\n",
      "Epoch: 984, Train Loss: 0.13707460463047028, Valid Loss: 0.1542130708694458\n",
      "Epoch: 985, Train Loss: 0.1368565708398819, Valid Loss: 0.1534651517868042\n",
      "Epoch: 986, Train Loss: 0.13663725554943085, Valid Loss: 0.15383002161979675\n",
      "Epoch: 987, Train Loss: 0.13641676306724548, Valid Loss: 0.1530124992132187\n",
      "Epoch: 988, Train Loss: 0.13619594275951385, Valid Loss: 0.15318946540355682\n",
      "Epoch: 989, Train Loss: 0.13597600162029266, Valid Loss: 0.152725949883461\n",
      "Epoch: 990, Train Loss: 0.1357574462890625, Valid Loss: 0.1524694561958313\n",
      "Epoch: 991, Train Loss: 0.13554009795188904, Valid Loss: 0.152425616979599\n",
      "Epoch: 992, Train Loss: 0.13532313704490662, Valid Loss: 0.15185080468654633\n",
      "Epoch: 993, Train Loss: 0.13510599732398987, Valid Loss: 0.15200908482074738\n",
      "Epoch: 994, Train Loss: 0.1348884403705597, Valid Loss: 0.15137234330177307\n",
      "Epoch: 995, Train Loss: 0.13467074930667877, Valid Loss: 0.1514737904071808\n",
      "Epoch: 996, Train Loss: 0.13445326685905457, Valid Loss: 0.1509777009487152\n",
      "Epoch: 997, Train Loss: 0.1342363804578781, Valid Loss: 0.15087361633777618\n",
      "Epoch: 998, Train Loss: 0.13402022421360016, Valid Loss: 0.15061402320861816\n",
      "Epoch: 999, Train Loss: 0.13380470871925354, Valid Loss: 0.15026994049549103\n",
      "Epoch: 1000, Train Loss: 0.13358956575393677, Valid Loss: 0.15023522078990936\n",
      "Epoch: 1001, Train Loss: 0.13337458670139313, Valid Loss: 0.14972296357154846\n",
      "Epoch: 1002, Train Loss: 0.13315963745117188, Valid Loss: 0.14979779720306396\n",
      "Epoch: 1003, Train Loss: 0.132944718003273, Valid Loss: 0.14926046133041382\n",
      "Epoch: 1004, Train Loss: 0.13273005187511444, Valid Loss: 0.1492834985256195\n",
      "Epoch: 1005, Train Loss: 0.13251560926437378, Valid Loss: 0.1488531529903412\n",
      "Epoch: 1006, Train Loss: 0.13230159878730774, Valid Loss: 0.1487254947423935\n",
      "Epoch: 1007, Train Loss: 0.13208799064159393, Valid Loss: 0.14846019446849823\n",
      "Epoch: 1008, Train Loss: 0.13187474012374878, Valid Loss: 0.1481820046901703\n",
      "Epoch: 1009, Train Loss: 0.13166187703609467, Valid Loss: 0.14805522561073303\n",
      "Epoch: 1010, Train Loss: 0.13144929707050323, Valid Loss: 0.14767612516880035\n",
      "Epoch: 1011, Train Loss: 0.13123701512813568, Valid Loss: 0.14762143790721893\n",
      "Epoch: 1012, Train Loss: 0.13102498650550842, Valid Loss: 0.1471959352493286\n",
      "Epoch: 1013, Train Loss: 0.13081306219100952, Valid Loss: 0.14716340601444244\n",
      "Epoch: 1014, Train Loss: 0.1306014508008957, Valid Loss: 0.14673389494419098\n",
      "Epoch: 1015, Train Loss: 0.13039012253284454, Valid Loss: 0.14669466018676758\n",
      "Epoch: 1016, Train Loss: 0.1301790177822113, Valid Loss: 0.14629147946834564\n",
      "Epoch: 1017, Train Loss: 0.12996819615364075, Valid Loss: 0.14621976017951965\n",
      "Epoch: 1018, Train Loss: 0.1297575980424881, Valid Loss: 0.1458626687526703\n",
      "Epoch: 1019, Train Loss: 0.1295473873615265, Valid Loss: 0.1457391381263733\n",
      "Epoch: 1020, Train Loss: 0.12933741509914398, Valid Loss: 0.14543676376342773\n",
      "Epoch: 1021, Train Loss: 0.12912775576114655, Valid Loss: 0.14525912702083588\n",
      "Epoch: 1022, Train Loss: 0.1289183646440506, Valid Loss: 0.1450107842683792\n",
      "Epoch: 1023, Train Loss: 0.12870922684669495, Valid Loss: 0.14478947222232819\n",
      "Epoch: 1024, Train Loss: 0.12850049138069153, Valid Loss: 0.1445847898721695\n",
      "Epoch: 1025, Train Loss: 0.12829194962978363, Valid Loss: 0.14433106780052185\n",
      "Epoch: 1026, Train Loss: 0.1280837059020996, Valid Loss: 0.14415572583675385\n",
      "Epoch: 1027, Train Loss: 0.12787571549415588, Valid Loss: 0.14387643337249756\n",
      "Epoch: 1028, Train Loss: 0.12766803801059723, Valid Loss: 0.14372724294662476\n",
      "Epoch: 1029, Train Loss: 0.12746064364910126, Valid Loss: 0.14342279732227325\n",
      "Epoch: 1030, Train Loss: 0.1272534728050232, Valid Loss: 0.1433068811893463\n",
      "Epoch: 1031, Train Loss: 0.1270466297864914, Valid Loss: 0.14296859502792358\n",
      "Epoch: 1032, Train Loss: 0.1268400400876999, Valid Loss: 0.14289827644824982\n",
      "Epoch: 1033, Train Loss: 0.12663382291793823, Valid Loss: 0.14250953495502472\n",
      "Epoch: 1034, Train Loss: 0.12642791867256165, Valid Loss: 0.14250421524047852\n",
      "Epoch: 1035, Train Loss: 0.12622234225273132, Valid Loss: 0.14203834533691406\n",
      "Epoch: 1036, Train Loss: 0.12601716816425323, Valid Loss: 0.14213314652442932\n",
      "Epoch: 1037, Train Loss: 0.12581250071525574, Valid Loss: 0.14154551923274994\n",
      "Epoch: 1038, Train Loss: 0.12560853362083435, Valid Loss: 0.14180190861225128\n",
      "Epoch: 1039, Train Loss: 0.12540540099143982, Valid Loss: 0.14101570844650269\n",
      "Epoch: 1040, Train Loss: 0.12520360946655273, Valid Loss: 0.14153875410556793\n",
      "Epoch: 1041, Train Loss: 0.12500376999378204, Valid Loss: 0.14041851460933685\n",
      "Epoch: 1042, Train Loss: 0.12480705231428146, Valid Loss: 0.1413903385400772\n",
      "Epoch: 1043, Train Loss: 0.12461507320404053, Valid Loss: 0.1397174894809723\n",
      "Epoch: 1044, Train Loss: 0.12443014979362488, Valid Loss: 0.14142575860023499\n",
      "Epoch: 1045, Train Loss: 0.12425500154495239, Valid Loss: 0.13889841735363007\n",
      "Epoch: 1046, Train Loss: 0.12408995628356934, Valid Loss: 0.14166681468486786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1047, Train Loss: 0.12393060326576233, Valid Loss: 0.13808907568454742\n",
      "Epoch: 1048, Train Loss: 0.12375859916210175, Valid Loss: 0.1417662799358368\n",
      "Epoch: 1049, Train Loss: 0.12355257570743561, Valid Loss: 0.13770851492881775\n",
      "Epoch: 1050, Train Loss: 0.12329769134521484, Valid Loss: 0.1407938152551651\n",
      "Epoch: 1051, Train Loss: 0.12302473932504654, Valid Loss: 0.13818511366844177\n",
      "Epoch: 1052, Train Loss: 0.1227756142616272, Valid Loss: 0.1387818157672882\n",
      "Epoch: 1053, Train Loss: 0.12257469445466995, Valid Loss: 0.13918378949165344\n",
      "Epoch: 1054, Train Loss: 0.12240368127822876, Valid Loss: 0.13724519312381744\n",
      "Epoch: 1055, Train Loss: 0.1222226694226265, Valid Loss: 0.139493927359581\n",
      "Epoch: 1056, Train Loss: 0.12199898064136505, Valid Loss: 0.13675932586193085\n",
      "Epoch: 1057, Train Loss: 0.12172853946685791, Valid Loss: 0.1380714774131775\n",
      "Epoch: 1058, Train Loss: 0.12147538363933563, Valid Loss: 0.13690485060214996\n",
      "Epoch: 1059, Train Loss: 0.12131624668836594, Valid Loss: 0.13639463484287262\n",
      "Epoch: 1060, Train Loss: 0.12112945318222046, Valid Loss: 0.13757295906543732\n",
      "Epoch: 1061, Train Loss: 0.12090316414833069, Valid Loss: 0.1355239748954773\n",
      "Epoch: 1062, Train Loss: 0.12068504095077515, Valid Loss: 0.13688790798187256\n",
      "Epoch: 1063, Train Loss: 0.12048783898353577, Valid Loss: 0.13569103181362152\n",
      "Epoch: 1064, Train Loss: 0.12029390782117844, Valid Loss: 0.1358085423707962\n",
      "Epoch: 1065, Train Loss: 0.12009492516517639, Valid Loss: 0.13619953393936157\n",
      "Epoch: 1066, Train Loss: 0.11988803744316101, Valid Loss: 0.13481685519218445\n",
      "Epoch: 1067, Train Loss: 0.119674451649189, Valid Loss: 0.13578656315803528\n",
      "Epoch: 1068, Train Loss: 0.1194654181599617, Valid Loss: 0.1344091296195984\n",
      "Epoch: 1069, Train Loss: 0.11927224695682526, Valid Loss: 0.13479083776474\n",
      "Epoch: 1070, Train Loss: 0.1190771758556366, Valid Loss: 0.13457445800304413\n",
      "Epoch: 1071, Train Loss: 0.11886659264564514, Valid Loss: 0.13388288021087646\n",
      "Epoch: 1072, Train Loss: 0.11865664273500443, Valid Loss: 0.13450366258621216\n",
      "Epoch: 1073, Train Loss: 0.11846055090427399, Valid Loss: 0.13340133428573608\n",
      "Epoch: 1074, Train Loss: 0.11826898902654648, Valid Loss: 0.1339425891637802\n",
      "Epoch: 1075, Train Loss: 0.11806903779506683, Valid Loss: 0.13334815204143524\n",
      "Epoch: 1076, Train Loss: 0.11786025762557983, Valid Loss: 0.13311618566513062\n",
      "Epoch: 1077, Train Loss: 0.11765332520008087, Valid Loss: 0.13318805396556854\n",
      "Epoch: 1078, Train Loss: 0.11745773255825043, Valid Loss: 0.13243812322616577\n",
      "Epoch: 1079, Train Loss: 0.1172674298286438, Valid Loss: 0.1328699141740799\n",
      "Epoch: 1080, Train Loss: 0.11706747859716415, Valid Loss: 0.13215015828609467\n",
      "Epoch: 1081, Train Loss: 0.1168607696890831, Valid Loss: 0.13225862383842468\n",
      "Epoch: 1082, Train Loss: 0.11666024476289749, Valid Loss: 0.13201691210269928\n",
      "Epoch: 1083, Train Loss: 0.11646676063537598, Valid Loss: 0.13167962431907654\n",
      "Epoch: 1084, Train Loss: 0.11627177149057388, Valid Loss: 0.13181072473526\n",
      "Epoch: 1085, Train Loss: 0.11607233434915543, Valid Loss: 0.13117188215255737\n",
      "Epoch: 1086, Train Loss: 0.11587322503328323, Valid Loss: 0.13137607276439667\n",
      "Epoch: 1087, Train Loss: 0.11567779630422592, Valid Loss: 0.13088327646255493\n",
      "Epoch: 1088, Train Loss: 0.11548144370317459, Valid Loss: 0.1308678686618805\n",
      "Epoch: 1089, Train Loss: 0.11528250575065613, Valid Loss: 0.13067270815372467\n",
      "Epoch: 1090, Train Loss: 0.1150866448879242, Valid Loss: 0.13033010065555573\n",
      "Epoch: 1091, Train Loss: 0.11489414423704147, Valid Loss: 0.13040529191493988\n",
      "Epoch: 1092, Train Loss: 0.11469941586256027, Valid Loss: 0.12991218268871307\n",
      "Epoch: 1093, Train Loss: 0.11450167000293732, Valid Loss: 0.1300021857023239\n",
      "Epoch: 1094, Train Loss: 0.11430581659078598, Valid Loss: 0.12958461046218872\n",
      "Epoch: 1095, Train Loss: 0.11411299556493759, Valid Loss: 0.1295289248228073\n",
      "Epoch: 1096, Train Loss: 0.11391914635896683, Valid Loss: 0.12933243811130524\n",
      "Epoch: 1097, Train Loss: 0.11372414976358414, Valid Loss: 0.12905019521713257\n",
      "Epoch: 1098, Train Loss: 0.11353103816509247, Valid Loss: 0.12904782593250275\n",
      "Epoch: 1099, Train Loss: 0.1133384183049202, Valid Loss: 0.1286362111568451\n",
      "Epoch: 1100, Train Loss: 0.11314459145069122, Valid Loss: 0.12866413593292236\n",
      "Epoch: 1101, Train Loss: 0.11295124143362045, Valid Loss: 0.12828025221824646\n",
      "Epoch: 1102, Train Loss: 0.11275952309370041, Valid Loss: 0.1282285451889038\n",
      "Epoch: 1103, Train Loss: 0.11256735771894455, Valid Loss: 0.12800262868404388\n",
      "Epoch: 1104, Train Loss: 0.1123746708035469, Valid Loss: 0.12778832018375397\n",
      "Epoch: 1105, Train Loss: 0.11218325048685074, Valid Loss: 0.1276952624320984\n",
      "Epoch: 1106, Train Loss: 0.11199229210615158, Valid Loss: 0.12735402584075928\n",
      "Epoch: 1107, Train Loss: 0.111800916492939, Valid Loss: 0.12733536958694458\n",
      "Epoch: 1108, Train Loss: 0.11160992830991745, Valid Loss: 0.12699319422245026\n",
      "Epoch: 1109, Train Loss: 0.11141961067914963, Valid Loss: 0.12695752084255219\n",
      "Epoch: 1110, Train Loss: 0.1112288385629654, Valid Loss: 0.12669116258621216\n",
      "Epoch: 1111, Train Loss: 0.11103860288858414, Valid Loss: 0.12653492391109467\n",
      "Epoch: 1112, Train Loss: 0.11084912717342377, Valid Loss: 0.12635259330272675\n",
      "Epoch: 1113, Train Loss: 0.11065961420536041, Valid Loss: 0.12610824406147003\n",
      "Epoch: 1114, Train Loss: 0.11047017574310303, Valid Loss: 0.12602894008159637\n",
      "Epoch: 1115, Train Loss: 0.11028128117322922, Valid Loss: 0.12575489282608032\n",
      "Epoch: 1116, Train Loss: 0.11009248346090317, Valid Loss: 0.1256965696811676\n",
      "Epoch: 1117, Train Loss: 0.10990379005670547, Valid Loss: 0.12540505826473236\n",
      "Epoch: 1118, Train Loss: 0.10971566289663315, Valid Loss: 0.1252916306257248\n",
      "Epoch: 1119, Train Loss: 0.10952769219875336, Valid Loss: 0.12504467368125916\n",
      "Epoch: 1120, Train Loss: 0.10933975130319595, Valid Loss: 0.124910868704319\n",
      "Epoch: 1121, Train Loss: 0.10915232449769974, Valid Loss: 0.12474826723337173\n",
      "Epoch: 1122, Train Loss: 0.10896513611078262, Valid Loss: 0.12456676363945007\n",
      "Epoch: 1123, Train Loss: 0.10877811163663864, Valid Loss: 0.12442070245742798\n",
      "Epoch: 1124, Train Loss: 0.10859143733978271, Valid Loss: 0.12417326122522354\n",
      "Epoch: 1125, Train Loss: 0.1084049716591835, Valid Loss: 0.12405118346214294\n",
      "Epoch: 1126, Train Loss: 0.1082187294960022, Valid Loss: 0.12381596863269806\n",
      "Epoch: 1127, Train Loss: 0.10803278535604477, Valid Loss: 0.12373189628124237\n",
      "Epoch: 1128, Train Loss: 0.10784710943698883, Valid Loss: 0.1235039159655571\n",
      "Epoch: 1129, Train Loss: 0.10766156762838364, Valid Loss: 0.12338083237409592\n",
      "Epoch: 1130, Train Loss: 0.10747639834880829, Valid Loss: 0.12313887476921082\n",
      "Epoch: 1131, Train Loss: 0.10729142278432846, Valid Loss: 0.12299560755491257\n",
      "Epoch: 1132, Train Loss: 0.10710666328668594, Valid Loss: 0.1228095218539238\n",
      "Epoch: 1133, Train Loss: 0.10692229121923447, Valid Loss: 0.12266618013381958\n",
      "Epoch: 1134, Train Loss: 0.1067381277680397, Valid Loss: 0.12250223010778427\n",
      "Epoch: 1135, Train Loss: 0.10655418038368225, Valid Loss: 0.12230763584375381\n",
      "Epoch: 1136, Train Loss: 0.10637051612138748, Valid Loss: 0.12214044481515884\n",
      "Epoch: 1137, Train Loss: 0.10618716478347778, Valid Loss: 0.12193843722343445\n",
      "Epoch: 1138, Train Loss: 0.10600399971008301, Valid Loss: 0.12181451171636581\n",
      "Epoch: 1139, Train Loss: 0.1058211475610733, Valid Loss: 0.12161967158317566\n",
      "Epoch: 1140, Train Loss: 0.10563848167657852, Valid Loss: 0.12149128317832947\n",
      "Epoch: 1141, Train Loss: 0.10545609891414642, Valid Loss: 0.12126664072275162\n",
      "Epoch: 1142, Train Loss: 0.10527396202087402, Valid Loss: 0.12113189697265625\n",
      "Epoch: 1143, Train Loss: 0.10509208589792252, Valid Loss: 0.12091486155986786\n",
      "Epoch: 1144, Train Loss: 0.1049104705452919, Valid Loss: 0.12080443650484085\n",
      "Epoch: 1145, Train Loss: 0.10472912341356277, Valid Loss: 0.12059188634157181\n",
      "Epoch: 1146, Train Loss: 0.10454807430505753, Valid Loss: 0.12047439813613892\n",
      "Epoch: 1147, Train Loss: 0.1043672040104866, Valid Loss: 0.12024606019258499\n",
      "Epoch: 1148, Train Loss: 0.10418664664030075, Valid Loss: 0.1201273649930954\n",
      "Epoch: 1149, Train Loss: 0.10400629788637161, Valid Loss: 0.11990362405776978\n",
      "Epoch: 1150, Train Loss: 0.10382628440856934, Valid Loss: 0.1198006272315979\n",
      "Epoch: 1151, Train Loss: 0.10364651679992676, Valid Loss: 0.11957313865423203\n",
      "Epoch: 1152, Train Loss: 0.10346700996160507, Valid Loss: 0.1194743737578392\n",
      "Epoch: 1153, Train Loss: 0.1032877191901207, Valid Loss: 0.11922869086265564\n",
      "Epoch: 1154, Train Loss: 0.10310883074998856, Valid Loss: 0.11914277076721191\n",
      "Epoch: 1155, Train Loss: 0.10293013602495193, Valid Loss: 0.11888507753610611\n",
      "Epoch: 1156, Train Loss: 0.10275167971849442, Valid Loss: 0.11882969737052917\n",
      "Epoch: 1157, Train Loss: 0.10257358849048615, Valid Loss: 0.11854495853185654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1158, Train Loss: 0.10239570587873459, Valid Loss: 0.11851625144481659\n",
      "Epoch: 1159, Train Loss: 0.1022181436419487, Valid Loss: 0.11818487197160721\n",
      "Epoch: 1160, Train Loss: 0.10204091668128967, Valid Loss: 0.1182110384106636\n",
      "Epoch: 1161, Train Loss: 0.10186398029327393, Valid Loss: 0.11782246828079224\n",
      "Epoch: 1162, Train Loss: 0.10168740898370743, Valid Loss: 0.11793656647205353\n",
      "Epoch: 1163, Train Loss: 0.10151135176420212, Valid Loss: 0.11744105070829391\n",
      "Epoch: 1164, Train Loss: 0.10133566707372665, Valid Loss: 0.11768033355474472\n",
      "Epoch: 1165, Train Loss: 0.10116080194711685, Valid Loss: 0.1170177087187767\n",
      "Epoch: 1166, Train Loss: 0.10098671168088913, Valid Loss: 0.11747291684150696\n",
      "Epoch: 1167, Train Loss: 0.10081382840871811, Valid Loss: 0.11655082553625107\n",
      "Epoch: 1168, Train Loss: 0.10064279288053513, Valid Loss: 0.11735217273235321\n",
      "Epoch: 1169, Train Loss: 0.10047442466020584, Valid Loss: 0.11600546538829803\n",
      "Epoch: 1170, Train Loss: 0.10031002014875412, Valid Loss: 0.11735156923532486\n",
      "Epoch: 1171, Train Loss: 0.10015111416578293, Valid Loss: 0.1153506264090538\n",
      "Epoch: 1172, Train Loss: 0.09999924898147583, Valid Loss: 0.11751530319452286\n",
      "Epoch: 1173, Train Loss: 0.09985402226448059, Valid Loss: 0.11463220417499542\n",
      "Epoch: 1174, Train Loss: 0.09971120953559875, Valid Loss: 0.1177559494972229\n",
      "Epoch: 1175, Train Loss: 0.09955902397632599, Valid Loss: 0.11403659731149673\n",
      "Epoch: 1176, Train Loss: 0.09938211739063263, Valid Loss: 0.11756397038698196\n",
      "Epoch: 1177, Train Loss: 0.09917280822992325, Valid Loss: 0.11394654214382172\n",
      "Epoch: 1178, Train Loss: 0.09894659370183945, Valid Loss: 0.11635967344045639\n",
      "Epoch: 1179, Train Loss: 0.09873376041650772, Valid Loss: 0.1146034300327301\n",
      "Epoch: 1180, Train Loss: 0.09855522960424423, Valid Loss: 0.11467692255973816\n",
      "Epoch: 1181, Train Loss: 0.09840615838766098, Valid Loss: 0.11551779508590698\n",
      "Epoch: 1182, Train Loss: 0.09826342016458511, Valid Loss: 0.11355239152908325\n",
      "Epoch: 1183, Train Loss: 0.09810344129800797, Valid Loss: 0.1157243624329567\n",
      "Epoch: 1184, Train Loss: 0.09791814535856247, Valid Loss: 0.1133175864815712\n",
      "Epoch: 1185, Train Loss: 0.09772047400474548, Valid Loss: 0.11484149843454361\n",
      "Epoch: 1186, Train Loss: 0.09753229469060898, Valid Loss: 0.11376405507326126\n",
      "Epoch: 1187, Train Loss: 0.0973646268248558, Valid Loss: 0.1135314479470253\n",
      "Epoch: 1188, Train Loss: 0.09721033275127411, Valid Loss: 0.11429564654827118\n",
      "Epoch: 1189, Train Loss: 0.09705366939306259, Valid Loss: 0.11266669631004333\n",
      "Epoch: 1190, Train Loss: 0.09688378125429153, Valid Loss: 0.11415715515613556\n",
      "Epoch: 1191, Train Loss: 0.09670278429985046, Valid Loss: 0.11257155239582062\n",
      "Epoch: 1192, Train Loss: 0.0965220257639885, Valid Loss: 0.11327147483825684\n",
      "Epoch: 1193, Train Loss: 0.09635122120380402, Valid Loss: 0.11291858553886414\n",
      "Epoch: 1194, Train Loss: 0.09619022160768509, Valid Loss: 0.11230380088090897\n",
      "Epoch: 1195, Train Loss: 0.09603116661310196, Valid Loss: 0.11309820413589478\n",
      "Epoch: 1196, Train Loss: 0.09586607664823532, Valid Loss: 0.11177501827478409\n",
      "Epoch: 1197, Train Loss: 0.09569421410560608, Valid Loss: 0.11270982772111893\n",
      "Epoch: 1198, Train Loss: 0.09552068263292313, Valid Loss: 0.11178336292505264\n",
      "Epoch: 1199, Train Loss: 0.09535133093595505, Valid Loss: 0.11192285269498825\n",
      "Epoch: 1200, Train Loss: 0.09518788754940033, Valid Loss: 0.11197629570960999\n",
      "Epoch: 1201, Train Loss: 0.09502699226140976, Valid Loss: 0.11123554408550262\n",
      "Epoch: 1202, Train Loss: 0.09486433118581772, Valid Loss: 0.11188511550426483\n",
      "Epoch: 1203, Train Loss: 0.09469793736934662, Valid Loss: 0.11090879142284393\n",
      "Epoch: 1204, Train Loss: 0.09452961385250092, Valid Loss: 0.11138929426670074\n",
      "Epoch: 1205, Train Loss: 0.0943627581000328, Valid Loss: 0.11089447885751724\n",
      "Epoch: 1206, Train Loss: 0.09419909864664078, Valid Loss: 0.11073937267065048\n",
      "Epoch: 1207, Train Loss: 0.09403764456510544, Valid Loss: 0.1109115481376648\n",
      "Epoch: 1208, Train Loss: 0.09387635439634323, Valid Loss: 0.11023428291082382\n",
      "Epoch: 1209, Train Loss: 0.09371348470449448, Valid Loss: 0.11067881435155869\n",
      "Epoch: 1210, Train Loss: 0.09354919195175171, Valid Loss: 0.10999268293380737\n",
      "Epoch: 1211, Train Loss: 0.09338504076004028, Valid Loss: 0.11018817126750946\n",
      "Epoch: 1212, Train Loss: 0.09322238713502884, Valid Loss: 0.10992195457220078\n",
      "Epoch: 1213, Train Loss: 0.09306129813194275, Valid Loss: 0.10965964943170547\n",
      "Epoch: 1214, Train Loss: 0.09290111064910889, Valid Loss: 0.10980916768312454\n",
      "Epoch: 1215, Train Loss: 0.09274061769247055, Valid Loss: 0.10925689339637756\n",
      "Epoch: 1216, Train Loss: 0.09257955849170685, Valid Loss: 0.10952044278383255\n",
      "Epoch: 1217, Train Loss: 0.09241815656423569, Valid Loss: 0.10902109742164612\n",
      "Epoch: 1218, Train Loss: 0.09225713461637497, Valid Loss: 0.10907819122076035\n",
      "Epoch: 1219, Train Loss: 0.09209713339805603, Valid Loss: 0.10888664424419403\n",
      "Epoch: 1220, Train Loss: 0.09193798899650574, Valid Loss: 0.10862573981285095\n",
      "Epoch: 1221, Train Loss: 0.09177932888269424, Valid Loss: 0.1087062805891037\n",
      "Epoch: 1222, Train Loss: 0.09162063896656036, Valid Loss: 0.10827071219682693\n",
      "Epoch: 1223, Train Loss: 0.09146179258823395, Valid Loss: 0.10840984433889389\n",
      "Epoch: 1224, Train Loss: 0.09130298346281052, Valid Loss: 0.10802707821130753\n",
      "Epoch: 1225, Train Loss: 0.09114458411931992, Valid Loss: 0.10802388936281204\n",
      "Epoch: 1226, Train Loss: 0.09098681062459946, Valid Loss: 0.10784264653921127\n",
      "Epoch: 1227, Train Loss: 0.09082962572574615, Valid Loss: 0.10762834548950195\n",
      "Epoch: 1228, Train Loss: 0.0906728133559227, Valid Loss: 0.10762985050678253\n",
      "Epoch: 1229, Train Loss: 0.09051617234945297, Valid Loss: 0.10729017108678818\n",
      "Epoch: 1230, Train Loss: 0.09035969525575638, Valid Loss: 0.1073467954993248\n",
      "Epoch: 1231, Train Loss: 0.09020336717367172, Valid Loss: 0.10702358931303024\n",
      "Epoch: 1232, Train Loss: 0.09004729241132736, Valid Loss: 0.10700196027755737\n",
      "Epoch: 1233, Train Loss: 0.08989163488149643, Valid Loss: 0.1067989319562912\n",
      "Epoch: 1234, Train Loss: 0.08973643183708191, Valid Loss: 0.10664016753435135\n",
      "Epoch: 1235, Train Loss: 0.08958163857460022, Valid Loss: 0.10656837373971939\n",
      "Epoch: 1236, Train Loss: 0.08942714333534241, Valid Loss: 0.10630681365728378\n",
      "Epoch: 1237, Train Loss: 0.0892728641629219, Valid Loss: 0.10630045086145401\n",
      "Epoch: 1238, Train Loss: 0.0891188457608223, Valid Loss: 0.10602285712957382\n",
      "Epoch: 1239, Train Loss: 0.08896510303020477, Valid Loss: 0.10598820447921753\n",
      "Epoch: 1240, Train Loss: 0.08881163597106934, Valid Loss: 0.10577096045017242\n",
      "Epoch: 1241, Train Loss: 0.08865857124328613, Valid Loss: 0.10565848648548126\n",
      "Epoch: 1242, Train Loss: 0.08850587904453278, Valid Loss: 0.105524942278862\n",
      "Epoch: 1243, Train Loss: 0.08835352212190628, Valid Loss: 0.10533636808395386\n",
      "Epoch: 1244, Train Loss: 0.08820150792598724, Valid Loss: 0.10526876151561737\n",
      "Epoch: 1245, Train Loss: 0.08804969489574432, Valid Loss: 0.1050364226102829\n",
      "Epoch: 1246, Train Loss: 0.08789825439453125, Valid Loss: 0.10498571395874023\n",
      "Epoch: 1247, Train Loss: 0.08774702996015549, Valid Loss: 0.10476205497980118\n",
      "Epoch: 1248, Train Loss: 0.08759617805480957, Valid Loss: 0.10468076914548874\n",
      "Epoch: 1249, Train Loss: 0.08744554221630096, Valid Loss: 0.10450275242328644\n",
      "Epoch: 1250, Train Loss: 0.08729537576436996, Valid Loss: 0.1043722853064537\n",
      "Epoch: 1251, Train Loss: 0.08714548498392105, Valid Loss: 0.10424565523862839\n",
      "Epoch: 1252, Train Loss: 0.0869959369301796, Valid Loss: 0.10407154262065887\n",
      "Epoch: 1253, Train Loss: 0.08684664219617844, Valid Loss: 0.10397765785455704\n",
      "Epoch: 1254, Train Loss: 0.08669771999120712, Valid Loss: 0.10378184914588928\n",
      "Epoch: 1255, Train Loss: 0.0865490511059761, Valid Loss: 0.10369819402694702\n",
      "Epoch: 1256, Train Loss: 0.08640072494745255, Valid Loss: 0.10350517928600311\n",
      "Epoch: 1257, Train Loss: 0.08625268191099167, Valid Loss: 0.10340932011604309\n",
      "Epoch: 1258, Train Loss: 0.08610496670007706, Valid Loss: 0.10323882848024368\n",
      "Epoch: 1259, Train Loss: 0.08595757931470871, Valid Loss: 0.10311620682477951\n",
      "Epoch: 1260, Train Loss: 0.08581049740314484, Valid Loss: 0.10297410190105438\n",
      "Epoch: 1261, Train Loss: 0.08566373586654663, Valid Loss: 0.1028241440653801\n",
      "Epoch: 1262, Train Loss: 0.08551731705665588, Valid Loss: 0.10270559042692184\n",
      "Epoch: 1263, Train Loss: 0.08537115901708603, Valid Loss: 0.10253950953483582\n",
      "Epoch: 1264, Train Loss: 0.08522535115480423, Valid Loss: 0.10243255645036697\n",
      "Epoch: 1265, Train Loss: 0.0850798487663269, Valid Loss: 0.10226075351238251\n",
      "Epoch: 1266, Train Loss: 0.08493468165397644, Valid Loss: 0.10215599834918976\n",
      "Epoch: 1267, Train Loss: 0.08478979766368866, Valid Loss: 0.10198783874511719\n",
      "Epoch: 1268, Train Loss: 0.08464521169662476, Valid Loss: 0.10187530517578125\n",
      "Epoch: 1269, Train Loss: 0.08450094610452652, Valid Loss: 0.10171819478273392\n",
      "Epoch: 1270, Train Loss: 0.08435697853565216, Valid Loss: 0.10159441083669662\n",
      "Epoch: 1271, Train Loss: 0.08421335369348526, Valid Loss: 0.10145016759634018\n",
      "Epoch: 1272, Train Loss: 0.08407001197338104, Valid Loss: 0.10131378471851349\n",
      "Epoch: 1273, Train Loss: 0.0839269831776619, Valid Loss: 0.10118236392736435\n",
      "Epoch: 1274, Train Loss: 0.08378434926271439, Valid Loss: 0.10103600472211838\n",
      "Epoch: 1275, Train Loss: 0.08364196866750717, Valid Loss: 0.10091287642717361\n",
      "Epoch: 1276, Train Loss: 0.08349981158971786, Valid Loss: 0.10076119750738144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1277, Train Loss: 0.08335813879966736, Valid Loss: 0.10064277797937393\n",
      "Epoch: 1278, Train Loss: 0.08321671187877655, Valid Loss: 0.10048732161521912\n",
      "Epoch: 1279, Train Loss: 0.08307555317878723, Valid Loss: 0.10037290304899216\n",
      "Epoch: 1280, Train Loss: 0.08293473720550537, Valid Loss: 0.1002151295542717\n",
      "Epoch: 1281, Train Loss: 0.082794189453125, Valid Loss: 0.10010304301977158\n",
      "Epoch: 1282, Train Loss: 0.0826539620757103, Valid Loss: 0.09994535148143768\n",
      "Epoch: 1283, Train Loss: 0.08251412212848663, Valid Loss: 0.09983297437429428\n",
      "Epoch: 1284, Train Loss: 0.08237450569868088, Valid Loss: 0.0996762365102768\n",
      "Epoch: 1285, Train Loss: 0.082235187292099, Valid Loss: 0.09956398606300354\n",
      "Epoch: 1286, Train Loss: 0.08209619671106339, Valid Loss: 0.09940733760595322\n",
      "Epoch: 1287, Train Loss: 0.08195757865905762, Valid Loss: 0.09929592162370682\n",
      "Epoch: 1288, Train Loss: 0.08181916922330856, Valid Loss: 0.09913910180330276\n",
      "Epoch: 1289, Train Loss: 0.08168110996484756, Valid Loss: 0.09902928024530411\n",
      "Epoch: 1290, Train Loss: 0.08154341578483582, Valid Loss: 0.09887129813432693\n",
      "Epoch: 1291, Train Loss: 0.0814058780670166, Valid Loss: 0.09876346588134766\n",
      "Epoch: 1292, Train Loss: 0.08126876503229141, Valid Loss: 0.09860295057296753\n",
      "Epoch: 1293, Train Loss: 0.0811319425702095, Valid Loss: 0.09850068390369415\n",
      "Epoch: 1294, Train Loss: 0.08099541813135147, Valid Loss: 0.09833326935768127\n",
      "Epoch: 1295, Train Loss: 0.08085920661687851, Valid Loss: 0.09824038296937943\n",
      "Epoch: 1296, Train Loss: 0.08072326332330704, Valid Loss: 0.09806298464536667\n",
      "Epoch: 1297, Train Loss: 0.08058769255876541, Valid Loss: 0.09798356145620346\n",
      "Epoch: 1298, Train Loss: 0.08045237511396408, Valid Loss: 0.09778901934623718\n",
      "Epoch: 1299, Train Loss: 0.0803174301981926, Valid Loss: 0.09773293137550354\n",
      "Epoch: 1300, Train Loss: 0.08018280565738678, Valid Loss: 0.09751027077436447\n",
      "Epoch: 1301, Train Loss: 0.08004853874444962, Valid Loss: 0.0974905788898468\n",
      "Epoch: 1302, Train Loss: 0.07991478592157364, Valid Loss: 0.09722330421209335\n",
      "Epoch: 1303, Train Loss: 0.07978136092424393, Valid Loss: 0.09726361185312271\n",
      "Epoch: 1304, Train Loss: 0.07964857667684555, Valid Loss: 0.0969199538230896\n",
      "Epoch: 1305, Train Loss: 0.07951641827821732, Valid Loss: 0.0970623791217804\n",
      "Epoch: 1306, Train Loss: 0.07938510179519653, Valid Loss: 0.09659227728843689\n",
      "Epoch: 1307, Train Loss: 0.07925451546907425, Valid Loss: 0.09689674526453018\n",
      "Epoch: 1308, Train Loss: 0.07912490516901016, Valid Loss: 0.09623275697231293\n",
      "Epoch: 1309, Train Loss: 0.07899601012468338, Valid Loss: 0.09676945954561234\n",
      "Epoch: 1310, Train Loss: 0.07886780053377151, Valid Loss: 0.09585161507129669\n",
      "Epoch: 1311, Train Loss: 0.07873991876840591, Valid Loss: 0.09664692729711533\n",
      "Epoch: 1312, Train Loss: 0.0786118283867836, Valid Loss: 0.09550268948078156\n",
      "Epoch: 1313, Train Loss: 0.07848294079303741, Valid Loss: 0.09645702689886093\n",
      "Epoch: 1314, Train Loss: 0.07835256308317184, Valid Loss: 0.09523747116327286\n",
      "Epoch: 1315, Train Loss: 0.07822056114673615, Valid Loss: 0.0961625799536705\n",
      "Epoch: 1316, Train Loss: 0.07808687537908554, Valid Loss: 0.09504427015781403\n",
      "Epoch: 1317, Train Loss: 0.07795208692550659, Valid Loss: 0.09578899294137955\n",
      "Epoch: 1318, Train Loss: 0.077817402780056, Valid Loss: 0.09490711987018585\n",
      "Epoch: 1319, Train Loss: 0.07768377661705017, Valid Loss: 0.09534753859043121\n",
      "Epoch: 1320, Train Loss: 0.07755192369222641, Valid Loss: 0.0948486402630806\n",
      "Epoch: 1321, Train Loss: 0.07742220908403397, Valid Loss: 0.09486072510480881\n",
      "Epoch: 1322, Train Loss: 0.07729446887969971, Valid Loss: 0.09480850398540497\n",
      "Epoch: 1323, Train Loss: 0.07716809958219528, Valid Loss: 0.09443309158086777\n",
      "Epoch: 1324, Train Loss: 0.0770423486828804, Valid Loss: 0.09468847513198853\n",
      "Epoch: 1325, Train Loss: 0.07691676169633865, Valid Loss: 0.09409917891025543\n",
      "Epoch: 1326, Train Loss: 0.07679075002670288, Valid Loss: 0.09449753910303116\n",
      "Epoch: 1327, Train Loss: 0.07666425406932831, Valid Loss: 0.09381218999624252\n",
      "Epoch: 1328, Train Loss: 0.0765371099114418, Valid Loss: 0.09424768388271332\n",
      "Epoch: 1329, Train Loss: 0.07640967518091202, Valid Loss: 0.09358634799718857\n",
      "Epoch: 1330, Train Loss: 0.07628212124109268, Valid Loss: 0.09392046183347702\n",
      "Epoch: 1331, Train Loss: 0.07615495473146439, Valid Loss: 0.09342680871486664\n",
      "Epoch: 1332, Train Loss: 0.07602836191654205, Valid Loss: 0.09355446696281433\n",
      "Epoch: 1333, Train Loss: 0.0759025290608406, Valid Loss: 0.09328484535217285\n",
      "Epoch: 1334, Train Loss: 0.07577747106552124, Valid Loss: 0.09320029616355896\n",
      "Epoch: 1335, Train Loss: 0.0756530910730362, Valid Loss: 0.0931277945637703\n",
      "Epoch: 1336, Train Loss: 0.07552924752235413, Valid Loss: 0.09287326037883759\n",
      "Epoch: 1337, Train Loss: 0.07540583610534668, Valid Loss: 0.0929483100771904\n",
      "Epoch: 1338, Train Loss: 0.07528255879878998, Valid Loss: 0.0925733745098114\n",
      "Epoch: 1339, Train Loss: 0.07515937834978104, Valid Loss: 0.09273933619260788\n",
      "Epoch: 1340, Train Loss: 0.07503628730773926, Valid Loss: 0.09230558574199677\n",
      "Epoch: 1341, Train Loss: 0.07491328567266464, Valid Loss: 0.09249083697795868\n",
      "Epoch: 1342, Train Loss: 0.07479032129049301, Valid Loss: 0.09207434952259064\n",
      "Epoch: 1343, Train Loss: 0.07466758787631989, Valid Loss: 0.09220963716506958\n",
      "Epoch: 1344, Train Loss: 0.07454507052898407, Valid Loss: 0.09186447411775589\n",
      "Epoch: 1345, Train Loss: 0.07442285120487213, Valid Loss: 0.09192034602165222\n",
      "Epoch: 1346, Train Loss: 0.07430092245340347, Valid Loss: 0.09165865182876587\n",
      "Epoch: 1347, Train Loss: 0.07417945563793182, Valid Loss: 0.09163001924753189\n",
      "Epoch: 1348, Train Loss: 0.07405830174684525, Valid Loss: 0.091459721326828\n",
      "Epoch: 1349, Train Loss: 0.07393748313188553, Valid Loss: 0.09133843332529068\n",
      "Epoch: 1350, Train Loss: 0.07381702959537506, Valid Loss: 0.09125698357820511\n",
      "Epoch: 1351, Train Loss: 0.07369683682918549, Valid Loss: 0.091061532497406\n",
      "Epoch: 1352, Train Loss: 0.07357696443796158, Valid Loss: 0.09104041010141373\n",
      "Epoch: 1353, Train Loss: 0.07345739752054214, Valid Loss: 0.09079811722040176\n",
      "Epoch: 1354, Train Loss: 0.07333796471357346, Valid Loss: 0.09081345796585083\n",
      "Epoch: 1355, Train Loss: 0.07321877032518387, Valid Loss: 0.09054415673017502\n",
      "Epoch: 1356, Train Loss: 0.07309983670711517, Valid Loss: 0.09057655930519104\n",
      "Epoch: 1357, Train Loss: 0.07298117876052856, Valid Loss: 0.0903000608086586\n",
      "Epoch: 1358, Train Loss: 0.07286269217729568, Valid Loss: 0.09033175557851791\n",
      "Epoch: 1359, Train Loss: 0.07274443656206131, Valid Loss: 0.09006404876708984\n",
      "Epoch: 1360, Train Loss: 0.07262641936540604, Valid Loss: 0.09008233994245529\n",
      "Epoch: 1361, Train Loss: 0.07250868529081345, Valid Loss: 0.08983256667852402\n",
      "Epoch: 1362, Train Loss: 0.07239118218421936, Valid Loss: 0.08983021974563599\n",
      "Epoch: 1363, Train Loss: 0.07227399945259094, Valid Loss: 0.08960407972335815\n",
      "Epoch: 1364, Train Loss: 0.07215697318315506, Valid Loss: 0.08957790583372116\n",
      "Epoch: 1365, Train Loss: 0.07204027473926544, Valid Loss: 0.08937627077102661\n",
      "Epoch: 1366, Train Loss: 0.07192384451627731, Valid Loss: 0.08932666480541229\n",
      "Epoch: 1367, Train Loss: 0.07180766761302948, Valid Loss: 0.08914865553379059\n",
      "Epoch: 1368, Train Loss: 0.07169171422719955, Valid Loss: 0.08907748013734818\n",
      "Epoch: 1369, Train Loss: 0.07157598435878754, Valid Loss: 0.08891905099153519\n",
      "Epoch: 1370, Train Loss: 0.07146061211824417, Valid Loss: 0.08883131295442581\n",
      "Epoch: 1371, Train Loss: 0.07134544104337692, Valid Loss: 0.08868901431560516\n",
      "Epoch: 1372, Train Loss: 0.07123053073883057, Valid Loss: 0.08858543634414673\n",
      "Epoch: 1373, Train Loss: 0.07111582159996033, Valid Loss: 0.0884588435292244\n",
      "Epoch: 1374, Train Loss: 0.07100138068199158, Valid Loss: 0.08834252506494522\n",
      "Epoch: 1375, Train Loss: 0.07088717073202133, Valid Loss: 0.08822686225175858\n",
      "Epoch: 1376, Train Loss: 0.07077327370643616, Valid Loss: 0.08810272067785263\n",
      "Epoch: 1377, Train Loss: 0.07065965980291367, Valid Loss: 0.0879947692155838\n",
      "Epoch: 1378, Train Loss: 0.07054613530635834, Valid Loss: 0.08786319941282272\n",
      "Epoch: 1379, Train Loss: 0.07043291628360748, Valid Loss: 0.08776406198740005\n",
      "Epoch: 1380, Train Loss: 0.07031995803117752, Valid Loss: 0.08762428909540176\n",
      "Epoch: 1381, Train Loss: 0.07020726799964905, Valid Loss: 0.08753257989883423\n",
      "Epoch: 1382, Train Loss: 0.0700947716832161, Valid Loss: 0.08738693594932556\n",
      "Epoch: 1383, Train Loss: 0.06998252123594284, Valid Loss: 0.0873013287782669\n",
      "Epoch: 1384, Train Loss: 0.0698704719543457, Valid Loss: 0.08715006709098816\n",
      "Epoch: 1385, Train Loss: 0.06975874304771423, Valid Loss: 0.08707132935523987\n",
      "Epoch: 1386, Train Loss: 0.06964720785617828, Valid Loss: 0.08691304922103882\n",
      "Epoch: 1387, Train Loss: 0.06953594833612442, Valid Loss: 0.08684305846691132\n",
      "Epoch: 1388, Train Loss: 0.06942488998174667, Valid Loss: 0.08667472749948502\n",
      "Epoch: 1389, Train Loss: 0.06931403279304504, Valid Loss: 0.0866168811917305\n",
      "Epoch: 1390, Train Loss: 0.06920348852872849, Valid Loss: 0.08643616735935211\n",
      "Epoch: 1391, Train Loss: 0.06909311562776566, Valid Loss: 0.08639300614595413\n",
      "Epoch: 1392, Train Loss: 0.06898301839828491, Valid Loss: 0.08619604259729385\n",
      "Epoch: 1393, Train Loss: 0.06887318938970566, Valid Loss: 0.08617258816957474\n",
      "Epoch: 1394, Train Loss: 0.06876356899738312, Valid Loss: 0.08595342934131622\n",
      "Epoch: 1395, Train Loss: 0.06865426152944565, Valid Loss: 0.08595609664916992\n",
      "Epoch: 1396, Train Loss: 0.06854524463415146, Valid Loss: 0.085706427693367\n",
      "Epoch: 1397, Train Loss: 0.0684363916516304, Valid Loss: 0.08574685454368591\n",
      "Epoch: 1398, Train Loss: 0.06832781434059143, Valid Loss: 0.08545348793268204\n",
      "Epoch: 1399, Train Loss: 0.06821967661380768, Valid Loss: 0.08554587513208389\n",
      "Epoch: 1400, Train Loss: 0.06811179965734482, Valid Loss: 0.08519356697797775\n",
      "Epoch: 1401, Train Loss: 0.06800435483455658, Valid Loss: 0.08535698801279068\n",
      "Epoch: 1402, Train Loss: 0.06789740175008774, Valid Loss: 0.08492084592580795\n",
      "Epoch: 1403, Train Loss: 0.0677909329533577, Valid Loss: 0.08518683165311813\n",
      "Epoch: 1404, Train Loss: 0.06768519431352615, Valid Loss: 0.08463341742753983\n",
      "Epoch: 1405, Train Loss: 0.0675802156329155, Valid Loss: 0.08503998816013336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1406, Train Loss: 0.06747625768184662, Valid Loss: 0.08432852476835251\n",
      "Epoch: 1407, Train Loss: 0.06737339496612549, Valid Loss: 0.08492261916399002\n",
      "Epoch: 1408, Train Loss: 0.06727183610200882, Valid Loss: 0.08400701731443405\n",
      "Epoch: 1409, Train Loss: 0.0671715959906578, Valid Loss: 0.08483235538005829\n",
      "Epoch: 1410, Train Loss: 0.06707216054201126, Valid Loss: 0.08368059992790222\n",
      "Epoch: 1411, Train Loss: 0.066973015666008, Valid Loss: 0.08474380522966385\n",
      "Epoch: 1412, Train Loss: 0.06687260419130325, Valid Loss: 0.08338040113449097\n",
      "Epoch: 1413, Train Loss: 0.06676929444074631, Valid Loss: 0.08458620309829712\n",
      "Epoch: 1414, Train Loss: 0.06666133552789688, Valid Loss: 0.0831587091088295\n",
      "Epoch: 1415, Train Loss: 0.06654854118824005, Valid Loss: 0.08426396548748016\n",
      "Epoch: 1416, Train Loss: 0.06643229722976685, Valid Loss: 0.08306673914194107\n",
      "Epoch: 1417, Train Loss: 0.06631597876548767, Valid Loss: 0.08376255631446838\n",
      "Epoch: 1418, Train Loss: 0.06620287895202637, Valid Loss: 0.08310474455356598\n",
      "Epoch: 1419, Train Loss: 0.06609524041414261, Valid Loss: 0.08320233225822449\n",
      "Epoch: 1420, Train Loss: 0.0659928023815155, Valid Loss: 0.08318682014942169\n",
      "Epoch: 1421, Train Loss: 0.06589372456073761, Valid Loss: 0.0827224850654602\n",
      "Epoch: 1422, Train Loss: 0.06579546630382538, Valid Loss: 0.08318696171045303\n",
      "Epoch: 1423, Train Loss: 0.06569566577672958, Valid Loss: 0.08238185197114944\n",
      "Epoch: 1424, Train Loss: 0.06559304893016815, Valid Loss: 0.08302044123411179\n",
      "Epoch: 1425, Train Loss: 0.06548774987459183, Valid Loss: 0.08218234032392502\n",
      "Epoch: 1426, Train Loss: 0.0653807520866394, Valid Loss: 0.08268427848815918\n",
      "Epoch: 1427, Train Loss: 0.06527404487133026, Valid Loss: 0.0821017250418663\n",
      "Epoch: 1428, Train Loss: 0.06516898423433304, Valid Loss: 0.0822552740573883\n",
      "Epoch: 1429, Train Loss: 0.0650663673877716, Valid Loss: 0.08207856118679047\n",
      "Epoch: 1430, Train Loss: 0.06496580690145493, Valid Loss: 0.0818445235490799\n",
      "Epoch: 1431, Train Loss: 0.06486630439758301, Valid Loss: 0.08201947808265686\n",
      "Epoch: 1432, Train Loss: 0.06476681679487228, Valid Loss: 0.08152256906032562\n",
      "Epoch: 1433, Train Loss: 0.06466636061668396, Valid Loss: 0.08185918629169464\n",
      "Epoch: 1434, Train Loss: 0.06456489861011505, Valid Loss: 0.08130082488059998\n",
      "Epoch: 1435, Train Loss: 0.06446272879838943, Valid Loss: 0.08159007132053375\n",
      "Epoch: 1436, Train Loss: 0.06436052918434143, Valid Loss: 0.08116055279970169\n",
      "Epoch: 1437, Train Loss: 0.06425889581441879, Valid Loss: 0.0812537670135498\n",
      "Epoch: 1438, Train Loss: 0.06415831297636032, Valid Loss: 0.08106118440628052\n",
      "Epoch: 1439, Train Loss: 0.06405864655971527, Valid Loss: 0.08091255277395248\n",
      "Epoch: 1440, Train Loss: 0.06395962834358215, Valid Loss: 0.0809476375579834\n",
      "Epoch: 1441, Train Loss: 0.0638609379529953, Valid Loss: 0.080617256462574\n",
      "Epoch: 1442, Train Loss: 0.06376214325428009, Valid Loss: 0.08077523857355118\n",
      "Epoch: 1443, Train Loss: 0.06366303563117981, Valid Loss: 0.0803866982460022\n",
      "Epoch: 1444, Train Loss: 0.06356371194124222, Valid Loss: 0.08053816854953766\n",
      "Epoch: 1445, Train Loss: 0.06346438825130463, Valid Loss: 0.08020837604999542\n",
      "Epoch: 1446, Train Loss: 0.06336533278226852, Valid Loss: 0.08025892078876495\n",
      "Epoch: 1447, Train Loss: 0.06326669454574585, Valid Loss: 0.08006057888269424\n",
      "Epoch: 1448, Train Loss: 0.06316852569580078, Valid Loss: 0.0799684226512909\n",
      "Epoch: 1449, Train Loss: 0.0630708709359169, Valid Loss: 0.07991331070661545\n",
      "Epoch: 1450, Train Loss: 0.06297346949577332, Valid Loss: 0.07969728857278824\n",
      "Epoch: 1451, Train Loss: 0.06287624686956406, Valid Loss: 0.07973775267601013\n",
      "Epoch: 1452, Train Loss: 0.06277903914451599, Valid Loss: 0.07946262508630753\n",
      "Epoch: 1453, Train Loss: 0.06268185377120972, Valid Loss: 0.07952360063791275\n",
      "Epoch: 1454, Train Loss: 0.0625847801566124, Valid Loss: 0.07926066219806671\n",
      "Epoch: 1455, Train Loss: 0.06248781085014343, Valid Loss: 0.0792803168296814\n",
      "Epoch: 1456, Train Loss: 0.062391117215156555, Valid Loss: 0.07908091694116592\n",
      "Epoch: 1457, Train Loss: 0.062294647097587585, Valid Loss: 0.07902318239212036\n",
      "Epoch: 1458, Train Loss: 0.06219851225614548, Valid Loss: 0.07890798896551132\n",
      "Epoch: 1459, Train Loss: 0.06210264191031456, Valid Loss: 0.07877042144536972\n",
      "Epoch: 1460, Train Loss: 0.06200697645545006, Valid Loss: 0.07872629165649414\n",
      "Epoch: 1461, Train Loss: 0.06191154941916466, Valid Loss: 0.07853386551141739\n",
      "Epoch: 1462, Train Loss: 0.06181618943810463, Valid Loss: 0.07852638512849808\n",
      "Epoch: 1463, Train Loss: 0.06172102689743042, Valid Loss: 0.07831825315952301\n",
      "Epoch: 1464, Train Loss: 0.06162595748901367, Valid Loss: 0.07830634713172913\n",
      "Epoch: 1465, Train Loss: 0.06153112277388573, Valid Loss: 0.07811938971281052\n",
      "Epoch: 1466, Train Loss: 0.06143639236688614, Valid Loss: 0.0780748575925827\n",
      "Epoch: 1467, Train Loss: 0.06134195253252983, Valid Loss: 0.07792860269546509\n",
      "Epoch: 1468, Train Loss: 0.06124767288565636, Valid Loss: 0.07783909142017365\n",
      "Epoch: 1469, Train Loss: 0.06115367263555527, Valid Loss: 0.07773992419242859\n",
      "Epoch: 1470, Train Loss: 0.06105978786945343, Valid Loss: 0.07760694622993469\n",
      "Epoch: 1471, Train Loss: 0.06096619367599487, Valid Loss: 0.07754424214363098\n",
      "Epoch: 1472, Train Loss: 0.060872726142406464, Valid Loss: 0.07738517969846725\n",
      "Epoch: 1473, Train Loss: 0.060779426246881485, Valid Loss: 0.07733908295631409\n",
      "Epoch: 1474, Train Loss: 0.06068625673651695, Valid Loss: 0.07717355340719223\n",
      "Epoch: 1475, Train Loss: 0.060593381524086, Valid Loss: 0.07712425291538239\n",
      "Epoch: 1476, Train Loss: 0.060500506311655045, Valid Loss: 0.0769718587398529\n",
      "Epoch: 1477, Train Loss: 0.06040794402360916, Valid Loss: 0.07690364122390747\n",
      "Epoch: 1478, Train Loss: 0.060315538197755814, Valid Loss: 0.07677337527275085\n",
      "Epoch: 1479, Train Loss: 0.0602233000099659, Valid Loss: 0.07668241858482361\n",
      "Epoch: 1480, Train Loss: 0.060131270438432693, Valid Loss: 0.07657686620950699\n",
      "Epoch: 1481, Train Loss: 0.06003950908780098, Valid Loss: 0.07646229863166809\n",
      "Epoch: 1482, Train Loss: 0.059947796165943146, Valid Loss: 0.07637789845466614\n",
      "Epoch: 1483, Train Loss: 0.05985637009143829, Valid Loss: 0.07624732702970505\n",
      "Epoch: 1484, Train Loss: 0.059765007346868515, Valid Loss: 0.07617370784282684\n",
      "Epoch: 1485, Train Loss: 0.05967388302087784, Valid Loss: 0.07603763043880463\n",
      "Epoch: 1486, Train Loss: 0.0595829077064991, Valid Loss: 0.07596541196107864\n",
      "Epoch: 1487, Train Loss: 0.059492167085409164, Valid Loss: 0.07583288848400116\n",
      "Epoch: 1488, Train Loss: 0.05940154939889908, Valid Loss: 0.07575451582670212\n",
      "Epoch: 1489, Train Loss: 0.0593111477792263, Valid Loss: 0.07563092559576035\n",
      "Epoch: 1490, Train Loss: 0.05922086536884308, Valid Loss: 0.07554212212562561\n",
      "Epoch: 1491, Train Loss: 0.059130795300006866, Valid Loss: 0.07543084025382996\n",
      "Epoch: 1492, Train Loss: 0.05904095992445946, Valid Loss: 0.07532979547977448\n",
      "Epoch: 1493, Train Loss: 0.0589512437582016, Valid Loss: 0.07523079216480255\n",
      "Epoch: 1494, Train Loss: 0.058861713856458664, Valid Loss: 0.0751194953918457\n",
      "Epoch: 1495, Train Loss: 0.058772340416908264, Valid Loss: 0.07502895593643188\n",
      "Epoch: 1496, Train Loss: 0.0586831159889698, Valid Loss: 0.07491197437047958\n",
      "Epoch: 1497, Train Loss: 0.058594152331352234, Valid Loss: 0.07482614368200302\n",
      "Epoch: 1498, Train Loss: 0.058505285531282425, Valid Loss: 0.07470563054084778\n",
      "Epoch: 1499, Train Loss: 0.058416616171598434, Valid Loss: 0.0746215283870697\n",
      "Epoch: 1500, Train Loss: 0.058328088372945786, Valid Loss: 0.07450317591428757\n",
      "Epoch: 1501, Train Loss: 0.058239810168743134, Valid Loss: 0.0744151622056961\n",
      "Epoch: 1502, Train Loss: 0.05815163999795914, Valid Loss: 0.0743018090724945\n",
      "Epoch: 1503, Train Loss: 0.058063652366399765, Valid Loss: 0.07420962303876877\n",
      "Epoch: 1504, Train Loss: 0.05797585844993591, Valid Loss: 0.07410121709108353\n",
      "Epoch: 1505, Train Loss: 0.057888213545084, Valid Loss: 0.0740034282207489\n",
      "Epoch: 1506, Train Loss: 0.05780073255300522, Valid Loss: 0.0739014521241188\n",
      "Epoch: 1507, Train Loss: 0.05771344527602196, Valid Loss: 0.07379854470491409\n",
      "Epoch: 1508, Train Loss: 0.057626303285360336, Valid Loss: 0.07370128482580185\n",
      "Epoch: 1509, Train Loss: 0.05753934755921364, Valid Loss: 0.07359439879655838\n",
      "Epoch: 1510, Train Loss: 0.05745253711938858, Valid Loss: 0.07350211590528488\n",
      "Epoch: 1511, Train Loss: 0.05736592039465904, Valid Loss: 0.0733916386961937\n",
      "Epoch: 1512, Train Loss: 0.057279471307992935, Valid Loss: 0.07330112904310226\n",
      "Epoch: 1513, Train Loss: 0.05719313770532608, Valid Loss: 0.07319073379039764\n",
      "Epoch: 1514, Train Loss: 0.05710700899362564, Valid Loss: 0.07310045510530472\n",
      "Epoch: 1515, Train Loss: 0.057020995765924454, Valid Loss: 0.0729905217885971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1516, Train Loss: 0.056935254484415054, Valid Loss: 0.07289977371692657\n",
      "Epoch: 1517, Train Loss: 0.05684962123632431, Valid Loss: 0.07279186695814133\n",
      "Epoch: 1518, Train Loss: 0.056764159351587296, Valid Loss: 0.07269805669784546\n",
      "Epoch: 1519, Train Loss: 0.05667886137962341, Valid Loss: 0.07259415090084076\n",
      "Epoch: 1520, Train Loss: 0.05659368634223938, Valid Loss: 0.0724978819489479\n",
      "Epoch: 1521, Train Loss: 0.05650874972343445, Valid Loss: 0.07239639014005661\n",
      "Epoch: 1522, Train Loss: 0.05642394348978996, Valid Loss: 0.07229763269424438\n",
      "Epoch: 1523, Train Loss: 0.05633927136659622, Valid Loss: 0.07219965755939484\n",
      "Epoch: 1524, Train Loss: 0.056254792958498, Valid Loss: 0.0720987394452095\n",
      "Epoch: 1525, Train Loss: 0.056170471012592316, Valid Loss: 0.0720018669962883\n",
      "Epoch: 1526, Train Loss: 0.05608628690242767, Valid Loss: 0.07190027832984924\n",
      "Epoch: 1527, Train Loss: 0.056002285331487656, Valid Loss: 0.07180574536323547\n",
      "Epoch: 1528, Train Loss: 0.05591842159628868, Valid Loss: 0.0717025026679039\n",
      "Epoch: 1529, Train Loss: 0.055834751576185226, Valid Loss: 0.07160897552967072\n",
      "Epoch: 1530, Train Loss: 0.05575120449066162, Valid Loss: 0.07150590419769287\n",
      "Epoch: 1531, Train Loss: 0.055667851120233536, Valid Loss: 0.07141254842281342\n",
      "Epoch: 1532, Train Loss: 0.0555846281349659, Valid Loss: 0.0713096559047699\n",
      "Epoch: 1533, Train Loss: 0.05550157651305199, Valid Loss: 0.07121694833040237\n",
      "Epoch: 1534, Train Loss: 0.055418699979782104, Valid Loss: 0.07111441344022751\n",
      "Epoch: 1535, Train Loss: 0.05533594265580177, Valid Loss: 0.07102088630199432\n",
      "Epoch: 1536, Train Loss: 0.055253397673368454, Valid Loss: 0.0709201991558075\n",
      "Epoch: 1537, Train Loss: 0.05517096817493439, Valid Loss: 0.07082533091306686\n",
      "Epoch: 1538, Train Loss: 0.05508871749043465, Valid Loss: 0.07072596251964569\n",
      "Epoch: 1539, Train Loss: 0.055006567388772964, Valid Loss: 0.0706309825181961\n",
      "Epoch: 1540, Train Loss: 0.054924678057432175, Valid Loss: 0.07053238153457642\n",
      "Epoch: 1541, Train Loss: 0.054842859506607056, Valid Loss: 0.07043690234422684\n",
      "Epoch: 1542, Train Loss: 0.054761238396167755, Valid Loss: 0.07033893465995789\n",
      "Epoch: 1543, Train Loss: 0.0546797513961792, Valid Loss: 0.07024314999580383\n",
      "Epoch: 1544, Train Loss: 0.05459841340780258, Valid Loss: 0.07014672458171844\n",
      "Epoch: 1545, Train Loss: 0.05451721325516701, Valid Loss: 0.07004961371421814\n",
      "Epoch: 1546, Train Loss: 0.05443621799349785, Valid Loss: 0.06995448470115662\n",
      "Epoch: 1547, Train Loss: 0.054355327039957047, Valid Loss: 0.06985790282487869\n",
      "Epoch: 1548, Train Loss: 0.054274655878543854, Valid Loss: 0.06976236402988434\n",
      "Epoch: 1549, Train Loss: 0.054194044321775436, Valid Loss: 0.06966559588909149\n",
      "Epoch: 1550, Train Loss: 0.054113660007715225, Valid Loss: 0.0695718452334404\n",
      "Epoch: 1551, Train Loss: 0.054033394902944565, Valid Loss: 0.06947416812181473\n",
      "Epoch: 1552, Train Loss: 0.05395334213972092, Valid Loss: 0.06938032805919647\n",
      "Epoch: 1553, Train Loss: 0.05387333407998085, Valid Loss: 0.06928403675556183\n",
      "Epoch: 1554, Train Loss: 0.05379354953765869, Valid Loss: 0.06918976455926895\n",
      "Epoch: 1555, Train Loss: 0.05371388792991638, Valid Loss: 0.06909403949975967\n",
      "Epoch: 1556, Train Loss: 0.05363438278436661, Valid Loss: 0.06899969279766083\n",
      "Epoch: 1557, Train Loss: 0.053555022925138474, Valid Loss: 0.06890442222356796\n",
      "Epoch: 1558, Train Loss: 0.05347583070397377, Valid Loss: 0.06881066411733627\n",
      "Epoch: 1559, Train Loss: 0.05339675769209862, Valid Loss: 0.0687151774764061\n",
      "Epoch: 1560, Train Loss: 0.0533178374171257, Valid Loss: 0.06862150132656097\n",
      "Epoch: 1561, Train Loss: 0.05323906987905502, Valid Loss: 0.06852709501981735\n",
      "Epoch: 1562, Train Loss: 0.05316043645143509, Valid Loss: 0.06843283772468567\n",
      "Epoch: 1563, Train Loss: 0.05308197811245918, Valid Loss: 0.06833916902542114\n",
      "Epoch: 1564, Train Loss: 0.053003665059804916, Valid Loss: 0.06824523955583572\n",
      "Epoch: 1565, Train Loss: 0.05292551591992378, Valid Loss: 0.0681515708565712\n",
      "Epoch: 1566, Train Loss: 0.052847448736429214, Valid Loss: 0.06805790215730667\n",
      "Epoch: 1567, Train Loss: 0.05276958644390106, Valid Loss: 0.06796436011791229\n",
      "Epoch: 1568, Train Loss: 0.05269189551472664, Valid Loss: 0.06787141412496567\n",
      "Epoch: 1569, Train Loss: 0.05261430889368057, Valid Loss: 0.0677776038646698\n",
      "Epoch: 1570, Train Loss: 0.05253682658076286, Valid Loss: 0.06768552213907242\n",
      "Epoch: 1571, Train Loss: 0.052459534257650375, Valid Loss: 0.06759171187877655\n",
      "Epoch: 1572, Train Loss: 0.052382372319698334, Valid Loss: 0.06749987602233887\n",
      "Epoch: 1573, Train Loss: 0.052305348217487335, Valid Loss: 0.06740596145391464\n",
      "Epoch: 1574, Train Loss: 0.05222846195101738, Valid Loss: 0.06731528043746948\n",
      "Epoch: 1575, Train Loss: 0.05215175077319145, Valid Loss: 0.0672207921743393\n",
      "Epoch: 1576, Train Loss: 0.05207515507936478, Valid Loss: 0.06713011860847473\n",
      "Epoch: 1577, Train Loss: 0.05199872702360153, Valid Loss: 0.06703687459230423\n",
      "Epoch: 1578, Train Loss: 0.05192246660590172, Valid Loss: 0.06694649904966354\n",
      "Epoch: 1579, Train Loss: 0.051846254616975784, Valid Loss: 0.0668523833155632\n",
      "Epoch: 1580, Train Loss: 0.05177023261785507, Valid Loss: 0.06676306575536728\n",
      "Epoch: 1581, Train Loss: 0.051694367080926895, Valid Loss: 0.06666897982358932\n",
      "Epoch: 1582, Train Loss: 0.051618680357933044, Valid Loss: 0.06658072769641876\n",
      "Epoch: 1583, Train Loss: 0.05154307931661606, Valid Loss: 0.06648530066013336\n",
      "Epoch: 1584, Train Loss: 0.051467616111040115, Valid Loss: 0.0663985088467598\n",
      "Epoch: 1585, Train Loss: 0.051392268389463425, Valid Loss: 0.06630315631628036\n",
      "Epoch: 1586, Train Loss: 0.05131708085536957, Valid Loss: 0.06621676683425903\n",
      "Epoch: 1587, Train Loss: 0.05124204233288765, Valid Loss: 0.06612040102481842\n",
      "Epoch: 1588, Train Loss: 0.05116720497608185, Valid Loss: 0.06603625416755676\n",
      "Epoch: 1589, Train Loss: 0.05109240859746933, Valid Loss: 0.06593851745128632\n",
      "Epoch: 1590, Train Loss: 0.051017772406339645, Valid Loss: 0.06585618108510971\n",
      "Epoch: 1591, Train Loss: 0.05094331130385399, Valid Loss: 0.06575663387775421\n",
      "Epoch: 1592, Train Loss: 0.050868988037109375, Valid Loss: 0.06567709892988205\n",
      "Epoch: 1593, Train Loss: 0.05079478397965431, Valid Loss: 0.06557486206293106\n",
      "Epoch: 1594, Train Loss: 0.0507206916809082, Valid Loss: 0.06549832224845886\n",
      "Epoch: 1595, Train Loss: 0.05064680054783821, Valid Loss: 0.06539440155029297\n",
      "Epoch: 1596, Train Loss: 0.05057298019528389, Valid Loss: 0.06532016396522522\n",
      "Epoch: 1597, Train Loss: 0.050499312579631805, Valid Loss: 0.06521318107843399\n",
      "Epoch: 1598, Train Loss: 0.050425827503204346, Valid Loss: 0.06514401733875275\n",
      "Epoch: 1599, Train Loss: 0.05035242810845375, Valid Loss: 0.06503167003393173\n",
      "Epoch: 1600, Train Loss: 0.050279174000024796, Valid Loss: 0.06496849656105042\n",
      "Epoch: 1601, Train Loss: 0.05020604655146599, Valid Loss: 0.06485052406787872\n",
      "Epoch: 1602, Train Loss: 0.05013304948806763, Valid Loss: 0.06479403376579285\n",
      "Epoch: 1603, Train Loss: 0.05006023496389389, Valid Loss: 0.06466948240995407\n",
      "Epoch: 1604, Train Loss: 0.04998749867081642, Valid Loss: 0.06462089717388153\n",
      "Epoch: 1605, Train Loss: 0.04991495609283447, Valid Loss: 0.06448717415332794\n",
      "Epoch: 1606, Train Loss: 0.049842528998851776, Valid Loss: 0.06445097178220749\n",
      "Epoch: 1607, Train Loss: 0.04977022111415863, Valid Loss: 0.06430289149284363\n",
      "Epoch: 1608, Train Loss: 0.049698058515787125, Valid Loss: 0.06428325176239014\n",
      "Epoch: 1609, Train Loss: 0.049626123160123825, Valid Loss: 0.06411759555339813\n",
      "Epoch: 1610, Train Loss: 0.04955427348613739, Valid Loss: 0.0641188770532608\n",
      "Epoch: 1611, Train Loss: 0.04948261007666588, Valid Loss: 0.0639292523264885\n",
      "Epoch: 1612, Train Loss: 0.04941114783287048, Valid Loss: 0.06395923346281052\n",
      "Epoch: 1613, Train Loss: 0.04933974891901016, Valid Loss: 0.06373754143714905\n",
      "Epoch: 1614, Train Loss: 0.04926871135830879, Valid Loss: 0.06380598247051239\n",
      "Epoch: 1615, Train Loss: 0.04919783025979996, Valid Loss: 0.06353991478681564\n",
      "Epoch: 1616, Train Loss: 0.0491272434592247, Valid Loss: 0.06366156041622162\n",
      "Epoch: 1617, Train Loss: 0.04905695095658302, Valid Loss: 0.06333612650632858\n",
      "Epoch: 1618, Train Loss: 0.04898707568645477, Valid Loss: 0.06352800130844116\n",
      "Epoch: 1619, Train Loss: 0.04891759157180786, Valid Loss: 0.06312383711338043\n",
      "Epoch: 1620, Train Loss: 0.04884863644838333, Valid Loss: 0.06340862065553665\n",
      "Epoch: 1621, Train Loss: 0.04878028854727745, Valid Loss: 0.06290322542190552\n",
      "Epoch: 1622, Train Loss: 0.04871266335248947, Valid Loss: 0.06330589205026627\n",
      "Epoch: 1623, Train Loss: 0.048645831644535065, Valid Loss: 0.06267443299293518\n",
      "Epoch: 1624, Train Loss: 0.048579733818769455, Valid Loss: 0.06321889162063599\n",
      "Epoch: 1625, Train Loss: 0.048514142632484436, Valid Loss: 0.06244523823261261\n",
      "Epoch: 1626, Train Loss: 0.04844871163368225, Valid Loss: 0.06313198059797287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1627, Train Loss: 0.048382632434368134, Valid Loss: 0.06223095953464508\n",
      "Epoch: 1628, Train Loss: 0.048315104097127914, Valid Loss: 0.06301060318946838\n",
      "Epoch: 1629, Train Loss: 0.04824491962790489, Valid Loss: 0.06205500289797783\n",
      "Epoch: 1630, Train Loss: 0.048171889036893845, Valid Loss: 0.06280458718538284\n",
      "Epoch: 1631, Train Loss: 0.048096105456352234, Valid Loss: 0.06194232031702995\n",
      "Epoch: 1632, Train Loss: 0.04801901802420616, Valid Loss: 0.062492407858371735\n",
      "Epoch: 1633, Train Loss: 0.047942548990249634, Valid Loss: 0.06190437451004982\n",
      "Epoch: 1634, Train Loss: 0.04786854609847069, Valid Loss: 0.062120288610458374\n",
      "Epoch: 1635, Train Loss: 0.04779776930809021, Valid Loss: 0.06191371753811836\n",
      "Epoch: 1636, Train Loss: 0.047730110585689545, Valid Loss: 0.06176883727312088\n",
      "Epoch: 1637, Train Loss: 0.04766447842121124, Valid Loss: 0.0619075633585453\n",
      "Epoch: 1638, Train Loss: 0.04759927839040756, Valid Loss: 0.061485372483730316\n",
      "Epoch: 1639, Train Loss: 0.04753338545560837, Valid Loss: 0.06183259189128876\n",
      "Epoch: 1640, Train Loss: 0.047466062009334564, Valid Loss: 0.06127750501036644\n",
      "Epoch: 1641, Train Loss: 0.047397125512361526, Valid Loss: 0.06166369467973709\n",
      "Epoch: 1642, Train Loss: 0.04732699319720268, Valid Loss: 0.061144642531871796\n",
      "Epoch: 1643, Train Loss: 0.04725649952888489, Valid Loss: 0.06141039356589317\n",
      "Epoch: 1644, Train Loss: 0.04718645289540291, Valid Loss: 0.061071380972862244\n",
      "Epoch: 1645, Train Loss: 0.04711756855249405, Valid Loss: 0.06112046167254448\n",
      "Epoch: 1646, Train Loss: 0.04705004394054413, Valid Loss: 0.061019353568553925\n",
      "Epoch: 1647, Train Loss: 0.0469835139811039, Valid Loss: 0.060849741101264954\n",
      "Epoch: 1648, Train Loss: 0.046917546540498734, Valid Loss: 0.06094174459576607\n",
      "Epoch: 1649, Train Loss: 0.046851493418216705, Valid Loss: 0.06062944978475571\n",
      "Epoch: 1650, Train Loss: 0.04678507521748543, Valid Loss: 0.06081032380461693\n",
      "Epoch: 1651, Train Loss: 0.04671812802553177, Valid Loss: 0.060459841042757034\n",
      "Epoch: 1652, Train Loss: 0.04665069654583931, Valid Loss: 0.06062422692775726\n",
      "Epoch: 1653, Train Loss: 0.046583227813243866, Valid Loss: 0.06033278629183769\n",
      "Epoch: 1654, Train Loss: 0.04651596024632454, Valid Loss: 0.06039886176586151\n",
      "Epoch: 1655, Train Loss: 0.04644917696714401, Valid Loss: 0.06023230031132698\n",
      "Epoch: 1656, Train Loss: 0.04638289660215378, Valid Loss: 0.06016429886221886\n",
      "Epoch: 1657, Train Loss: 0.04631713032722473, Valid Loss: 0.060131777077913284\n",
      "Epoch: 1658, Train Loss: 0.046251602470874786, Valid Loss: 0.05994855985045433\n",
      "Epoch: 1659, Train Loss: 0.046186141669750214, Valid Loss: 0.06000525504350662\n",
      "Epoch: 1660, Train Loss: 0.04612061008810997, Valid Loss: 0.05976680666208267\n",
      "Epoch: 1661, Train Loss: 0.04605499282479286, Valid Loss: 0.059844259172677994\n",
      "Epoch: 1662, Train Loss: 0.045989252626895905, Valid Loss: 0.059615593403577805\n",
      "Epoch: 1663, Train Loss: 0.045923586934804916, Valid Loss: 0.05965692177414894\n",
      "Epoch: 1664, Train Loss: 0.045858047902584076, Valid Loss: 0.0594848208129406\n",
      "Epoch: 1665, Train Loss: 0.04579271376132965, Valid Loss: 0.05945584923028946\n",
      "Epoch: 1666, Train Loss: 0.045727670192718506, Valid Loss: 0.059362612664699554\n",
      "Epoch: 1667, Train Loss: 0.045662883669137955, Valid Loss: 0.059257637709379196\n",
      "Epoch: 1668, Train Loss: 0.045598242431879044, Valid Loss: 0.05923281982541084\n",
      "Epoch: 1669, Train Loss: 0.04553370177745819, Valid Loss: 0.059075068682432175\n",
      "Epoch: 1670, Train Loss: 0.04546922817826271, Valid Loss: 0.05908496305346489\n",
      "Epoch: 1671, Train Loss: 0.04540475085377693, Valid Loss: 0.0589120090007782\n",
      "Epoch: 1672, Train Loss: 0.0453404001891613, Valid Loss: 0.05891859531402588\n",
      "Epoch: 1673, Train Loss: 0.045276083052158356, Valid Loss: 0.058764468878507614\n",
      "Epoch: 1674, Train Loss: 0.04521190747618675, Valid Loss: 0.05874020606279373\n",
      "Epoch: 1675, Train Loss: 0.0451478585600853, Valid Loss: 0.058624934405088425\n",
      "Epoch: 1676, Train Loss: 0.04508396238088608, Valid Loss: 0.05855889245867729\n",
      "Epoch: 1677, Train Loss: 0.0450202152132988, Valid Loss: 0.058486372232437134\n",
      "Epoch: 1678, Train Loss: 0.044956646859645844, Valid Loss: 0.058380890637636185\n",
      "Epoch: 1679, Train Loss: 0.044893164187669754, Valid Loss: 0.058342691510915756\n",
      "Epoch: 1680, Train Loss: 0.044829804450273514, Valid Loss: 0.05821312963962555\n",
      "Epoch: 1681, Train Loss: 0.044766489416360855, Valid Loss: 0.058187924325466156\n",
      "Epoch: 1682, Train Loss: 0.04470331221818924, Valid Loss: 0.058056723326444626\n",
      "Epoch: 1683, Train Loss: 0.04464014247059822, Valid Loss: 0.058024004101753235\n",
      "Epoch: 1684, Train Loss: 0.044577162712812424, Valid Loss: 0.057909078896045685\n",
      "Epoch: 1685, Train Loss: 0.04451427608728409, Valid Loss: 0.05785512924194336\n",
      "Epoch: 1686, Train Loss: 0.04445153847336769, Valid Loss: 0.0577644482254982\n",
      "Epoch: 1687, Train Loss: 0.04438889026641846, Valid Loss: 0.05768636241555214\n",
      "Epoch: 1688, Train Loss: 0.04432638734579086, Valid Loss: 0.05761905014514923\n",
      "Epoch: 1689, Train Loss: 0.044263970106840134, Valid Loss: 0.05752086266875267\n",
      "Epoch: 1690, Train Loss: 0.044201694428920746, Valid Loss: 0.05746999382972717\n",
      "Epoch: 1691, Train Loss: 0.04413949325680733, Valid Loss: 0.05736074969172478\n",
      "Epoch: 1692, Train Loss: 0.04407740756869316, Valid Loss: 0.057315293699502945\n",
      "Epoch: 1693, Train Loss: 0.044015463441610336, Valid Loss: 0.057206977158784866\n",
      "Epoch: 1694, Train Loss: 0.0439535528421402, Valid Loss: 0.05715569481253624\n",
      "Epoch: 1695, Train Loss: 0.04389180988073349, Valid Loss: 0.057057663798332214\n",
      "Epoch: 1696, Train Loss: 0.04383012279868126, Valid Loss: 0.05699379742145538\n",
      "Epoch: 1697, Train Loss: 0.04376858472824097, Valid Loss: 0.05691061541438103\n",
      "Epoch: 1698, Train Loss: 0.04370715469121933, Valid Loss: 0.05683232843875885\n",
      "Epoch: 1699, Train Loss: 0.043645817786455154, Valid Loss: 0.05676257982850075\n",
      "Epoch: 1700, Train Loss: 0.04358458146452904, Valid Loss: 0.056673623621463776\n",
      "Epoch: 1701, Train Loss: 0.04352348670363426, Valid Loss: 0.056612785905599594\n",
      "Epoch: 1702, Train Loss: 0.04346250370144844, Valid Loss: 0.05651790648698807\n",
      "Epoch: 1703, Train Loss: 0.0434015691280365, Valid Loss: 0.05646037682890892\n",
      "Epoch: 1704, Train Loss: 0.0433407761156559, Valid Loss: 0.056366272270679474\n",
      "Epoch: 1705, Train Loss: 0.04328010976314545, Valid Loss: 0.056305304169654846\n",
      "Epoch: 1706, Train Loss: 0.04321952164173126, Valid Loss: 0.0562172457575798\n",
      "Epoch: 1707, Train Loss: 0.04315904155373573, Valid Loss: 0.05614914000034332\n",
      "Epoch: 1708, Train Loss: 0.043098658323287964, Valid Loss: 0.056069761514663696\n",
      "Epoch: 1709, Train Loss: 0.04303842410445213, Valid Loss: 0.055993251502513885\n",
      "Epoch: 1710, Train Loss: 0.04297824576497078, Valid Loss: 0.055921491235494614\n",
      "Epoch: 1711, Train Loss: 0.042918190360069275, Valid Loss: 0.05583973973989487\n",
      "Epoch: 1712, Train Loss: 0.04285825788974762, Valid Loss: 0.055771950632333755\n",
      "Epoch: 1713, Train Loss: 0.04279836639761925, Valid Loss: 0.055687714368104935\n",
      "Epoch: 1714, Train Loss: 0.042738672345876694, Valid Loss: 0.05562194809317589\n",
      "Epoch: 1715, Train Loss: 0.042679015547037125, Valid Loss: 0.05553719401359558\n",
      "Epoch: 1716, Train Loss: 0.042619455605745316, Valid Loss: 0.055470529943704605\n",
      "Epoch: 1717, Train Loss: 0.04256001487374306, Valid Loss: 0.05538903549313545\n",
      "Epoch: 1718, Train Loss: 0.04250071570277214, Valid Loss: 0.05531845986843109\n",
      "Epoch: 1719, Train Loss: 0.042441476136446, Valid Loss: 0.05524127930402756\n",
      "Epoch: 1720, Train Loss: 0.042382366955280304, Valid Loss: 0.055167388170957565\n",
      "Epoch: 1721, Train Loss: 0.04232332855463028, Valid Loss: 0.05509357899427414\n",
      "Epoch: 1722, Train Loss: 0.04226440563797951, Valid Loss: 0.05501718446612358\n",
      "Epoch: 1723, Train Loss: 0.0422055684030056, Valid Loss: 0.05494563281536102\n",
      "Epoch: 1724, Train Loss: 0.042146869003772736, Valid Loss: 0.05486808717250824\n",
      "Epoch: 1725, Train Loss: 0.042088236659765244, Valid Loss: 0.05479788780212402\n",
      "Epoch: 1726, Train Loss: 0.04202974587678909, Valid Loss: 0.0547197163105011\n",
      "Epoch: 1727, Train Loss: 0.04197134077548981, Valid Loss: 0.054649919271469116\n",
      "Epoch: 1728, Train Loss: 0.0419129878282547, Valid Loss: 0.05457257106900215\n",
      "Epoch: 1729, Train Loss: 0.04185481742024422, Valid Loss: 0.05450158566236496\n",
      "Epoch: 1730, Train Loss: 0.041796717792749405, Valid Loss: 0.05442682281136513\n",
      "Epoch: 1731, Train Loss: 0.041738733649253845, Valid Loss: 0.05435310676693916\n",
      "Epoch: 1732, Train Loss: 0.041680801659822464, Valid Loss: 0.054280929267406464\n",
      "Epoch: 1733, Train Loss: 0.04162297025322914, Valid Loss: 0.05420583859086037\n",
      "Epoch: 1734, Train Loss: 0.04156528785824776, Valid Loss: 0.05413515120744705\n",
      "Epoch: 1735, Train Loss: 0.04150767996907234, Valid Loss: 0.05405917018651962\n",
      "Epoch: 1736, Train Loss: 0.0414501316845417, Valid Loss: 0.05398938059806824\n",
      "Epoch: 1737, Train Loss: 0.0413927286863327, Valid Loss: 0.053913190960884094\n",
      "Epoch: 1738, Train Loss: 0.04133543744683266, Valid Loss: 0.05384408310055733\n",
      "Epoch: 1739, Train Loss: 0.04127821698784828, Valid Loss: 0.053767845034599304\n",
      "Epoch: 1740, Train Loss: 0.04122108593583107, Valid Loss: 0.05369863659143448\n",
      "Epoch: 1741, Train Loss: 0.041164103895425797, Valid Loss: 0.0536235049366951\n",
      "Epoch: 1742, Train Loss: 0.041107166558504105, Valid Loss: 0.05355290323495865\n",
      "Epoch: 1743, Train Loss: 0.041050348430871964, Valid Loss: 0.05348019674420357\n",
      "Epoch: 1744, Train Loss: 0.04099361598491669, Valid Loss: 0.053407374769449234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1745, Train Loss: 0.04093701392412186, Valid Loss: 0.05333738401532173\n",
      "Epoch: 1746, Train Loss: 0.04088045656681061, Valid Loss: 0.05326218530535698\n",
      "Epoch: 1747, Train Loss: 0.040824055671691895, Valid Loss: 0.05319387838244438\n",
      "Epoch: 1748, Train Loss: 0.04076770320534706, Valid Loss: 0.053119316697120667\n",
      "Epoch: 1749, Train Loss: 0.040711499750614166, Valid Loss: 0.0530502051115036\n",
      "Epoch: 1750, Train Loss: 0.040655337274074554, Valid Loss: 0.05297604948282242\n",
      "Epoch: 1751, Train Loss: 0.0405992716550827, Valid Loss: 0.05290757492184639\n",
      "Epoch: 1752, Train Loss: 0.0405433289706707, Valid Loss: 0.052833255380392075\n",
      "Epoch: 1753, Train Loss: 0.040487486869096756, Valid Loss: 0.052764903753995895\n",
      "Epoch: 1754, Train Loss: 0.040431734174489975, Valid Loss: 0.05269164219498634\n",
      "Epoch: 1755, Train Loss: 0.04037606343626976, Valid Loss: 0.052621908485889435\n",
      "Epoch: 1756, Train Loss: 0.040320515632629395, Valid Loss: 0.05255080386996269\n",
      "Epoch: 1757, Train Loss: 0.04026500880718231, Valid Loss: 0.05247917026281357\n",
      "Epoch: 1758, Train Loss: 0.040209684520959854, Valid Loss: 0.05241028219461441\n",
      "Epoch: 1759, Train Loss: 0.04015436768531799, Valid Loss: 0.0523374117910862\n",
      "Epoch: 1760, Train Loss: 0.04009918123483658, Valid Loss: 0.05226900056004524\n",
      "Epoch: 1761, Train Loss: 0.04004412889480591, Valid Loss: 0.052196599543094635\n",
      "Epoch: 1762, Train Loss: 0.03998910263180733, Valid Loss: 0.05212852358818054\n",
      "Epoch: 1763, Train Loss: 0.03993421420454979, Valid Loss: 0.05205585062503815\n",
      "Epoch: 1764, Train Loss: 0.039879392832517624, Valid Loss: 0.05198792368173599\n",
      "Epoch: 1765, Train Loss: 0.03982469066977501, Valid Loss: 0.051916178315877914\n",
      "Epoch: 1766, Train Loss: 0.03977009281516075, Valid Loss: 0.051847904920578\n",
      "Epoch: 1767, Train Loss: 0.03971553593873978, Valid Loss: 0.051776252686977386\n",
      "Epoch: 1768, Train Loss: 0.03966110944747925, Valid Loss: 0.05170828476548195\n",
      "Epoch: 1769, Train Loss: 0.03960677981376648, Valid Loss: 0.05163728818297386\n",
      "Epoch: 1770, Train Loss: 0.03955252468585968, Valid Loss: 0.051568757742643356\n",
      "Epoch: 1771, Train Loss: 0.03949834033846855, Valid Loss: 0.05149891972541809\n",
      "Epoch: 1772, Train Loss: 0.03944427892565727, Valid Loss: 0.051429539918899536\n",
      "Epoch: 1773, Train Loss: 0.03939031437039375, Valid Loss: 0.05136040598154068\n",
      "Epoch: 1774, Train Loss: 0.03933647647500038, Valid Loss: 0.05129144340753555\n",
      "Epoch: 1775, Train Loss: 0.0392826646566391, Valid Loss: 0.05122208595275879\n",
      "Epoch: 1776, Train Loss: 0.03922896832227707, Valid Loss: 0.05115372687578201\n",
      "Epoch: 1777, Train Loss: 0.03917538747191429, Valid Loss: 0.05108420550823212\n",
      "Epoch: 1778, Train Loss: 0.0391218438744545, Valid Loss: 0.051015667617321014\n",
      "Epoch: 1779, Train Loss: 0.03906842693686485, Valid Loss: 0.050947461277246475\n",
      "Epoch: 1780, Train Loss: 0.039015091955661774, Valid Loss: 0.05087849497795105\n",
      "Epoch: 1781, Train Loss: 0.038961879909038544, Valid Loss: 0.05080990865826607\n",
      "Epoch: 1782, Train Loss: 0.0389087088406086, Valid Loss: 0.05074189603328705\n",
      "Epoch: 1783, Train Loss: 0.038855649530887604, Valid Loss: 0.050673071295022964\n",
      "Epoch: 1784, Train Loss: 0.038802701979875565, Valid Loss: 0.05060599371790886\n",
      "Epoch: 1785, Train Loss: 0.0387498140335083, Valid Loss: 0.05053640529513359\n",
      "Epoch: 1786, Train Loss: 0.03869707137346268, Valid Loss: 0.05046959966421127\n",
      "Epoch: 1787, Train Loss: 0.03864433243870735, Valid Loss: 0.05040103942155838\n",
      "Epoch: 1788, Train Loss: 0.03859173506498337, Valid Loss: 0.05033368989825249\n",
      "Epoch: 1789, Train Loss: 0.03853921964764595, Valid Loss: 0.05026531592011452\n",
      "Epoch: 1790, Train Loss: 0.0384867861866951, Valid Loss: 0.05019866302609444\n",
      "Epoch: 1791, Train Loss: 0.038434434682130814, Valid Loss: 0.05013005807995796\n",
      "Epoch: 1792, Train Loss: 0.03838219493627548, Valid Loss: 0.05006318911910057\n",
      "Epoch: 1793, Train Loss: 0.03833002597093582, Valid Loss: 0.0499960221350193\n",
      "Epoch: 1794, Train Loss: 0.038277991116046906, Valid Loss: 0.04992843046784401\n",
      "Epoch: 1795, Train Loss: 0.03822597116231918, Valid Loss: 0.049861565232276917\n",
      "Epoch: 1796, Train Loss: 0.03817407414317131, Valid Loss: 0.04979371652007103\n",
      "Epoch: 1797, Train Loss: 0.038122255355119705, Valid Loss: 0.049727946519851685\n",
      "Epoch: 1798, Train Loss: 0.03807053342461586, Valid Loss: 0.049659933894872665\n",
      "Epoch: 1799, Train Loss: 0.03801891580224037, Valid Loss: 0.049593955278396606\n",
      "Epoch: 1800, Train Loss: 0.037967387586832047, Valid Loss: 0.04952635616064072\n",
      "Epoch: 1801, Train Loss: 0.037915877997875214, Valid Loss: 0.049460772424936295\n",
      "Epoch: 1802, Train Loss: 0.03786451369524002, Valid Loss: 0.04939332604408264\n",
      "Epoch: 1803, Train Loss: 0.037813249975442886, Valid Loss: 0.049327410757541656\n",
      "Epoch: 1804, Train Loss: 0.037762049585580826, Valid Loss: 0.04926100745797157\n",
      "Epoch: 1805, Train Loss: 0.03771094232797623, Valid Loss: 0.04919387772679329\n",
      "Epoch: 1806, Train Loss: 0.03765992447733879, Valid Loss: 0.04912972077727318\n",
      "Epoch: 1807, Train Loss: 0.03760899230837822, Valid Loss: 0.04906079173088074\n",
      "Epoch: 1808, Train Loss: 0.03755814954638481, Valid Loss: 0.048997849225997925\n",
      "Epoch: 1809, Train Loss: 0.03750734031200409, Valid Loss: 0.048929013311862946\n",
      "Epoch: 1810, Train Loss: 0.0374567024409771, Valid Loss: 0.04886569082736969\n",
      "Epoch: 1811, Train Loss: 0.03740612417459488, Valid Loss: 0.0487978458404541\n",
      "Epoch: 1812, Train Loss: 0.03735560551285744, Valid Loss: 0.04873419180512428\n",
      "Epoch: 1813, Train Loss: 0.03730516508221626, Valid Loss: 0.048666033893823624\n",
      "Epoch: 1814, Train Loss: 0.03725484386086464, Valid Loss: 0.04860401526093483\n",
      "Epoch: 1815, Train Loss: 0.03720458969473839, Valid Loss: 0.048534706234931946\n",
      "Epoch: 1816, Train Loss: 0.03715444728732109, Valid Loss: 0.04847291111946106\n",
      "Epoch: 1817, Train Loss: 0.03710431233048439, Valid Loss: 0.04840517044067383\n",
      "Epoch: 1818, Train Loss: 0.03705437481403351, Valid Loss: 0.04834149777889252\n",
      "Epoch: 1819, Train Loss: 0.037004418671131134, Valid Loss: 0.04827531799674034\n",
      "Epoch: 1820, Train Loss: 0.0369546115398407, Valid Loss: 0.048211440443992615\n",
      "Epoch: 1821, Train Loss: 0.036904897540807724, Valid Loss: 0.04814543575048447\n",
      "Epoch: 1822, Train Loss: 0.036855194717645645, Valid Loss: 0.04808199778199196\n",
      "Epoch: 1823, Train Loss: 0.0368056446313858, Valid Loss: 0.048015810549259186\n",
      "Epoch: 1824, Train Loss: 0.036756157875061035, Valid Loss: 0.047951992601156235\n",
      "Epoch: 1825, Train Loss: 0.03670674189925194, Valid Loss: 0.047887176275253296\n",
      "Epoch: 1826, Train Loss: 0.036657415330410004, Valid Loss: 0.04782244190573692\n",
      "Epoch: 1827, Train Loss: 0.036608170717954636, Valid Loss: 0.04775865375995636\n",
      "Epoch: 1828, Train Loss: 0.03655901551246643, Valid Loss: 0.0476936437189579\n",
      "Epoch: 1829, Train Loss: 0.036509934812784195, Valid Loss: 0.047629714012145996\n",
      "Epoch: 1830, Train Loss: 0.03646097704768181, Valid Loss: 0.047565508633852005\n",
      "Epoch: 1831, Train Loss: 0.03641204163432121, Valid Loss: 0.04750173166394234\n",
      "Epoch: 1832, Train Loss: 0.03636322170495987, Valid Loss: 0.04743702709674835\n",
      "Epoch: 1833, Train Loss: 0.0363144725561142, Valid Loss: 0.04737413302063942\n",
      "Epoch: 1834, Train Loss: 0.03626581281423569, Valid Loss: 0.047308873385190964\n",
      "Epoch: 1835, Train Loss: 0.036217205226421356, Valid Loss: 0.04724687710404396\n",
      "Epoch: 1836, Train Loss: 0.03616873174905777, Valid Loss: 0.047181349247694016\n",
      "Epoch: 1837, Train Loss: 0.036120302975177765, Valid Loss: 0.047118786722421646\n",
      "Epoch: 1838, Train Loss: 0.03607197478413582, Valid Loss: 0.047055091708898544\n",
      "Epoch: 1839, Train Loss: 0.036023713648319244, Valid Loss: 0.04699138551950455\n",
      "Epoch: 1840, Train Loss: 0.03597552329301834, Valid Loss: 0.046928200870752335\n",
      "Epoch: 1841, Train Loss: 0.035927463322877884, Valid Loss: 0.04686513543128967\n",
      "Epoch: 1842, Train Loss: 0.03587944805622101, Valid Loss: 0.0468011200428009\n",
      "Epoch: 1843, Train Loss: 0.03583149611949921, Valid Loss: 0.04673856869339943\n",
      "Epoch: 1844, Train Loss: 0.03578369319438934, Valid Loss: 0.04667523503303528\n",
      "Epoch: 1845, Train Loss: 0.03573590889573097, Valid Loss: 0.0466122180223465\n",
      "Epoch: 1846, Train Loss: 0.03568821772933006, Valid Loss: 0.04654974862933159\n",
      "Epoch: 1847, Train Loss: 0.03564062342047691, Valid Loss: 0.04648600518703461\n",
      "Epoch: 1848, Train Loss: 0.03559308499097824, Valid Loss: 0.04642396420240402\n",
      "Epoch: 1849, Train Loss: 0.03554562106728554, Valid Loss: 0.04636107757687569\n",
      "Epoch: 1850, Train Loss: 0.03549828380346298, Valid Loss: 0.04629809781908989\n",
      "Epoch: 1851, Train Loss: 0.03545096889138222, Valid Loss: 0.046235669404268265\n",
      "Epoch: 1852, Train Loss: 0.0354037806391716, Valid Loss: 0.046173345297575\n",
      "Epoch: 1853, Train Loss: 0.03535662591457367, Valid Loss: 0.04611022025346756\n",
      "Epoch: 1854, Train Loss: 0.0353095680475235, Valid Loss: 0.04604912921786308\n",
      "Epoch: 1855, Train Loss: 0.035262566059827805, Valid Loss: 0.04598493501543999\n",
      "Epoch: 1856, Train Loss: 0.035215724259614944, Valid Loss: 0.0459245890378952\n",
      "Epoch: 1857, Train Loss: 0.035168930888175964, Valid Loss: 0.045860931277275085\n",
      "Epoch: 1858, Train Loss: 0.03512216731905937, Valid Loss: 0.04579973593354225\n",
      "Epoch: 1859, Train Loss: 0.03507550060749054, Valid Loss: 0.045737117528915405\n",
      "Epoch: 1860, Train Loss: 0.03502892702817917, Valid Loss: 0.045675765722990036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1861, Train Loss: 0.034982454031705856, Valid Loss: 0.045612383633852005\n",
      "Epoch: 1862, Train Loss: 0.034936025738716125, Valid Loss: 0.04555269703269005\n",
      "Epoch: 1863, Train Loss: 0.034889671951532364, Valid Loss: 0.04548823833465576\n",
      "Epoch: 1864, Train Loss: 0.03484339639544487, Valid Loss: 0.04542938619852066\n",
      "Epoch: 1865, Train Loss: 0.03479720279574394, Valid Loss: 0.04536453261971474\n",
      "Epoch: 1866, Train Loss: 0.03475111350417137, Valid Loss: 0.04530598968267441\n",
      "Epoch: 1867, Train Loss: 0.034705039113759995, Valid Loss: 0.04524175077676773\n",
      "Epoch: 1868, Train Loss: 0.034659091383218765, Valid Loss: 0.04518236219882965\n",
      "Epoch: 1869, Train Loss: 0.03461320325732231, Valid Loss: 0.04511842131614685\n",
      "Epoch: 1870, Train Loss: 0.034567419439554214, Valid Loss: 0.04506050422787666\n",
      "Epoch: 1871, Train Loss: 0.03452169522643089, Valid Loss: 0.044994745403528214\n",
      "Epoch: 1872, Train Loss: 0.034476008266210556, Valid Loss: 0.04493829607963562\n",
      "Epoch: 1873, Train Loss: 0.03443047031760216, Valid Loss: 0.04487170651555061\n",
      "Epoch: 1874, Train Loss: 0.03438497707247734, Valid Loss: 0.044816091656684875\n",
      "Epoch: 1875, Train Loss: 0.0343395434319973, Valid Loss: 0.04474927857518196\n",
      "Epoch: 1876, Train Loss: 0.03429418429732323, Valid Loss: 0.04469356685876846\n",
      "Epoch: 1877, Train Loss: 0.034248948097229004, Valid Loss: 0.0446271076798439\n",
      "Epoch: 1878, Train Loss: 0.03420373424887657, Valid Loss: 0.04457194358110428\n",
      "Epoch: 1879, Train Loss: 0.034158602356910706, Valid Loss: 0.04450390487909317\n",
      "Epoch: 1880, Train Loss: 0.03411354869604111, Valid Loss: 0.044451117515563965\n",
      "Epoch: 1881, Train Loss: 0.034068603068590164, Valid Loss: 0.04438093304634094\n",
      "Epoch: 1882, Train Loss: 0.03402367979288101, Valid Loss: 0.044330425560474396\n",
      "Epoch: 1883, Train Loss: 0.03397888317704201, Valid Loss: 0.04425787553191185\n",
      "Epoch: 1884, Train Loss: 0.0339340940117836, Valid Loss: 0.044209882616996765\n",
      "Epoch: 1885, Train Loss: 0.03388947620987892, Valid Loss: 0.04413536190986633\n",
      "Epoch: 1886, Train Loss: 0.033844832330942154, Valid Loss: 0.04408957436680794\n",
      "Epoch: 1887, Train Loss: 0.03380032628774643, Valid Loss: 0.044011518359184265\n",
      "Epoch: 1888, Train Loss: 0.03375590965151787, Valid Loss: 0.043970987200737\n",
      "Epoch: 1889, Train Loss: 0.03371148928999901, Valid Loss: 0.04388664290308952\n",
      "Epoch: 1890, Train Loss: 0.033667221665382385, Valid Loss: 0.043853458017110825\n",
      "Epoch: 1891, Train Loss: 0.03362298756837845, Valid Loss: 0.0437610000371933\n",
      "Epoch: 1892, Train Loss: 0.03357885405421257, Valid Loss: 0.04373700171709061\n",
      "Epoch: 1893, Train Loss: 0.033534787595272064, Valid Loss: 0.04363347589969635\n",
      "Epoch: 1894, Train Loss: 0.03349081054329872, Valid Loss: 0.04362313449382782\n",
      "Epoch: 1895, Train Loss: 0.03344694897532463, Valid Loss: 0.043502774089574814\n",
      "Epoch: 1896, Train Loss: 0.033403124660253525, Valid Loss: 0.043514434248209\n",
      "Epoch: 1897, Train Loss: 0.03335943818092346, Valid Loss: 0.04336578771471977\n",
      "Epoch: 1898, Train Loss: 0.033315882086753845, Valid Loss: 0.043412961065769196\n",
      "Epoch: 1899, Train Loss: 0.03327248618006706, Valid Loss: 0.04322130233049393\n",
      "Epoch: 1900, Train Loss: 0.03322929888963699, Valid Loss: 0.04332203418016434\n",
      "Epoch: 1901, Train Loss: 0.03318639472126961, Valid Loss: 0.04306464642286301\n",
      "Epoch: 1902, Train Loss: 0.03314394876360893, Valid Loss: 0.0432497076690197\n",
      "Epoch: 1903, Train Loss: 0.03310206159949303, Valid Loss: 0.04288863018155098\n",
      "Epoch: 1904, Train Loss: 0.033061157912015915, Valid Loss: 0.043209485709667206\n",
      "Epoch: 1905, Train Loss: 0.0330217108130455, Valid Loss: 0.04268364980816841\n",
      "Epoch: 1906, Train Loss: 0.032984402030706406, Valid Loss: 0.04322277009487152\n",
      "Epoch: 1907, Train Loss: 0.03295015171170235, Valid Loss: 0.04244418069720268\n",
      "Epoch: 1908, Train Loss: 0.0329202301800251, Valid Loss: 0.04330946132540703\n",
      "Epoch: 1909, Train Loss: 0.03289416804909706, Valid Loss: 0.0421920120716095\n",
      "Epoch: 1910, Train Loss: 0.03287193179130554, Valid Loss: 0.043436020612716675\n",
      "Epoch: 1911, Train Loss: 0.032845135778188705, Valid Loss: 0.04200463369488716\n",
      "Epoch: 1912, Train Loss: 0.03280869498848915, Valid Loss: 0.043396662920713425\n",
      "Epoch: 1913, Train Loss: 0.03274914249777794, Valid Loss: 0.04198240116238594\n",
      "Epoch: 1914, Train Loss: 0.03267442062497139, Valid Loss: 0.04292568564414978\n",
      "Epoch: 1915, Train Loss: 0.03259824216365814, Valid Loss: 0.042165130376815796\n",
      "Epoch: 1916, Train Loss: 0.032541219145059586, Valid Loss: 0.04227849096059799\n",
      "Epoch: 1917, Train Loss: 0.03250752389431, Valid Loss: 0.042474471032619476\n",
      "Epoch: 1918, Train Loss: 0.032484110444784164, Valid Loss: 0.04189601540565491\n",
      "Epoch: 1919, Train Loss: 0.0324535109102726, Valid Loss: 0.04257306456565857\n",
      "Epoch: 1920, Train Loss: 0.03240522742271423, Valid Loss: 0.041759371757507324\n",
      "Epoch: 1921, Train Loss: 0.032346274703741074, Valid Loss: 0.04228731617331505\n",
      "Epoch: 1922, Train Loss: 0.03229008615016937, Valid Loss: 0.041827164590358734\n",
      "Epoch: 1923, Train Loss: 0.03224651515483856, Valid Loss: 0.04185735061764717\n",
      "Epoch: 1924, Train Loss: 0.03221335634589195, Valid Loss: 0.04204637557268143\n",
      "Epoch: 1925, Train Loss: 0.03218065947294235, Valid Loss: 0.04151049628853798\n",
      "Epoch: 1926, Train Loss: 0.03214074298739433, Valid Loss: 0.04207758605480194\n",
      "Epoch: 1927, Train Loss: 0.03209211677312851, Valid Loss: 0.041374463587999344\n",
      "Epoch: 1928, Train Loss: 0.03204122558236122, Valid Loss: 0.041776224970817566\n",
      "Epoch: 1929, Train Loss: 0.03199482709169388, Valid Loss: 0.04150104522705078\n",
      "Epoch: 1930, Train Loss: 0.03195514529943466, Valid Loss: 0.04138284549117088\n",
      "Epoch: 1931, Train Loss: 0.03191883862018585, Valid Loss: 0.04164445772767067\n",
      "Epoch: 1932, Train Loss: 0.031880952417850494, Valid Loss: 0.041114840656518936\n",
      "Epoch: 1933, Train Loss: 0.03183901309967041, Valid Loss: 0.041541118174791336\n",
      "Epoch: 1934, Train Loss: 0.03179360553622246, Valid Loss: 0.04103931784629822\n",
      "Epoch: 1935, Train Loss: 0.03174791485071182, Valid Loss: 0.04127218574285507\n",
      "Epoch: 1936, Train Loss: 0.031704530119895935, Valid Loss: 0.0410882942378521\n",
      "Epoch: 1937, Train Loss: 0.0316641665995121, Valid Loss: 0.04097793623805046\n",
      "Epoch: 1938, Train Loss: 0.0316254124045372, Valid Loss: 0.04111243784427643\n",
      "Epoch: 1939, Train Loss: 0.03158622980117798, Valid Loss: 0.04071444645524025\n",
      "Epoch: 1940, Train Loss: 0.031545475125312805, Valid Loss: 0.04104190692305565\n",
      "Epoch: 1941, Train Loss: 0.03150298073887825, Valid Loss: 0.04056625813245773\n",
      "Epoch: 1942, Train Loss: 0.03145955875515938, Valid Loss: 0.04086956009268761\n",
      "Epoch: 1943, Train Loss: 0.03141610324382782, Valid Loss: 0.0405234657227993\n",
      "Epoch: 1944, Train Loss: 0.03137314319610596, Valid Loss: 0.04060334712266922\n",
      "Epoch: 1945, Train Loss: 0.03133079409599304, Valid Loss: 0.04049461707472801\n",
      "Epoch: 1946, Train Loss: 0.031288959085941315, Valid Loss: 0.04034517705440521\n",
      "Epoch: 1947, Train Loss: 0.031247081235051155, Valid Loss: 0.04044352099299431\n",
      "Epoch: 1948, Train Loss: 0.03120502084493637, Valid Loss: 0.04015030339360237\n",
      "Epoch: 1949, Train Loss: 0.031162509694695473, Valid Loss: 0.04038999602198601\n",
      "Epoch: 1950, Train Loss: 0.031119657680392265, Valid Loss: 0.039952054619789124\n",
      "Epoch: 1951, Train Loss: 0.031076783314347267, Valid Loss: 0.04037638008594513\n",
      "Epoch: 1952, Train Loss: 0.03103484772145748, Valid Loss: 0.03973912075161934\n",
      "Epoch: 1953, Train Loss: 0.03099556267261505, Valid Loss: 0.04049878567457199\n",
      "Epoch: 1954, Train Loss: 0.030961602926254272, Valid Loss: 0.0395720973610878\n",
      "Epoch: 1955, Train Loss: 0.030936231836676598, Valid Loss: 0.040839266031980515\n",
      "Epoch: 1956, Train Loss: 0.030915800482034683, Valid Loss: 0.039568230509757996\n",
      "Epoch: 1957, Train Loss: 0.030886005610227585, Valid Loss: 0.04123449698090553\n",
      "Epoch: 1958, Train Loss: 0.030819909647107124, Valid Loss: 0.03994487226009369\n",
      "Epoch: 1959, Train Loss: 0.0307212695479393, Valid Loss: 0.04106397181749344\n",
      "Epoch: 1960, Train Loss: 0.030638623982667923, Valid Loss: 0.04073633626103401\n",
      "Epoch: 1961, Train Loss: 0.030607404187321663, Valid Loss: 0.040618158876895905\n",
      "Epoch: 1962, Train Loss: 0.030594034120440483, Valid Loss: 0.0413367934525013\n",
      "Epoch: 1963, Train Loss: 0.03054777719080448, Valid Loss: 0.04054985195398331\n",
      "Epoch: 1964, Train Loss: 0.030468784272670746, Valid Loss: 0.04082121327519417\n",
      "Epoch: 1965, Train Loss: 0.030401095747947693, Valid Loss: 0.0405532643198967\n",
      "Epoch: 1966, Train Loss: 0.0303677786141634, Valid Loss: 0.04019889980554581\n",
      "Epoch: 1967, Train Loss: 0.030346298590302467, Valid Loss: 0.04054510220885277\n",
      "Epoch: 1968, Train Loss: 0.030305102467536926, Valid Loss: 0.03991907089948654\n",
      "Epoch: 1969, Train Loss: 0.03024381585419178, Valid Loss: 0.04029097035527229\n",
      "Epoch: 1970, Train Loss: 0.030186450108885765, Valid Loss: 0.03987529128789902\n",
      "Epoch: 1971, Train Loss: 0.030144771561026573, Valid Loss: 0.039958737790584564\n",
      "Epoch: 1972, Train Loss: 0.030110934749245644, Valid Loss: 0.04028576985001564\n",
      "Epoch: 1973, Train Loss: 0.030070075765252113, Valid Loss: 0.03985551744699478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1974, Train Loss: 0.030017709359526634, Valid Loss: 0.04039986431598663\n",
      "Epoch: 1975, Train Loss: 0.0299679022282362, Valid Loss: 0.0401310920715332\n",
      "Epoch: 1976, Train Loss: 0.029931936413049698, Valid Loss: 0.039999574422836304\n",
      "Epoch: 1977, Train Loss: 0.02989749237895012, Valid Loss: 0.04036135971546173\n",
      "Epoch: 1978, Train Loss: 0.02985226921737194, Valid Loss: 0.03988843783736229\n",
      "Epoch: 1979, Train Loss: 0.029804153367877007, Valid Loss: 0.03994016349315643\n",
      "Epoch: 1980, Train Loss: 0.029763113707304, Valid Loss: 0.03986155614256859\n",
      "Epoch: 1981, Train Loss: 0.029726294800639153, Valid Loss: 0.03941543400287628\n",
      "Epoch: 1982, Train Loss: 0.029687048867344856, Valid Loss: 0.0395231619477272\n",
      "Epoch: 1983, Train Loss: 0.029644066467881203, Valid Loss: 0.03925877436995506\n",
      "Epoch: 1984, Train Loss: 0.02960147149860859, Valid Loss: 0.03920559957623482\n",
      "Epoch: 1985, Train Loss: 0.029562868177890778, Valid Loss: 0.039218392223119736\n",
      "Epoch: 1986, Train Loss: 0.029525140300393105, Valid Loss: 0.03905447572469711\n",
      "Epoch: 1987, Train Loss: 0.029484348371624947, Valid Loss: 0.03915944695472717\n",
      "Epoch: 1988, Train Loss: 0.02944233827292919, Valid Loss: 0.039043061435222626\n",
      "Epoch: 1989, Train Loss: 0.02940281480550766, Valid Loss: 0.03912714123725891\n",
      "Epoch: 1990, Train Loss: 0.02936532348394394, Valid Loss: 0.039142757654190063\n",
      "Epoch: 1991, Train Loss: 0.029327010735869408, Valid Loss: 0.038976844400167465\n",
      "Epoch: 1992, Train Loss: 0.029287122189998627, Valid Loss: 0.03906095400452614\n",
      "Epoch: 1993, Train Loss: 0.029247229918837547, Valid Loss: 0.03887711837887764\n",
      "Epoch: 1994, Train Loss: 0.029208850115537643, Valid Loss: 0.038769301027059555\n",
      "Epoch: 1995, Train Loss: 0.02917117066681385, Valid Loss: 0.0387960784137249\n",
      "Epoch: 1996, Train Loss: 0.029132617637515068, Valid Loss: 0.03855359926819801\n",
      "Epoch: 1997, Train Loss: 0.029093747958540916, Valid Loss: 0.03855237737298012\n",
      "Epoch: 1998, Train Loss: 0.029055684804916382, Valid Loss: 0.038499169051647186\n",
      "Epoch: 1999, Train Loss: 0.029018118977546692, Valid Loss: 0.03835378587245941\n",
      "Epoch: 2000, Train Loss: 0.028980184346437454, Valid Loss: 0.038422636687755585\n",
      "Epoch: 2001, Train Loss: 0.02894185110926628, Valid Loss: 0.038332562893629074\n",
      "Epoch: 2002, Train Loss: 0.02890382707118988, Valid Loss: 0.03830043971538544\n",
      "Epoch: 2003, Train Loss: 0.028866466134786606, Valid Loss: 0.038330335170030594\n",
      "Epoch: 2004, Train Loss: 0.028829282149672508, Valid Loss: 0.038239192217588425\n",
      "Epoch: 2005, Train Loss: 0.02879173308610916, Valid Loss: 0.03822408616542816\n",
      "Epoch: 2006, Train Loss: 0.028754040598869324, Valid Loss: 0.03815769776701927\n",
      "Epoch: 2007, Train Loss: 0.02871672250330448, Valid Loss: 0.038079068064689636\n",
      "Epoch: 2008, Train Loss: 0.028679752722382545, Valid Loss: 0.03803752362728119\n",
      "Epoch: 2009, Train Loss: 0.028642673045396805, Valid Loss: 0.037945445626974106\n",
      "Epoch: 2010, Train Loss: 0.028605487197637558, Valid Loss: 0.037907689809799194\n",
      "Epoch: 2011, Train Loss: 0.02856854721903801, Valid Loss: 0.037834037095308304\n",
      "Epoch: 2012, Train Loss: 0.028531834483146667, Valid Loss: 0.03777511417865753\n",
      "Epoch: 2013, Train Loss: 0.028495140373706818, Valid Loss: 0.03776320070028305\n",
      "Epoch: 2014, Train Loss: 0.028458328917622566, Valid Loss: 0.03769078105688095\n",
      "Epoch: 2015, Train Loss: 0.028421573340892792, Valid Loss: 0.03768429160118103\n",
      "Epoch: 2016, Train Loss: 0.028385143727064133, Valid Loss: 0.03765357658267021\n",
      "Epoch: 2017, Train Loss: 0.028348805382847786, Valid Loss: 0.0375785194337368\n",
      "Epoch: 2018, Train Loss: 0.028312426060438156, Valid Loss: 0.037570368498563766\n",
      "Epoch: 2019, Train Loss: 0.028276029974222183, Valid Loss: 0.03750145435333252\n",
      "Epoch: 2020, Train Loss: 0.028239835053682327, Valid Loss: 0.03744104132056236\n",
      "Epoch: 2021, Train Loss: 0.02820374257862568, Valid Loss: 0.03741542249917984\n",
      "Epoch: 2022, Train Loss: 0.028167665004730225, Valid Loss: 0.037330061197280884\n",
      "Epoch: 2023, Train Loss: 0.028131620958447456, Valid Loss: 0.03728361427783966\n",
      "Epoch: 2024, Train Loss: 0.028095727786421776, Valid Loss: 0.03724139556288719\n",
      "Epoch: 2025, Train Loss: 0.028059927746653557, Valid Loss: 0.037180013954639435\n",
      "Epoch: 2026, Train Loss: 0.02802417427301407, Valid Loss: 0.037155117839574814\n",
      "Epoch: 2027, Train Loss: 0.027988450601696968, Valid Loss: 0.03711055591702461\n",
      "Epoch: 2028, Train Loss: 0.027952807024121284, Valid Loss: 0.03706714138388634\n",
      "Epoch: 2029, Train Loss: 0.027917293831706047, Valid Loss: 0.03703136742115021\n",
      "Epoch: 2030, Train Loss: 0.027881847694516182, Valid Loss: 0.03698420152068138\n",
      "Epoch: 2031, Train Loss: 0.0278464388102293, Valid Loss: 0.03694577515125275\n",
      "Epoch: 2032, Train Loss: 0.02781107649207115, Valid Loss: 0.03689282014966011\n",
      "Epoch: 2033, Train Loss: 0.027775846421718597, Valid Loss: 0.03684305399656296\n",
      "Epoch: 2034, Train Loss: 0.027740662917494774, Valid Loss: 0.03679261356592178\n",
      "Epoch: 2035, Train Loss: 0.02770552597939968, Valid Loss: 0.03673051670193672\n",
      "Epoch: 2036, Train Loss: 0.02767048217356205, Valid Loss: 0.03668910264968872\n",
      "Epoch: 2037, Train Loss: 0.02763550728559494, Valid Loss: 0.03663523122668266\n",
      "Epoch: 2038, Train Loss: 0.0276006069034338, Valid Loss: 0.03658369556069374\n",
      "Epoch: 2039, Train Loss: 0.027565771713852882, Valid Loss: 0.03655067831277847\n",
      "Epoch: 2040, Train Loss: 0.02753099985420704, Valid Loss: 0.036498233675956726\n",
      "Epoch: 2041, Train Loss: 0.027496296912431717, Valid Loss: 0.03645973280072212\n",
      "Epoch: 2042, Train Loss: 0.027461646124720573, Valid Loss: 0.036424193531274796\n",
      "Epoch: 2043, Train Loss: 0.02742709405720234, Valid Loss: 0.03637172281742096\n",
      "Epoch: 2044, Train Loss: 0.027392571792006493, Valid Loss: 0.03633507341146469\n",
      "Epoch: 2045, Train Loss: 0.027358166873455048, Valid Loss: 0.03629005327820778\n",
      "Epoch: 2046, Train Loss: 0.027323804795742035, Valid Loss: 0.036238644272089005\n",
      "Epoch: 2047, Train Loss: 0.027289511635899544, Valid Loss: 0.03619706630706787\n",
      "Epoch: 2048, Train Loss: 0.027255255728960037, Valid Loss: 0.03614508733153343\n",
      "Epoch: 2049, Train Loss: 0.027221081778407097, Valid Loss: 0.03609706833958626\n",
      "Epoch: 2050, Train Loss: 0.027186961844563484, Valid Loss: 0.03605293855071068\n",
      "Epoch: 2051, Train Loss: 0.02715293876826763, Valid Loss: 0.03600533679127693\n",
      "Epoch: 2052, Train Loss: 0.027118979021906853, Valid Loss: 0.03596293926239014\n",
      "Epoch: 2053, Train Loss: 0.027085060253739357, Valid Loss: 0.035917773842811584\n",
      "Epoch: 2054, Train Loss: 0.027051184326410294, Valid Loss: 0.035874780267477036\n",
      "Epoch: 2055, Train Loss: 0.02701743133366108, Valid Loss: 0.035832151770591736\n",
      "Epoch: 2056, Train Loss: 0.02698371559381485, Valid Loss: 0.0357864648103714\n",
      "Epoch: 2057, Train Loss: 0.026950038969516754, Valid Loss: 0.03574537858366966\n",
      "Epoch: 2058, Train Loss: 0.02691647596657276, Valid Loss: 0.03569873422384262\n",
      "Epoch: 2059, Train Loss: 0.026882914826273918, Valid Loss: 0.03565192222595215\n",
      "Epoch: 2060, Train Loss: 0.026849467307329178, Valid Loss: 0.03560830280184746\n",
      "Epoch: 2061, Train Loss: 0.026816081255674362, Valid Loss: 0.035559091717004776\n",
      "Epoch: 2062, Train Loss: 0.02678271010518074, Valid Loss: 0.0355149544775486\n",
      "Epoch: 2063, Train Loss: 0.02674940414726734, Valid Loss: 0.035471219569444656\n",
      "Epoch: 2064, Train Loss: 0.026716213673353195, Valid Loss: 0.03542344644665718\n",
      "Epoch: 2065, Train Loss: 0.026683086529374123, Valid Loss: 0.03538145497441292\n",
      "Epoch: 2066, Train Loss: 0.026649946346879005, Valid Loss: 0.03533683344721794\n",
      "Epoch: 2067, Train Loss: 0.026616917923092842, Valid Loss: 0.0352913923561573\n",
      "Epoch: 2068, Train Loss: 0.026583945378661156, Valid Loss: 0.035250186920166016\n",
      "Epoch: 2069, Train Loss: 0.026551034301519394, Valid Loss: 0.03520496189594269\n",
      "Epoch: 2070, Train Loss: 0.02651817351579666, Valid Loss: 0.03515949472784996\n",
      "Epoch: 2071, Train Loss: 0.02648538164794445, Valid Loss: 0.03511606156826019\n",
      "Epoch: 2072, Train Loss: 0.026452668011188507, Valid Loss: 0.035069625824689865\n",
      "Epoch: 2073, Train Loss: 0.026419971138238907, Valid Loss: 0.03502433001995087\n",
      "Epoch: 2074, Train Loss: 0.026387372985482216, Valid Loss: 0.034979674965143204\n",
      "Epoch: 2075, Train Loss: 0.026354825124144554, Valid Loss: 0.034934211522340775\n",
      "Epoch: 2076, Train Loss: 0.026322340592741966, Valid Loss: 0.03488972410559654\n",
      "Epoch: 2077, Train Loss: 0.02628987841308117, Valid Loss: 0.03484528884291649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2078, Train Loss: 0.026257477700710297, Valid Loss: 0.03480156511068344\n",
      "Epoch: 2079, Train Loss: 0.026225177571177483, Valid Loss: 0.034757521003484726\n",
      "Epoch: 2080, Train Loss: 0.026192905381321907, Valid Loss: 0.03471410274505615\n",
      "Epoch: 2081, Train Loss: 0.026160700246691704, Valid Loss: 0.03467118367552757\n",
      "Epoch: 2082, Train Loss: 0.026128552854061127, Valid Loss: 0.03462669253349304\n",
      "Epoch: 2083, Train Loss: 0.026096446439623833, Valid Loss: 0.03458350524306297\n",
      "Epoch: 2084, Train Loss: 0.026064433157444, Valid Loss: 0.0345400832593441\n",
      "Epoch: 2085, Train Loss: 0.026032455265522003, Valid Loss: 0.03449445217847824\n",
      "Epoch: 2086, Train Loss: 0.02600054070353508, Valid Loss: 0.03445139527320862\n",
      "Epoch: 2087, Train Loss: 0.025968676432967186, Valid Loss: 0.03440764918923378\n",
      "Epoch: 2088, Train Loss: 0.025936853140592575, Valid Loss: 0.03436307609081268\n",
      "Epoch: 2089, Train Loss: 0.025905108079314232, Valid Loss: 0.03432025760412216\n",
      "Epoch: 2090, Train Loss: 0.02587343379855156, Valid Loss: 0.03427638113498688\n",
      "Epoch: 2091, Train Loss: 0.025841791182756424, Valid Loss: 0.03423266485333443\n",
      "Epoch: 2092, Train Loss: 0.025810182094573975, Valid Loss: 0.03419051319360733\n",
      "Epoch: 2093, Train Loss: 0.025778673589229584, Valid Loss: 0.03414725139737129\n",
      "Epoch: 2094, Train Loss: 0.025747237727046013, Valid Loss: 0.034104123711586\n",
      "Epoch: 2095, Train Loss: 0.025715811178088188, Valid Loss: 0.03406139463186264\n",
      "Epoch: 2096, Train Loss: 0.025684447959065437, Valid Loss: 0.034018225967884064\n",
      "Epoch: 2097, Train Loss: 0.025653136894106865, Valid Loss: 0.03397497907280922\n",
      "Epoch: 2098, Train Loss: 0.02562187798321247, Valid Loss: 0.03393201529979706\n",
      "Epoch: 2099, Train Loss: 0.025590717792510986, Valid Loss: 0.03388938307762146\n",
      "Epoch: 2100, Train Loss: 0.02555958367884159, Valid Loss: 0.03384586423635483\n",
      "Epoch: 2101, Train Loss: 0.025528503581881523, Valid Loss: 0.033803362399339676\n",
      "Epoch: 2102, Train Loss: 0.025497473776340485, Valid Loss: 0.033760856837034225\n",
      "Epoch: 2103, Train Loss: 0.025466501712799072, Valid Loss: 0.03371784836053848\n",
      "Epoch: 2104, Train Loss: 0.025435572490096092, Valid Loss: 0.033676065504550934\n",
      "Epoch: 2105, Train Loss: 0.025404702872037888, Valid Loss: 0.033633507788181305\n",
      "Epoch: 2106, Train Loss: 0.025373898446559906, Valid Loss: 0.03359101712703705\n",
      "Epoch: 2107, Train Loss: 0.0253431499004364, Valid Loss: 0.0335492342710495\n",
      "Epoch: 2108, Train Loss: 0.025312449783086777, Valid Loss: 0.0335068479180336\n",
      "Epoch: 2109, Train Loss: 0.025281758978962898, Valid Loss: 0.03346435725688934\n",
      "Epoch: 2110, Train Loss: 0.025251176208257675, Valid Loss: 0.03342259302735329\n",
      "Epoch: 2111, Train Loss: 0.025220617651939392, Valid Loss: 0.03338047116994858\n",
      "Epoch: 2112, Train Loss: 0.02519015409052372, Valid Loss: 0.03333808109164238\n",
      "Epoch: 2113, Train Loss: 0.02515970729291439, Valid Loss: 0.033296603709459305\n",
      "Epoch: 2114, Train Loss: 0.025129303336143494, Valid Loss: 0.03325460106134415\n",
      "Epoch: 2115, Train Loss: 0.025098970159888268, Valid Loss: 0.033212535083293915\n",
      "Epoch: 2116, Train Loss: 0.02506866492331028, Valid Loss: 0.03317148610949516\n",
      "Epoch: 2117, Train Loss: 0.02503843605518341, Valid Loss: 0.033129625022411346\n",
      "Epoch: 2118, Train Loss: 0.02500826120376587, Valid Loss: 0.033087946474552155\n",
      "Epoch: 2119, Train Loss: 0.02497813291847706, Valid Loss: 0.033047113567590714\n",
      "Epoch: 2120, Train Loss: 0.024948066100478172, Valid Loss: 0.03300559148192406\n",
      "Epoch: 2121, Train Loss: 0.02491801604628563, Valid Loss: 0.032964013516902924\n",
      "Epoch: 2122, Train Loss: 0.024888044223189354, Valid Loss: 0.03292326629161835\n",
      "Epoch: 2123, Train Loss: 0.02485812082886696, Valid Loss: 0.032881543040275574\n",
      "Epoch: 2124, Train Loss: 0.0248282328248024, Valid Loss: 0.03284027427434921\n",
      "Epoch: 2125, Train Loss: 0.024798434227705002, Valid Loss: 0.03279973566532135\n",
      "Epoch: 2126, Train Loss: 0.024768643081188202, Valid Loss: 0.03275825083255768\n",
      "Epoch: 2127, Train Loss: 0.024738915264606476, Valid Loss: 0.0327172577381134\n",
      "Epoch: 2128, Train Loss: 0.024709252640604973, Valid Loss: 0.032676905393600464\n",
      "Epoch: 2129, Train Loss: 0.024679625406861305, Valid Loss: 0.03263553977012634\n",
      "Epoch: 2130, Train Loss: 0.024650046601891518, Valid Loss: 0.03259504213929176\n",
      "Epoch: 2131, Train Loss: 0.024620523676276207, Valid Loss: 0.032554637640714645\n",
      "Epoch: 2132, Train Loss: 0.024591052904725075, Valid Loss: 0.032513707876205444\n",
      "Epoch: 2133, Train Loss: 0.024561645463109016, Valid Loss: 0.03247345611453056\n",
      "Epoch: 2134, Train Loss: 0.0245322585105896, Valid Loss: 0.032432910054922104\n",
      "Epoch: 2135, Train Loss: 0.0245029479265213, Valid Loss: 0.03239241987466812\n",
      "Epoch: 2136, Train Loss: 0.024473659694194794, Valid Loss: 0.03235211595892906\n",
      "Epoch: 2137, Train Loss: 0.024444418027997017, Valid Loss: 0.03231179341673851\n",
      "Epoch: 2138, Train Loss: 0.02441525086760521, Valid Loss: 0.032271698117256165\n",
      "Epoch: 2139, Train Loss: 0.024386130273342133, Valid Loss: 0.032231591641902924\n",
      "Epoch: 2140, Train Loss: 0.024357043206691742, Valid Loss: 0.03219136595726013\n",
      "Epoch: 2141, Train Loss: 0.024328000843524933, Valid Loss: 0.032151393592357635\n",
      "Epoch: 2142, Train Loss: 0.024299027398228645, Valid Loss: 0.03211168199777603\n",
      "Epoch: 2143, Train Loss: 0.02427009306848049, Valid Loss: 0.03207169845700264\n",
      "Epoch: 2144, Train Loss: 0.024241222068667412, Valid Loss: 0.03203189745545387\n",
      "Epoch: 2145, Train Loss: 0.024212390184402466, Valid Loss: 0.031992193311452866\n",
      "Epoch: 2146, Train Loss: 0.02418358065187931, Valid Loss: 0.031952448189258575\n",
      "Epoch: 2147, Train Loss: 0.02415485307574272, Valid Loss: 0.03191307187080383\n",
      "Epoch: 2148, Train Loss: 0.02412613108754158, Valid Loss: 0.03187320753931999\n",
      "Epoch: 2149, Train Loss: 0.024097491055727005, Valid Loss: 0.0318337120115757\n",
      "Epoch: 2150, Train Loss: 0.024068893864750862, Valid Loss: 0.03179451450705528\n",
      "Epoch: 2151, Train Loss: 0.024040352553129196, Valid Loss: 0.03175513073801994\n",
      "Epoch: 2152, Train Loss: 0.024011846631765366, Valid Loss: 0.03171592205762863\n",
      "Epoch: 2153, Train Loss: 0.02398340404033661, Valid Loss: 0.031676724553108215\n",
      "Epoch: 2154, Train Loss: 0.023954959586262703, Valid Loss: 0.03163742274045944\n",
      "Epoch: 2155, Train Loss: 0.02392660453915596, Valid Loss: 0.03159821406006813\n",
      "Epoch: 2156, Train Loss: 0.02389829233288765, Valid Loss: 0.03155959025025368\n",
      "Epoch: 2157, Train Loss: 0.023870008066296577, Valid Loss: 0.03152051195502281\n",
      "Epoch: 2158, Train Loss: 0.023841779679059982, Valid Loss: 0.031481530517339706\n",
      "Epoch: 2159, Train Loss: 0.023813588544726372, Valid Loss: 0.03144287317991257\n",
      "Epoch: 2160, Train Loss: 0.023785462602972984, Valid Loss: 0.03140386566519737\n",
      "Epoch: 2161, Train Loss: 0.023757370188832283, Valid Loss: 0.031365253031253815\n",
      "Epoch: 2162, Train Loss: 0.02372933365404606, Valid Loss: 0.03132692351937294\n",
      "Epoch: 2163, Train Loss: 0.023701339960098267, Valid Loss: 0.03128797560930252\n",
      "Epoch: 2164, Train Loss: 0.02367340959608555, Valid Loss: 0.03124966472387314\n",
      "Epoch: 2165, Train Loss: 0.02364550530910492, Valid Loss: 0.031211361289024353\n",
      "Epoch: 2166, Train Loss: 0.023617632687091827, Valid Loss: 0.031172651797533035\n",
      "Epoch: 2167, Train Loss: 0.023589815944433212, Valid Loss: 0.031134460121393204\n",
      "Epoch: 2168, Train Loss: 0.02356206253170967, Valid Loss: 0.031096363440155983\n",
      "Epoch: 2169, Train Loss: 0.02353433333337307, Valid Loss: 0.03105815500020981\n",
      "Epoch: 2170, Train Loss: 0.02350662648677826, Valid Loss: 0.031019940972328186\n",
      "Epoch: 2171, Train Loss: 0.023479001596570015, Valid Loss: 0.03098195604979992\n",
      "Epoch: 2172, Train Loss: 0.02345140464603901, Valid Loss: 0.03094395436346531\n",
      "Epoch: 2173, Train Loss: 0.02342386543750763, Valid Loss: 0.030905883759260178\n",
      "Epoch: 2174, Train Loss: 0.023396365344524384, Valid Loss: 0.03086812049150467\n",
      "Epoch: 2175, Train Loss: 0.023368924856185913, Valid Loss: 0.030830329284071922\n",
      "Epoch: 2176, Train Loss: 0.02334148995578289, Valid Loss: 0.03079266846179962\n",
      "Epoch: 2177, Train Loss: 0.02331412397325039, Valid Loss: 0.0307550597935915\n",
      "Epoch: 2178, Train Loss: 0.02328682132065296, Valid Loss: 0.03071725368499756\n",
      "Epoch: 2179, Train Loss: 0.023259518668055534, Valid Loss: 0.030679618939757347\n",
      "Epoch: 2180, Train Loss: 0.02323228307068348, Valid Loss: 0.030642475932836533\n",
      "Epoch: 2181, Train Loss: 0.023205101490020752, Valid Loss: 0.030604831874370575\n",
      "Epoch: 2182, Train Loss: 0.023177944123744965, Valid Loss: 0.03056742250919342\n",
      "Epoch: 2183, Train Loss: 0.023150835186243057, Valid Loss: 0.03053029626607895\n",
      "Epoch: 2184, Train Loss: 0.023123767226934433, Valid Loss: 0.03049287386238575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2185, Train Loss: 0.023096762597560883, Valid Loss: 0.03045574575662613\n",
      "Epoch: 2186, Train Loss: 0.02306981012225151, Valid Loss: 0.030418695881962776\n",
      "Epoch: 2187, Train Loss: 0.02304285578429699, Valid Loss: 0.0303815770894289\n",
      "Epoch: 2188, Train Loss: 0.023015953600406647, Valid Loss: 0.030344707891345024\n",
      "Epoch: 2189, Train Loss: 0.02298911288380623, Valid Loss: 0.030307712033391\n",
      "Epoch: 2190, Train Loss: 0.022962316870689392, Valid Loss: 0.030270591378211975\n",
      "Epoch: 2191, Train Loss: 0.022935546934604645, Valid Loss: 0.030233953148126602\n",
      "Epoch: 2192, Train Loss: 0.02290884032845497, Valid Loss: 0.030197449028491974\n",
      "Epoch: 2193, Train Loss: 0.02288215048611164, Valid Loss: 0.030160319060087204\n",
      "Epoch: 2194, Train Loss: 0.02285551093518734, Valid Loss: 0.03012390062212944\n",
      "Epoch: 2195, Train Loss: 0.02282891981303692, Valid Loss: 0.030087267979979515\n",
      "Epoch: 2196, Train Loss: 0.022802382707595825, Valid Loss: 0.030050599947571754\n",
      "Epoch: 2197, Train Loss: 0.02277587167918682, Valid Loss: 0.030014492571353912\n",
      "Epoch: 2198, Train Loss: 0.022749388590455055, Valid Loss: 0.029977984726428986\n",
      "Epoch: 2199, Train Loss: 0.022722981870174408, Valid Loss: 0.02994144707918167\n",
      "Epoch: 2200, Train Loss: 0.022696591913700104, Valid Loss: 0.02990555763244629\n",
      "Epoch: 2201, Train Loss: 0.022670259699225426, Valid Loss: 0.029869213700294495\n",
      "Epoch: 2202, Train Loss: 0.022643934935331345, Valid Loss: 0.029832953587174416\n",
      "Epoch: 2203, Train Loss: 0.022617680951952934, Valid Loss: 0.02979704551398754\n",
      "Epoch: 2204, Train Loss: 0.02259148471057415, Valid Loss: 0.029760805889964104\n",
      "Epoch: 2205, Train Loss: 0.022565308958292007, Valid Loss: 0.02972462587058544\n",
      "Epoch: 2206, Train Loss: 0.022539161145687103, Valid Loss: 0.029689092189073563\n",
      "Epoch: 2207, Train Loss: 0.022513078525662422, Valid Loss: 0.029653126373887062\n",
      "Epoch: 2208, Train Loss: 0.022487040609121323, Valid Loss: 0.02961716428399086\n",
      "Epoch: 2209, Train Loss: 0.022461028769612312, Valid Loss: 0.02958180382847786\n",
      "Epoch: 2210, Train Loss: 0.02243504673242569, Valid Loss: 0.029545709490776062\n",
      "Epoch: 2211, Train Loss: 0.02240910939872265, Valid Loss: 0.029510099440813065\n",
      "Epoch: 2212, Train Loss: 0.02238323912024498, Valid Loss: 0.029475077986717224\n",
      "Epoch: 2213, Train Loss: 0.022357381880283356, Valid Loss: 0.0294391680508852\n",
      "Epoch: 2214, Train Loss: 0.022331563755869865, Valid Loss: 0.029403652995824814\n",
      "Epoch: 2215, Train Loss: 0.022305801510810852, Valid Loss: 0.02936854213476181\n",
      "Epoch: 2216, Train Loss: 0.022280076518654823, Valid Loss: 0.029333123937249184\n",
      "Epoch: 2217, Train Loss: 0.022254372015595436, Valid Loss: 0.029297612607479095\n",
      "Epoch: 2218, Train Loss: 0.022228755056858063, Valid Loss: 0.029262874275445938\n",
      "Epoch: 2219, Train Loss: 0.02220313809812069, Valid Loss: 0.029227375984191895\n",
      "Epoch: 2220, Train Loss: 0.02217755652964115, Valid Loss: 0.029192108660936356\n",
      "Epoch: 2221, Train Loss: 0.022152042016386986, Valid Loss: 0.029157496988773346\n",
      "Epoch: 2222, Train Loss: 0.02212655171751976, Valid Loss: 0.029122162610292435\n",
      "Epoch: 2223, Train Loss: 0.022101078182458878, Valid Loss: 0.029087118804454803\n",
      "Epoch: 2224, Train Loss: 0.02207566238939762, Valid Loss: 0.029052842408418655\n",
      "Epoch: 2225, Train Loss: 0.022050295025110245, Valid Loss: 0.029017454013228416\n",
      "Epoch: 2226, Train Loss: 0.022024961188435555, Valid Loss: 0.028982724994421005\n",
      "Epoch: 2227, Train Loss: 0.021999657154083252, Valid Loss: 0.02894839458167553\n",
      "Epoch: 2228, Train Loss: 0.021974416449666023, Valid Loss: 0.028913460671901703\n",
      "Epoch: 2229, Train Loss: 0.021949216723442078, Valid Loss: 0.028879011049866676\n",
      "Epoch: 2230, Train Loss: 0.021924007683992386, Valid Loss: 0.028844546526670456\n",
      "Epoch: 2231, Train Loss: 0.02189888246357441, Valid Loss: 0.028809767216444016\n",
      "Epoch: 2232, Train Loss: 0.021873772144317627, Valid Loss: 0.028775528073310852\n",
      "Epoch: 2233, Train Loss: 0.021848702803254128, Valid Loss: 0.0287412628531456\n",
      "Epoch: 2234, Train Loss: 0.021823700517416, Valid Loss: 0.028706777840852737\n",
      "Epoch: 2235, Train Loss: 0.021798690780997276, Valid Loss: 0.028672359883785248\n",
      "Epoch: 2236, Train Loss: 0.021773766726255417, Valid Loss: 0.02863839827477932\n",
      "Epoch: 2237, Train Loss: 0.0217488594353199, Valid Loss: 0.02860432118177414\n",
      "Epoch: 2238, Train Loss: 0.02172398939728737, Valid Loss: 0.028570150956511497\n",
      "Epoch: 2239, Train Loss: 0.02169913984835148, Valid Loss: 0.02853596955537796\n",
      "Epoch: 2240, Train Loss: 0.02167435921728611, Valid Loss: 0.028502142056822777\n",
      "Epoch: 2241, Train Loss: 0.02164958231151104, Valid Loss: 0.028468217700719833\n",
      "Epoch: 2242, Train Loss: 0.021624870598316193, Valid Loss: 0.02843429520726204\n",
      "Epoch: 2243, Train Loss: 0.021600186824798584, Valid Loss: 0.028400521725416183\n",
      "Epoch: 2244, Train Loss: 0.02157554030418396, Valid Loss: 0.02836662344634533\n",
      "Epoch: 2245, Train Loss: 0.021550940349698067, Valid Loss: 0.02833305113017559\n",
      "Epoch: 2246, Train Loss: 0.021526381373405457, Valid Loss: 0.02829948253929615\n",
      "Epoch: 2247, Train Loss: 0.021501848474144936, Valid Loss: 0.02826562337577343\n",
      "Epoch: 2248, Train Loss: 0.0214773528277874, Valid Loss: 0.02823219820857048\n",
      "Epoch: 2249, Train Loss: 0.021452898159623146, Valid Loss: 0.028198912739753723\n",
      "Epoch: 2250, Train Loss: 0.021428454667329788, Valid Loss: 0.028165146708488464\n",
      "Epoch: 2251, Train Loss: 0.02140410616993904, Valid Loss: 0.028131894767284393\n",
      "Epoch: 2252, Train Loss: 0.021379729732871056, Valid Loss: 0.028098592534661293\n",
      "Epoch: 2253, Train Loss: 0.021355431526899338, Valid Loss: 0.028065228834748268\n",
      "Epoch: 2254, Train Loss: 0.02133115381002426, Valid Loss: 0.0280319731682539\n",
      "Epoch: 2255, Train Loss: 0.021306922659277916, Valid Loss: 0.02799881063401699\n",
      "Epoch: 2256, Train Loss: 0.021282710134983063, Valid Loss: 0.02796568162739277\n",
      "Epoch: 2257, Train Loss: 0.02125854417681694, Valid Loss: 0.027932602912187576\n",
      "Epoch: 2258, Train Loss: 0.021234406158328056, Valid Loss: 0.027899792417883873\n",
      "Epoch: 2259, Train Loss: 0.021210333332419395, Valid Loss: 0.027866704389452934\n",
      "Epoch: 2260, Train Loss: 0.021186284720897675, Valid Loss: 0.027833735570311546\n",
      "Epoch: 2261, Train Loss: 0.02116224355995655, Valid Loss: 0.027801090851426125\n",
      "Epoch: 2262, Train Loss: 0.02113829180598259, Valid Loss: 0.027768166735768318\n",
      "Epoch: 2263, Train Loss: 0.02111433632671833, Valid Loss: 0.027735352516174316\n",
      "Epoch: 2264, Train Loss: 0.02109041064977646, Valid Loss: 0.027702879160642624\n",
      "Epoch: 2265, Train Loss: 0.021066565066576004, Valid Loss: 0.027670107781887054\n",
      "Epoch: 2266, Train Loss: 0.021042710170149803, Valid Loss: 0.027637459337711334\n",
      "Epoch: 2267, Train Loss: 0.021018901839852333, Valid Loss: 0.027604741975665092\n",
      "Epoch: 2268, Train Loss: 0.020995130762457848, Valid Loss: 0.027572454884648323\n",
      "Epoch: 2269, Train Loss: 0.020971382036805153, Valid Loss: 0.027540059760212898\n",
      "Epoch: 2270, Train Loss: 0.020947691053152084, Valid Loss: 0.027507519349455833\n",
      "Epoch: 2271, Train Loss: 0.02092403918504715, Valid Loss: 0.02747526578605175\n",
      "Epoch: 2272, Train Loss: 0.020900413393974304, Valid Loss: 0.027442768216133118\n",
      "Epoch: 2273, Train Loss: 0.020876824855804443, Valid Loss: 0.027410786598920822\n",
      "Epoch: 2274, Train Loss: 0.02085324563086033, Valid Loss: 0.027378547936677933\n",
      "Epoch: 2275, Train Loss: 0.020829731598496437, Valid Loss: 0.027346409857273102\n",
      "Epoch: 2276, Train Loss: 0.020806247368454933, Valid Loss: 0.027314158156514168\n",
      "Epoch: 2277, Train Loss: 0.020782791078090668, Valid Loss: 0.02728239819407463\n",
      "Epoch: 2278, Train Loss: 0.02075941115617752, Valid Loss: 0.027250416576862335\n",
      "Epoch: 2279, Train Loss: 0.02073599584400654, Valid Loss: 0.027218256145715714\n",
      "Epoch: 2280, Train Loss: 0.020712628960609436, Valid Loss: 0.02718670293688774\n",
      "Epoch: 2281, Train Loss: 0.0206893477588892, Valid Loss: 0.02715463377535343\n",
      "Epoch: 2282, Train Loss: 0.020666053518652916, Valid Loss: 0.02712276764214039\n",
      "Epoch: 2283, Train Loss: 0.02064279466867447, Valid Loss: 0.027091335505247116\n",
      "Epoch: 2284, Train Loss: 0.02061961591243744, Valid Loss: 0.027059463784098625\n",
      "Epoch: 2285, Train Loss: 0.020596422255039215, Valid Loss: 0.027028046548366547\n",
      "Epoch: 2286, Train Loss: 0.020573284476995468, Valid Loss: 0.026996362954378128\n",
      "Epoch: 2287, Train Loss: 0.020550180226564407, Valid Loss: 0.026964586228132248\n",
      "Epoch: 2288, Train Loss: 0.020527100190520287, Valid Loss: 0.02693318761885166\n",
      "Epoch: 2289, Train Loss: 0.020504072308540344, Valid Loss: 0.026902111247181892\n",
      "Epoch: 2290, Train Loss: 0.020481059327721596, Valid Loss: 0.026870446279644966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2291, Train Loss: 0.020458070561289787, Valid Loss: 0.026839228346943855\n",
      "Epoch: 2292, Train Loss: 0.02043512649834156, Valid Loss: 0.026808016002178192\n",
      "Epoch: 2293, Train Loss: 0.02041221596300602, Valid Loss: 0.026776442304253578\n",
      "Epoch: 2294, Train Loss: 0.020389365032315254, Valid Loss: 0.026745488867163658\n",
      "Epoch: 2295, Train Loss: 0.020366519689559937, Valid Loss: 0.026714369654655457\n",
      "Epoch: 2296, Train Loss: 0.020343715324997902, Valid Loss: 0.026683203876018524\n",
      "Epoch: 2297, Train Loss: 0.020320972427725792, Valid Loss: 0.02665221504867077\n",
      "Epoch: 2298, Train Loss: 0.02029818668961525, Valid Loss: 0.026621170341968536\n",
      "Epoch: 2299, Train Loss: 0.02027549408376217, Valid Loss: 0.026590125635266304\n",
      "Epoch: 2300, Train Loss: 0.020252814516425133, Valid Loss: 0.02655942179262638\n",
      "Epoch: 2301, Train Loss: 0.020230185240507126, Valid Loss: 0.02652863971889019\n",
      "Epoch: 2302, Train Loss: 0.020207583904266357, Valid Loss: 0.026497727259993553\n",
      "Epoch: 2303, Train Loss: 0.020184997469186783, Valid Loss: 0.026467053219676018\n",
      "Epoch: 2304, Train Loss: 0.02016245760023594, Valid Loss: 0.026436351239681244\n",
      "Epoch: 2305, Train Loss: 0.02013998106122017, Valid Loss: 0.026405563578009605\n",
      "Epoch: 2306, Train Loss: 0.020117472857236862, Valid Loss: 0.02637513168156147\n",
      "Epoch: 2307, Train Loss: 0.020095041021704674, Valid Loss: 0.026344647631049156\n",
      "Epoch: 2308, Train Loss: 0.020072616636753082, Valid Loss: 0.026313818991184235\n",
      "Epoch: 2309, Train Loss: 0.020050233229994774, Valid Loss: 0.026283595710992813\n",
      "Epoch: 2310, Train Loss: 0.0200278852134943, Valid Loss: 0.02625317871570587\n",
      "Epoch: 2311, Train Loss: 0.02000558003783226, Valid Loss: 0.026222536340355873\n",
      "Epoch: 2312, Train Loss: 0.01998330093920231, Valid Loss: 0.026192426681518555\n",
      "Epoch: 2313, Train Loss: 0.019961075857281685, Valid Loss: 0.02616223320364952\n",
      "Epoch: 2314, Train Loss: 0.019938848912715912, Valid Loss: 0.02613190934062004\n",
      "Epoch: 2315, Train Loss: 0.019916648045182228, Valid Loss: 0.026101650670170784\n",
      "Epoch: 2316, Train Loss: 0.019894495606422424, Valid Loss: 0.02607164904475212\n",
      "Epoch: 2317, Train Loss: 0.019872397184371948, Valid Loss: 0.02604161761701107\n",
      "Epoch: 2318, Train Loss: 0.019850289449095726, Valid Loss: 0.02601148933172226\n",
      "Epoch: 2319, Train Loss: 0.01982823759317398, Valid Loss: 0.025981469079852104\n",
      "Epoch: 2320, Train Loss: 0.019806209951639175, Valid Loss: 0.025951463729143143\n",
      "Epoch: 2321, Train Loss: 0.019784199073910713, Valid Loss: 0.025921685621142387\n",
      "Epoch: 2322, Train Loss: 0.01976224221289158, Valid Loss: 0.025891974568367004\n",
      "Epoch: 2323, Train Loss: 0.01974032074213028, Valid Loss: 0.025862019509077072\n",
      "Epoch: 2324, Train Loss: 0.01971840299665928, Valid Loss: 0.02583201974630356\n",
      "Epoch: 2325, Train Loss: 0.01969657465815544, Valid Loss: 0.02580271288752556\n",
      "Epoch: 2326, Train Loss: 0.01967471092939377, Valid Loss: 0.025772901251912117\n",
      "Epoch: 2327, Train Loss: 0.01965290680527687, Valid Loss: 0.02574319764971733\n",
      "Epoch: 2328, Train Loss: 0.01963113434612751, Valid Loss: 0.025713719427585602\n",
      "Epoch: 2329, Train Loss: 0.019609401002526283, Valid Loss: 0.025684205815196037\n",
      "Epoch: 2330, Train Loss: 0.01958768256008625, Valid Loss: 0.02565474435687065\n",
      "Epoch: 2331, Train Loss: 0.01956600323319435, Valid Loss: 0.02562527358531952\n",
      "Epoch: 2332, Train Loss: 0.019544333219528198, Valid Loss: 0.025595825165510178\n",
      "Epoch: 2333, Train Loss: 0.019522715359926224, Valid Loss: 0.025566572323441505\n",
      "Epoch: 2334, Train Loss: 0.019501136615872383, Valid Loss: 0.02553723379969597\n",
      "Epoch: 2335, Train Loss: 0.019479596987366676, Valid Loss: 0.025507904589176178\n",
      "Epoch: 2336, Train Loss: 0.019458064809441566, Valid Loss: 0.025478726252913475\n",
      "Epoch: 2337, Train Loss: 0.019436543807387352, Valid Loss: 0.025449540466070175\n",
      "Epoch: 2338, Train Loss: 0.019415080547332764, Valid Loss: 0.025420574471354485\n",
      "Epoch: 2339, Train Loss: 0.019393641501665115, Valid Loss: 0.02539140172302723\n",
      "Epoch: 2340, Train Loss: 0.019372235983610153, Valid Loss: 0.02536211907863617\n",
      "Epoch: 2341, Train Loss: 0.019350869581103325, Valid Loss: 0.02533341944217682\n",
      "Epoch: 2342, Train Loss: 0.019329508766531944, Valid Loss: 0.025304583832621574\n",
      "Epoch: 2343, Train Loss: 0.01930818147957325, Valid Loss: 0.025275638327002525\n",
      "Epoch: 2344, Train Loss: 0.019286898896098137, Valid Loss: 0.025246618315577507\n",
      "Epoch: 2345, Train Loss: 0.01926565170288086, Valid Loss: 0.025217749178409576\n",
      "Epoch: 2346, Train Loss: 0.01924443617463112, Valid Loss: 0.025189155712723732\n",
      "Epoch: 2347, Train Loss: 0.01922323927283287, Valid Loss: 0.0251604150980711\n",
      "Epoch: 2348, Train Loss: 0.019202064722776413, Valid Loss: 0.02513161487877369\n",
      "Epoch: 2349, Train Loss: 0.019180934876203537, Valid Loss: 0.025103064253926277\n",
      "Epoch: 2350, Train Loss: 0.01915981061756611, Valid Loss: 0.025074386969208717\n",
      "Epoch: 2351, Train Loss: 0.019138755276799202, Valid Loss: 0.025045834481716156\n",
      "Epoch: 2352, Train Loss: 0.0191176887601614, Valid Loss: 0.02501739002764225\n",
      "Epoch: 2353, Train Loss: 0.019096672534942627, Valid Loss: 0.02498890459537506\n",
      "Epoch: 2354, Train Loss: 0.019075701013207436, Valid Loss: 0.024960681796073914\n",
      "Epoch: 2355, Train Loss: 0.01905473694205284, Valid Loss: 0.024932214990258217\n",
      "Epoch: 2356, Train Loss: 0.019033795222640038, Valid Loss: 0.024903664365410805\n",
      "Epoch: 2357, Train Loss: 0.01901290938258171, Valid Loss: 0.024875616654753685\n",
      "Epoch: 2358, Train Loss: 0.018992025405168533, Valid Loss: 0.024847356602549553\n",
      "Epoch: 2359, Train Loss: 0.01897120103240013, Valid Loss: 0.024819068610668182\n",
      "Epoch: 2360, Train Loss: 0.018950393423438072, Valid Loss: 0.02479097992181778\n",
      "Epoch: 2361, Train Loss: 0.01892959512770176, Valid Loss: 0.024762718006968498\n",
      "Epoch: 2362, Train Loss: 0.018908828496932983, Valid Loss: 0.024734849110245705\n",
      "Epoch: 2363, Train Loss: 0.018888097256422043, Valid Loss: 0.024706926196813583\n",
      "Epoch: 2364, Train Loss: 0.018867425620555878, Valid Loss: 0.024678682908415794\n",
      "Epoch: 2365, Train Loss: 0.018846748396754265, Valid Loss: 0.02465076744556427\n",
      "Epoch: 2366, Train Loss: 0.01882612332701683, Valid Loss: 0.024623027071356773\n",
      "Epoch: 2367, Train Loss: 0.018805501982569695, Valid Loss: 0.024595079943537712\n",
      "Epoch: 2368, Train Loss: 0.018784916028380394, Valid Loss: 0.02456735074520111\n",
      "Epoch: 2369, Train Loss: 0.018764374777674675, Valid Loss: 0.02453950233757496\n",
      "Epoch: 2370, Train Loss: 0.018743839114904404, Valid Loss: 0.02451152727007866\n",
      "Epoch: 2371, Train Loss: 0.018723348155617714, Valid Loss: 0.02448406256735325\n",
      "Epoch: 2372, Train Loss: 0.018702855333685875, Valid Loss: 0.024456536397337914\n",
      "Epoch: 2373, Train Loss: 0.018682433292269707, Valid Loss: 0.024428855627775192\n",
      "Epoch: 2374, Train Loss: 0.01866201125085354, Valid Loss: 0.024401212111115456\n",
      "Epoch: 2375, Train Loss: 0.018641648814082146, Valid Loss: 0.02437390573322773\n",
      "Epoch: 2376, Train Loss: 0.018621278926730156, Valid Loss: 0.02434609830379486\n",
      "Epoch: 2377, Train Loss: 0.018600940704345703, Valid Loss: 0.02431883104145527\n",
      "Epoch: 2378, Train Loss: 0.018580662086606026, Valid Loss: 0.024291682988405228\n",
      "Epoch: 2379, Train Loss: 0.018560413271188736, Valid Loss: 0.024264026433229446\n",
      "Epoch: 2380, Train Loss: 0.018540142104029655, Valid Loss: 0.02423666976392269\n",
      "Epoch: 2381, Train Loss: 0.0185199286788702, Valid Loss: 0.024209601804614067\n",
      "Epoch: 2382, Train Loss: 0.018499739468097687, Valid Loss: 0.024182261899113655\n",
      "Epoch: 2383, Train Loss: 0.01847958378493786, Valid Loss: 0.02415514923632145\n",
      "Epoch: 2384, Train Loss: 0.018459435552358627, Valid Loss: 0.024127932265400887\n",
      "Epoch: 2385, Train Loss: 0.018439341336488724, Valid Loss: 0.024100644513964653\n",
      "Epoch: 2386, Train Loss: 0.018419260159134865, Valid Loss: 0.024073703214526176\n",
      "Epoch: 2387, Train Loss: 0.01839921809732914, Valid Loss: 0.02404700219631195\n",
      "Epoch: 2388, Train Loss: 0.01837919093668461, Valid Loss: 0.024019720032811165\n",
      "Epoch: 2389, Train Loss: 0.018359197303652763, Valid Loss: 0.02399265021085739\n",
      "Epoch: 2390, Train Loss: 0.018339216709136963, Valid Loss: 0.02396603673696518\n",
      "Epoch: 2391, Train Loss: 0.01831929385662079, Valid Loss: 0.0239389818161726\n",
      "Epoch: 2392, Train Loss: 0.018299389630556107, Valid Loss: 0.023912131786346436\n",
      "Epoch: 2393, Train Loss: 0.018279481679201126, Valid Loss: 0.023885514587163925\n",
      "Epoch: 2394, Train Loss: 0.01825963333249092, Valid Loss: 0.02385866455733776\n",
      "Epoch: 2395, Train Loss: 0.01823980174958706, Valid Loss: 0.0238319281488657\n",
      "Epoch: 2396, Train Loss: 0.01822000928223133, Valid Loss: 0.023805448785424232\n",
      "Epoch: 2397, Train Loss: 0.018200237303972244, Valid Loss: 0.023778650909662247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2398, Train Loss: 0.01818046160042286, Valid Loss: 0.023752016946673393\n",
      "Epoch: 2399, Train Loss: 0.01816074550151825, Valid Loss: 0.02372577413916588\n",
      "Epoch: 2400, Train Loss: 0.018141061067581177, Valid Loss: 0.023699147626757622\n",
      "Epoch: 2401, Train Loss: 0.018121372908353806, Valid Loss: 0.023672468960285187\n",
      "Epoch: 2402, Train Loss: 0.01810172013938427, Valid Loss: 0.023646293208003044\n",
      "Epoch: 2403, Train Loss: 0.018082089722156525, Valid Loss: 0.023619819432497025\n",
      "Epoch: 2404, Train Loss: 0.018062543123960495, Valid Loss: 0.023593436926603317\n",
      "Epoch: 2405, Train Loss: 0.01804295927286148, Valid Loss: 0.023567117750644684\n",
      "Epoch: 2406, Train Loss: 0.018023431301116943, Valid Loss: 0.023540876805782318\n",
      "Epoch: 2407, Train Loss: 0.01800389215350151, Valid Loss: 0.023514501750469208\n",
      "Epoch: 2408, Train Loss: 0.017984438687562943, Valid Loss: 0.023488519713282585\n",
      "Epoch: 2409, Train Loss: 0.017964975908398628, Valid Loss: 0.023462263867259026\n",
      "Epoch: 2410, Train Loss: 0.017945541068911552, Valid Loss: 0.0234360471367836\n",
      "Epoch: 2411, Train Loss: 0.017926141619682312, Valid Loss: 0.023410234600305557\n",
      "Epoch: 2412, Train Loss: 0.017906758934259415, Valid Loss: 0.02338426373898983\n",
      "Epoch: 2413, Train Loss: 0.017887398600578308, Valid Loss: 0.02335795946419239\n",
      "Epoch: 2414, Train Loss: 0.017868079245090485, Valid Loss: 0.023332202807068825\n",
      "Epoch: 2415, Train Loss: 0.017848767340183258, Valid Loss: 0.023306354880332947\n",
      "Epoch: 2416, Train Loss: 0.01782950386404991, Valid Loss: 0.023280268535017967\n",
      "Epoch: 2417, Train Loss: 0.017810264602303505, Valid Loss: 0.02325456775724888\n",
      "Epoch: 2418, Train Loss: 0.017791029065847397, Valid Loss: 0.023228783160448074\n",
      "Epoch: 2419, Train Loss: 0.017771830782294273, Valid Loss: 0.023202862590551376\n",
      "Epoch: 2420, Train Loss: 0.01775265671312809, Valid Loss: 0.02317744307219982\n",
      "Epoch: 2421, Train Loss: 0.017733529210090637, Valid Loss: 0.02315165475010872\n",
      "Epoch: 2422, Train Loss: 0.017714397981762886, Valid Loss: 0.023125654086470604\n",
      "Epoch: 2423, Train Loss: 0.017695322632789612, Valid Loss: 0.023100387305021286\n",
      "Epoch: 2424, Train Loss: 0.01767621748149395, Valid Loss: 0.023074675351381302\n",
      "Epoch: 2425, Train Loss: 0.01765718311071396, Valid Loss: 0.023049207404255867\n",
      "Epoch: 2426, Train Loss: 0.017638159915804863, Valid Loss: 0.023023761808872223\n",
      "Epoch: 2427, Train Loss: 0.017619166523218155, Valid Loss: 0.022998176515102386\n",
      "Epoch: 2428, Train Loss: 0.01760019361972809, Valid Loss: 0.022972751408815384\n",
      "Epoch: 2429, Train Loss: 0.017581269145011902, Valid Loss: 0.022947488352656364\n",
      "Epoch: 2430, Train Loss: 0.01756233535706997, Valid Loss: 0.022922160103917122\n",
      "Epoch: 2431, Train Loss: 0.017543455585837364, Valid Loss: 0.02289668470621109\n",
      "Epoch: 2432, Train Loss: 0.017524605616927147, Valid Loss: 0.022871432825922966\n",
      "Epoch: 2433, Train Loss: 0.01750575564801693, Valid Loss: 0.022846324369311333\n",
      "Epoch: 2434, Train Loss: 0.01748691499233246, Valid Loss: 0.0228209737688303\n",
      "Epoch: 2435, Train Loss: 0.017468158155679703, Valid Loss: 0.02279595099389553\n",
      "Epoch: 2436, Train Loss: 0.017449382692575455, Valid Loss: 0.022770781069993973\n",
      "Epoch: 2437, Train Loss: 0.0174306258559227, Valid Loss: 0.022745531052350998\n",
      "Epoch: 2438, Train Loss: 0.01741190440952778, Valid Loss: 0.02272077277302742\n",
      "Epoch: 2439, Train Loss: 0.0173932071775198, Valid Loss: 0.022695649415254593\n",
      "Epoch: 2440, Train Loss: 0.01737455651164055, Valid Loss: 0.022670555859804153\n",
      "Epoch: 2441, Train Loss: 0.01735590770840645, Valid Loss: 0.0226457342505455\n",
      "Epoch: 2442, Train Loss: 0.01733730360865593, Valid Loss: 0.022620711475610733\n",
      "Epoch: 2443, Train Loss: 0.01731870509684086, Valid Loss: 0.022595765069127083\n",
      "Epoch: 2444, Train Loss: 0.017300128936767578, Valid Loss: 0.02257119119167328\n",
      "Epoch: 2445, Train Loss: 0.017281580716371536, Valid Loss: 0.022546283900737762\n",
      "Epoch: 2446, Train Loss: 0.017263077199459076, Valid Loss: 0.022521523758769035\n",
      "Epoch: 2447, Train Loss: 0.01724458485841751, Valid Loss: 0.022496793419122696\n",
      "Epoch: 2448, Train Loss: 0.017226101830601692, Valid Loss: 0.022472012788057327\n",
      "Epoch: 2449, Train Loss: 0.017207659780979156, Valid Loss: 0.022447416558861732\n",
      "Epoch: 2450, Train Loss: 0.017189234495162964, Valid Loss: 0.02242283895611763\n",
      "Epoch: 2451, Train Loss: 0.01717086136341095, Valid Loss: 0.02239817939698696\n",
      "Epoch: 2452, Train Loss: 0.017152464017271996, Valid Loss: 0.02237379550933838\n",
      "Epoch: 2453, Train Loss: 0.017134107649326324, Valid Loss: 0.022349229082465172\n",
      "Epoch: 2454, Train Loss: 0.017115790396928787, Valid Loss: 0.022324606776237488\n",
      "Epoch: 2455, Train Loss: 0.017097512260079384, Valid Loss: 0.022300343960523605\n",
      "Epoch: 2456, Train Loss: 0.017079206183552742, Valid Loss: 0.022275827825069427\n",
      "Epoch: 2457, Train Loss: 0.01706094853579998, Valid Loss: 0.022251538932323456\n",
      "Epoch: 2458, Train Loss: 0.0170427393168211, Valid Loss: 0.022227270528674126\n",
      "Epoch: 2459, Train Loss: 0.017024530097842216, Valid Loss: 0.02220272459089756\n",
      "Epoch: 2460, Train Loss: 0.017006339505314827, Valid Loss: 0.022178422659635544\n",
      "Epoch: 2461, Train Loss: 0.01698819361627102, Valid Loss: 0.02215445600450039\n",
      "Epoch: 2462, Train Loss: 0.01697004958987236, Valid Loss: 0.022130154073238373\n",
      "Epoch: 2463, Train Loss: 0.016951948404312134, Valid Loss: 0.022105904296040535\n",
      "Epoch: 2464, Train Loss: 0.016933858394622803, Valid Loss: 0.02208198793232441\n",
      "Epoch: 2465, Train Loss: 0.016915788874030113, Valid Loss: 0.022057661786675453\n",
      "Epoch: 2466, Train Loss: 0.016897769644856453, Valid Loss: 0.022033600136637688\n",
      "Epoch: 2467, Train Loss: 0.016879728063941002, Valid Loss: 0.022009843960404396\n",
      "Epoch: 2468, Train Loss: 0.016861746087670326, Valid Loss: 0.021985644474625587\n",
      "Epoch: 2469, Train Loss: 0.01684378832578659, Valid Loss: 0.02196170575916767\n",
      "Epoch: 2470, Train Loss: 0.016825834289193153, Valid Loss: 0.021937904879450798\n",
      "Epoch: 2471, Train Loss: 0.016807904466986656, Valid Loss: 0.021913791075348854\n",
      "Epoch: 2472, Train Loss: 0.016790008172392845, Valid Loss: 0.02188996598124504\n",
      "Epoch: 2473, Train Loss: 0.016772141680121422, Valid Loss: 0.021866433322429657\n",
      "Epoch: 2474, Train Loss: 0.016754280775785446, Valid Loss: 0.02184247225522995\n",
      "Epoch: 2475, Train Loss: 0.016736438497900963, Valid Loss: 0.02181856706738472\n",
      "Epoch: 2476, Train Loss: 0.016718659549951553, Valid Loss: 0.021795058622956276\n",
      "Epoch: 2477, Train Loss: 0.0167008638381958, Valid Loss: 0.02177131362259388\n",
      "Epoch: 2478, Train Loss: 0.016683092340826988, Valid Loss: 0.021747566759586334\n",
      "Epoch: 2479, Train Loss: 0.01666535623371601, Valid Loss: 0.021724123507738113\n",
      "Epoch: 2480, Train Loss: 0.01664765551686287, Valid Loss: 0.021700317040085793\n",
      "Epoch: 2481, Train Loss: 0.01662997156381607, Valid Loss: 0.021676644682884216\n",
      "Epoch: 2482, Train Loss: 0.016612296923995018, Valid Loss: 0.021653542295098305\n",
      "Epoch: 2483, Train Loss: 0.016594653949141502, Valid Loss: 0.021629810333251953\n",
      "Epoch: 2484, Train Loss: 0.016577033326029778, Valid Loss: 0.021606268361210823\n",
      "Epoch: 2485, Train Loss: 0.01655944436788559, Valid Loss: 0.021583104506134987\n",
      "Epoch: 2486, Train Loss: 0.016541853547096252, Valid Loss: 0.021559564396739006\n",
      "Epoch: 2487, Train Loss: 0.016524285078048706, Valid Loss: 0.021536044776439667\n",
      "Epoch: 2488, Train Loss: 0.01650676317512989, Valid Loss: 0.021513139829039574\n",
      "Epoch: 2489, Train Loss: 0.016489243134856224, Valid Loss: 0.021489519625902176\n",
      "Epoch: 2490, Train Loss: 0.016471775248646736, Valid Loss: 0.021466286852955818\n",
      "Epoch: 2491, Train Loss: 0.0164543017745018, Valid Loss: 0.021443229168653488\n",
      "Epoch: 2492, Train Loss: 0.016436884179711342, Valid Loss: 0.021420013159513474\n",
      "Epoch: 2493, Train Loss: 0.016419440507888794, Valid Loss: 0.021396761760115623\n",
      "Epoch: 2494, Train Loss: 0.016402045264840126, Valid Loss: 0.021373674273490906\n",
      "Epoch: 2495, Train Loss: 0.01638467237353325, Valid Loss: 0.021350521594285965\n",
      "Epoch: 2496, Train Loss: 0.016367323696613312, Valid Loss: 0.021327370777726173\n",
      "Epoch: 2497, Train Loss: 0.01634998805820942, Valid Loss: 0.021304406225681305\n",
      "Epoch: 2498, Train Loss: 0.016332685947418213, Valid Loss: 0.021281566470861435\n",
      "Epoch: 2499, Train Loss: 0.016315411776304245, Valid Loss: 0.02125832997262478\n",
      "Epoch: 2500, Train Loss: 0.01629812829196453, Valid Loss: 0.021235354244709015\n",
      "Epoch: 2501, Train Loss: 0.016280898824334145, Valid Loss: 0.021212654188275337\n",
      "Epoch: 2502, Train Loss: 0.016263680532574654, Valid Loss: 0.021189739927649498\n",
      "Epoch: 2503, Train Loss: 0.016246480867266655, Valid Loss: 0.021166792139410973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2504, Train Loss: 0.016229301691055298, Valid Loss: 0.021143991500139236\n",
      "Epoch: 2505, Train Loss: 0.016212165355682373, Valid Loss: 0.0211213119328022\n",
      "Epoch: 2506, Train Loss: 0.016195017844438553, Valid Loss: 0.021098406985402107\n",
      "Epoch: 2507, Train Loss: 0.016177913174033165, Valid Loss: 0.021075887605547905\n",
      "Epoch: 2508, Train Loss: 0.016160830855369568, Valid Loss: 0.021053221076726913\n",
      "Epoch: 2509, Train Loss: 0.01614375412464142, Valid Loss: 0.021030256524682045\n",
      "Epoch: 2510, Train Loss: 0.01612669788300991, Valid Loss: 0.021007664501667023\n",
      "Epoch: 2511, Train Loss: 0.016109682619571686, Valid Loss: 0.020985202863812447\n",
      "Epoch: 2512, Train Loss: 0.016092682257294655, Valid Loss: 0.020962581038475037\n",
      "Epoch: 2513, Train Loss: 0.01607571728527546, Valid Loss: 0.02094004675745964\n",
      "Epoch: 2514, Train Loss: 0.016058754175901413, Valid Loss: 0.02091757021844387\n",
      "Epoch: 2515, Train Loss: 0.016041819006204605, Valid Loss: 0.020895009860396385\n",
      "Epoch: 2516, Train Loss: 0.016024915501475334, Valid Loss: 0.020872710272669792\n",
      "Epoch: 2517, Train Loss: 0.016008004546165466, Valid Loss: 0.020850257948040962\n",
      "Epoch: 2518, Train Loss: 0.01599114201962948, Valid Loss: 0.02082774229347706\n",
      "Epoch: 2519, Train Loss: 0.015974292531609535, Valid Loss: 0.020805468782782555\n",
      "Epoch: 2520, Train Loss: 0.015957454219460487, Valid Loss: 0.0207832008600235\n",
      "Epoch: 2521, Train Loss: 0.015940649434924126, Valid Loss: 0.020760828629136086\n",
      "Epoch: 2522, Train Loss: 0.015923865139484406, Valid Loss: 0.02073848992586136\n",
      "Epoch: 2523, Train Loss: 0.015907105058431625, Valid Loss: 0.020716391503810883\n",
      "Epoch: 2524, Train Loss: 0.015890352427959442, Valid Loss: 0.020694009959697723\n",
      "Epoch: 2525, Train Loss: 0.015873638913035393, Valid Loss: 0.020671799778938293\n",
      "Epoch: 2526, Train Loss: 0.015856945887207985, Valid Loss: 0.020649872720241547\n",
      "Epoch: 2527, Train Loss: 0.015840278938412666, Valid Loss: 0.020627548918128014\n",
      "Epoch: 2528, Train Loss: 0.015823617577552795, Valid Loss: 0.02060539461672306\n",
      "Epoch: 2529, Train Loss: 0.015806961804628372, Valid Loss: 0.02058347314596176\n",
      "Epoch: 2530, Train Loss: 0.01579034887254238, Valid Loss: 0.020561395213007927\n",
      "Epoch: 2531, Train Loss: 0.015773756429553032, Valid Loss: 0.020539365708827972\n",
      "Epoch: 2532, Train Loss: 0.015757190063595772, Valid Loss: 0.020517371594905853\n",
      "Epoch: 2533, Train Loss: 0.015740621834993362, Valid Loss: 0.020495429635047913\n",
      "Epoch: 2534, Train Loss: 0.015724100172519684, Valid Loss: 0.020473461598157883\n",
      "Epoch: 2535, Train Loss: 0.01570757105946541, Valid Loss: 0.02045164257287979\n",
      "Epoch: 2536, Train Loss: 0.015691101551055908, Valid Loss: 0.02042977139353752\n",
      "Epoch: 2537, Train Loss: 0.015674613416194916, Valid Loss: 0.020407866686582565\n",
      "Epoch: 2538, Train Loss: 0.015658166259527206, Valid Loss: 0.020385965704917908\n",
      "Epoch: 2539, Train Loss: 0.015641748905181885, Valid Loss: 0.020364336669445038\n",
      "Epoch: 2540, Train Loss: 0.015625329688191414, Valid Loss: 0.020342614501714706\n",
      "Epoch: 2541, Train Loss: 0.0156089561060071, Valid Loss: 0.020320864394307137\n",
      "Epoch: 2542, Train Loss: 0.015592572279274464, Valid Loss: 0.02029910497367382\n",
      "Epoch: 2543, Train Loss: 0.015576214529573917, Valid Loss: 0.020277440547943115\n",
      "Epoch: 2544, Train Loss: 0.015559905208647251, Valid Loss: 0.020255815237760544\n",
      "Epoch: 2545, Train Loss: 0.015543597750365734, Valid Loss: 0.02023426815867424\n",
      "Epoch: 2546, Train Loss: 0.015527321957051754, Valid Loss: 0.020212499424815178\n",
      "Epoch: 2547, Train Loss: 0.0155110452324152, Valid Loss: 0.02019108459353447\n",
      "Epoch: 2548, Train Loss: 0.01549482624977827, Valid Loss: 0.02016950212419033\n",
      "Epoch: 2549, Train Loss: 0.0154785867780447, Valid Loss: 0.02014796808362007\n",
      "Epoch: 2550, Train Loss: 0.01546237338334322, Valid Loss: 0.02012653276324272\n",
      "Epoch: 2551, Train Loss: 0.015446188859641552, Valid Loss: 0.020105021074414253\n",
      "Epoch: 2552, Train Loss: 0.015430040657520294, Valid Loss: 0.02008361555635929\n",
      "Epoch: 2553, Train Loss: 0.01541390735656023, Valid Loss: 0.02006242237985134\n",
      "Epoch: 2554, Train Loss: 0.015397768467664719, Valid Loss: 0.020040832459926605\n",
      "Epoch: 2555, Train Loss: 0.015381657518446445, Valid Loss: 0.020019257441163063\n",
      "Epoch: 2556, Train Loss: 0.015365584753453732, Valid Loss: 0.01999826729297638\n",
      "Epoch: 2557, Train Loss: 0.015349521301686764, Valid Loss: 0.019976966083049774\n",
      "Epoch: 2558, Train Loss: 0.015333469957113266, Valid Loss: 0.019955534487962723\n",
      "Epoch: 2559, Train Loss: 0.015317462384700775, Valid Loss: 0.01993432454764843\n",
      "Epoch: 2560, Train Loss: 0.015301459468901157, Valid Loss: 0.019913066178560257\n",
      "Epoch: 2561, Train Loss: 0.015285474248230457, Valid Loss: 0.019891906529664993\n",
      "Epoch: 2562, Train Loss: 0.015269526280462742, Valid Loss: 0.01987089402973652\n",
      "Epoch: 2563, Train Loss: 0.015253591351211071, Valid Loss: 0.019849753007292747\n",
      "Epoch: 2564, Train Loss: 0.015237648971378803, Valid Loss: 0.019828511402010918\n",
      "Epoch: 2565, Train Loss: 0.015221750363707542, Valid Loss: 0.01980733685195446\n",
      "Epoch: 2566, Train Loss: 0.0152058694511652, Valid Loss: 0.01978653110563755\n",
      "Epoch: 2567, Train Loss: 0.01519001368433237, Valid Loss: 0.019765526056289673\n",
      "Epoch: 2568, Train Loss: 0.015174155123531818, Valid Loss: 0.019744396209716797\n",
      "Epoch: 2569, Train Loss: 0.015158344991505146, Valid Loss: 0.019723407924175262\n",
      "Epoch: 2570, Train Loss: 0.015142517164349556, Valid Loss: 0.019702380523085594\n",
      "Epoch: 2571, Train Loss: 0.01512673869729042, Valid Loss: 0.019681476056575775\n",
      "Epoch: 2572, Train Loss: 0.015110964886844158, Valid Loss: 0.01966073364019394\n",
      "Epoch: 2573, Train Loss: 0.01509524043649435, Valid Loss: 0.019639935344457626\n",
      "Epoch: 2574, Train Loss: 0.015079507604241371, Valid Loss: 0.019618820399045944\n",
      "Epoch: 2575, Train Loss: 0.01506381668150425, Valid Loss: 0.01959800347685814\n",
      "Epoch: 2576, Train Loss: 0.015048105269670486, Valid Loss: 0.019577331840991974\n",
      "Epoch: 2577, Train Loss: 0.015032462775707245, Valid Loss: 0.019556546583771706\n",
      "Epoch: 2578, Train Loss: 0.015016812831163406, Valid Loss: 0.019535722211003304\n",
      "Epoch: 2579, Train Loss: 0.015001186169683933, Valid Loss: 0.01951509155333042\n",
      "Epoch: 2580, Train Loss: 0.014985563233494759, Valid Loss: 0.019494347274303436\n",
      "Epoch: 2581, Train Loss: 0.014969970099627972, Valid Loss: 0.019473515450954437\n",
      "Epoch: 2582, Train Loss: 0.014954391866922379, Valid Loss: 0.019452981650829315\n",
      "Epoch: 2583, Train Loss: 0.014938847161829472, Valid Loss: 0.019432324916124344\n",
      "Epoch: 2584, Train Loss: 0.014923307113349438, Valid Loss: 0.019411660730838776\n",
      "Epoch: 2585, Train Loss: 0.014907811768352985, Valid Loss: 0.019391104578971863\n",
      "Epoch: 2586, Train Loss: 0.014892315492033958, Valid Loss: 0.01937061920762062\n",
      "Epoch: 2587, Train Loss: 0.014876851812005043, Valid Loss: 0.019350113347172737\n",
      "Epoch: 2588, Train Loss: 0.014861386269330978, Valid Loss: 0.019329600036144257\n",
      "Epoch: 2589, Train Loss: 0.014845951460301876, Valid Loss: 0.01930910162627697\n",
      "Epoch: 2590, Train Loss: 0.014830535277724266, Valid Loss: 0.019288789480924606\n",
      "Epoch: 2591, Train Loss: 0.014815127477049828, Valid Loss: 0.019268127158284187\n",
      "Epoch: 2592, Train Loss: 0.014799758791923523, Valid Loss: 0.019247757270932198\n",
      "Epoch: 2593, Train Loss: 0.014784392900764942, Valid Loss: 0.019227460026741028\n",
      "Epoch: 2594, Train Loss: 0.014769058674573898, Valid Loss: 0.019207049161195755\n",
      "Epoch: 2595, Train Loss: 0.014753734692931175, Valid Loss: 0.01918671280145645\n",
      "Epoch: 2596, Train Loss: 0.014738427475094795, Valid Loss: 0.019166333600878716\n",
      "Epoch: 2597, Train Loss: 0.014723140746355057, Valid Loss: 0.019146068021655083\n",
      "Epoch: 2598, Train Loss: 0.014707875438034534, Valid Loss: 0.01912585087120533\n",
      "Epoch: 2599, Train Loss: 0.014692637138068676, Valid Loss: 0.019105756655335426\n",
      "Epoch: 2600, Train Loss: 0.01467740349471569, Valid Loss: 0.019085580483078957\n",
      "Epoch: 2601, Train Loss: 0.014662202447652817, Valid Loss: 0.01906510442495346\n",
      "Epoch: 2602, Train Loss: 0.014646993950009346, Valid Loss: 0.01904498040676117\n",
      "Epoch: 2603, Train Loss: 0.0146318469196558, Valid Loss: 0.019024886190891266\n",
      "Epoch: 2604, Train Loss: 0.014616675674915314, Valid Loss: 0.019004862755537033\n",
      "Epoch: 2605, Train Loss: 0.014601548202335835, Valid Loss: 0.0189848430454731\n",
      "Epoch: 2606, Train Loss: 0.014586446806788445, Valid Loss: 0.018964475020766258\n",
      "Epoch: 2607, Train Loss: 0.014571337960660458, Valid Loss: 0.01894429512321949\n",
      "Epoch: 2608, Train Loss: 0.01455625519156456, Valid Loss: 0.018924681469798088\n",
      "Epoch: 2609, Train Loss: 0.014541187323629856, Valid Loss: 0.018904656171798706\n",
      "Epoch: 2610, Train Loss: 0.01452614739537239, Valid Loss: 0.018884368240833282\n",
      "Epoch: 2611, Train Loss: 0.014511119574308395, Valid Loss: 0.01886451430618763\n",
      "Epoch: 2612, Train Loss: 0.014496123418211937, Valid Loss: 0.0188447218388319\n",
      "Epoch: 2613, Train Loss: 0.014481130056083202, Valid Loss: 0.018824763596057892\n",
      "Epoch: 2614, Train Loss: 0.014466166496276855, Valid Loss: 0.018804989755153656\n",
      "Epoch: 2615, Train Loss: 0.014451206661760807, Valid Loss: 0.01878495141863823\n",
      "Epoch: 2616, Train Loss: 0.014436283148825169, Valid Loss: 0.018765000626444817\n",
      "Epoch: 2617, Train Loss: 0.01442137360572815, Valid Loss: 0.01874530501663685\n",
      "Epoch: 2618, Train Loss: 0.014406472444534302, Valid Loss: 0.018725689500570297\n",
      "Epoch: 2619, Train Loss: 0.014391597360372543, Valid Loss: 0.01870572566986084\n",
      "Epoch: 2620, Train Loss: 0.014376730658113956, Valid Loss: 0.01868579350411892\n",
      "Epoch: 2621, Train Loss: 0.014361907728016376, Valid Loss: 0.018666325137019157\n",
      "Epoch: 2622, Train Loss: 0.014347067102789879, Valid Loss: 0.018646612763404846\n",
      "Epoch: 2623, Train Loss: 0.014332260936498642, Valid Loss: 0.01862681470811367\n",
      "Epoch: 2624, Train Loss: 0.014317461289465427, Valid Loss: 0.01860732212662697\n",
      "Epoch: 2625, Train Loss: 0.014302712865173817, Valid Loss: 0.018587548285722733\n",
      "Epoch: 2626, Train Loss: 0.014287964440882206, Valid Loss: 0.018567832186818123\n",
      "Epoch: 2627, Train Loss: 0.014273211359977722, Valid Loss: 0.018548395484685898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2628, Train Loss: 0.014258508570492268, Valid Loss: 0.01852891780436039\n",
      "Epoch: 2629, Train Loss: 0.014243812300264835, Valid Loss: 0.01850905641913414\n",
      "Epoch: 2630, Train Loss: 0.014229129068553448, Valid Loss: 0.018489573150873184\n",
      "Epoch: 2631, Train Loss: 0.01421446818858385, Valid Loss: 0.01847010850906372\n",
      "Epoch: 2632, Train Loss: 0.014199797064065933, Valid Loss: 0.018450628966093063\n",
      "Epoch: 2633, Train Loss: 0.014185190200805664, Valid Loss: 0.01843118853867054\n",
      "Epoch: 2634, Train Loss: 0.01417058426886797, Valid Loss: 0.018411794677376747\n",
      "Epoch: 2635, Train Loss: 0.014155993238091469, Valid Loss: 0.018392257392406464\n",
      "Epoch: 2636, Train Loss: 0.01414141058921814, Valid Loss: 0.01837288588285446\n",
      "Epoch: 2637, Train Loss: 0.014126874506473541, Valid Loss: 0.0183535385876894\n",
      "Epoch: 2638, Train Loss: 0.014112324453890324, Valid Loss: 0.0183342844247818\n",
      "Epoch: 2639, Train Loss: 0.014097816310822964, Valid Loss: 0.01831493154168129\n",
      "Epoch: 2640, Train Loss: 0.0140833156183362, Valid Loss: 0.01829550415277481\n",
      "Epoch: 2641, Train Loss: 0.014068816788494587, Valid Loss: 0.018276207149028778\n",
      "Epoch: 2642, Train Loss: 0.014054352417588234, Valid Loss: 0.018257049843668938\n",
      "Epoch: 2643, Train Loss: 0.014039905741810799, Valid Loss: 0.018237685784697533\n",
      "Epoch: 2644, Train Loss: 0.014025467447936535, Valid Loss: 0.018218621611595154\n",
      "Epoch: 2645, Train Loss: 0.014011058956384659, Valid Loss: 0.018199291080236435\n",
      "Epoch: 2646, Train Loss: 0.013996674679219723, Valid Loss: 0.018180033192038536\n",
      "Epoch: 2647, Train Loss: 0.013982286676764488, Valid Loss: 0.018161030486226082\n",
      "Epoch: 2648, Train Loss: 0.013967907056212425, Valid Loss: 0.018142027780413628\n",
      "Epoch: 2649, Train Loss: 0.013953566551208496, Valid Loss: 0.01812266744673252\n",
      "Epoch: 2650, Train Loss: 0.013939237222075462, Valid Loss: 0.01810356229543686\n",
      "Epoch: 2651, Train Loss: 0.01392494048923254, Valid Loss: 0.018084662035107613\n",
      "Epoch: 2652, Train Loss: 0.013910628855228424, Valid Loss: 0.01806551404297352\n",
      "Epoch: 2653, Train Loss: 0.013896354474127293, Valid Loss: 0.018046479672193527\n",
      "Epoch: 2654, Train Loss: 0.013882101513445377, Valid Loss: 0.01802750490605831\n",
      "Epoch: 2655, Train Loss: 0.013867855072021484, Valid Loss: 0.018008463084697723\n",
      "Epoch: 2656, Train Loss: 0.013853632844984531, Valid Loss: 0.017989646643400192\n",
      "Epoch: 2657, Train Loss: 0.013839432038366795, Valid Loss: 0.017970597371459007\n",
      "Epoch: 2658, Train Loss: 0.013825241476297379, Valid Loss: 0.017951600253582\n",
      "Epoch: 2659, Train Loss: 0.013811071403324604, Valid Loss: 0.017932772636413574\n",
      "Epoch: 2660, Train Loss: 0.013796903192996979, Valid Loss: 0.017913855612277985\n",
      "Epoch: 2661, Train Loss: 0.013782791793346405, Valid Loss: 0.01789497770369053\n",
      "Epoch: 2662, Train Loss: 0.013768650591373444, Valid Loss: 0.017876340076327324\n",
      "Epoch: 2663, Train Loss: 0.013754529878497124, Valid Loss: 0.0178573839366436\n",
      "Epoch: 2664, Train Loss: 0.013740461319684982, Valid Loss: 0.01783841662108898\n",
      "Epoch: 2665, Train Loss: 0.013726380653679371, Valid Loss: 0.017819803208112717\n",
      "Epoch: 2666, Train Loss: 0.013712323270738125, Valid Loss: 0.017801018431782722\n",
      "Epoch: 2667, Train Loss: 0.013698294758796692, Valid Loss: 0.017782237380743027\n",
      "Epoch: 2668, Train Loss: 0.013684272766113281, Valid Loss: 0.01776357740163803\n",
      "Epoch: 2669, Train Loss: 0.013670268468558788, Valid Loss: 0.017744893208146095\n",
      "Epoch: 2670, Train Loss: 0.01365628745406866, Valid Loss: 0.017726093530654907\n",
      "Epoch: 2671, Train Loss: 0.013642293401062489, Valid Loss: 0.017707500606775284\n",
      "Epoch: 2672, Train Loss: 0.01362835243344307, Valid Loss: 0.01768895424902439\n",
      "Epoch: 2673, Train Loss: 0.013614422641694546, Valid Loss: 0.01767013780772686\n",
      "Epoch: 2674, Train Loss: 0.013600492849946022, Valid Loss: 0.01765161007642746\n",
      "Epoch: 2675, Train Loss: 0.013586586341261864, Valid Loss: 0.01763310842216015\n",
      "Epoch: 2676, Train Loss: 0.013572688214480877, Valid Loss: 0.017614541575312614\n",
      "Epoch: 2677, Train Loss: 0.013558821752667427, Valid Loss: 0.01759607344865799\n",
      "Epoch: 2678, Train Loss: 0.013544982299208641, Valid Loss: 0.017577484250068665\n",
      "Epoch: 2679, Train Loss: 0.013531138189136982, Valid Loss: 0.017558898776769638\n",
      "Epoch: 2680, Train Loss: 0.013517321087419987, Valid Loss: 0.017540449276566505\n",
      "Epoch: 2681, Train Loss: 0.01350350584834814, Valid Loss: 0.01752212457358837\n",
      "Epoch: 2682, Train Loss: 0.013489716686308384, Valid Loss: 0.017503680661320686\n",
      "Epoch: 2683, Train Loss: 0.013475933112204075, Valid Loss: 0.017485089600086212\n",
      "Epoch: 2684, Train Loss: 0.013462183065712452, Valid Loss: 0.017466740682721138\n",
      "Epoch: 2685, Train Loss: 0.013448470272123814, Valid Loss: 0.017448456957936287\n",
      "Epoch: 2686, Train Loss: 0.013434742577373981, Valid Loss: 0.01743006706237793\n",
      "Epoch: 2687, Train Loss: 0.013421034440398216, Valid Loss: 0.01741170696914196\n",
      "Epoch: 2688, Train Loss: 0.013407333754003048, Valid Loss: 0.017393484711647034\n",
      "Epoch: 2689, Train Loss: 0.013393662869930267, Valid Loss: 0.01737508736550808\n",
      "Epoch: 2690, Train Loss: 0.013379993848502636, Valid Loss: 0.017356840893626213\n",
      "Epoch: 2691, Train Loss: 0.01336637046188116, Valid Loss: 0.01733856275677681\n",
      "Epoch: 2692, Train Loss: 0.013352745212614536, Valid Loss: 0.01732037588953972\n",
      "Epoch: 2693, Train Loss: 0.013339134864509106, Valid Loss: 0.01730206049978733\n",
      "Epoch: 2694, Train Loss: 0.013325556181371212, Valid Loss: 0.01728387176990509\n",
      "Epoch: 2695, Train Loss: 0.013311970047652721, Valid Loss: 0.017265763133764267\n",
      "Epoch: 2696, Train Loss: 0.01329840812832117, Valid Loss: 0.017247701063752174\n",
      "Epoch: 2697, Train Loss: 0.013284873217344284, Valid Loss: 0.017229391261935234\n",
      "Epoch: 2698, Train Loss: 0.013271323405206203, Valid Loss: 0.017211323603987694\n",
      "Epoch: 2699, Train Loss: 0.013257834129035473, Valid Loss: 0.01719335839152336\n",
      "Epoch: 2700, Train Loss: 0.013244333676993847, Valid Loss: 0.017175083979964256\n",
      "Epoch: 2701, Train Loss: 0.013230851851403713, Valid Loss: 0.017157001420855522\n",
      "Epoch: 2702, Train Loss: 0.013217385858297348, Valid Loss: 0.017139172181487083\n",
      "Epoch: 2703, Train Loss: 0.013203938491642475, Valid Loss: 0.017120981588959694\n",
      "Epoch: 2704, Train Loss: 0.01319050882011652, Valid Loss: 0.017102858051657677\n",
      "Epoch: 2705, Train Loss: 0.013177093118429184, Valid Loss: 0.017085086554288864\n",
      "Epoch: 2706, Train Loss: 0.013163688592612743, Valid Loss: 0.01706705056130886\n",
      "Epoch: 2707, Train Loss: 0.013150320388376713, Valid Loss: 0.01704900898039341\n",
      "Epoch: 2708, Train Loss: 0.013136938214302063, Valid Loss: 0.017031226307153702\n",
      "Epoch: 2709, Train Loss: 0.013123595155775547, Valid Loss: 0.01701321080327034\n",
      "Epoch: 2710, Train Loss: 0.013110250234603882, Valid Loss: 0.01699521578848362\n",
      "Epoch: 2711, Train Loss: 0.013096941635012627, Valid Loss: 0.016977639868855476\n",
      "Epoch: 2712, Train Loss: 0.013083633966743946, Valid Loss: 0.01695975847542286\n",
      "Epoch: 2713, Train Loss: 0.013070336543023586, Valid Loss: 0.01694156788289547\n",
      "Epoch: 2714, Train Loss: 0.013057071715593338, Valid Loss: 0.01692386530339718\n",
      "Epoch: 2715, Train Loss: 0.013043815270066261, Valid Loss: 0.0169062539935112\n",
      "Epoch: 2716, Train Loss: 0.013030576519668102, Valid Loss: 0.016888327896595\n",
      "Epoch: 2717, Train Loss: 0.013017355464398861, Valid Loss: 0.01687052473425865\n",
      "Epoch: 2718, Train Loss: 0.013004135340452194, Valid Loss: 0.0168528463691473\n",
      "Epoch: 2719, Train Loss: 0.012990927323698997, Valid Loss: 0.016834953799843788\n",
      "Epoch: 2720, Train Loss: 0.01297775749117136, Valid Loss: 0.016817260533571243\n",
      "Epoch: 2721, Train Loss: 0.012964596971869469, Valid Loss: 0.016799787059426308\n",
      "Epoch: 2722, Train Loss: 0.012951456941664219, Valid Loss: 0.016782013699412346\n",
      "Epoch: 2723, Train Loss: 0.012938306666910648, Valid Loss: 0.016764216125011444\n",
      "Epoch: 2724, Train Loss: 0.012925203889608383, Valid Loss: 0.016746599227190018\n",
      "Epoch: 2725, Train Loss: 0.012912096455693245, Valid Loss: 0.01672907918691635\n",
      "Epoch: 2726, Train Loss: 0.012898996472358704, Valid Loss: 0.016711441799998283\n",
      "Epoch: 2727, Train Loss: 0.01288595236837864, Valid Loss: 0.016693873330950737\n",
      "Epoch: 2728, Train Loss: 0.012872886843979359, Valid Loss: 0.016676127910614014\n",
      "Epoch: 2729, Train Loss: 0.012859845533967018, Valid Loss: 0.016658585518598557\n",
      "Epoch: 2730, Train Loss: 0.012846826575696468, Valid Loss: 0.0166411604732275\n",
      "Epoch: 2731, Train Loss: 0.012833804823458195, Valid Loss: 0.01662367396056652\n",
      "Epoch: 2732, Train Loss: 0.012820824980735779, Valid Loss: 0.016606183722615242\n",
      "Epoch: 2733, Train Loss: 0.012807833030819893, Valid Loss: 0.016588537022471428\n",
      "Epoch: 2734, Train Loss: 0.012794878333806992, Valid Loss: 0.016571085900068283\n",
      "Epoch: 2735, Train Loss: 0.01278192549943924, Valid Loss: 0.016553757712244987\n",
      "Epoch: 2736, Train Loss: 0.012768988497555256, Valid Loss: 0.016536207869648933\n",
      "Epoch: 2737, Train Loss: 0.01275606919080019, Valid Loss: 0.016518794000148773\n",
      "Epoch: 2738, Train Loss: 0.012743158265948296, Valid Loss: 0.016501352190971375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2739, Train Loss: 0.012730288319289684, Valid Loss: 0.016483895480632782\n",
      "Epoch: 2740, Train Loss: 0.012717396952211857, Valid Loss: 0.016466569155454636\n",
      "Epoch: 2741, Train Loss: 0.012704551219940186, Valid Loss: 0.016449308022856712\n",
      "Epoch: 2742, Train Loss: 0.012691710144281387, Valid Loss: 0.016431819647550583\n",
      "Epoch: 2743, Train Loss: 0.012678866274654865, Valid Loss: 0.01641455478966236\n",
      "Epoch: 2744, Train Loss: 0.012666045688092709, Valid Loss: 0.01639719307422638\n",
      "Epoch: 2745, Train Loss: 0.012653255835175514, Valid Loss: 0.01637989468872547\n",
      "Epoch: 2746, Train Loss: 0.012640492990612984, Valid Loss: 0.01636270061135292\n",
      "Epoch: 2747, Train Loss: 0.012627724558115005, Valid Loss: 0.016345364972949028\n",
      "Epoch: 2748, Train Loss: 0.012614968232810497, Valid Loss: 0.01632804051041603\n",
      "Epoch: 2749, Train Loss: 0.012602224014699459, Valid Loss: 0.016310924664139748\n",
      "Epoch: 2750, Train Loss: 0.01258950587362051, Valid Loss: 0.016293631866574287\n",
      "Epoch: 2751, Train Loss: 0.012576797977089882, Valid Loss: 0.016276339069008827\n",
      "Epoch: 2752, Train Loss: 0.012564101256430149, Valid Loss: 0.01625925861299038\n",
      "Epoch: 2753, Train Loss: 0.012551424093544483, Valid Loss: 0.016242127865552902\n",
      "Epoch: 2754, Train Loss: 0.012538760900497437, Valid Loss: 0.016224930062890053\n",
      "Epoch: 2755, Train Loss: 0.012526125647127628, Valid Loss: 0.01620778813958168\n",
      "Epoch: 2756, Train Loss: 0.012513481080532074, Valid Loss: 0.016190649941563606\n",
      "Epoch: 2757, Train Loss: 0.01250087097287178, Valid Loss: 0.016173526644706726\n",
      "Epoch: 2758, Train Loss: 0.01248827576637268, Valid Loss: 0.016156479716300964\n",
      "Epoch: 2759, Train Loss: 0.012475674040615559, Valid Loss: 0.016139434650540352\n",
      "Epoch: 2760, Train Loss: 0.012463108636438847, Valid Loss: 0.01612226851284504\n",
      "Epoch: 2761, Train Loss: 0.012450536713004112, Valid Loss: 0.016105160117149353\n",
      "Epoch: 2762, Train Loss: 0.012438004836440086, Valid Loss: 0.016088252887129784\n",
      "Epoch: 2763, Train Loss: 0.012425476685166359, Valid Loss: 0.01607118360698223\n",
      "Epoch: 2764, Train Loss: 0.012412949465215206, Valid Loss: 0.016054190695285797\n",
      "Epoch: 2765, Train Loss: 0.012400454841554165, Valid Loss: 0.01603713072836399\n",
      "Epoch: 2766, Train Loss: 0.012387988157570362, Valid Loss: 0.016020163893699646\n",
      "Epoch: 2767, Train Loss: 0.012375498190522194, Valid Loss: 0.0160031970590353\n",
      "Epoch: 2768, Train Loss: 0.012363049201667309, Valid Loss: 0.01598632149398327\n",
      "Epoch: 2769, Train Loss: 0.012350602075457573, Valid Loss: 0.015969447791576385\n",
      "Epoch: 2770, Train Loss: 0.012338172644376755, Valid Loss: 0.015952326357364655\n",
      "Epoch: 2771, Train Loss: 0.012325765565037727, Valid Loss: 0.015935499221086502\n",
      "Epoch: 2772, Train Loss: 0.0123133584856987, Valid Loss: 0.015918757766485214\n",
      "Epoch: 2773, Train Loss: 0.01230098307132721, Valid Loss: 0.015901725739240646\n",
      "Epoch: 2774, Train Loss: 0.01228860579431057, Valid Loss: 0.015884816646575928\n",
      "Epoch: 2775, Train Loss: 0.012276259250938892, Valid Loss: 0.0158680509775877\n",
      "Epoch: 2776, Train Loss: 0.012263936921954155, Valid Loss: 0.015851177275180817\n",
      "Epoch: 2777, Train Loss: 0.01225160714238882, Valid Loss: 0.015834322199225426\n",
      "Epoch: 2778, Train Loss: 0.012239299714565277, Valid Loss: 0.015817567706108093\n",
      "Epoch: 2779, Train Loss: 0.01222700159996748, Valid Loss: 0.01580079272389412\n",
      "Epoch: 2780, Train Loss: 0.012214710004627705, Valid Loss: 0.01578388549387455\n",
      "Epoch: 2781, Train Loss: 0.012202444486320019, Valid Loss: 0.015767201781272888\n",
      "Epoch: 2782, Train Loss: 0.012190205976366997, Valid Loss: 0.015750518068671227\n",
      "Epoch: 2783, Train Loss: 0.012177967466413975, Valid Loss: 0.01573370397090912\n",
      "Epoch: 2784, Train Loss: 0.012165749445557594, Valid Loss: 0.01571696437895298\n",
      "Epoch: 2785, Train Loss: 0.012153521180152893, Valid Loss: 0.015700308606028557\n",
      "Epoch: 2786, Train Loss: 0.012141335755586624, Valid Loss: 0.015683678910136223\n",
      "Epoch: 2787, Train Loss: 0.012129157781600952, Valid Loss: 0.015666835010051727\n",
      "Epoch: 2788, Train Loss: 0.012116990983486176, Valid Loss: 0.015650160610675812\n",
      "Epoch: 2789, Train Loss: 0.012104841880500317, Valid Loss: 0.0156337209045887\n",
      "Epoch: 2790, Train Loss: 0.012092698365449905, Valid Loss: 0.015616890974342823\n",
      "Epoch: 2791, Train Loss: 0.012080575339496136, Valid Loss: 0.015600260347127914\n",
      "Epoch: 2792, Train Loss: 0.012068464420735836, Valid Loss: 0.015583779662847519\n",
      "Epoch: 2793, Train Loss: 0.012056374922394753, Valid Loss: 0.015567103400826454\n",
      "Epoch: 2794, Train Loss: 0.012044296599924564, Valid Loss: 0.01555042527616024\n",
      "Epoch: 2795, Train Loss: 0.012032230384647846, Valid Loss: 0.01553395763039589\n",
      "Epoch: 2796, Train Loss: 0.012020189315080643, Valid Loss: 0.015517358668148518\n",
      "Epoch: 2797, Train Loss: 0.012008149176836014, Valid Loss: 0.015500751323997974\n",
      "Epoch: 2798, Train Loss: 0.011996116489171982, Valid Loss: 0.015484387055039406\n",
      "Epoch: 2799, Train Loss: 0.011984112672507763, Valid Loss: 0.015467868186533451\n",
      "Epoch: 2800, Train Loss: 0.011972101405262947, Valid Loss: 0.015451171435415745\n",
      "Epoch: 2801, Train Loss: 0.011960139498114586, Valid Loss: 0.015434782952070236\n",
      "Epoch: 2802, Train Loss: 0.011948175728321075, Valid Loss: 0.015418351627886295\n",
      "Epoch: 2803, Train Loss: 0.011936217546463013, Valid Loss: 0.015401826240122318\n",
      "Epoch: 2804, Train Loss: 0.011924275197088718, Valid Loss: 0.01538537722080946\n",
      "Epoch: 2805, Train Loss: 0.01191234402358532, Valid Loss: 0.015368971973657608\n",
      "Epoch: 2806, Train Loss: 0.011900440789759159, Valid Loss: 0.015352590009570122\n",
      "Epoch: 2807, Train Loss: 0.011888544075191021, Valid Loss: 0.015336070209741592\n",
      "Epoch: 2808, Train Loss: 0.01187667716294527, Valid Loss: 0.015319735743105412\n",
      "Epoch: 2809, Train Loss: 0.01186481025069952, Valid Loss: 0.015303362160921097\n",
      "Epoch: 2810, Train Loss: 0.011852950789034367, Valid Loss: 0.015286965295672417\n",
      "Epoch: 2811, Train Loss: 0.011841097846627235, Valid Loss: 0.015270636416971684\n",
      "Epoch: 2812, Train Loss: 0.011829281225800514, Valid Loss: 0.015254367142915726\n",
      "Epoch: 2813, Train Loss: 0.01181747391819954, Valid Loss: 0.015237927436828613\n",
      "Epoch: 2814, Train Loss: 0.011805668473243713, Valid Loss: 0.01522160042077303\n",
      "Epoch: 2815, Train Loss: 0.011793887242674828, Valid Loss: 0.01520545594394207\n",
      "Epoch: 2816, Train Loss: 0.011782119050621986, Valid Loss: 0.01518916618078947\n",
      "Epoch: 2817, Train Loss: 0.011770368553698063, Valid Loss: 0.015172692947089672\n",
      "Epoch: 2818, Train Loss: 0.011758621782064438, Valid Loss: 0.015156549401581287\n",
      "Epoch: 2819, Train Loss: 0.01174689270555973, Valid Loss: 0.01514040119946003\n",
      "Epoch: 2820, Train Loss: 0.011735165491700172, Valid Loss: 0.015124074183404446\n",
      "Epoch: 2821, Train Loss: 0.011723476462066174, Valid Loss: 0.01510792039334774\n",
      "Epoch: 2822, Train Loss: 0.011711803264915943, Valid Loss: 0.01509180385619402\n",
      "Epoch: 2823, Train Loss: 0.011700115166604519, Valid Loss: 0.015075449831783772\n",
      "Epoch: 2824, Train Loss: 0.01168846059590578, Valid Loss: 0.015059314668178558\n",
      "Epoch: 2825, Train Loss: 0.011676819063723087, Valid Loss: 0.015043280087411404\n",
      "Epoch: 2826, Train Loss: 0.011665189638733864, Valid Loss: 0.015027117915451527\n",
      "Epoch: 2827, Train Loss: 0.011653569526970387, Valid Loss: 0.015010839328169823\n",
      "Epoch: 2828, Train Loss: 0.011641970835626125, Valid Loss: 0.01499483734369278\n",
      "Epoch: 2829, Train Loss: 0.011630374938249588, Valid Loss: 0.014978828839957714\n",
      "Epoch: 2830, Train Loss: 0.011618793942034245, Valid Loss: 0.014962596818804741\n",
      "Epoch: 2831, Train Loss: 0.011607225984334946, Valid Loss: 0.01494655478745699\n",
      "Epoch: 2832, Train Loss: 0.011595678515732288, Valid Loss: 0.014930594712495804\n",
      "Epoch: 2833, Train Loss: 0.011584151536226273, Valid Loss: 0.014914440922439098\n",
      "Epoch: 2834, Train Loss: 0.011572632007300854, Valid Loss: 0.014898410066962242\n",
      "Epoch: 2835, Train Loss: 0.011561116203665733, Valid Loss: 0.0148824667558074\n",
      "Epoch: 2836, Train Loss: 0.011549616232514381, Valid Loss: 0.014866430312395096\n",
      "Epoch: 2837, Train Loss: 0.011538134887814522, Valid Loss: 0.014850395731627941\n",
      "Epoch: 2838, Train Loss: 0.011526667512953281, Valid Loss: 0.014834452420473099\n",
      "Epoch: 2839, Train Loss: 0.01151522621512413, Valid Loss: 0.014818544499576092\n",
      "Epoch: 2840, Train Loss: 0.011503786779940128, Valid Loss: 0.014802656136453152\n",
      "Epoch: 2841, Train Loss: 0.011492357589304447, Valid Loss: 0.014786634594202042\n",
      "Epoch: 2842, Train Loss: 0.011480932123959064, Valid Loss: 0.014770700596272945\n",
      "Epoch: 2843, Train Loss: 0.011469553224742413, Valid Loss: 0.01475480105727911\n",
      "Epoch: 2844, Train Loss: 0.011458160355687141, Valid Loss: 0.014739014208316803\n",
      "Epoch: 2845, Train Loss: 0.011446794494986534, Valid Loss: 0.014723177067935467\n",
      "Epoch: 2846, Train Loss: 0.011435440741479397, Valid Loss: 0.01470730546861887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2847, Train Loss: 0.011424077674746513, Valid Loss: 0.014691326767206192\n",
      "Epoch: 2848, Train Loss: 0.011412747204303741, Valid Loss: 0.014675655402243137\n",
      "Epoch: 2849, Train Loss: 0.011401450261473656, Valid Loss: 0.014659915119409561\n",
      "Epoch: 2850, Train Loss: 0.01139013096690178, Valid Loss: 0.014644009061157703\n",
      "Epoch: 2851, Train Loss: 0.011378847993910313, Valid Loss: 0.014628258533775806\n",
      "Epoch: 2852, Train Loss: 0.011367564089596272, Valid Loss: 0.014612526632845402\n",
      "Epoch: 2853, Train Loss: 0.011356298811733723, Valid Loss: 0.014596739783883095\n",
      "Epoch: 2854, Train Loss: 0.011345054022967815, Valid Loss: 0.014581113122403622\n",
      "Epoch: 2855, Train Loss: 0.011333825066685677, Valid Loss: 0.014565433375537395\n",
      "Epoch: 2856, Train Loss: 0.011322586797177792, Valid Loss: 0.014549529179930687\n",
      "Epoch: 2857, Train Loss: 0.011311382986605167, Valid Loss: 0.014533928595483303\n",
      "Epoch: 2858, Train Loss: 0.011300185695290565, Valid Loss: 0.014518359676003456\n",
      "Epoch: 2859, Train Loss: 0.011288990266621113, Valid Loss: 0.014502701349556446\n",
      "Epoch: 2860, Train Loss: 0.011277823708951473, Valid Loss: 0.014487058855593204\n",
      "Epoch: 2861, Train Loss: 0.011266681365668774, Valid Loss: 0.014471299946308136\n",
      "Epoch: 2862, Train Loss: 0.011255540885031223, Valid Loss: 0.01445582415908575\n",
      "Epoch: 2863, Train Loss: 0.011244397610425949, Valid Loss: 0.014440246857702732\n",
      "Epoch: 2864, Train Loss: 0.011233288794755936, Valid Loss: 0.014424672350287437\n",
      "Epoch: 2865, Train Loss: 0.011222176253795624, Valid Loss: 0.014409146271646023\n",
      "Epoch: 2866, Train Loss: 0.011211073957383633, Valid Loss: 0.014393545687198639\n",
      "Epoch: 2867, Train Loss: 0.011200006119906902, Valid Loss: 0.01437806524336338\n",
      "Epoch: 2868, Train Loss: 0.011188932694494724, Valid Loss: 0.014362557791173458\n",
      "Epoch: 2869, Train Loss: 0.011177894659340382, Valid Loss: 0.014347107149660587\n",
      "Epoch: 2870, Train Loss: 0.011166851036250591, Valid Loss: 0.014331536367535591\n",
      "Epoch: 2871, Train Loss: 0.011155839078128338, Valid Loss: 0.014316138811409473\n",
      "Epoch: 2872, Train Loss: 0.011144817806780338, Valid Loss: 0.014300758019089699\n",
      "Epoch: 2873, Train Loss: 0.011133805848658085, Valid Loss: 0.014285371638834476\n",
      "Epoch: 2874, Train Loss: 0.01112282183021307, Valid Loss: 0.014269839972257614\n",
      "Epoch: 2875, Train Loss: 0.011111860163509846, Valid Loss: 0.014254492707550526\n",
      "Epoch: 2876, Train Loss: 0.011100896634161472, Valid Loss: 0.014239143580198288\n",
      "Epoch: 2877, Train Loss: 0.01108995359390974, Valid Loss: 0.0142237963154912\n",
      "Epoch: 2878, Train Loss: 0.011079015210270882, Valid Loss: 0.014208454638719559\n",
      "Epoch: 2879, Train Loss: 0.011068115942180157, Valid Loss: 0.014193139038980007\n",
      "Epoch: 2880, Train Loss: 0.011057200841605663, Valid Loss: 0.014177880249917507\n",
      "Epoch: 2881, Train Loss: 0.011046298779547215, Valid Loss: 0.01416252925992012\n",
      "Epoch: 2882, Train Loss: 0.01103542186319828, Valid Loss: 0.014147324487566948\n",
      "Epoch: 2883, Train Loss: 0.011024548672139645, Valid Loss: 0.014131993986666203\n",
      "Epoch: 2884, Train Loss: 0.011013702489435673, Valid Loss: 0.014116758480668068\n",
      "Epoch: 2885, Train Loss: 0.011002855375409126, Valid Loss: 0.014101559296250343\n",
      "Epoch: 2886, Train Loss: 0.010992013849318027, Valid Loss: 0.014086331240832806\n",
      "Epoch: 2887, Train Loss: 0.010981201194226742, Valid Loss: 0.014071187935769558\n",
      "Epoch: 2888, Train Loss: 0.0109704053029418, Valid Loss: 0.014056064188480377\n",
      "Epoch: 2889, Train Loss: 0.010959611274302006, Valid Loss: 0.014040919952094555\n",
      "Epoch: 2890, Train Loss: 0.010948842391371727, Valid Loss: 0.014025670476257801\n",
      "Epoch: 2891, Train Loss: 0.010938073508441448, Valid Loss: 0.014010570012032986\n",
      "Epoch: 2892, Train Loss: 0.01092731487005949, Valid Loss: 0.013995588757097721\n",
      "Epoch: 2893, Train Loss: 0.010916582308709621, Valid Loss: 0.013980546034872532\n",
      "Epoch: 2894, Train Loss: 0.010905833914875984, Valid Loss: 0.01396536361426115\n",
      "Epoch: 2895, Train Loss: 0.01089514046907425, Valid Loss: 0.013950277119874954\n",
      "Epoch: 2896, Train Loss: 0.010884425602853298, Valid Loss: 0.013935270719230175\n",
      "Epoch: 2897, Train Loss: 0.010873742401599884, Valid Loss: 0.013920288532972336\n",
      "Epoch: 2898, Train Loss: 0.010863065719604492, Valid Loss: 0.01390535943210125\n",
      "Epoch: 2899, Train Loss: 0.010852405801415443, Valid Loss: 0.013890301808714867\n",
      "Epoch: 2900, Train Loss: 0.010841763578355312, Valid Loss: 0.013875311240553856\n",
      "Epoch: 2901, Train Loss: 0.010831108316779137, Valid Loss: 0.013860375620424747\n",
      "Epoch: 2902, Train Loss: 0.010820489376783371, Valid Loss: 0.013845560140907764\n",
      "Epoch: 2903, Train Loss: 0.01080986950546503, Valid Loss: 0.013830590061843395\n",
      "Epoch: 2904, Train Loss: 0.010799276642501354, Valid Loss: 0.013815636746585369\n",
      "Epoch: 2905, Train Loss: 0.010788684710860252, Valid Loss: 0.013800744898617268\n",
      "Epoch: 2906, Train Loss: 0.01077811885625124, Valid Loss: 0.013786013238132\n",
      "Epoch: 2907, Train Loss: 0.010767548345029354, Valid Loss: 0.013771209865808487\n",
      "Epoch: 2908, Train Loss: 0.010756999254226685, Valid Loss: 0.013756385073065758\n",
      "Epoch: 2909, Train Loss: 0.01074646320194006, Valid Loss: 0.013741441071033478\n",
      "Epoch: 2910, Train Loss: 0.010735943913459778, Valid Loss: 0.013726694509387016\n",
      "Epoch: 2911, Train Loss: 0.010725429281592369, Valid Loss: 0.013712100684642792\n",
      "Epoch: 2912, Train Loss: 0.01071492861956358, Valid Loss: 0.013697254471480846\n",
      "Epoch: 2913, Train Loss: 0.010704440996050835, Valid Loss: 0.013682454824447632\n",
      "Epoch: 2914, Train Loss: 0.010693967342376709, Valid Loss: 0.013667788356542587\n",
      "Epoch: 2915, Train Loss: 0.010683502070605755, Valid Loss: 0.01365311723202467\n",
      "Epoch: 2916, Train Loss: 0.010673055425286293, Valid Loss: 0.013638452626764774\n",
      "Epoch: 2917, Train Loss: 0.010662606917321682, Valid Loss: 0.013623845763504505\n",
      "Epoch: 2918, Train Loss: 0.010652192868292332, Valid Loss: 0.013609200716018677\n",
      "Epoch: 2919, Train Loss: 0.010641777887940407, Valid Loss: 0.01359447743743658\n",
      "Epoch: 2920, Train Loss: 0.0106313806027174, Valid Loss: 0.013579917140305042\n",
      "Epoch: 2921, Train Loss: 0.010620989836752415, Valid Loss: 0.013565421104431152\n",
      "Epoch: 2922, Train Loss: 0.01061062142252922, Valid Loss: 0.01355087198317051\n",
      "Epoch: 2923, Train Loss: 0.0106002576649189, Valid Loss: 0.013536248356103897\n",
      "Epoch: 2924, Train Loss: 0.010589906014502048, Valid Loss: 0.013521624729037285\n",
      "Epoch: 2925, Train Loss: 0.010579567402601242, Valid Loss: 0.013507203198969364\n",
      "Epoch: 2926, Train Loss: 0.010569226928055286, Valid Loss: 0.0134927062317729\n",
      "Epoch: 2927, Train Loss: 0.010558925569057465, Valid Loss: 0.013478286564350128\n",
      "Epoch: 2928, Train Loss: 0.010548627004027367, Valid Loss: 0.013463863171637058\n",
      "Epoch: 2929, Train Loss: 0.010538347065448761, Valid Loss: 0.013449318706989288\n",
      "Epoch: 2930, Train Loss: 0.01052805781364441, Valid Loss: 0.013434908352792263\n",
      "Epoch: 2931, Train Loss: 0.010517793707549572, Valid Loss: 0.013420608825981617\n",
      "Epoch: 2932, Train Loss: 0.010507548227906227, Valid Loss: 0.013406175188720226\n",
      "Epoch: 2933, Train Loss: 0.010497299954295158, Valid Loss: 0.013391809538006783\n",
      "Epoch: 2934, Train Loss: 0.010487073101103306, Valid Loss: 0.013377422466874123\n",
      "Epoch: 2935, Train Loss: 0.010476849041879177, Valid Loss: 0.013363143429160118\n",
      "Epoch: 2936, Train Loss: 0.01046664547175169, Valid Loss: 0.013348817825317383\n",
      "Epoch: 2937, Train Loss: 0.01045646145939827, Valid Loss: 0.013334551826119423\n",
      "Epoch: 2938, Train Loss: 0.010446285828948021, Valid Loss: 0.013320338912308216\n",
      "Epoch: 2939, Train Loss: 0.010436124168336391, Valid Loss: 0.01330599095672369\n",
      "Epoch: 2940, Train Loss: 0.010425963439047337, Valid Loss: 0.013291801325976849\n",
      "Epoch: 2941, Train Loss: 0.010415831580758095, Valid Loss: 0.013277645222842693\n",
      "Epoch: 2942, Train Loss: 0.010405689477920532, Valid Loss: 0.01326347328722477\n",
      "Epoch: 2943, Train Loss: 0.010395579040050507, Valid Loss: 0.013249197043478489\n",
      "Epoch: 2944, Train Loss: 0.010385462082922459, Valid Loss: 0.013235031627118587\n",
      "Epoch: 2945, Train Loss: 0.010375372134149075, Valid Loss: 0.013220898807048798\n",
      "Epoch: 2946, Train Loss: 0.010365278460085392, Valid Loss: 0.01320682279765606\n",
      "Epoch: 2947, Train Loss: 0.010355214588344097, Valid Loss: 0.013192721642553806\n",
      "Epoch: 2948, Train Loss: 0.010345148853957653, Valid Loss: 0.013178592547774315\n",
      "Epoch: 2949, Train Loss: 0.010335098952054977, Valid Loss: 0.013164512813091278\n",
      "Epoch: 2950, Train Loss: 0.01032505463808775, Valid Loss: 0.013150508515536785\n",
      "Epoch: 2951, Train Loss: 0.010315042920410633, Valid Loss: 0.01313647348433733\n",
      "Epoch: 2952, Train Loss: 0.010305025614798069, Valid Loss: 0.013122446835041046\n",
      "Epoch: 2953, Train Loss: 0.010295026004314423, Valid Loss: 0.013108419254422188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2954, Train Loss: 0.010285046882927418, Valid Loss: 0.013094443827867508\n",
      "Epoch: 2955, Train Loss: 0.010275076143443584, Valid Loss: 0.013080529868602753\n",
      "Epoch: 2956, Train Loss: 0.010265094228088856, Valid Loss: 0.013066631741821766\n",
      "Epoch: 2957, Train Loss: 0.010255161672830582, Valid Loss: 0.013052711263298988\n",
      "Epoch: 2958, Train Loss: 0.010245201177895069, Valid Loss: 0.013038706965744495\n",
      "Epoch: 2959, Train Loss: 0.010235280729830265, Valid Loss: 0.013024847954511642\n",
      "Epoch: 2960, Train Loss: 0.010225366801023483, Valid Loss: 0.013011046685278416\n",
      "Epoch: 2961, Train Loss: 0.010215452872216702, Valid Loss: 0.012997204437851906\n",
      "Epoch: 2962, Train Loss: 0.010205562226474285, Valid Loss: 0.012983296066522598\n",
      "Epoch: 2963, Train Loss: 0.010195674374699593, Valid Loss: 0.01296952459961176\n",
      "Epoch: 2964, Train Loss: 0.010185809805989265, Valid Loss: 0.012955771759152412\n",
      "Epoch: 2965, Train Loss: 0.010175952687859535, Valid Loss: 0.012941974215209484\n",
      "Epoch: 2966, Train Loss: 0.010166091844439507, Valid Loss: 0.012928253039717674\n",
      "Epoch: 2967, Train Loss: 0.010156265459954739, Valid Loss: 0.012914511375129223\n",
      "Epoch: 2968, Train Loss: 0.010146446526050568, Valid Loss: 0.012900707311928272\n",
      "Epoch: 2969, Train Loss: 0.010136637836694717, Valid Loss: 0.012887081131339073\n",
      "Epoch: 2970, Train Loss: 0.01012683380395174, Valid Loss: 0.012873420491814613\n",
      "Epoch: 2971, Train Loss: 0.01011703908443451, Valid Loss: 0.01285974308848381\n",
      "Epoch: 2972, Train Loss: 0.010107280686497688, Valid Loss: 0.012846147641539574\n",
      "Epoch: 2973, Train Loss: 0.010097509250044823, Valid Loss: 0.012832404114305973\n",
      "Epoch: 2974, Train Loss: 0.010087751783430576, Valid Loss: 0.01281879935413599\n",
      "Epoch: 2975, Train Loss: 0.010077999904751778, Valid Loss: 0.012805348262190819\n",
      "Epoch: 2976, Train Loss: 0.010068275965750217, Valid Loss: 0.012791646644473076\n",
      "Epoch: 2977, Train Loss: 0.010058549232780933, Valid Loss: 0.01277807354927063\n",
      "Epoch: 2978, Train Loss: 0.010048847645521164, Valid Loss: 0.01276464480906725\n",
      "Epoch: 2979, Train Loss: 0.010039153508841991, Valid Loss: 0.012751162983477116\n",
      "Epoch: 2980, Train Loss: 0.010029465891420841, Valid Loss: 0.012737581506371498\n",
      "Epoch: 2981, Train Loss: 0.010019790381193161, Valid Loss: 0.012724172323942184\n",
      "Epoch: 2982, Train Loss: 0.010010127909481525, Valid Loss: 0.012710673734545708\n",
      "Epoch: 2983, Train Loss: 0.010000483132898808, Valid Loss: 0.01269722729921341\n",
      "Epoch: 2984, Train Loss: 0.009990835562348366, Valid Loss: 0.01268372405320406\n",
      "Epoch: 2985, Train Loss: 0.00998120941221714, Valid Loss: 0.012670410796999931\n",
      "Epoch: 2986, Train Loss: 0.009971589781343937, Valid Loss: 0.012656931765377522\n",
      "Epoch: 2987, Train Loss: 0.00996200181543827, Valid Loss: 0.012643609195947647\n",
      "Epoch: 2988, Train Loss: 0.009952390566468239, Valid Loss: 0.012630339711904526\n",
      "Epoch: 2989, Train Loss: 0.009942807257175446, Valid Loss: 0.012617021799087524\n",
      "Epoch: 2990, Train Loss: 0.009933242574334145, Valid Loss: 0.012603545561432838\n",
      "Epoch: 2991, Train Loss: 0.009923689998686314, Valid Loss: 0.01259035337716341\n",
      "Epoch: 2992, Train Loss: 0.009914142079651356, Valid Loss: 0.012577113695442677\n",
      "Epoch: 2993, Train Loss: 0.009904603473842144, Valid Loss: 0.012563815340399742\n",
      "Epoch: 2994, Train Loss: 0.009895077906548977, Valid Loss: 0.012550601735711098\n",
      "Epoch: 2995, Train Loss: 0.009885557927191257, Valid Loss: 0.012537350878119469\n",
      "Epoch: 2996, Train Loss: 0.009876063093543053, Valid Loss: 0.012524174526333809\n",
      "Epoch: 2997, Train Loss: 0.009866565465927124, Valid Loss: 0.012510934844613075\n",
      "Epoch: 2998, Train Loss: 0.009857083670794964, Valid Loss: 0.0124977957457304\n",
      "Epoch: 2999, Train Loss: 0.009847617708146572, Valid Loss: 0.012484653852880001\n",
      "Epoch: 3000, Train Loss: 0.009838157333433628, Valid Loss: 0.012471458874642849\n",
      "Epoch: 3001, Train Loss: 0.009828722104430199, Valid Loss: 0.012458359822630882\n",
      "Epoch: 3002, Train Loss: 0.009819275699555874, Valid Loss: 0.012445349246263504\n",
      "Epoch: 3003, Train Loss: 0.009809848852455616, Valid Loss: 0.012432264164090157\n",
      "Epoch: 3004, Train Loss: 0.009800425730645657, Valid Loss: 0.012419120408594608\n",
      "Epoch: 3005, Train Loss: 0.009791027754545212, Valid Loss: 0.012406124733388424\n",
      "Epoch: 3006, Train Loss: 0.00978163443505764, Valid Loss: 0.012393058277666569\n",
      "Epoch: 3007, Train Loss: 0.009772256016731262, Valid Loss: 0.0123800840228796\n",
      "Epoch: 3008, Train Loss: 0.009762891568243504, Valid Loss: 0.012367086485028267\n",
      "Epoch: 3009, Train Loss: 0.009753525257110596, Valid Loss: 0.012354123406112194\n",
      "Epoch: 3010, Train Loss: 0.009744185023009777, Valid Loss: 0.012341137044131756\n",
      "Epoch: 3011, Train Loss: 0.009734837338328362, Valid Loss: 0.012328221462666988\n",
      "Epoch: 3012, Train Loss: 0.009725512005388737, Valid Loss: 0.012315315194427967\n",
      "Epoch: 3013, Train Loss: 0.009716206230223179, Valid Loss: 0.01230235118418932\n",
      "Epoch: 3014, Train Loss: 0.009706908836960793, Valid Loss: 0.012289541773498058\n",
      "Epoch: 3015, Train Loss: 0.009697601199150085, Valid Loss: 0.012276628986001015\n",
      "Epoch: 3016, Train Loss: 0.00968832615762949, Valid Loss: 0.012263733893632889\n",
      "Epoch: 3017, Train Loss: 0.009679054841399193, Valid Loss: 0.012250976637005806\n",
      "Epoch: 3018, Train Loss: 0.00966979656368494, Valid Loss: 0.01223822683095932\n",
      "Epoch: 3019, Train Loss: 0.009660549461841583, Valid Loss: 0.012225287966430187\n",
      "Epoch: 3020, Train Loss: 0.009651313535869122, Valid Loss: 0.01221251767128706\n",
      "Epoch: 3021, Train Loss: 0.009642081335186958, Valid Loss: 0.012199867516756058\n",
      "Epoch: 3022, Train Loss: 0.009632867760956287, Valid Loss: 0.012187088839709759\n",
      "Epoch: 3023, Train Loss: 0.009623662568628788, Valid Loss: 0.012174312956631184\n",
      "Epoch: 3024, Train Loss: 0.009614471346139908, Valid Loss: 0.012161578983068466\n",
      "Epoch: 3025, Train Loss: 0.0096052847802639, Valid Loss: 0.012148896232247353\n",
      "Epoch: 3026, Train Loss: 0.00959611777216196, Valid Loss: 0.012136274948716164\n",
      "Epoch: 3027, Train Loss: 0.009586954489350319, Valid Loss: 0.012123665772378445\n",
      "Epoch: 3028, Train Loss: 0.009577805176377296, Valid Loss: 0.012110954150557518\n",
      "Epoch: 3029, Train Loss: 0.00956866703927517, Valid Loss: 0.012098279781639576\n",
      "Epoch: 3030, Train Loss: 0.009559537284076214, Valid Loss: 0.012085813097655773\n",
      "Epoch: 3031, Train Loss: 0.009550421498715878, Valid Loss: 0.012073175981640816\n",
      "Epoch: 3032, Train Loss: 0.009541303850710392, Valid Loss: 0.012060507200658321\n",
      "Epoch: 3033, Train Loss: 0.009532202035188675, Valid Loss: 0.012048019096255302\n",
      "Epoch: 3034, Train Loss: 0.009523122571408749, Valid Loss: 0.012035560794174671\n",
      "Epoch: 3035, Train Loss: 0.00951405894011259, Valid Loss: 0.012022905051708221\n",
      "Epoch: 3036, Train Loss: 0.009504982270300388, Valid Loss: 0.012010430917143822\n",
      "Epoch: 3037, Train Loss: 0.009495927952229977, Valid Loss: 0.011998049914836884\n",
      "Epoch: 3038, Train Loss: 0.009486883878707886, Valid Loss: 0.011985479854047298\n",
      "Epoch: 3039, Train Loss: 0.009477856568992138, Valid Loss: 0.011972926557064056\n",
      "Epoch: 3040, Train Loss: 0.00946883112192154, Valid Loss: 0.011960664764046669\n",
      "Epoch: 3041, Train Loss: 0.009459820576012135, Valid Loss: 0.01194818690419197\n",
      "Epoch: 3042, Train Loss: 0.009450823068618774, Valid Loss: 0.0119357630610466\n",
      "Epoch: 3043, Train Loss: 0.009441838599741459, Valid Loss: 0.011923463083803654\n",
      "Epoch: 3044, Train Loss: 0.009432855993509293, Valid Loss: 0.011911042965948582\n",
      "Epoch: 3045, Train Loss: 0.009423874318599701, Valid Loss: 0.011898615397512913\n",
      "Epoch: 3046, Train Loss: 0.00941491313278675, Valid Loss: 0.01188640482723713\n",
      "Epoch: 3047, Train Loss: 0.009405977092683315, Valid Loss: 0.01187407597899437\n",
      "Epoch: 3048, Train Loss: 0.009397043846547604, Valid Loss: 0.01186167448759079\n",
      "Epoch: 3049, Train Loss: 0.009388111531734467, Valid Loss: 0.011849412694573402\n",
      "Epoch: 3050, Train Loss: 0.009379199706017971, Valid Loss: 0.011837274767458439\n",
      "Epoch: 3051, Train Loss: 0.009370287880301476, Valid Loss: 0.011824983172118664\n",
      "Epoch: 3052, Train Loss: 0.009361394681036472, Valid Loss: 0.011812621727585793\n",
      "Epoch: 3053, Train Loss: 0.009352517314255238, Valid Loss: 0.011800492182374\n",
      "Epoch: 3054, Train Loss: 0.009343641810119152, Valid Loss: 0.01178828440606594\n",
      "Epoch: 3055, Train Loss: 0.009334777481853962, Valid Loss: 0.011776106432080269\n",
      "Epoch: 3056, Train Loss: 0.009325925260782242, Valid Loss: 0.01176396943628788\n",
      "Epoch: 3057, Train Loss: 0.009317082352936268, Valid Loss: 0.011751854792237282\n",
      "Epoch: 3058, Train Loss: 0.009308240376412868, Valid Loss: 0.01173965260386467\n",
      "Epoch: 3059, Train Loss: 0.009299419820308685, Valid Loss: 0.011727457866072655\n",
      "Epoch: 3060, Train Loss: 0.009290613234043121, Valid Loss: 0.011715484783053398\n",
      "Epoch: 3061, Train Loss: 0.009281801991164684, Valid Loss: 0.011703402735292912\n",
      "Epoch: 3062, Train Loss: 0.00927301961928606, Valid Loss: 0.011691255494952202\n",
      "Epoch: 3063, Train Loss: 0.009264234453439713, Valid Loss: 0.011679193004965782\n",
      "Epoch: 3064, Train Loss: 0.009255465120077133, Valid Loss: 0.011667207814753056\n",
      "Epoch: 3065, Train Loss: 0.00924670696258545, Valid Loss: 0.011655165813863277\n",
      "Epoch: 3066, Train Loss: 0.009237956255674362, Valid Loss: 0.011643179692327976\n",
      "Epoch: 3067, Train Loss: 0.00922922883182764, Valid Loss: 0.011631181463599205\n",
      "Epoch: 3068, Train Loss: 0.009220488369464874, Valid Loss: 0.011619244702160358\n",
      "Epoch: 3069, Train Loss: 0.009211761876940727, Valid Loss: 0.011607314459979534\n",
      "Epoch: 3070, Train Loss: 0.00920305959880352, Valid Loss: 0.011595278978347778\n",
      "Epoch: 3071, Train Loss: 0.00919436477124691, Valid Loss: 0.011583423241972923\n",
      "Epoch: 3072, Train Loss: 0.00918567180633545, Valid Loss: 0.011571523733437061\n",
      "Epoch: 3073, Train Loss: 0.009177003055810928, Valid Loss: 0.011559562757611275\n",
      "Epoch: 3074, Train Loss: 0.009168329648673534, Valid Loss: 0.01154779177159071\n",
      "Epoch: 3075, Train Loss: 0.00915967021137476, Valid Loss: 0.0115359453484416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3076, Train Loss: 0.009151024743914604, Valid Loss: 0.011524052359163761\n",
      "Epoch: 3077, Train Loss: 0.00914238952100277, Valid Loss: 0.011512229219079018\n",
      "Epoch: 3078, Train Loss: 0.009133764542639256, Valid Loss: 0.011500400491058826\n",
      "Epoch: 3079, Train Loss: 0.009125136770308018, Valid Loss: 0.011488620191812515\n",
      "Epoch: 3080, Train Loss: 0.009116542525589466, Valid Loss: 0.011476855725049973\n",
      "Epoch: 3081, Train Loss: 0.009107944555580616, Valid Loss: 0.011465086601674557\n",
      "Epoch: 3082, Train Loss: 0.00909934937953949, Valid Loss: 0.011453354731202126\n",
      "Epoch: 3083, Train Loss: 0.009090771898627281, Valid Loss: 0.011441542766988277\n",
      "Epoch: 3084, Train Loss: 0.009082209318876266, Valid Loss: 0.011429873295128345\n",
      "Epoch: 3085, Train Loss: 0.009073649533092976, Valid Loss: 0.011418215930461884\n",
      "Epoch: 3086, Train Loss: 0.009065108373761177, Valid Loss: 0.011406502686440945\n",
      "Epoch: 3087, Train Loss: 0.009056576527655125, Valid Loss: 0.011394822970032692\n",
      "Epoch: 3088, Train Loss: 0.009048045612871647, Valid Loss: 0.011383259668946266\n",
      "Epoch: 3089, Train Loss: 0.009039532393217087, Valid Loss: 0.01137156505137682\n",
      "Epoch: 3090, Train Loss: 0.009031038731336594, Valid Loss: 0.011359967291355133\n",
      "Epoch: 3091, Train Loss: 0.009022527374327183, Valid Loss: 0.011348377913236618\n",
      "Epoch: 3092, Train Loss: 0.009014040231704712, Valid Loss: 0.011336819268763065\n",
      "Epoch: 3093, Train Loss: 0.009005571715533733, Valid Loss: 0.011325106956064701\n",
      "Epoch: 3094, Train Loss: 0.008997095748782158, Valid Loss: 0.011313611641526222\n",
      "Epoch: 3095, Train Loss: 0.008988645859062672, Valid Loss: 0.011302193626761436\n",
      "Epoch: 3096, Train Loss: 0.008980200625956059, Valid Loss: 0.011290536262094975\n",
      "Epoch: 3097, Train Loss: 0.008971765637397766, Valid Loss: 0.011279003694653511\n",
      "Epoch: 3098, Train Loss: 0.00896333809942007, Valid Loss: 0.011267641559243202\n",
      "Epoch: 3099, Train Loss: 0.008954917080700397, Valid Loss: 0.011256073601543903\n",
      "Epoch: 3100, Train Loss: 0.008946520276367664, Valid Loss: 0.011244636960327625\n",
      "Epoch: 3101, Train Loss: 0.00893812533468008, Valid Loss: 0.011233202181756496\n",
      "Epoch: 3102, Train Loss: 0.00892973318696022, Valid Loss: 0.011221753433346748\n",
      "Epoch: 3103, Train Loss: 0.008921354077756405, Valid Loss: 0.011210254393517971\n",
      "Epoch: 3104, Train Loss: 0.00891298707574606, Valid Loss: 0.011198938824236393\n",
      "Epoch: 3105, Train Loss: 0.008904639631509781, Valid Loss: 0.011187629774212837\n",
      "Epoch: 3106, Train Loss: 0.00889628380537033, Valid Loss: 0.011176109313964844\n",
      "Epoch: 3107, Train Loss: 0.008887947537004948, Valid Loss: 0.011164783500134945\n",
      "Epoch: 3108, Train Loss: 0.008879624307155609, Valid Loss: 0.011153565719723701\n",
      "Epoch: 3109, Train Loss: 0.008871293626725674, Valid Loss: 0.011142110452055931\n",
      "Epoch: 3110, Train Loss: 0.00886299554258585, Valid Loss: 0.011130759492516518\n",
      "Epoch: 3111, Train Loss: 0.00885470025241375, Valid Loss: 0.011119551956653595\n",
      "Epoch: 3112, Train Loss: 0.008846414275467396, Valid Loss: 0.011108334176242352\n",
      "Epoch: 3113, Train Loss: 0.008838131092488766, Valid Loss: 0.011096959002315998\n",
      "Epoch: 3114, Train Loss: 0.008829861879348755, Valid Loss: 0.011085756123065948\n",
      "Epoch: 3115, Train Loss: 0.00882161408662796, Valid Loss: 0.011074509471654892\n",
      "Epoch: 3116, Train Loss: 0.008813353255391121, Valid Loss: 0.011063270270824432\n",
      "Epoch: 3117, Train Loss: 0.00880512036383152, Valid Loss: 0.011052139103412628\n",
      "Epoch: 3118, Train Loss: 0.008796884678304195, Valid Loss: 0.011040973477065563\n",
      "Epoch: 3119, Train Loss: 0.008788651786744595, Valid Loss: 0.0110296830534935\n",
      "Epoch: 3120, Train Loss: 0.008780455216765404, Valid Loss: 0.011018533259630203\n",
      "Epoch: 3121, Train Loss: 0.008772242814302444, Valid Loss: 0.011007418856024742\n",
      "Epoch: 3122, Train Loss: 0.008764058351516724, Valid Loss: 0.010996261611580849\n",
      "Epoch: 3123, Train Loss: 0.008755884133279324, Valid Loss: 0.010985135100781918\n",
      "Epoch: 3124, Train Loss: 0.008747698739171028, Valid Loss: 0.010974125005304813\n",
      "Epoch: 3125, Train Loss: 0.008739542216062546, Valid Loss: 0.010963019914925098\n",
      "Epoch: 3126, Train Loss: 0.008731383830308914, Valid Loss: 0.010951843112707138\n",
      "Epoch: 3127, Train Loss: 0.008723247796297073, Valid Loss: 0.010940920561552048\n",
      "Epoch: 3128, Train Loss: 0.008715114556252956, Valid Loss: 0.010929839685559273\n",
      "Epoch: 3129, Train Loss: 0.008706984110176563, Valid Loss: 0.01091880165040493\n",
      "Epoch: 3130, Train Loss: 0.008698883466422558, Valid Loss: 0.010907789692282677\n",
      "Epoch: 3131, Train Loss: 0.008690761402249336, Valid Loss: 0.01089677307754755\n",
      "Epoch: 3132, Train Loss: 0.008682668209075928, Valid Loss: 0.010885767638683319\n",
      "Epoch: 3133, Train Loss: 0.008674586191773415, Valid Loss: 0.010874862782657146\n",
      "Epoch: 3134, Train Loss: 0.008666513487696648, Valid Loss: 0.010863877832889557\n",
      "Epoch: 3135, Train Loss: 0.008658453822135925, Valid Loss: 0.010852877050638199\n",
      "Epoch: 3136, Train Loss: 0.008650394156575203, Valid Loss: 0.01084203738719225\n",
      "Epoch: 3137, Train Loss: 0.008642339147627354, Valid Loss: 0.010831166058778763\n",
      "Epoch: 3138, Train Loss: 0.00863430742174387, Valid Loss: 0.010820228606462479\n",
      "Epoch: 3139, Train Loss: 0.008626280352473259, Valid Loss: 0.010809293016791344\n",
      "Epoch: 3140, Train Loss: 0.008618256077170372, Valid Loss: 0.010798501782119274\n",
      "Epoch: 3141, Train Loss: 0.008610241115093231, Valid Loss: 0.010787677019834518\n",
      "Epoch: 3142, Train Loss: 0.008602241054177284, Valid Loss: 0.01077673677355051\n",
      "Epoch: 3143, Train Loss: 0.008594250306487083, Valid Loss: 0.010765966959297657\n",
      "Epoch: 3144, Train Loss: 0.008586268872022629, Valid Loss: 0.010755215771496296\n",
      "Epoch: 3145, Train Loss: 0.008578293956816196, Valid Loss: 0.010744364000856876\n",
      "Epoch: 3146, Train Loss: 0.008570334874093533, Valid Loss: 0.010733505710959435\n",
      "Epoch: 3147, Train Loss: 0.008562383241951466, Valid Loss: 0.010722807608544827\n",
      "Epoch: 3148, Train Loss: 0.00855441763997078, Valid Loss: 0.010712121613323689\n",
      "Epoch: 3149, Train Loss: 0.008546498604118824, Valid Loss: 0.010701400227844715\n",
      "Epoch: 3150, Train Loss: 0.008538562804460526, Valid Loss: 0.010690532624721527\n",
      "Epoch: 3151, Train Loss: 0.008530642837285995, Valid Loss: 0.010679837316274643\n",
      "Epoch: 3152, Train Loss: 0.008522740565240383, Valid Loss: 0.010669262148439884\n",
      "Epoch: 3153, Train Loss: 0.00851485040038824, Valid Loss: 0.0106586255133152\n",
      "Epoch: 3154, Train Loss: 0.008506959304213524, Valid Loss: 0.010647917166352272\n",
      "Epoch: 3155, Train Loss: 0.008499077521264553, Valid Loss: 0.010637211613357067\n",
      "Epoch: 3156, Train Loss: 0.008491210639476776, Valid Loss: 0.010626591742038727\n",
      "Epoch: 3157, Train Loss: 0.008483351208269596, Valid Loss: 0.010616007260978222\n",
      "Epoch: 3158, Train Loss: 0.008475502021610737, Valid Loss: 0.01060541719198227\n",
      "Epoch: 3159, Train Loss: 0.008467650040984154, Valid Loss: 0.010594789870083332\n",
      "Epoch: 3160, Train Loss: 0.008459811098873615, Valid Loss: 0.010584112256765366\n",
      "Epoch: 3161, Train Loss: 0.00845200102776289, Valid Loss: 0.010573607869446278\n",
      "Epoch: 3162, Train Loss: 0.008444168604910374, Valid Loss: 0.010563109070062637\n",
      "Epoch: 3163, Train Loss: 0.00843637716025114, Valid Loss: 0.010552603751420975\n",
      "Epoch: 3164, Train Loss: 0.008428576402366161, Valid Loss: 0.010541987605392933\n",
      "Epoch: 3165, Train Loss: 0.008420795202255249, Valid Loss: 0.010531443171203136\n",
      "Epoch: 3166, Train Loss: 0.008413014933466911, Valid Loss: 0.010521025396883488\n",
      "Epoch: 3167, Train Loss: 0.00840524397790432, Valid Loss: 0.010510588064789772\n",
      "Epoch: 3168, Train Loss: 0.008397471159696579, Valid Loss: 0.01050012931227684\n",
      "Epoch: 3169, Train Loss: 0.008389723487198353, Valid Loss: 0.010489637032151222\n",
      "Epoch: 3170, Train Loss: 0.008381980471313, Valid Loss: 0.010479092597961426\n",
      "Epoch: 3171, Train Loss: 0.008374255150556564, Valid Loss: 0.010468725115060806\n",
      "Epoch: 3172, Train Loss: 0.008366533555090427, Valid Loss: 0.010458400472998619\n",
      "Epoch: 3173, Train Loss: 0.008358828723430634, Valid Loss: 0.010447969660162926\n",
      "Epoch: 3174, Train Loss: 0.00835111178457737, Valid Loss: 0.010437602177262306\n",
      "Epoch: 3175, Train Loss: 0.008343417197465897, Valid Loss: 0.01042717695236206\n",
      "Epoch: 3176, Train Loss: 0.008335725404322147, Valid Loss: 0.010416793636977673\n",
      "Epoch: 3177, Train Loss: 0.008328045718371868, Valid Loss: 0.010406535118818283\n",
      "Epoch: 3178, Train Loss: 0.008320392109453678, Valid Loss: 0.010396209545433521\n",
      "Epoch: 3179, Train Loss: 0.00831272080540657, Valid Loss: 0.010385829955339432\n",
      "Epoch: 3180, Train Loss: 0.008305069990456104, Valid Loss: 0.010375547222793102\n",
      "Epoch: 3181, Train Loss: 0.008297423832118511, Valid Loss: 0.010365215130150318\n",
      "Epoch: 3182, Train Loss: 0.008289795368909836, Valid Loss: 0.010355009697377682\n",
      "Epoch: 3183, Train Loss: 0.008282163180410862, Valid Loss: 0.010344773530960083\n",
      "Epoch: 3184, Train Loss: 0.00827456172555685, Valid Loss: 0.010334508493542671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3185, Train Loss: 0.008266950026154518, Valid Loss: 0.010324222035706043\n",
      "Epoch: 3186, Train Loss: 0.008259359747171402, Valid Loss: 0.010314050130546093\n",
      "Epoch: 3187, Train Loss: 0.008251756429672241, Valid Loss: 0.010303898714482784\n",
      "Epoch: 3188, Train Loss: 0.008244176395237446, Valid Loss: 0.010293636471033096\n",
      "Epoch: 3189, Train Loss: 0.00823662057518959, Valid Loss: 0.010283447802066803\n",
      "Epoch: 3190, Train Loss: 0.008229045197367668, Valid Loss: 0.010273242369294167\n",
      "Epoch: 3191, Train Loss: 0.008221505209803581, Valid Loss: 0.010263238102197647\n",
      "Epoch: 3192, Train Loss: 0.008213941007852554, Valid Loss: 0.010253028944134712\n",
      "Epoch: 3193, Train Loss: 0.008206414990127087, Valid Loss: 0.010242857970297337\n",
      "Epoch: 3194, Train Loss: 0.008198888041079044, Valid Loss: 0.010232822969555855\n",
      "Epoch: 3195, Train Loss: 0.008191374130547047, Valid Loss: 0.010222670622169971\n",
      "Epoch: 3196, Train Loss: 0.008183862082660198, Valid Loss: 0.010212551802396774\n",
      "Epoch: 3197, Train Loss: 0.008176366798579693, Valid Loss: 0.010202574543654919\n",
      "Epoch: 3198, Train Loss: 0.008168878965079784, Valid Loss: 0.01019250601530075\n",
      "Epoch: 3199, Train Loss: 0.008161388337612152, Valid Loss: 0.010182416066527367\n",
      "Epoch: 3200, Train Loss: 0.008153918199241161, Valid Loss: 0.010172405280172825\n",
      "Epoch: 3201, Train Loss: 0.008146450854837894, Valid Loss: 0.01016238797456026\n",
      "Epoch: 3202, Train Loss: 0.008138994686305523, Valid Loss: 0.010152323171496391\n",
      "Epoch: 3203, Train Loss: 0.008131533861160278, Valid Loss: 0.0101424315944314\n",
      "Epoch: 3204, Train Loss: 0.008124107494950294, Valid Loss: 0.01013242918998003\n",
      "Epoch: 3205, Train Loss: 0.008116673678159714, Valid Loss: 0.01012236624956131\n",
      "Epoch: 3206, Train Loss: 0.008109252899885178, Valid Loss: 0.010112549178302288\n",
      "Epoch: 3207, Train Loss: 0.00810184609144926, Valid Loss: 0.010102633386850357\n",
      "Epoch: 3208, Train Loss: 0.008094432763755322, Valid Loss: 0.010092632845044136\n",
      "Epoch: 3209, Train Loss: 0.008087036199867725, Valid Loss: 0.010082689113914967\n",
      "Epoch: 3210, Train Loss: 0.008079656399786472, Valid Loss: 0.010072847828269005\n",
      "Epoch: 3211, Train Loss: 0.00807227659970522, Valid Loss: 0.01006301399320364\n",
      "Epoch: 3212, Train Loss: 0.008064910769462585, Valid Loss: 0.010053093545138836\n",
      "Epoch: 3213, Train Loss: 0.008057553321123123, Valid Loss: 0.010043228976428509\n",
      "Epoch: 3214, Train Loss: 0.008050200529396534, Valid Loss: 0.01003339421004057\n",
      "Epoch: 3215, Train Loss: 0.008042853325605392, Valid Loss: 0.010023525916039944\n",
      "Epoch: 3216, Train Loss: 0.008035513572394848, Valid Loss: 0.010013737715780735\n",
      "Epoch: 3217, Train Loss: 0.008028194308280945, Valid Loss: 0.010003975592553616\n",
      "Epoch: 3218, Train Loss: 0.008020873181521893, Valid Loss: 0.009994134306907654\n",
      "Epoch: 3219, Train Loss: 0.008013560436666012, Valid Loss: 0.00998434703797102\n",
      "Epoch: 3220, Train Loss: 0.008006257936358452, Valid Loss: 0.009974646382033825\n",
      "Epoch: 3221, Train Loss: 0.007998961955308914, Valid Loss: 0.009964881464838982\n",
      "Epoch: 3222, Train Loss: 0.007991686463356018, Valid Loss: 0.009955096989870071\n",
      "Epoch: 3223, Train Loss: 0.007984408177435398, Valid Loss: 0.009945375844836235\n",
      "Epoch: 3224, Train Loss: 0.007977147586643696, Valid Loss: 0.009935704059898853\n",
      "Epoch: 3225, Train Loss: 0.00796988233923912, Valid Loss: 0.009925993159413338\n",
      "Epoch: 3226, Train Loss: 0.007962635718286037, Valid Loss: 0.009916281327605247\n",
      "Epoch: 3227, Train Loss: 0.007955402135848999, Valid Loss: 0.009906640276312828\n",
      "Epoch: 3228, Train Loss: 0.007948167622089386, Valid Loss: 0.009896908886730671\n",
      "Epoch: 3229, Train Loss: 0.007940945215523243, Valid Loss: 0.009887289255857468\n",
      "Epoch: 3230, Train Loss: 0.007933721877634525, Valid Loss: 0.009877705946564674\n",
      "Epoch: 3231, Train Loss: 0.007926512509584427, Valid Loss: 0.00986799318343401\n",
      "Epoch: 3232, Train Loss: 0.007919322699308395, Valid Loss: 0.009858449921011925\n",
      "Epoch: 3233, Train Loss: 0.007912127301096916, Valid Loss: 0.009848845191299915\n",
      "Epoch: 3234, Train Loss: 0.007904939353466034, Valid Loss: 0.009839176200330257\n",
      "Epoch: 3235, Train Loss: 0.00789776910096407, Valid Loss: 0.00982970092445612\n",
      "Epoch: 3236, Train Loss: 0.007890605367720127, Valid Loss: 0.009820155799388885\n",
      "Epoch: 3237, Train Loss: 0.007883459329605103, Valid Loss: 0.00981054175645113\n",
      "Epoch: 3238, Train Loss: 0.007876312360167503, Valid Loss: 0.009801039472222328\n",
      "Epoch: 3239, Train Loss: 0.007869165390729904, Valid Loss: 0.009791524149477482\n",
      "Epoch: 3240, Train Loss: 0.00786204356700182, Valid Loss: 0.009782016277313232\n",
      "Epoch: 3241, Train Loss: 0.007854914292693138, Valid Loss: 0.009772476740181446\n",
      "Epoch: 3242, Train Loss: 0.007847798988223076, Valid Loss: 0.009763006120920181\n",
      "Epoch: 3243, Train Loss: 0.007840687409043312, Valid Loss: 0.009753557853400707\n",
      "Epoch: 3244, Train Loss: 0.007833592593669891, Valid Loss: 0.009744091890752316\n",
      "Epoch: 3245, Train Loss: 0.007826504297554493, Valid Loss: 0.009734655730426311\n",
      "Epoch: 3246, Train Loss: 0.007819416001439095, Valid Loss: 0.009725200943648815\n",
      "Epoch: 3247, Train Loss: 0.007812348194420338, Valid Loss: 0.009715785272419453\n",
      "Epoch: 3248, Train Loss: 0.007805286440998316, Valid Loss: 0.009706389158964157\n",
      "Epoch: 3249, Train Loss: 0.007798215374350548, Valid Loss: 0.009697037748992443\n",
      "Epoch: 3250, Train Loss: 0.0077911727130413055, Valid Loss: 0.00968760997056961\n",
      "Epoch: 3251, Train Loss: 0.007784136105328798, Valid Loss: 0.00967817846685648\n",
      "Epoch: 3252, Train Loss: 0.007777103688567877, Valid Loss: 0.00966886430978775\n",
      "Epoch: 3253, Train Loss: 0.007770076394081116, Valid Loss: 0.009659552946686745\n",
      "Epoch: 3254, Train Loss: 0.007763063069432974, Valid Loss: 0.00965020339936018\n",
      "Epoch: 3255, Train Loss: 0.007756054401397705, Valid Loss: 0.009640884585678577\n",
      "Epoch: 3256, Train Loss: 0.007749049458652735, Valid Loss: 0.009631547145545483\n",
      "Epoch: 3257, Train Loss: 0.007742058485746384, Valid Loss: 0.009622259065508842\n",
      "Epoch: 3258, Train Loss: 0.007735077757388353, Valid Loss: 0.009613010101020336\n",
      "Epoch: 3259, Train Loss: 0.007728099822998047, Valid Loss: 0.009603735990822315\n",
      "Epoch: 3260, Train Loss: 0.007721133064478636, Valid Loss: 0.009594487026333809\n",
      "Epoch: 3261, Train Loss: 0.007714183535426855, Valid Loss: 0.009585174731910229\n",
      "Epoch: 3262, Train Loss: 0.007707222364842892, Valid Loss: 0.00957594532519579\n",
      "Epoch: 3263, Train Loss: 0.007700289133936167, Valid Loss: 0.009566787630319595\n",
      "Epoch: 3264, Train Loss: 0.007693351246416569, Valid Loss: 0.009557618759572506\n",
      "Epoch: 3265, Train Loss: 0.007686426863074303, Valid Loss: 0.009548344649374485\n",
      "Epoch: 3266, Train Loss: 0.007679510861635208, Valid Loss: 0.00953909195959568\n",
      "Epoch: 3267, Train Loss: 0.007672599051147699, Valid Loss: 0.009530004113912582\n",
      "Epoch: 3268, Train Loss: 0.0076657007448375225, Valid Loss: 0.009520872496068478\n",
      "Epoch: 3269, Train Loss: 0.007658801972866058, Valid Loss: 0.009511667303740978\n",
      "Epoch: 3270, Train Loss: 0.007651910185813904, Valid Loss: 0.00950251892209053\n",
      "Epoch: 3271, Train Loss: 0.00764503562822938, Valid Loss: 0.009493360295891762\n",
      "Epoch: 3272, Train Loss: 0.007638171315193176, Valid Loss: 0.009484265930950642\n",
      "Epoch: 3273, Train Loss: 0.007631303276866674, Valid Loss: 0.009475214406847954\n",
      "Epoch: 3274, Train Loss: 0.007624449674040079, Valid Loss: 0.009466174989938736\n",
      "Epoch: 3275, Train Loss: 0.007617620751261711, Valid Loss: 0.009456988424062729\n",
      "Epoch: 3276, Train Loss: 0.007610767614096403, Valid Loss: 0.009447933174669743\n",
      "Epoch: 3277, Train Loss: 0.007603947538882494, Valid Loss: 0.009438947774469852\n",
      "Epoch: 3278, Train Loss: 0.007597122807055712, Valid Loss: 0.009429900906980038\n",
      "Epoch: 3279, Train Loss: 0.007590300869196653, Valid Loss: 0.009420851245522499\n",
      "Epoch: 3280, Train Loss: 0.007583487778902054, Valid Loss: 0.009411782957613468\n",
      "Epoch: 3281, Train Loss: 0.007576698437333107, Valid Loss: 0.009402772411704063\n",
      "Epoch: 3282, Train Loss: 0.007569902576506138, Valid Loss: 0.009393850341439247\n",
      "Epoch: 3283, Train Loss: 0.007563119754195213, Valid Loss: 0.009384862147271633\n",
      "Epoch: 3284, Train Loss: 0.007556356023997068, Valid Loss: 0.00937584601342678\n",
      "Epoch: 3285, Train Loss: 0.007549588568508625, Valid Loss: 0.009366857819259167\n",
      "Epoch: 3286, Train Loss: 0.007542832754552364, Valid Loss: 0.009357971139252186\n",
      "Epoch: 3287, Train Loss: 0.00753607414662838, Valid Loss: 0.009348989464342594\n",
      "Epoch: 3288, Train Loss: 0.007529336027801037, Valid Loss: 0.009340121410787106\n",
      "Epoch: 3289, Train Loss: 0.007522599771618843, Valid Loss: 0.009331203997135162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3290, Train Loss: 0.007515879347920418, Valid Loss: 0.009322193451225758\n",
      "Epoch: 3291, Train Loss: 0.007509158458560705, Valid Loss: 0.009313350543379784\n",
      "Epoch: 3292, Train Loss: 0.0075024510733783245, Valid Loss: 0.009304514154791832\n",
      "Epoch: 3293, Train Loss: 0.007495749741792679, Valid Loss: 0.009295693598687649\n",
      "Epoch: 3294, Train Loss: 0.007489047013223171, Valid Loss: 0.009286737069487572\n",
      "Epoch: 3295, Train Loss: 0.007482355460524559, Valid Loss: 0.009277922101318836\n",
      "Epoch: 3296, Train Loss: 0.0074756694957613945, Valid Loss: 0.009269091300666332\n",
      "Epoch: 3297, Train Loss: 0.007469007279723883, Valid Loss: 0.00926024280488491\n",
      "Epoch: 3298, Train Loss: 0.007462345529347658, Valid Loss: 0.00925145298242569\n",
      "Epoch: 3299, Train Loss: 0.0074556805193424225, Valid Loss: 0.0092427097260952\n",
      "Epoch: 3300, Train Loss: 0.007449040189385414, Valid Loss: 0.009233878925442696\n",
      "Epoch: 3301, Train Loss: 0.0074423919431865215, Valid Loss: 0.009225083515048027\n",
      "Epoch: 3302, Train Loss: 0.00743575906381011, Valid Loss: 0.009216359816491604\n",
      "Epoch: 3303, Train Loss: 0.007429138757288456, Valid Loss: 0.00920751504600048\n",
      "Epoch: 3304, Train Loss: 0.007422521244734526, Valid Loss: 0.009198838844895363\n",
      "Epoch: 3305, Train Loss: 0.007415903266519308, Valid Loss: 0.009190117940306664\n",
      "Epoch: 3306, Train Loss: 0.007409300189465284, Valid Loss: 0.00918133370578289\n",
      "Epoch: 3307, Train Loss: 0.007402712479233742, Valid Loss: 0.009172651916742325\n",
      "Epoch: 3308, Train Loss: 0.007396124303340912, Valid Loss: 0.009163972921669483\n",
      "Epoch: 3309, Train Loss: 0.007389531005173922, Valid Loss: 0.00915522314608097\n",
      "Epoch: 3310, Train Loss: 0.007382967509329319, Valid Loss: 0.0091466149315238\n",
      "Epoch: 3311, Train Loss: 0.007376402150839567, Valid Loss: 0.009137921966612339\n",
      "Epoch: 3312, Train Loss: 0.007369842380285263, Valid Loss: 0.009129264391958714\n",
      "Epoch: 3313, Train Loss: 0.0073632956482470036, Valid Loss: 0.009120643138885498\n",
      "Epoch: 3314, Train Loss: 0.007356751710176468, Valid Loss: 0.00911195669323206\n",
      "Epoch: 3315, Train Loss: 0.00735021336004138, Valid Loss: 0.009103411808609962\n",
      "Epoch: 3316, Train Loss: 0.007343697361648083, Valid Loss: 0.009094745852053165\n",
      "Epoch: 3317, Train Loss: 0.007337180897593498, Valid Loss: 0.009086137637495995\n",
      "Epoch: 3318, Train Loss: 0.00733066163957119, Valid Loss: 0.009077501483261585\n",
      "Epoch: 3319, Train Loss: 0.007324159145355225, Valid Loss: 0.009068986400961876\n",
      "Epoch: 3320, Train Loss: 0.007317666430026293, Valid Loss: 0.009060421027243137\n",
      "Epoch: 3321, Train Loss: 0.007311179768294096, Valid Loss: 0.009051807224750519\n",
      "Epoch: 3322, Train Loss: 0.007304688449949026, Valid Loss: 0.009043284691870213\n",
      "Epoch: 3323, Train Loss: 0.007298216689378023, Valid Loss: 0.009034715592861176\n",
      "Epoch: 3324, Train Loss: 0.007291752379387617, Valid Loss: 0.00902621541172266\n",
      "Epoch: 3325, Train Loss: 0.007285289000719786, Valid Loss: 0.009017698466777802\n",
      "Epoch: 3326, Train Loss: 0.0072788395918905735, Valid Loss: 0.009009209461510181\n",
      "Epoch: 3327, Train Loss: 0.007272399961948395, Valid Loss: 0.009000713936984539\n",
      "Epoch: 3328, Train Loss: 0.007265964988619089, Valid Loss: 0.008992302231490612\n",
      "Epoch: 3329, Train Loss: 0.007259539794176817, Valid Loss: 0.008983761072158813\n",
      "Epoch: 3330, Train Loss: 0.007253114599734545, Valid Loss: 0.008975251577794552\n",
      "Epoch: 3331, Train Loss: 0.007246695458889008, Valid Loss: 0.008966860361397266\n",
      "Epoch: 3332, Train Loss: 0.00724029541015625, Valid Loss: 0.00895843654870987\n",
      "Epoch: 3333, Train Loss: 0.007233893033117056, Valid Loss: 0.008949928916990757\n",
      "Epoch: 3334, Train Loss: 0.007227495312690735, Valid Loss: 0.008941507898271084\n",
      "Epoch: 3335, Train Loss: 0.007221118547022343, Valid Loss: 0.008933072909712791\n",
      "Epoch: 3336, Train Loss: 0.007214745506644249, Valid Loss: 0.008924686349928379\n",
      "Epoch: 3337, Train Loss: 0.007208371069282293, Valid Loss: 0.008916318416595459\n",
      "Epoch: 3338, Train Loss: 0.007202014792710543, Valid Loss: 0.008907916955649853\n",
      "Epoch: 3339, Train Loss: 0.007195652462542057, Valid Loss: 0.008899515494704247\n",
      "Epoch: 3340, Train Loss: 0.007189305033534765, Valid Loss: 0.008891108445823193\n",
      "Epoch: 3341, Train Loss: 0.00718295993283391, Valid Loss: 0.008882838301360607\n",
      "Epoch: 3342, Train Loss: 0.007176632061600685, Valid Loss: 0.008874527178704739\n",
      "Epoch: 3343, Train Loss: 0.007170300465077162, Valid Loss: 0.00886612106114626\n",
      "Epoch: 3344, Train Loss: 0.007163993548601866, Valid Loss: 0.008857796899974346\n",
      "Epoch: 3345, Train Loss: 0.007157671265304089, Valid Loss: 0.00884944573044777\n",
      "Epoch: 3346, Train Loss: 0.0071513717994093895, Valid Loss: 0.008841235190629959\n",
      "Epoch: 3347, Train Loss: 0.007145067676901817, Valid Loss: 0.008832940831780434\n",
      "Epoch: 3348, Train Loss: 0.00713878171518445, Valid Loss: 0.008824546821415424\n",
      "Epoch: 3349, Train Loss: 0.007132500875741243, Valid Loss: 0.008816298097372055\n",
      "Epoch: 3350, Train Loss: 0.007126227952539921, Valid Loss: 0.008808057755231857\n",
      "Epoch: 3351, Train Loss: 0.0071199615485966206, Valid Loss: 0.008799807168543339\n",
      "Epoch: 3352, Train Loss: 0.007113706320524216, Valid Loss: 0.008791551925241947\n",
      "Epoch: 3353, Train Loss: 0.007107450161129236, Valid Loss: 0.008783260360360146\n",
      "Epoch: 3354, Train Loss: 0.007101206108927727, Valid Loss: 0.008775024674832821\n",
      "Epoch: 3355, Train Loss: 0.007094965782016516, Valid Loss: 0.00876685418188572\n",
      "Epoch: 3356, Train Loss: 0.007088731043040752, Valid Loss: 0.008758647367358208\n",
      "Epoch: 3357, Train Loss: 0.007082514930516481, Valid Loss: 0.00875044334679842\n",
      "Epoch: 3358, Train Loss: 0.00707629369571805, Valid Loss: 0.008742250502109528\n",
      "Epoch: 3359, Train Loss: 0.0070700859650969505, Valid Loss: 0.008734089322388172\n",
      "Epoch: 3360, Train Loss: 0.007063883822411299, Valid Loss: 0.008725857362151146\n",
      "Epoch: 3361, Train Loss: 0.007057687267661095, Valid Loss: 0.008717771619558334\n",
      "Epoch: 3362, Train Loss: 0.0070514981634914875, Valid Loss: 0.008709574118256569\n",
      "Epoch: 3363, Train Loss: 0.007045314181596041, Valid Loss: 0.008701416663825512\n",
      "Epoch: 3364, Train Loss: 0.007039140909910202, Valid Loss: 0.008693255484104156\n",
      "Epoch: 3365, Train Loss: 0.0070329755544662476, Valid Loss: 0.008685166016221046\n",
      "Epoch: 3366, Train Loss: 0.007026818580925465, Valid Loss: 0.008677031844854355\n",
      "Epoch: 3367, Train Loss: 0.007020661141723394, Valid Loss: 0.00866891723126173\n",
      "Epoch: 3368, Train Loss: 0.007014515344053507, Valid Loss: 0.008660835213959217\n",
      "Epoch: 3369, Train Loss: 0.007008369080722332, Valid Loss: 0.008652699179947376\n",
      "Epoch: 3370, Train Loss: 0.007002245634794235, Valid Loss: 0.00864463485777378\n",
      "Epoch: 3371, Train Loss: 0.006996129173785448, Valid Loss: 0.008636564947664738\n",
      "Epoch: 3372, Train Loss: 0.006990001071244478, Valid Loss: 0.008628496900200844\n",
      "Epoch: 3373, Train Loss: 0.006983896251767874, Valid Loss: 0.008620426058769226\n",
      "Epoch: 3374, Train Loss: 0.00697779655456543, Valid Loss: 0.008612408302724361\n",
      "Epoch: 3375, Train Loss: 0.0069716922007501125, Valid Loss: 0.008604337461292744\n",
      "Epoch: 3376, Train Loss: 0.006965606007725, Valid Loss: 0.00859630573540926\n",
      "Epoch: 3377, Train Loss: 0.0069595216773450375, Valid Loss: 0.00858832523226738\n",
      "Epoch: 3378, Train Loss: 0.006953449919819832, Valid Loss: 0.008580244146287441\n",
      "Epoch: 3379, Train Loss: 0.00694737583398819, Valid Loss: 0.008572218008339405\n",
      "Epoch: 3380, Train Loss: 0.0069413152523338795, Valid Loss: 0.008564252406358719\n",
      "Epoch: 3381, Train Loss: 0.006935270503163338, Valid Loss: 0.008556263521313667\n",
      "Epoch: 3382, Train Loss: 0.006929210852831602, Valid Loss: 0.008548296988010406\n",
      "Epoch: 3383, Train Loss: 0.006923175882548094, Valid Loss: 0.008540291339159012\n",
      "Epoch: 3384, Train Loss: 0.006917144637554884, Valid Loss: 0.008532308042049408\n",
      "Epoch: 3385, Train Loss: 0.006911115720868111, Valid Loss: 0.008524347096681595\n",
      "Epoch: 3386, Train Loss: 0.006905093789100647, Valid Loss: 0.008516463451087475\n",
      "Epoch: 3387, Train Loss: 0.006899081636220217, Valid Loss: 0.00850850623100996\n",
      "Epoch: 3388, Train Loss: 0.0068930769339203835, Valid Loss: 0.008500552736222744\n",
      "Epoch: 3389, Train Loss: 0.006887080613523722, Valid Loss: 0.008492594584822655\n",
      "Epoch: 3390, Train Loss: 0.0068810805678367615, Valid Loss: 0.008484689518809319\n",
      "Epoch: 3391, Train Loss: 0.006875104736536741, Valid Loss: 0.00847677793353796\n",
      "Epoch: 3392, Train Loss: 0.00686913076788187, Valid Loss: 0.008468923158943653\n",
      "Epoch: 3393, Train Loss: 0.006863151211291552, Valid Loss: 0.008460987359285355\n",
      "Epoch: 3394, Train Loss: 0.006857182830572128, Valid Loss: 0.008453089743852615\n",
      "Epoch: 3395, Train Loss: 0.0068512242287397385, Valid Loss: 0.00844514835625887\n",
      "Epoch: 3396, Train Loss: 0.006845269817858934, Valid Loss: 0.008437340147793293\n",
      "Epoch: 3397, Train Loss: 0.006839334033429623, Valid Loss: 0.008429551497101784\n",
      "Epoch: 3398, Train Loss: 0.0068333991803228855, Valid Loss: 0.008421605452895164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3399, Train Loss: 0.006827455945312977, Valid Loss: 0.008413733914494514\n",
      "Epoch: 3400, Train Loss: 0.006821535527706146, Valid Loss: 0.008405888453125954\n",
      "Epoch: 3401, Train Loss: 0.006815616507083178, Valid Loss: 0.008398070000112057\n",
      "Epoch: 3402, Train Loss: 0.006809712387621403, Valid Loss: 0.00839026365429163\n",
      "Epoch: 3403, Train Loss: 0.006803807336837053, Valid Loss: 0.008382442407310009\n",
      "Epoch: 3404, Train Loss: 0.006797909736633301, Valid Loss: 0.00837458111345768\n",
      "Epoch: 3405, Train Loss: 0.006792023312300444, Valid Loss: 0.00836675614118576\n",
      "Epoch: 3406, Train Loss: 0.006786139216274023, Valid Loss: 0.008358977735042572\n",
      "Epoch: 3407, Train Loss: 0.006780252326279879, Valid Loss: 0.008351173251867294\n",
      "Epoch: 3408, Train Loss: 0.0067743826657533646, Valid Loss: 0.008343437686562538\n",
      "Epoch: 3409, Train Loss: 0.006768523249775171, Valid Loss: 0.008335624821484089\n",
      "Epoch: 3410, Train Loss: 0.006762661039829254, Valid Loss: 0.008327812887728214\n",
      "Epoch: 3411, Train Loss: 0.006756808143109083, Valid Loss: 0.008320090360939503\n",
      "Epoch: 3412, Train Loss: 0.006750969216227531, Valid Loss: 0.008312319405376911\n",
      "Epoch: 3413, Train Loss: 0.0067451391369104385, Valid Loss: 0.008304597809910774\n",
      "Epoch: 3414, Train Loss: 0.006739302538335323, Valid Loss: 0.008296840824186802\n",
      "Epoch: 3415, Train Loss: 0.006733483634889126, Valid Loss: 0.008289026096463203\n",
      "Epoch: 3416, Train Loss: 0.006727667525410652, Valid Loss: 0.008281317539513111\n",
      "Epoch: 3417, Train Loss: 0.00672185281291604, Valid Loss: 0.008273635059595108\n",
      "Epoch: 3418, Train Loss: 0.006716052070260048, Valid Loss: 0.008265877142548561\n",
      "Epoch: 3419, Train Loss: 0.006710248999297619, Valid Loss: 0.008258125744760036\n",
      "Epoch: 3420, Train Loss: 0.006704462226480246, Valid Loss: 0.008250439539551735\n",
      "Epoch: 3421, Train Loss: 0.006698680110275745, Valid Loss: 0.008242746815085411\n",
      "Epoch: 3422, Train Loss: 0.00669290404766798, Valid Loss: 0.00823504850268364\n",
      "Epoch: 3423, Train Loss: 0.0066871303133666515, Valid Loss: 0.008227375335991383\n",
      "Epoch: 3424, Train Loss: 0.006681367754936218, Valid Loss: 0.008219676092267036\n",
      "Epoch: 3425, Train Loss: 0.006675605196505785, Valid Loss: 0.00821199081838131\n",
      "Epoch: 3426, Train Loss: 0.006669855210930109, Valid Loss: 0.008204306475818157\n",
      "Epoch: 3427, Train Loss: 0.00666411779820919, Valid Loss: 0.008196646347641945\n",
      "Epoch: 3428, Train Loss: 0.006658374331891537, Valid Loss: 0.00818899180740118\n",
      "Epoch: 3429, Train Loss: 0.006652644835412502, Valid Loss: 0.008181334473192692\n",
      "Epoch: 3430, Train Loss: 0.006646918598562479, Valid Loss: 0.0081736259162426\n",
      "Epoch: 3431, Train Loss: 0.006641204468905926, Valid Loss: 0.008165950886905193\n",
      "Epoch: 3432, Train Loss: 0.0066354842856526375, Valid Loss: 0.008158366195857525\n",
      "Epoch: 3433, Train Loss: 0.006629779003560543, Valid Loss: 0.008150768466293812\n",
      "Epoch: 3434, Train Loss: 0.006624084897339344, Valid Loss: 0.008143110200762749\n",
      "Epoch: 3435, Train Loss: 0.0066183931194245815, Valid Loss: 0.008135432377457619\n",
      "Epoch: 3436, Train Loss: 0.00661270460113883, Valid Loss: 0.008127819746732712\n",
      "Epoch: 3437, Train Loss: 0.0066070170141756535, Valid Loss: 0.008120210841298103\n",
      "Epoch: 3438, Train Loss: 0.00660135829821229, Valid Loss: 0.008112628012895584\n",
      "Epoch: 3439, Train Loss: 0.0065956879407167435, Valid Loss: 0.00810499582439661\n",
      "Epoch: 3440, Train Loss: 0.0065900180488824844, Valid Loss: 0.008097407408058643\n",
      "Epoch: 3441, Train Loss: 0.006584360264241695, Valid Loss: 0.008089790120720863\n",
      "Epoch: 3442, Train Loss: 0.006578728090971708, Valid Loss: 0.008082214742898941\n",
      "Epoch: 3443, Train Loss: 0.006573072634637356, Valid Loss: 0.008074677549302578\n",
      "Epoch: 3444, Train Loss: 0.0065674372017383575, Valid Loss: 0.008067070506513119\n",
      "Epoch: 3445, Train Loss: 0.006561816670000553, Valid Loss: 0.008059386163949966\n",
      "Epoch: 3446, Train Loss: 0.006556197069585323, Valid Loss: 0.008051854558289051\n",
      "Epoch: 3447, Train Loss: 0.00655057467520237, Valid Loss: 0.008044354617595673\n",
      "Epoch: 3448, Train Loss: 0.006544958334416151, Valid Loss: 0.008036712184548378\n",
      "Epoch: 3449, Train Loss: 0.0065393527038395405, Valid Loss: 0.008029155433177948\n",
      "Epoch: 3450, Train Loss: 0.0065337615087628365, Valid Loss: 0.008021621964871883\n",
      "Epoch: 3451, Train Loss: 0.006528170313686132, Valid Loss: 0.008013996295630932\n",
      "Epoch: 3452, Train Loss: 0.006522583309561014, Valid Loss: 0.008006472140550613\n",
      "Epoch: 3453, Train Loss: 0.006517006549984217, Valid Loss: 0.00799900759011507\n",
      "Epoch: 3454, Train Loss: 0.006511432118713856, Valid Loss: 0.007991398684680462\n",
      "Epoch: 3455, Train Loss: 0.006505867466330528, Valid Loss: 0.00798377487808466\n",
      "Epoch: 3456, Train Loss: 0.006500317715108395, Valid Loss: 0.007976335473358631\n",
      "Epoch: 3457, Train Loss: 0.006494767032563686, Valid Loss: 0.007968808524310589\n",
      "Epoch: 3458, Train Loss: 0.006489206105470657, Valid Loss: 0.007961226627230644\n",
      "Epoch: 3459, Train Loss: 0.006483669392764568, Valid Loss: 0.007953700609505177\n",
      "Epoch: 3460, Train Loss: 0.006478132680058479, Valid Loss: 0.00794620905071497\n",
      "Epoch: 3461, Train Loss: 0.006472607608884573, Valid Loss: 0.007938593626022339\n",
      "Epoch: 3462, Train Loss: 0.006467076018452644, Valid Loss: 0.007931090891361237\n",
      "Epoch: 3463, Train Loss: 0.006461565848439932, Valid Loss: 0.00792362354695797\n",
      "Epoch: 3464, Train Loss: 0.006456065457314253, Valid Loss: 0.007916049100458622\n",
      "Epoch: 3465, Train Loss: 0.006450556218624115, Valid Loss: 0.007908515632152557\n",
      "Epoch: 3466, Train Loss: 0.006445050705224276, Valid Loss: 0.007901003584265709\n",
      "Epoch: 3467, Train Loss: 0.006439565680921078, Valid Loss: 0.007893521338701248\n",
      "Epoch: 3468, Train Loss: 0.006434071809053421, Valid Loss: 0.00788595899939537\n",
      "Epoch: 3469, Train Loss: 0.006428590975701809, Valid Loss: 0.00787848699837923\n",
      "Epoch: 3470, Train Loss: 0.006423125974833965, Valid Loss: 0.00787096843123436\n",
      "Epoch: 3471, Train Loss: 0.006417656783014536, Valid Loss: 0.007863405160605907\n",
      "Epoch: 3472, Train Loss: 0.006412200629711151, Valid Loss: 0.007855982519686222\n",
      "Epoch: 3473, Train Loss: 0.006406739354133606, Valid Loss: 0.007848506793379784\n",
      "Epoch: 3474, Train Loss: 0.0064012957736849785, Valid Loss: 0.007840950042009354\n",
      "Epoch: 3475, Train Loss: 0.006395845673978329, Valid Loss: 0.007833404466509819\n",
      "Epoch: 3476, Train Loss: 0.006390413269400597, Valid Loss: 0.007825937122106552\n",
      "Epoch: 3477, Train Loss: 0.006384986452758312, Valid Loss: 0.007818457670509815\n",
      "Epoch: 3478, Train Loss: 0.00637955404818058, Valid Loss: 0.007810909766703844\n",
      "Epoch: 3479, Train Loss: 0.0063741328194737434, Valid Loss: 0.007803386077284813\n",
      "Epoch: 3480, Train Loss: 0.006368723697960377, Valid Loss: 0.0077958786860108376\n",
      "Epoch: 3481, Train Loss: 0.00636331457644701, Valid Loss: 0.0077883838675916195\n",
      "Epoch: 3482, Train Loss: 0.006357916165143251, Valid Loss: 0.007780889049172401\n",
      "Epoch: 3483, Train Loss: 0.006352524273097515, Valid Loss: 0.007773375604301691\n",
      "Epoch: 3484, Train Loss: 0.006347130052745342, Valid Loss: 0.007765882182866335\n",
      "Epoch: 3485, Train Loss: 0.006341739557683468, Valid Loss: 0.00775831239297986\n",
      "Epoch: 3486, Train Loss: 0.0063363597728312016, Valid Loss: 0.007750811520963907\n",
      "Epoch: 3487, Train Loss: 0.006331001874059439, Valid Loss: 0.007743373513221741\n",
      "Epoch: 3488, Train Loss: 0.006325633730739355, Valid Loss: 0.007735813967883587\n",
      "Epoch: 3489, Train Loss: 0.006320285610854626, Valid Loss: 0.0077283428981900215\n",
      "Epoch: 3490, Train Loss: 0.006314918864518404, Valid Loss: 0.007720781024545431\n",
      "Epoch: 3491, Train Loss: 0.006309576332569122, Valid Loss: 0.00771327456459403\n",
      "Epoch: 3492, Train Loss: 0.006304234266281128, Valid Loss: 0.007705722004175186\n",
      "Epoch: 3493, Train Loss: 0.0062988935969769955, Valid Loss: 0.007698246277868748\n",
      "Epoch: 3494, Train Loss: 0.006293566431850195, Valid Loss: 0.007690710946917534\n",
      "Epoch: 3495, Train Loss: 0.006288239732384682, Valid Loss: 0.007683077827095985\n",
      "Epoch: 3496, Train Loss: 0.006282918620854616, Valid Loss: 0.007675626780837774\n",
      "Epoch: 3497, Train Loss: 0.00627761147916317, Valid Loss: 0.0076681021600961685\n",
      "Epoch: 3498, Train Loss: 0.006272301543504, Valid Loss: 0.007660546340048313\n",
      "Epoch: 3499, Train Loss: 0.006267003249377012, Valid Loss: 0.007653010077774525\n",
      "Epoch: 3500, Train Loss: 0.006261708680540323, Valid Loss: 0.007645387668162584\n",
      "Epoch: 3501, Train Loss: 0.006256414577364922, Valid Loss: 0.007637817412614822\n",
      "Epoch: 3502, Train Loss: 0.006251130718737841, Valid Loss: 0.007630284875631332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3503, Train Loss: 0.0062458571046590805, Valid Loss: 0.007622822653502226\n",
      "Epoch: 3504, Train Loss: 0.006240582559257746, Valid Loss: 0.007615191861987114\n",
      "Epoch: 3505, Train Loss: 0.00623530987650156, Valid Loss: 0.007607548031955957\n",
      "Epoch: 3506, Train Loss: 0.006230047903954983, Valid Loss: 0.007599974051117897\n",
      "Epoch: 3507, Train Loss: 0.006224790588021278, Valid Loss: 0.00759241683408618\n",
      "Epoch: 3508, Train Loss: 0.006219550967216492, Valid Loss: 0.007584822364151478\n",
      "Epoch: 3509, Train Loss: 0.006214300636202097, Valid Loss: 0.007577221374958754\n",
      "Epoch: 3510, Train Loss: 0.006209057290107012, Valid Loss: 0.007569541223347187\n",
      "Epoch: 3511, Train Loss: 0.006203826051205397, Valid Loss: 0.007561966776847839\n",
      "Epoch: 3512, Train Loss: 0.006198591087013483, Valid Loss: 0.0075543890707194805\n",
      "Epoch: 3513, Train Loss: 0.006193375680595636, Valid Loss: 0.007546727079898119\n",
      "Epoch: 3514, Train Loss: 0.006188156548887491, Valid Loss: 0.007539058104157448\n",
      "Epoch: 3515, Train Loss: 0.006182953715324402, Valid Loss: 0.007531389128416777\n",
      "Epoch: 3516, Train Loss: 0.006177740637212992, Valid Loss: 0.007523724809288979\n",
      "Epoch: 3517, Train Loss: 0.006172538734972477, Valid Loss: 0.007516026496887207\n",
      "Epoch: 3518, Train Loss: 0.006167345214635134, Valid Loss: 0.0075083947740495205\n",
      "Epoch: 3519, Train Loss: 0.006162152159959078, Valid Loss: 0.00750067038461566\n",
      "Epoch: 3520, Train Loss: 0.0061569674871861935, Valid Loss: 0.00749294925481081\n",
      "Epoch: 3521, Train Loss: 0.00615179305896163, Valid Loss: 0.007485243026167154\n",
      "Epoch: 3522, Train Loss: 0.006146616768091917, Valid Loss: 0.007477479055523872\n",
      "Epoch: 3523, Train Loss: 0.006141450256109238, Valid Loss: 0.007469767238944769\n",
      "Epoch: 3524, Train Loss: 0.006136275362223387, Valid Loss: 0.007462055888026953\n",
      "Epoch: 3525, Train Loss: 0.0061311242170631886, Valid Loss: 0.007454242557287216\n",
      "Epoch: 3526, Train Loss: 0.006125973537564278, Valid Loss: 0.007446440402418375\n",
      "Epoch: 3527, Train Loss: 0.006120830308645964, Valid Loss: 0.0074386997148394585\n",
      "Epoch: 3528, Train Loss: 0.0061156791634857655, Valid Loss: 0.0074308584444224834\n",
      "Epoch: 3529, Train Loss: 0.006110542919486761, Valid Loss: 0.007423029746860266\n",
      "Epoch: 3530, Train Loss: 0.006105415988713503, Valid Loss: 0.0074152336455881596\n",
      "Epoch: 3531, Train Loss: 0.006100283470004797, Valid Loss: 0.007407339755445719\n",
      "Epoch: 3532, Train Loss: 0.006095164455473423, Valid Loss: 0.007399424910545349\n",
      "Epoch: 3533, Train Loss: 0.006090058013796806, Valid Loss: 0.0073915692046284676\n",
      "Epoch: 3534, Train Loss: 0.006084939930588007, Valid Loss: 0.007383678108453751\n",
      "Epoch: 3535, Train Loss: 0.0060798292979598045, Valid Loss: 0.007375732064247131\n",
      "Epoch: 3536, Train Loss: 0.0060747237876057625, Valid Loss: 0.007367804646492004\n",
      "Epoch: 3537, Train Loss: 0.006069633178412914, Valid Loss: 0.007359785493463278\n",
      "Epoch: 3538, Train Loss: 0.006064542569220066, Valid Loss: 0.007351804990321398\n",
      "Epoch: 3539, Train Loss: 0.006059444509446621, Valid Loss: 0.007343858014792204\n",
      "Epoch: 3540, Train Loss: 0.006054372992366552, Valid Loss: 0.007335839793086052\n",
      "Epoch: 3541, Train Loss: 0.006049293093383312, Valid Loss: 0.007327774073928595\n",
      "Epoch: 3542, Train Loss: 0.006044221576303244, Valid Loss: 0.00731970788910985\n",
      "Epoch: 3543, Train Loss: 0.006039153318852186, Valid Loss: 0.007311626803129911\n",
      "Epoch: 3544, Train Loss: 0.0060340967029333115, Valid Loss: 0.007303556893020868\n",
      "Epoch: 3545, Train Loss: 0.006029030773788691, Valid Loss: 0.007295427843928337\n",
      "Epoch: 3546, Train Loss: 0.006023980211466551, Valid Loss: 0.007287285290658474\n",
      "Epoch: 3547, Train Loss: 0.0060189226642251015, Valid Loss: 0.007279081270098686\n",
      "Epoch: 3548, Train Loss: 0.006013878155499697, Valid Loss: 0.00727083720266819\n",
      "Epoch: 3549, Train Loss: 0.006008845288306475, Valid Loss: 0.007262644823640585\n",
      "Epoch: 3550, Train Loss: 0.0060038091614842415, Valid Loss: 0.007254506926983595\n",
      "Epoch: 3551, Train Loss: 0.005998771172016859, Valid Loss: 0.007246159482747316\n",
      "Epoch: 3552, Train Loss: 0.0059937406331300735, Valid Loss: 0.007237853482365608\n",
      "Epoch: 3553, Train Loss: 0.005988723132759333, Valid Loss: 0.0072295148856937885\n",
      "Epoch: 3554, Train Loss: 0.005983702372759581, Valid Loss: 0.007221177686005831\n",
      "Epoch: 3555, Train Loss: 0.005978694185614586, Valid Loss: 0.007212847005575895\n",
      "Epoch: 3556, Train Loss: 0.005973678547888994, Valid Loss: 0.007204474415630102\n",
      "Epoch: 3557, Train Loss: 0.005968667101114988, Valid Loss: 0.007196051999926567\n",
      "Epoch: 3558, Train Loss: 0.0059636663645505905, Valid Loss: 0.007187532261013985\n",
      "Epoch: 3559, Train Loss: 0.005958670284599066, Valid Loss: 0.0071791051886975765\n",
      "Epoch: 3560, Train Loss: 0.005953678861260414, Valid Loss: 0.007170605473220348\n",
      "Epoch: 3561, Train Loss: 0.005948677659034729, Valid Loss: 0.007162130903452635\n",
      "Epoch: 3562, Train Loss: 0.0059436955489218235, Valid Loss: 0.007153579033911228\n",
      "Epoch: 3563, Train Loss: 0.005938712507486343, Valid Loss: 0.0071449582464993\n",
      "Epoch: 3564, Train Loss: 0.005933729466050863, Valid Loss: 0.007136389147490263\n",
      "Epoch: 3565, Train Loss: 0.0059287589974701405, Valid Loss: 0.007127770688384771\n",
      "Epoch: 3566, Train Loss: 0.0059237852692604065, Valid Loss: 0.007119172252714634\n",
      "Epoch: 3567, Train Loss: 0.005918818525969982, Valid Loss: 0.007110459264367819\n",
      "Epoch: 3568, Train Loss: 0.005913850385695696, Valid Loss: 0.007101751398295164\n",
      "Epoch: 3569, Train Loss: 0.005908890161663294, Valid Loss: 0.0070930905640125275\n",
      "Epoch: 3570, Train Loss: 0.00590393366292119, Valid Loss: 0.0070843808352947235\n",
      "Epoch: 3571, Train Loss: 0.005898980423808098, Valid Loss: 0.00707563990727067\n",
      "Epoch: 3572, Train Loss: 0.005894030909985304, Valid Loss: 0.007066942285746336\n",
      "Epoch: 3573, Train Loss: 0.005889092106372118, Valid Loss: 0.007058145944029093\n",
      "Epoch: 3574, Train Loss: 0.005884148180484772, Valid Loss: 0.007049317471683025\n",
      "Epoch: 3575, Train Loss: 0.005879200529307127, Valid Loss: 0.0070406049489974976\n",
      "Epoch: 3576, Train Loss: 0.005874271970242262, Valid Loss: 0.007031792774796486\n",
      "Epoch: 3577, Train Loss: 0.0058693354949355125, Valid Loss: 0.00702295359224081\n",
      "Epoch: 3578, Train Loss: 0.005864415317773819, Valid Loss: 0.0070142317563295364\n",
      "Epoch: 3579, Train Loss: 0.0058594862930476665, Valid Loss: 0.007005384191870689\n",
      "Epoch: 3580, Train Loss: 0.005854567047208548, Valid Loss: 0.006996542681008577\n",
      "Epoch: 3581, Train Loss: 0.0058496431447565556, Valid Loss: 0.006987789645791054\n",
      "Epoch: 3582, Train Loss: 0.005844736006110907, Valid Loss: 0.006979031953960657\n",
      "Epoch: 3583, Train Loss: 0.005839819088578224, Valid Loss: 0.006970172747969627\n",
      "Epoch: 3584, Train Loss: 0.005834921728819609, Valid Loss: 0.006961438804864883\n",
      "Epoch: 3585, Train Loss: 0.005830019246786833, Valid Loss: 0.006952752359211445\n",
      "Epoch: 3586, Train Loss: 0.00582511629909277, Valid Loss: 0.0069439830258488655\n",
      "Epoch: 3587, Train Loss: 0.0058202240616083145, Valid Loss: 0.0069352430291473866\n",
      "Epoch: 3588, Train Loss: 0.005815335549414158, Valid Loss: 0.006926598027348518\n",
      "Epoch: 3589, Train Loss: 0.0058104507625103, Valid Loss: 0.006917961873114109\n",
      "Epoch: 3590, Train Loss: 0.0058055659756064415, Valid Loss: 0.006909333635121584\n",
      "Epoch: 3591, Train Loss: 0.005800686776638031, Valid Loss: 0.006900718901306391\n",
      "Epoch: 3592, Train Loss: 0.005795807112008333, Valid Loss: 0.006892210803925991\n",
      "Epoch: 3593, Train Loss: 0.005790937691926956, Valid Loss: 0.0068836938589811325\n",
      "Epoch: 3594, Train Loss: 0.0057860733941197395, Valid Loss: 0.006875252816826105\n",
      "Epoch: 3595, Train Loss: 0.005781212355941534, Valid Loss: 0.006866874638944864\n",
      "Epoch: 3596, Train Loss: 0.0057763634249567986, Valid Loss: 0.006858526263386011\n",
      "Epoch: 3597, Train Loss: 0.005771508440375328, Valid Loss: 0.006850209087133408\n",
      "Epoch: 3598, Train Loss: 0.005766660440713167, Valid Loss: 0.00684194965288043\n",
      "Epoch: 3599, Train Loss: 0.005761811975389719, Valid Loss: 0.006833820138126612\n",
      "Epoch: 3600, Train Loss: 0.005756978411227465, Valid Loss: 0.006825686898082495\n",
      "Epoch: 3601, Train Loss: 0.005752146244049072, Valid Loss: 0.006817673332989216\n",
      "Epoch: 3602, Train Loss: 0.00574731919914484, Valid Loss: 0.006809715647250414\n",
      "Epoch: 3603, Train Loss: 0.005742491222918034, Valid Loss: 0.006801739800721407\n",
      "Epoch: 3604, Train Loss: 0.005737674422562122, Valid Loss: 0.00679390411823988\n",
      "Epoch: 3605, Train Loss: 0.005732860416173935, Valid Loss: 0.0067861033603549\n",
      "Epoch: 3606, Train Loss: 0.005728046875447035, Valid Loss: 0.006778407841920853\n",
      "Epoch: 3607, Train Loss: 0.005723242182284594, Valid Loss: 0.006770736072212458\n",
      "Epoch: 3608, Train Loss: 0.005718443542718887, Valid Loss: 0.006763185374438763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3609, Train Loss: 0.005713644903153181, Valid Loss: 0.00675572594627738\n",
      "Epoch: 3610, Train Loss: 0.0057088593021035194, Valid Loss: 0.006748270243406296\n",
      "Epoch: 3611, Train Loss: 0.005704081617295742, Valid Loss: 0.006740894168615341\n",
      "Epoch: 3612, Train Loss: 0.005699296947568655, Valid Loss: 0.006733600050210953\n",
      "Epoch: 3613, Train Loss: 0.0056945257820189, Valid Loss: 0.006726349703967571\n",
      "Epoch: 3614, Train Loss: 0.005689751356840134, Valid Loss: 0.006719192955642939\n",
      "Epoch: 3615, Train Loss: 0.0056849876418709755, Valid Loss: 0.006712089758366346\n",
      "Epoch: 3616, Train Loss: 0.005680236034095287, Valid Loss: 0.006705081090331078\n",
      "Epoch: 3617, Train Loss: 0.0056754713878035545, Valid Loss: 0.006698060780763626\n",
      "Epoch: 3618, Train Loss: 0.0056707290932536125, Valid Loss: 0.006691163871437311\n",
      "Epoch: 3619, Train Loss: 0.005665982607752085, Valid Loss: 0.006684316322207451\n",
      "Epoch: 3620, Train Loss: 0.005661246366798878, Valid Loss: 0.006677523255348206\n",
      "Epoch: 3621, Train Loss: 0.005656513385474682, Valid Loss: 0.006670726463198662\n",
      "Epoch: 3622, Train Loss: 0.005651786923408508, Valid Loss: 0.006664039101451635\n",
      "Epoch: 3623, Train Loss: 0.005647058133035898, Valid Loss: 0.006657444406300783\n",
      "Epoch: 3624, Train Loss: 0.005642342381179333, Valid Loss: 0.006650798954069614\n",
      "Epoch: 3625, Train Loss: 0.005637638736516237, Valid Loss: 0.006644227541983128\n",
      "Epoch: 3626, Train Loss: 0.005632932297885418, Valid Loss: 0.00663774786517024\n",
      "Epoch: 3627, Train Loss: 0.005628227721899748, Valid Loss: 0.0066312868148088455\n",
      "Epoch: 3628, Train Loss: 0.005623530596494675, Valid Loss: 0.006624853238463402\n",
      "Epoch: 3629, Train Loss: 0.005618850234895945, Valid Loss: 0.006618443876504898\n",
      "Epoch: 3630, Train Loss: 0.005614153575152159, Valid Loss: 0.006612052209675312\n",
      "Epoch: 3631, Train Loss: 0.005609489977359772, Valid Loss: 0.0066058035008609295\n",
      "Epoch: 3632, Train Loss: 0.005604809615761042, Valid Loss: 0.006599505431950092\n",
      "Epoch: 3633, Train Loss: 0.005600135773420334, Valid Loss: 0.006593231577426195\n",
      "Epoch: 3634, Train Loss: 0.0055954791605472565, Valid Loss: 0.006587036419659853\n",
      "Epoch: 3635, Train Loss: 0.005590821150690317, Valid Loss: 0.006580840330570936\n",
      "Epoch: 3636, Train Loss: 0.0055861640721559525, Valid Loss: 0.006574626080691814\n",
      "Epoch: 3637, Train Loss: 0.005581522826105356, Valid Loss: 0.006568478886038065\n",
      "Epoch: 3638, Train Loss: 0.005576870869845152, Valid Loss: 0.006562437862157822\n",
      "Epoch: 3639, Train Loss: 0.005572240334004164, Valid Loss: 0.006556338164955378\n",
      "Epoch: 3640, Train Loss: 0.005567611660808325, Valid Loss: 0.0065501993522048\n",
      "Epoch: 3641, Train Loss: 0.005562982056289911, Valid Loss: 0.006544224452227354\n",
      "Epoch: 3642, Train Loss: 0.005558360368013382, Valid Loss: 0.006538278888911009\n",
      "Epoch: 3643, Train Loss: 0.0055537475273013115, Valid Loss: 0.006532206665724516\n",
      "Epoch: 3644, Train Loss: 0.005549133755266666, Valid Loss: 0.006526208017021418\n",
      "Epoch: 3645, Train Loss: 0.005544534418731928, Valid Loss: 0.0065203336998820305\n",
      "Epoch: 3646, Train Loss: 0.00553993321955204, Valid Loss: 0.006514400243759155\n",
      "Epoch: 3647, Train Loss: 0.005535339470952749, Valid Loss: 0.006508424412459135\n",
      "Epoch: 3648, Train Loss: 0.00553075410425663, Valid Loss: 0.006502642761915922\n",
      "Epoch: 3649, Train Loss: 0.005526167340576649, Valid Loss: 0.006496753543615341\n",
      "Epoch: 3650, Train Loss: 0.005521588027477264, Valid Loss: 0.006490777712315321\n",
      "Epoch: 3651, Train Loss: 0.005517021752893925, Valid Loss: 0.006485003978013992\n",
      "Epoch: 3652, Train Loss: 0.00551245640963316, Valid Loss: 0.006479286588728428\n",
      "Epoch: 3653, Train Loss: 0.005507884081453085, Valid Loss: 0.00647339504212141\n",
      "Epoch: 3654, Train Loss: 0.005503328051418066, Valid Loss: 0.0064675225876271725\n",
      "Epoch: 3655, Train Loss: 0.005498774349689484, Valid Loss: 0.0064618815667927265\n",
      "Epoch: 3656, Train Loss: 0.005494231358170509, Valid Loss: 0.006456100847572088\n",
      "Epoch: 3657, Train Loss: 0.0054896920919418335, Valid Loss: 0.00645033223554492\n",
      "Epoch: 3658, Train Loss: 0.005485157482326031, Valid Loss: 0.006444633472710848\n",
      "Epoch: 3659, Train Loss: 0.00548062426969409, Valid Loss: 0.0064389449544250965\n",
      "Epoch: 3660, Train Loss: 0.005476105026900768, Valid Loss: 0.006433201488107443\n",
      "Epoch: 3661, Train Loss: 0.005471581593155861, Valid Loss: 0.006427483633160591\n",
      "Epoch: 3662, Train Loss: 0.005467068403959274, Valid Loss: 0.006421943195164204\n",
      "Epoch: 3663, Train Loss: 0.0054625580087304115, Valid Loss: 0.006416316144168377\n",
      "Epoch: 3664, Train Loss: 0.005458050407469273, Valid Loss: 0.006410540547221899\n",
      "Epoch: 3665, Train Loss: 0.005453549325466156, Valid Loss: 0.006404944229871035\n",
      "Epoch: 3666, Train Loss: 0.005449044518172741, Valid Loss: 0.0063994042575359344\n",
      "Epoch: 3667, Train Loss: 0.005444562062621117, Valid Loss: 0.00639375438913703\n",
      "Epoch: 3668, Train Loss: 0.005440079607069492, Valid Loss: 0.00638815201818943\n",
      "Epoch: 3669, Train Loss: 0.005435596220195293, Valid Loss: 0.006382614374160767\n",
      "Epoch: 3670, Train Loss: 0.0054311249405145645, Valid Loss: 0.0063770306296646595\n",
      "Epoch: 3671, Train Loss: 0.005426663439720869, Valid Loss: 0.006371440831571817\n",
      "Epoch: 3672, Train Loss: 0.005422188434749842, Valid Loss: 0.0063659693114459515\n",
      "Epoch: 3673, Train Loss: 0.005417732056230307, Valid Loss: 0.00636042607948184\n",
      "Epoch: 3674, Train Loss: 0.005413276143372059, Valid Loss: 0.006354862824082375\n",
      "Epoch: 3675, Train Loss: 0.005408827215433121, Valid Loss: 0.00634937034919858\n",
      "Epoch: 3676, Train Loss: 0.0054043796844780445, Valid Loss: 0.006343897432088852\n",
      "Epoch: 3677, Train Loss: 0.005399941001087427, Valid Loss: 0.006338432896882296\n",
      "Epoch: 3678, Train Loss: 0.005395508836954832, Valid Loss: 0.006332931574434042\n",
      "Epoch: 3679, Train Loss: 0.005391073413193226, Valid Loss: 0.006327459122985601\n",
      "Epoch: 3680, Train Loss: 0.00538665009662509, Valid Loss: 0.006322015542536974\n",
      "Epoch: 3681, Train Loss: 0.005382230039685965, Valid Loss: 0.0063165826722979546\n",
      "Epoch: 3682, Train Loss: 0.005377816502004862, Valid Loss: 0.006311155389994383\n",
      "Epoch: 3683, Train Loss: 0.005373403429985046, Valid Loss: 0.006305714137852192\n",
      "Epoch: 3684, Train Loss: 0.005368998274207115, Valid Loss: 0.006300298497080803\n",
      "Epoch: 3685, Train Loss: 0.005364598240703344, Valid Loss: 0.006294865161180496\n",
      "Epoch: 3686, Train Loss: 0.005360202863812447, Valid Loss: 0.006289505399763584\n",
      "Epoch: 3687, Train Loss: 0.00535581586882472, Valid Loss: 0.0062841749750077724\n",
      "Epoch: 3688, Train Loss: 0.0053514279425144196, Valid Loss: 0.0062787639908492565\n",
      "Epoch: 3689, Train Loss: 0.005347053054720163, Valid Loss: 0.006273387465626001\n",
      "Epoch: 3690, Train Loss: 0.005342675838619471, Valid Loss: 0.00626801373437047\n",
      "Epoch: 3691, Train Loss: 0.005338297225534916, Valid Loss: 0.006262687034904957\n",
      "Epoch: 3692, Train Loss: 0.005333936307579279, Valid Loss: 0.0062573873437941074\n",
      "Epoch: 3693, Train Loss: 0.005329574923962355, Valid Loss: 0.0062520164065063\n",
      "Epoch: 3694, Train Loss: 0.005325217731297016, Valid Loss: 0.006246705073863268\n",
      "Epoch: 3695, Train Loss: 0.005320866126567125, Valid Loss: 0.006241399794816971\n",
      "Epoch: 3696, Train Loss: 0.005316514056175947, Valid Loss: 0.006236101500689983\n",
      "Epoch: 3697, Train Loss: 0.005312173627316952, Valid Loss: 0.006230831146240234\n",
      "Epoch: 3698, Train Loss: 0.005307840649038553, Valid Loss: 0.006225532852113247\n",
      "Epoch: 3699, Train Loss: 0.005303509067744017, Valid Loss: 0.006220234092324972\n",
      "Epoch: 3700, Train Loss: 0.005299185868352652, Valid Loss: 0.0062149763107299805\n",
      "Epoch: 3701, Train Loss: 0.005294853821396828, Valid Loss: 0.006209767889231443\n",
      "Epoch: 3702, Train Loss: 0.005290531553328037, Valid Loss: 0.0062044947408139706\n",
      "Epoch: 3703, Train Loss: 0.005286217201501131, Valid Loss: 0.006199246738106012\n",
      "Epoch: 3704, Train Loss: 0.0052819144912064075, Valid Loss: 0.006194033194333315\n",
      "Epoch: 3705, Train Loss: 0.005277602467685938, Valid Loss: 0.006188808009028435\n",
      "Epoch: 3706, Train Loss: 0.005273306276649237, Valid Loss: 0.006183601450175047\n",
      "Epoch: 3707, Train Loss: 0.00526900589466095, Valid Loss: 0.006178385578095913\n",
      "Epoch: 3708, Train Loss: 0.005264716688543558, Valid Loss: 0.006173191126435995\n",
      "Epoch: 3709, Train Loss: 0.005260429810732603, Valid Loss: 0.006168013904243708\n",
      "Epoch: 3710, Train Loss: 0.00525615643709898, Valid Loss: 0.006162849720567465\n",
      "Epoch: 3711, Train Loss: 0.005251878872513771, Valid Loss: 0.006157654337584972\n",
      "Epoch: 3712, Train Loss: 0.005247604101896286, Valid Loss: 0.006152499932795763\n",
      "Epoch: 3713, Train Loss: 0.005243333056569099, Valid Loss: 0.006147363223135471\n",
      "Epoch: 3714, Train Loss: 0.005239064339548349, Valid Loss: 0.006142167840152979\n",
      "Epoch: 3715, Train Loss: 0.005234809126704931, Valid Loss: 0.006137062795460224\n",
      "Epoch: 3716, Train Loss: 0.005230555310845375, Valid Loss: 0.006131972651928663\n",
      "Epoch: 3717, Train Loss: 0.00522630987688899, Valid Loss: 0.006126857828348875\n",
      "Epoch: 3718, Train Loss: 0.00522206025198102, Valid Loss: 0.006121678743511438\n",
      "Epoch: 3719, Train Loss: 0.005217829719185829, Valid Loss: 0.006116602569818497\n",
      "Epoch: 3720, Train Loss: 0.00521358847618103, Valid Loss: 0.00611152034252882\n",
      "Epoch: 3721, Train Loss: 0.0052093579433858395, Valid Loss: 0.006106439046561718\n",
      "Epoch: 3722, Train Loss: 0.005205132067203522, Valid Loss: 0.006101352162659168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3723, Train Loss: 0.005200907588005066, Valid Loss: 0.006096278317272663\n",
      "Epoch: 3724, Train Loss: 0.005196692887693644, Valid Loss: 0.0060911886394023895\n",
      "Epoch: 3725, Train Loss: 0.005192481447011232, Valid Loss: 0.006086157634854317\n",
      "Epoch: 3726, Train Loss: 0.005188269540667534, Valid Loss: 0.006081158295273781\n",
      "Epoch: 3727, Train Loss: 0.005184064153581858, Valid Loss: 0.006076084449887276\n",
      "Epoch: 3728, Train Loss: 0.005179864354431629, Valid Loss: 0.006071011535823345\n",
      "Epoch: 3729, Train Loss: 0.005175672005861998, Valid Loss: 0.0060660261660814285\n",
      "Epoch: 3730, Train Loss: 0.005171477794647217, Valid Loss: 0.00606104452162981\n",
      "Epoch: 3731, Train Loss: 0.005167294759303331, Valid Loss: 0.006056026089936495\n",
      "Epoch: 3732, Train Loss: 0.005163115449249744, Valid Loss: 0.006051035597920418\n",
      "Epoch: 3733, Train Loss: 0.005158939864486456, Valid Loss: 0.006046064663678408\n",
      "Epoch: 3734, Train Loss: 0.00515477079898119, Valid Loss: 0.006041054148226976\n",
      "Epoch: 3735, Train Loss: 0.0051505956798791885, Valid Loss: 0.0060360850766301155\n",
      "Epoch: 3736, Train Loss: 0.005146434996277094, Valid Loss: 0.006031138356775045\n",
      "Epoch: 3737, Train Loss: 0.005142278503626585, Valid Loss: 0.00602618558332324\n",
      "Epoch: 3738, Train Loss: 0.005138113163411617, Valid Loss: 0.0060212379321455956\n",
      "Epoch: 3739, Train Loss: 0.005133968312293291, Valid Loss: 0.006016305647790432\n",
      "Epoch: 3740, Train Loss: 0.00512982252985239, Valid Loss: 0.0060113961808383465\n",
      "Epoch: 3741, Train Loss: 0.005125680938363075, Valid Loss: 0.006006441079080105\n",
      "Epoch: 3742, Train Loss: 0.0051215458661317825, Valid Loss: 0.006001570262014866\n",
      "Epoch: 3743, Train Loss: 0.005117404740303755, Valid Loss: 0.005996666382998228\n",
      "Epoch: 3744, Train Loss: 0.005113278515636921, Valid Loss: 0.00599173316732049\n",
      "Epoch: 3745, Train Loss: 0.0051091499626636505, Valid Loss: 0.005986838135868311\n",
      "Epoch: 3746, Train Loss: 0.005105031654238701, Valid Loss: 0.005981996189802885\n",
      "Epoch: 3747, Train Loss: 0.005100912880152464, Valid Loss: 0.005977126769721508\n",
      "Epoch: 3748, Train Loss: 0.005096805281937122, Valid Loss: 0.005972257815301418\n",
      "Epoch: 3749, Train Loss: 0.005092695355415344, Valid Loss: 0.0059674205258488655\n",
      "Epoch: 3750, Train Loss: 0.005088591482490301, Valid Loss: 0.005962604656815529\n",
      "Epoch: 3751, Train Loss: 0.00508448900654912, Valid Loss: 0.005957741290330887\n",
      "Epoch: 3752, Train Loss: 0.005080397706478834, Valid Loss: 0.0059528774581849575\n",
      "Epoch: 3753, Train Loss: 0.005076299887150526, Valid Loss: 0.005948091857135296\n",
      "Epoch: 3754, Train Loss: 0.005072218831628561, Valid Loss: 0.00594330532476306\n",
      "Epoch: 3755, Train Loss: 0.005068146623671055, Valid Loss: 0.005938500165939331\n",
      "Epoch: 3756, Train Loss: 0.005064064636826515, Valid Loss: 0.005933715496212244\n",
      "Epoch: 3757, Train Loss: 0.005059993360191584, Valid Loss: 0.005928945727646351\n",
      "Epoch: 3758, Train Loss: 0.005055916495621204, Valid Loss: 0.005924156866967678\n",
      "Epoch: 3759, Train Loss: 0.005051857326179743, Valid Loss: 0.005919394548982382\n",
      "Epoch: 3760, Train Loss: 0.005047800485044718, Valid Loss: 0.005914646200835705\n",
      "Epoch: 3761, Train Loss: 0.005043733865022659, Valid Loss: 0.0059098731726408005\n",
      "Epoch: 3762, Train Loss: 0.005039696116000414, Valid Loss: 0.005905169993638992\n",
      "Epoch: 3763, Train Loss: 0.00503563741222024, Valid Loss: 0.005900472402572632\n",
      "Epoch: 3764, Train Loss: 0.005031596403568983, Valid Loss: 0.005895746406167746\n",
      "Epoch: 3765, Train Loss: 0.005027561914175749, Valid Loss: 0.005891005974262953\n",
      "Epoch: 3766, Train Loss: 0.005023518577218056, Valid Loss: 0.0058863041922450066\n",
      "Epoch: 3767, Train Loss: 0.005019492469727993, Valid Loss: 0.005881648510694504\n",
      "Epoch: 3768, Train Loss: 0.00501546123996377, Valid Loss: 0.005876945797353983\n",
      "Epoch: 3769, Train Loss: 0.005011445842683315, Valid Loss: 0.00587227800861001\n",
      "Epoch: 3770, Train Loss: 0.005007427651435137, Valid Loss: 0.005867641419172287\n",
      "Epoch: 3771, Train Loss: 0.005003413185477257, Valid Loss: 0.005862968973815441\n",
      "Epoch: 3772, Train Loss: 0.004999395459890366, Valid Loss: 0.005858310963958502\n",
      "Epoch: 3773, Train Loss: 0.004995401483029127, Valid Loss: 0.005853693932294846\n",
      "Epoch: 3774, Train Loss: 0.004991389811038971, Valid Loss: 0.005849076900631189\n",
      "Epoch: 3775, Train Loss: 0.0049874004907906055, Valid Loss: 0.005844452418386936\n",
      "Epoch: 3776, Train Loss: 0.0049833995290100574, Valid Loss: 0.005839847959578037\n",
      "Epoch: 3777, Train Loss: 0.004979401361197233, Valid Loss: 0.005835243500769138\n",
      "Epoch: 3778, Train Loss: 0.0049754255451262, Valid Loss: 0.005830663256347179\n",
      "Epoch: 3779, Train Loss: 0.004971442744135857, Valid Loss: 0.005826070439070463\n",
      "Epoch: 3780, Train Loss: 0.004967469722032547, Valid Loss: 0.005821519996970892\n",
      "Epoch: 3781, Train Loss: 0.004963507875800133, Valid Loss: 0.005816928576678038\n",
      "Epoch: 3782, Train Loss: 0.004959526006132364, Valid Loss: 0.0058123879134655\n",
      "Epoch: 3783, Train Loss: 0.004955556243658066, Valid Loss: 0.005807892885059118\n",
      "Epoch: 3784, Train Loss: 0.004951599054038525, Valid Loss: 0.005803355015814304\n",
      "Epoch: 3785, Train Loss: 0.004947638139128685, Valid Loss: 0.005798784550279379\n",
      "Epoch: 3786, Train Loss: 0.004943689331412315, Valid Loss: 0.0057943109422922134\n",
      "Epoch: 3787, Train Loss: 0.0049397386610507965, Valid Loss: 0.005789820570498705\n",
      "Epoch: 3788, Train Loss: 0.004935805685818195, Valid Loss: 0.005785341374576092\n",
      "Epoch: 3789, Train Loss: 0.0049318731762468815, Valid Loss: 0.005780830513685942\n",
      "Epoch: 3790, Train Loss: 0.0049279252998530865, Valid Loss: 0.0057763755321502686\n",
      "Epoch: 3791, Train Loss: 0.004923991393297911, Valid Loss: 0.005771912168711424\n",
      "Epoch: 3792, Train Loss: 0.0049200644716620445, Valid Loss: 0.005767429247498512\n",
      "Epoch: 3793, Train Loss: 0.004916138481348753, Valid Loss: 0.00576299661770463\n",
      "Epoch: 3794, Train Loss: 0.004912219941616058, Valid Loss: 0.005758593790233135\n",
      "Epoch: 3795, Train Loss: 0.004908306058496237, Valid Loss: 0.005754179786890745\n",
      "Epoch: 3796, Train Loss: 0.004904390778392553, Valid Loss: 0.0057497103698551655\n",
      "Epoch: 3797, Train Loss: 0.004900488071143627, Valid Loss: 0.005745323840528727\n",
      "Epoch: 3798, Train Loss: 0.00489658210426569, Valid Loss: 0.0057409596629440784\n",
      "Epoch: 3799, Train Loss: 0.004892678000032902, Valid Loss: 0.00573656614869833\n",
      "Epoch: 3800, Train Loss: 0.004888780880719423, Valid Loss: 0.005732161458581686\n",
      "Epoch: 3801, Train Loss: 0.00488489493727684, Valid Loss: 0.0057278103195130825\n",
      "Epoch: 3802, Train Loss: 0.004881004337221384, Valid Loss: 0.005723504349589348\n",
      "Epoch: 3803, Train Loss: 0.004877127707004547, Valid Loss: 0.005719131324440241\n",
      "Epoch: 3804, Train Loss: 0.004873240832239389, Valid Loss: 0.005714812781661749\n",
      "Epoch: 3805, Train Loss: 0.004869361408054829, Valid Loss: 0.0057104905135929585\n",
      "Epoch: 3806, Train Loss: 0.004865500144660473, Valid Loss: 0.005706212483346462\n",
      "Epoch: 3807, Train Loss: 0.0048616244457662106, Valid Loss: 0.005701885093003511\n",
      "Epoch: 3808, Train Loss: 0.004857758060097694, Valid Loss: 0.00569757167249918\n",
      "Epoch: 3809, Train Loss: 0.004853898659348488, Valid Loss: 0.00569330295547843\n",
      "Epoch: 3810, Train Loss: 0.00485004298388958, Valid Loss: 0.005689060781151056\n",
      "Epoch: 3811, Train Loss: 0.004846194759011269, Valid Loss: 0.005684791132807732\n",
      "Epoch: 3812, Train Loss: 0.004842344205826521, Valid Loss: 0.005680512636899948\n",
      "Epoch: 3813, Train Loss: 0.0048385001718997955, Valid Loss: 0.0056762900203466415\n",
      "Epoch: 3814, Train Loss: 0.004834666848182678, Valid Loss: 0.005672097206115723\n",
      "Epoch: 3815, Train Loss: 0.004830822814255953, Valid Loss: 0.005667814984917641\n",
      "Epoch: 3816, Train Loss: 0.004826994612812996, Valid Loss: 0.005663660820573568\n",
      "Epoch: 3817, Train Loss: 0.004823160823434591, Valid Loss: 0.005659444257616997\n",
      "Epoch: 3818, Train Loss: 0.004819341469556093, Valid Loss: 0.00565525284036994\n",
      "Epoch: 3819, Train Loss: 0.004815516993403435, Valid Loss: 0.0056510851718485355\n",
      "Epoch: 3820, Train Loss: 0.004811699967831373, Valid Loss: 0.00564692122861743\n",
      "Epoch: 3821, Train Loss: 0.004807885270565748, Valid Loss: 0.005642741918563843\n",
      "Epoch: 3822, Train Loss: 0.004804084077477455, Valid Loss: 0.005638622213155031\n",
      "Epoch: 3823, Train Loss: 0.004800271242856979, Valid Loss: 0.005634528584778309\n",
      "Epoch: 3824, Train Loss: 0.004796464461833239, Valid Loss: 0.005630373489111662\n",
      "Epoch: 3825, Train Loss: 0.00479267118498683, Valid Loss: 0.005626231897622347\n",
      "Epoch: 3826, Train Loss: 0.004788888152688742, Valid Loss: 0.005622137803584337\n",
      "Epoch: 3827, Train Loss: 0.004785091150552034, Valid Loss: 0.005618073511868715\n",
      "Epoch: 3828, Train Loss: 0.004781304392963648, Valid Loss: 0.005613986868411303\n",
      "Epoch: 3829, Train Loss: 0.004777519963681698, Valid Loss: 0.005609930958598852\n",
      "Epoch: 3830, Train Loss: 0.004773742984980345, Valid Loss: 0.005605836398899555\n",
      "Epoch: 3831, Train Loss: 0.004769966006278992, Valid Loss: 0.005601764190942049\n",
      "Epoch: 3832, Train Loss: 0.004766191355884075, Valid Loss: 0.005597778595983982\n",
      "Epoch: 3833, Train Loss: 0.0047624316066503525, Valid Loss: 0.005593766458332539\n",
      "Epoch: 3834, Train Loss: 0.0047586699947714806, Valid Loss: 0.0055896867997944355\n",
      "Epoch: 3835, Train Loss: 0.004754913039505482, Valid Loss: 0.005585705861449242\n",
      "Epoch: 3836, Train Loss: 0.004751157946884632, Valid Loss: 0.0055817668326199055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3837, Train Loss: 0.004747407510876656, Valid Loss: 0.005577718839049339\n",
      "Epoch: 3838, Train Loss: 0.004743661265820265, Valid Loss: 0.005573743022978306\n",
      "Epoch: 3839, Train Loss: 0.004739911295473576, Valid Loss: 0.00556985242292285\n",
      "Epoch: 3840, Train Loss: 0.004736169707030058, Valid Loss: 0.005565866362303495\n",
      "Epoch: 3841, Train Loss: 0.00473244022578001, Valid Loss: 0.005561875645071268\n",
      "Epoch: 3842, Train Loss: 0.004728710278868675, Valid Loss: 0.005557998549193144\n",
      "Epoch: 3843, Train Loss: 0.004724972415715456, Valid Loss: 0.0055541167967021465\n",
      "Epoch: 3844, Train Loss: 0.004721248056739569, Valid Loss: 0.005550156347453594\n",
      "Epoch: 3845, Train Loss: 0.00471753254532814, Valid Loss: 0.005546231288462877\n",
      "Epoch: 3846, Train Loss: 0.004713818430900574, Valid Loss: 0.00554243428632617\n",
      "Epoch: 3847, Train Loss: 0.004710097331553698, Valid Loss: 0.005538543686270714\n",
      "Epoch: 3848, Train Loss: 0.004706390202045441, Valid Loss: 0.005534602794796228\n",
      "Epoch: 3849, Train Loss: 0.0047026886604726315, Valid Loss: 0.005530807189643383\n",
      "Epoch: 3850, Train Loss: 0.004698983859270811, Valid Loss: 0.005527017638087273\n",
      "Epoch: 3851, Train Loss: 0.004695284180343151, Valid Loss: 0.0055231256410479546\n",
      "Epoch: 3852, Train Loss: 0.004691588692367077, Valid Loss: 0.005519296508282423\n",
      "Epoch: 3853, Train Loss: 0.004687904845923185, Valid Loss: 0.005515535362064838\n",
      "Epoch: 3854, Train Loss: 0.0046842158772051334, Valid Loss: 0.005511727184057236\n",
      "Epoch: 3855, Train Loss: 0.004680536687374115, Valid Loss: 0.005507894791662693\n",
      "Epoch: 3856, Train Loss: 0.004676855634897947, Valid Loss: 0.00550414901226759\n",
      "Epoch: 3857, Train Loss: 0.004673178307712078, Valid Loss: 0.005500431638211012\n",
      "Epoch: 3858, Train Loss: 0.004669515416026115, Valid Loss: 0.0054966164752841\n",
      "Epoch: 3859, Train Loss: 0.00466583389788866, Valid Loss: 0.005492855794727802\n",
      "Epoch: 3860, Train Loss: 0.004662180785089731, Valid Loss: 0.005489189177751541\n",
      "Epoch: 3861, Train Loss: 0.004658516962081194, Valid Loss: 0.0054854899644851685\n",
      "Epoch: 3862, Train Loss: 0.00465485779568553, Valid Loss: 0.005481711123138666\n",
      "Epoch: 3863, Train Loss: 0.0046512046828866005, Valid Loss: 0.005478023085743189\n",
      "Epoch: 3864, Train Loss: 0.004647561348974705, Valid Loss: 0.005474397912621498\n",
      "Epoch: 3865, Train Loss: 0.004643910098820925, Valid Loss: 0.005470668897032738\n",
      "Epoch: 3866, Train Loss: 0.004640268161892891, Valid Loss: 0.00546698272228241\n",
      "Epoch: 3867, Train Loss: 0.004636632278561592, Valid Loss: 0.005463351495563984\n",
      "Epoch: 3868, Train Loss: 0.004632994532585144, Valid Loss: 0.005459694191813469\n",
      "Epoch: 3869, Train Loss: 0.004629364237189293, Valid Loss: 0.005456061568111181\n",
      "Epoch: 3870, Train Loss: 0.0046257441863417625, Valid Loss: 0.005452433601021767\n",
      "Epoch: 3871, Train Loss: 0.004622121341526508, Valid Loss: 0.005448857322335243\n",
      "Epoch: 3872, Train Loss: 0.004618495237082243, Valid Loss: 0.005445254035294056\n",
      "Epoch: 3873, Train Loss: 0.00461488077417016, Valid Loss: 0.005441646091639996\n",
      "Epoch: 3874, Train Loss: 0.004611266311258078, Valid Loss: 0.0054380702786147594\n",
      "Epoch: 3875, Train Loss: 0.004607656970620155, Valid Loss: 0.005434522405266762\n",
      "Epoch: 3876, Train Loss: 0.004604059271514416, Valid Loss: 0.005430953577160835\n",
      "Epoch: 3877, Train Loss: 0.0046004545874893665, Valid Loss: 0.005427391733974218\n",
      "Epoch: 3878, Train Loss: 0.004596863407641649, Valid Loss: 0.005423895549029112\n",
      "Epoch: 3879, Train Loss: 0.004593262914568186, Valid Loss: 0.005420359782874584\n",
      "Epoch: 3880, Train Loss: 0.004589678253978491, Valid Loss: 0.005416780710220337\n",
      "Epoch: 3881, Train Loss: 0.0045860870741307735, Valid Loss: 0.005413319915533066\n",
      "Epoch: 3882, Train Loss: 0.004582513123750687, Valid Loss: 0.005409877281636\n",
      "Epoch: 3883, Train Loss: 0.004578928928822279, Valid Loss: 0.00540634710341692\n",
      "Epoch: 3884, Train Loss: 0.0045753587037324905, Valid Loss: 0.005402860231697559\n",
      "Epoch: 3885, Train Loss: 0.004571781028062105, Valid Loss: 0.005399414803832769\n",
      "Epoch: 3886, Train Loss: 0.0045682149939239025, Valid Loss: 0.005395984742790461\n",
      "Epoch: 3887, Train Loss: 0.004564651753753424, Valid Loss: 0.005392523016780615\n",
      "Epoch: 3888, Train Loss: 0.004561092238873243, Valid Loss: 0.005389124155044556\n",
      "Epoch: 3889, Train Loss: 0.004557535983622074, Valid Loss: 0.005385708995163441\n",
      "Epoch: 3890, Train Loss: 0.004553982522338629, Valid Loss: 0.005382264032959938\n",
      "Epoch: 3891, Train Loss: 0.004550434183329344, Valid Loss: 0.005378855857998133\n",
      "Epoch: 3892, Train Loss: 0.0045468867756426334, Valid Loss: 0.005375527311116457\n",
      "Epoch: 3893, Train Loss: 0.004543344955891371, Valid Loss: 0.005372123792767525\n",
      "Epoch: 3894, Train Loss: 0.004539804998785257, Valid Loss: 0.005368730518966913\n",
      "Epoch: 3895, Train Loss: 0.004536265507340431, Valid Loss: 0.005365380086004734\n",
      "Epoch: 3896, Train Loss: 0.004532738123089075, Valid Loss: 0.005362054333090782\n",
      "Epoch: 3897, Train Loss: 0.004529209807515144, Valid Loss: 0.005358727648854256\n",
      "Epoch: 3898, Train Loss: 0.004525688476860523, Valid Loss: 0.0053553800098598\n",
      "Epoch: 3899, Train Loss: 0.004522165283560753, Valid Loss: 0.005352043081074953\n",
      "Epoch: 3900, Train Loss: 0.004518646281212568, Valid Loss: 0.005348765291273594\n",
      "Epoch: 3901, Train Loss: 0.004515130538493395, Valid Loss: 0.0053454311564564705\n",
      "Epoch: 3902, Train Loss: 0.004511627368628979, Valid Loss: 0.005342145450413227\n",
      "Epoch: 3903, Train Loss: 0.004508122336119413, Valid Loss: 0.00533895380795002\n",
      "Epoch: 3904, Train Loss: 0.004504616837948561, Valid Loss: 0.005335642024874687\n",
      "Epoch: 3905, Train Loss: 0.004501122049987316, Valid Loss: 0.005332338623702526\n",
      "Epoch: 3906, Train Loss: 0.004497626796364784, Valid Loss: 0.005329130683094263\n",
      "Epoch: 3907, Train Loss: 0.004494135733693838, Valid Loss: 0.005325919948518276\n",
      "Epoch: 3908, Train Loss: 0.00449065025895834, Valid Loss: 0.005322673358023167\n",
      "Epoch: 3909, Train Loss: 0.004487159196287394, Valid Loss: 0.0053194016218185425\n",
      "Epoch: 3910, Train Loss: 0.004483681637793779, Valid Loss: 0.0053162709809839725\n",
      "Epoch: 3911, Train Loss: 0.004480202682316303, Valid Loss: 0.005313067231327295\n",
      "Epoch: 3912, Train Loss: 0.0044767283834517, Valid Loss: 0.005309858359396458\n",
      "Epoch: 3913, Train Loss: 0.004473263397812843, Valid Loss: 0.0053066653199493885\n",
      "Epoch: 3914, Train Loss: 0.004469792824238539, Valid Loss: 0.005303528159856796\n",
      "Epoch: 3915, Train Loss: 0.0044663348235189915, Valid Loss: 0.005300351418554783\n",
      "Epoch: 3916, Train Loss: 0.004462872166186571, Valid Loss: 0.005297193303704262\n",
      "Epoch: 3917, Train Loss: 0.004459420684725046, Valid Loss: 0.005294062662869692\n",
      "Epoch: 3918, Train Loss: 0.00445596594363451, Valid Loss: 0.005290925968438387\n",
      "Epoch: 3919, Train Loss: 0.004452514927834272, Valid Loss: 0.005287808366119862\n",
      "Epoch: 3920, Train Loss: 0.00444906996563077, Valid Loss: 0.0052846986800432205\n",
      "Epoch: 3921, Train Loss: 0.004445632919669151, Valid Loss: 0.005281589459627867\n",
      "Epoch: 3922, Train Loss: 0.004442191682755947, Valid Loss: 0.005278487224131823\n",
      "Epoch: 3923, Train Loss: 0.004438754636794329, Valid Loss: 0.005275378003716469\n",
      "Epoch: 3924, Train Loss: 0.004435330163687468, Valid Loss: 0.005272319540381432\n",
      "Epoch: 3925, Train Loss: 0.004431906156241894, Valid Loss: 0.005269297864288092\n",
      "Epoch: 3926, Train Loss: 0.004428483080118895, Valid Loss: 0.005266200285404921\n",
      "Epoch: 3927, Train Loss: 0.00442506093531847, Valid Loss: 0.005263098515570164\n",
      "Epoch: 3928, Train Loss: 0.00442163972184062, Valid Loss: 0.00526008615270257\n",
      "Epoch: 3929, Train Loss: 0.00441823061555624, Valid Loss: 0.005257070064544678\n",
      "Epoch: 3930, Train Loss: 0.004414824768900871, Valid Loss: 0.005254033952951431\n",
      "Epoch: 3931, Train Loss: 0.004411417059600353, Valid Loss: 0.005251026712357998\n",
      "Epoch: 3932, Train Loss: 0.004408017732203007, Valid Loss: 0.005247998051345348\n",
      "Epoch: 3933, Train Loss: 0.0044046202674508095, Valid Loss: 0.005244992207735777\n",
      "Epoch: 3934, Train Loss: 0.004401216749101877, Valid Loss: 0.005242008715867996\n",
      "Epoch: 3935, Train Loss: 0.0043978276662528515, Valid Loss: 0.005239033605903387\n",
      "Epoch: 3936, Train Loss: 0.004394442308694124, Valid Loss: 0.0052360356785357\n",
      "Epoch: 3937, Train Loss: 0.004391051828861237, Valid Loss: 0.005233070347458124\n",
      "Epoch: 3938, Train Loss: 0.004387677647173405, Valid Loss: 0.005230066832154989\n",
      "Epoch: 3939, Train Loss: 0.004384299740195274, Valid Loss: 0.005227146670222282\n",
      "Epoch: 3940, Train Loss: 0.004380926955491304, Valid Loss: 0.005224219523370266\n",
      "Epoch: 3941, Train Loss: 0.004377554636448622, Valid Loss: 0.005221245344728231\n",
      "Epoch: 3942, Train Loss: 0.0043741920962929726, Valid Loss: 0.005218317732214928\n",
      "Epoch: 3943, Train Loss: 0.0043708267621695995, Valid Loss: 0.00521539431065321\n",
      "Epoch: 3944, Train Loss: 0.0043674674816429615, Valid Loss: 0.005212487652897835\n",
      "Epoch: 3945, Train Loss: 0.004364111926406622, Valid Loss: 0.005209578201174736\n",
      "Epoch: 3946, Train Loss: 0.004360753111541271, Valid Loss: 0.005206678062677383\n",
      "Epoch: 3947, Train Loss: 0.004357405938208103, Valid Loss: 0.005203749518841505\n",
      "Epoch: 3948, Train Loss: 0.004354068543761969, Valid Loss: 0.005200873129069805\n",
      "Epoch: 3949, Train Loss: 0.004350714851170778, Valid Loss: 0.005197959952056408\n",
      "Epoch: 3950, Train Loss: 0.004347383044660091, Valid Loss: 0.005195151083171368\n",
      "Epoch: 3951, Train Loss: 0.004344044718891382, Valid Loss: 0.0051922607235610485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3952, Train Loss: 0.00434071384370327, Valid Loss: 0.0051893931813538074\n",
      "Epoch: 3953, Train Loss: 0.0043373797088861465, Valid Loss: 0.005186539143323898\n",
      "Epoch: 3954, Train Loss: 0.004334054421633482, Valid Loss: 0.0051836613565683365\n",
      "Epoch: 3955, Train Loss: 0.004330740310251713, Valid Loss: 0.005180854815989733\n",
      "Epoch: 3956, Train Loss: 0.004327427130192518, Valid Loss: 0.0051780217327177525\n",
      "Epoch: 3957, Train Loss: 0.004324106965214014, Valid Loss: 0.0051751649007201195\n",
      "Epoch: 3958, Train Loss: 0.004320796113461256, Valid Loss: 0.0051723141223192215\n",
      "Epoch: 3959, Train Loss: 0.004317488055676222, Valid Loss: 0.005169549956917763\n",
      "Epoch: 3960, Train Loss: 0.0043141827918589115, Valid Loss: 0.005166730843484402\n",
      "Epoch: 3961, Train Loss: 0.00431088637560606, Valid Loss: 0.005163908004760742\n",
      "Epoch: 3962, Train Loss: 0.004307585768401623, Valid Loss: 0.0051610954105854034\n",
      "Epoch: 3963, Train Loss: 0.004304300062358379, Valid Loss: 0.005158328451216221\n",
      "Epoch: 3964, Train Loss: 0.004301000386476517, Valid Loss: 0.005155513994395733\n",
      "Epoch: 3965, Train Loss: 0.004297714680433273, Valid Loss: 0.005152741447091103\n",
      "Epoch: 3966, Train Loss: 0.004294433631002903, Valid Loss: 0.005149997305124998\n",
      "Epoch: 3967, Train Loss: 0.004291153512895107, Valid Loss: 0.005147167015820742\n",
      "Epoch: 3968, Train Loss: 0.004287876188755035, Valid Loss: 0.005144383758306503\n",
      "Epoch: 3969, Train Loss: 0.004284603055566549, Valid Loss: 0.005141647066920996\n",
      "Epoch: 3970, Train Loss: 0.004281334578990936, Valid Loss: 0.005138942040503025\n",
      "Epoch: 3971, Train Loss: 0.004278066102415323, Valid Loss: 0.005136133637279272\n",
      "Epoch: 3972, Train Loss: 0.004274806939065456, Valid Loss: 0.005133380182087421\n",
      "Epoch: 3973, Train Loss: 0.004271544050425291, Valid Loss: 0.005130676552653313\n",
      "Epoch: 3974, Train Loss: 0.004268290009349585, Valid Loss: 0.005127928219735622\n",
      "Epoch: 3975, Train Loss: 0.004265038762241602, Valid Loss: 0.005125158466398716\n",
      "Epoch: 3976, Train Loss: 0.004261788446456194, Valid Loss: 0.005122448317706585\n",
      "Epoch: 3977, Train Loss: 0.004258544184267521, Valid Loss: 0.005119731649756432\n",
      "Epoch: 3978, Train Loss: 0.004255298059433699, Valid Loss: 0.005117007996886969\n",
      "Epoch: 3979, Train Loss: 0.004252062179148197, Valid Loss: 0.005114268511533737\n",
      "Epoch: 3980, Train Loss: 0.0042488304898142815, Valid Loss: 0.0051115876995027065\n",
      "Epoch: 3981, Train Loss: 0.004245592746883631, Valid Loss: 0.005108855199068785\n",
      "Epoch: 3982, Train Loss: 0.004242369905114174, Valid Loss: 0.005106148310005665\n",
      "Epoch: 3983, Train Loss: 0.0042391447350382805, Valid Loss: 0.005103470757603645\n",
      "Epoch: 3984, Train Loss: 0.004235913977026939, Valid Loss: 0.0051007624715566635\n",
      "Epoch: 3985, Train Loss: 0.004232697654515505, Valid Loss: 0.005098059307783842\n",
      "Epoch: 3986, Train Loss: 0.004229479003697634, Valid Loss: 0.005095375701785088\n",
      "Epoch: 3987, Train Loss: 0.00422627292573452, Valid Loss: 0.005092689301818609\n",
      "Epoch: 3988, Train Loss: 0.004223063122481108, Valid Loss: 0.005089984741061926\n",
      "Epoch: 3989, Train Loss: 0.004219855647534132, Valid Loss: 0.0050873542204499245\n",
      "Epoch: 3990, Train Loss: 0.00421665795147419, Valid Loss: 0.005084657110273838\n",
      "Epoch: 3991, Train Loss: 0.004213465377688408, Valid Loss: 0.005082000512629747\n",
      "Epoch: 3992, Train Loss: 0.004210265818983316, Valid Loss: 0.005079283844679594\n",
      "Epoch: 3993, Train Loss: 0.004207079764455557, Valid Loss: 0.005076632369309664\n",
      "Epoch: 3994, Train Loss: 0.004203887656331062, Valid Loss: 0.00507399020716548\n",
      "Epoch: 3995, Train Loss: 0.004200703930109739, Valid Loss: 0.005071314517408609\n",
      "Epoch: 3996, Train Loss: 0.0041975220665335655, Valid Loss: 0.00506864907220006\n",
      "Epoch: 3997, Train Loss: 0.004194342996925116, Valid Loss: 0.005066001787781715\n",
      "Epoch: 3998, Train Loss: 0.004191168118268251, Valid Loss: 0.005063308402895927\n",
      "Epoch: 3999, Train Loss: 0.004187996964901686, Valid Loss: 0.005060700234025717\n",
      "Epoch: 4000, Train Loss: 0.004184825345873833, Valid Loss: 0.005058052949607372\n",
      "Epoch: 4001, Train Loss: 0.004181660246104002, Valid Loss: 0.0050553930923342705\n",
      "Epoch: 4002, Train Loss: 0.0041784984059631824, Valid Loss: 0.005052723456174135\n",
      "Epoch: 4003, Train Loss: 0.004175346344709396, Valid Loss: 0.0050501273944973946\n",
      "Epoch: 4004, Train Loss: 0.0041721840389072895, Valid Loss: 0.005047482438385487\n",
      "Epoch: 4005, Train Loss: 0.004169038962572813, Valid Loss: 0.005044838413596153\n",
      "Epoch: 4006, Train Loss: 0.00416588643565774, Valid Loss: 0.005042176228016615\n",
      "Epoch: 4007, Train Loss: 0.004162742290645838, Valid Loss: 0.0050395699217915535\n",
      "Epoch: 4008, Train Loss: 0.0041595930233597755, Valid Loss: 0.005036941729485989\n",
      "Epoch: 4009, Train Loss: 0.00415645819157362, Valid Loss: 0.005034293048083782\n",
      "Epoch: 4010, Train Loss: 0.0041533284820616245, Valid Loss: 0.005031665787100792\n",
      "Epoch: 4011, Train Loss: 0.004150195512920618, Valid Loss: 0.0050290413200855255\n",
      "Epoch: 4012, Train Loss: 0.004147064872086048, Valid Loss: 0.0050264084711670876\n",
      "Epoch: 4013, Train Loss: 0.004143941216170788, Valid Loss: 0.005023786332458258\n",
      "Epoch: 4014, Train Loss: 0.004140818491578102, Valid Loss: 0.0050211576744914055\n",
      "Epoch: 4015, Train Loss: 0.004137698095291853, Valid Loss: 0.005018562078475952\n",
      "Epoch: 4016, Train Loss: 0.00413458002731204, Valid Loss: 0.005015897564589977\n",
      "Epoch: 4017, Train Loss: 0.0041314722038805485, Valid Loss: 0.005013292655348778\n",
      "Epoch: 4018, Train Loss: 0.004128362517803907, Valid Loss: 0.005010670516639948\n",
      "Epoch: 4019, Train Loss: 0.00412525562569499, Valid Loss: 0.005008023232221603\n",
      "Epoch: 4020, Train Loss: 0.004122151527553797, Valid Loss: 0.005005442537367344\n",
      "Epoch: 4021, Train Loss: 0.004119056276977062, Valid Loss: 0.005002811085432768\n",
      "Epoch: 4022, Train Loss: 0.004115961026400328, Valid Loss: 0.005000164732336998\n",
      "Epoch: 4023, Train Loss: 0.0041128662414848804, Valid Loss: 0.004997570067644119\n",
      "Epoch: 4024, Train Loss: 0.004109780769795179, Valid Loss: 0.004994971677660942\n",
      "Epoch: 4025, Train Loss: 0.0041066925041377544, Valid Loss: 0.004992342088371515\n",
      "Epoch: 4026, Train Loss: 0.004103608429431915, Valid Loss: 0.0049897003918886185\n",
      "Epoch: 4027, Train Loss: 0.004100527614355087, Valid Loss: 0.0049871401861310005\n",
      "Epoch: 4028, Train Loss: 0.004097449593245983, Valid Loss: 0.004984491039067507\n",
      "Epoch: 4029, Train Loss: 0.004094375763088465, Valid Loss: 0.004981854930520058\n",
      "Epoch: 4030, Train Loss: 0.004091303795576096, Valid Loss: 0.0049792807549238205\n",
      "Epoch: 4031, Train Loss: 0.004088233225047588, Valid Loss: 0.004976654425263405\n",
      "Epoch: 4032, Train Loss: 0.004085177090018988, Valid Loss: 0.004974051378667355\n",
      "Epoch: 4033, Train Loss: 0.004082114901393652, Valid Loss: 0.004971422720700502\n",
      "Epoch: 4034, Train Loss: 0.004079050850123167, Valid Loss: 0.0049688140861690044\n",
      "Epoch: 4035, Train Loss: 0.004076000768691301, Valid Loss: 0.004966182634234428\n",
      "Epoch: 4036, Train Loss: 0.004072949290275574, Valid Loss: 0.004963589832186699\n",
      "Epoch: 4037, Train Loss: 0.004069898743182421, Valid Loss: 0.004960996098816395\n",
      "Epoch: 4038, Train Loss: 0.004066851455718279, Valid Loss: 0.004958350211381912\n",
      "Epoch: 4039, Train Loss: 0.0040638139471411705, Valid Loss: 0.004955712705850601\n",
      "Epoch: 4040, Train Loss: 0.004060776438564062, Valid Loss: 0.004953105002641678\n",
      "Epoch: 4041, Train Loss: 0.004057745914906263, Valid Loss: 0.004950519185513258\n",
      "Epoch: 4042, Train Loss: 0.004054707009345293, Valid Loss: 0.004947897978127003\n",
      "Epoch: 4043, Train Loss: 0.004051681142300367, Valid Loss: 0.0049452693201601505\n",
      "Epoch: 4044, Train Loss: 0.004048652481287718, Valid Loss: 0.004942653700709343\n",
      "Epoch: 4045, Train Loss: 0.004045627545565367, Valid Loss: 0.0049400245770812035\n",
      "Epoch: 4046, Train Loss: 0.004042612388730049, Valid Loss: 0.004937413148581982\n",
      "Epoch: 4047, Train Loss: 0.004039590712636709, Valid Loss: 0.004934794269502163\n",
      "Epoch: 4048, Train Loss: 0.0040365769527852535, Valid Loss: 0.004932194482535124\n",
      "Epoch: 4049, Train Loss: 0.004033567849546671, Valid Loss: 0.004929547663778067\n",
      "Epoch: 4050, Train Loss: 0.0040305620059370995, Valid Loss: 0.004926927853375673\n",
      "Epoch: 4051, Train Loss: 0.004027555696666241, Valid Loss: 0.0049243224784731865\n",
      "Epoch: 4052, Train Loss: 0.004024553578346968, Valid Loss: 0.004921691492199898\n",
      "Epoch: 4053, Train Loss: 0.004021551460027695, Valid Loss: 0.004919054917991161\n",
      "Epoch: 4054, Train Loss: 0.004018561914563179, Valid Loss: 0.004916405770927668\n",
      "Epoch: 4055, Train Loss: 0.004015567246824503, Valid Loss: 0.004913792479783297\n",
      "Epoch: 4056, Train Loss: 0.004012580495327711, Valid Loss: 0.004911173600703478\n",
      "Epoch: 4057, Train Loss: 0.004009592346847057, Valid Loss: 0.004908532369881868\n",
      "Epoch: 4058, Train Loss: 0.004006612114608288, Valid Loss: 0.004905915353447199\n",
      "Epoch: 4059, Train Loss: 0.004003628622740507, Valid Loss: 0.004903268534690142\n",
      "Epoch: 4060, Train Loss: 0.004000658635050058, Valid Loss: 0.004900634754449129\n",
      "Epoch: 4061, Train Loss: 0.003997682593762875, Valid Loss: 0.0048980205319821835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4062, Train Loss: 0.00399471540004015, Valid Loss: 0.004895405378192663\n",
      "Epoch: 4063, Train Loss: 0.003991739824414253, Valid Loss: 0.004892725497484207\n",
      "Epoch: 4064, Train Loss: 0.003988771233707666, Valid Loss: 0.004890103358775377\n",
      "Epoch: 4065, Train Loss: 0.003985818475484848, Valid Loss: 0.004887463059276342\n",
      "Epoch: 4066, Train Loss: 0.003982855938374996, Valid Loss: 0.004884826950728893\n",
      "Epoch: 4067, Train Loss: 0.003979904111474752, Valid Loss: 0.004882201086729765\n",
      "Epoch: 4068, Train Loss: 0.0039769504219293594, Valid Loss: 0.004879514686763287\n",
      "Epoch: 4069, Train Loss: 0.00397399952635169, Valid Loss: 0.0048769088461995125\n",
      "Epoch: 4070, Train Loss: 0.003971050027757883, Valid Loss: 0.004874222446233034\n",
      "Epoch: 4071, Train Loss: 0.003968110308051109, Valid Loss: 0.004871586337685585\n",
      "Epoch: 4072, Train Loss: 0.00396516639739275, Valid Loss: 0.0048689525574445724\n",
      "Epoch: 4073, Train Loss: 0.0039622364565730095, Valid Loss: 0.004866324830800295\n",
      "Epoch: 4074, Train Loss: 0.00395929953083396, Valid Loss: 0.0048636202700436115\n",
      "Epoch: 4075, Train Loss: 0.003956368658691645, Valid Loss: 0.0048609767109155655\n",
      "Epoch: 4076, Train Loss: 0.003953434061259031, Valid Loss: 0.004858344327658415\n",
      "Epoch: 4077, Train Loss: 0.003950513433665037, Valid Loss: 0.00485571613535285\n",
      "Epoch: 4078, Train Loss: 0.003947591874748468, Valid Loss: 0.0048530008643865585\n",
      "Epoch: 4079, Train Loss: 0.003944663796573877, Valid Loss: 0.004850312601774931\n",
      "Epoch: 4080, Train Loss: 0.003941755276173353, Valid Loss: 0.004847733303904533\n",
      "Epoch: 4081, Train Loss: 0.003938845358788967, Valid Loss: 0.004845068324357271\n",
      "Epoch: 4082, Train Loss: 0.0039359284564852715, Valid Loss: 0.004842361900955439\n",
      "Epoch: 4083, Train Loss: 0.003933021333068609, Valid Loss: 0.004839666187763214\n",
      "Epoch: 4084, Train Loss: 0.003930112347006798, Valid Loss: 0.004837054759263992\n",
      "Epoch: 4085, Train Loss: 0.003927217796444893, Valid Loss: 0.004834344610571861\n",
      "Epoch: 4086, Train Loss: 0.003924320451915264, Valid Loss: 0.004831694532185793\n",
      "Epoch: 4087, Train Loss: 0.003921419382095337, Valid Loss: 0.004829044453799725\n",
      "Epoch: 4088, Train Loss: 0.003918529953807592, Valid Loss: 0.004826357588171959\n",
      "Epoch: 4089, Train Loss: 0.003915639594197273, Valid Loss: 0.004823646973818541\n",
      "Epoch: 4090, Train Loss: 0.003912753891199827, Valid Loss: 0.004820982925593853\n",
      "Epoch: 4091, Train Loss: 0.003909872379153967, Valid Loss: 0.004818350542336702\n",
      "Epoch: 4092, Train Loss: 0.0039069876074790955, Valid Loss: 0.004815653432160616\n",
      "Epoch: 4093, Train Loss: 0.003904110984876752, Valid Loss: 0.004812929313629866\n",
      "Epoch: 4094, Train Loss: 0.003901231335476041, Valid Loss: 0.004810260608792305\n",
      "Epoch: 4095, Train Loss: 0.0038983612321317196, Valid Loss: 0.004807624965906143\n",
      "Epoch: 4096, Train Loss: 0.0038954850751906633, Valid Loss: 0.004804861731827259\n",
      "Epoch: 4097, Train Loss: 0.003892625914886594, Valid Loss: 0.004802193492650986\n",
      "Epoch: 4098, Train Loss: 0.0038897537160664797, Valid Loss: 0.004799529444426298\n",
      "Epoch: 4099, Train Loss: 0.0038868975825607777, Valid Loss: 0.004796813707798719\n",
      "Epoch: 4100, Train Loss: 0.0038840421475470066, Valid Loss: 0.004794114734977484\n",
      "Epoch: 4101, Train Loss: 0.0038811827544122934, Valid Loss: 0.004791449289768934\n",
      "Epoch: 4102, Train Loss: 0.003878330811858177, Valid Loss: 0.004788742866367102\n",
      "Epoch: 4103, Train Loss: 0.0038754879496991634, Valid Loss: 0.004786036908626556\n",
      "Epoch: 4104, Train Loss: 0.003872631350532174, Valid Loss: 0.004783327691257\n",
      "Epoch: 4105, Train Loss: 0.0038697898853570223, Valid Loss: 0.0047806380316615105\n",
      "Epoch: 4106, Train Loss: 0.003866951446980238, Valid Loss: 0.004777922760695219\n",
      "Epoch: 4107, Train Loss: 0.0038641123101115227, Valid Loss: 0.004775216802954674\n",
      "Epoch: 4108, Train Loss: 0.003861277597025037, Valid Loss: 0.004772530402988195\n",
      "Epoch: 4109, Train Loss: 0.0038584447465837, Valid Loss: 0.004769828636199236\n",
      "Epoch: 4110, Train Loss: 0.003855613060295582, Valid Loss: 0.004767128266394138\n",
      "Epoch: 4111, Train Loss: 0.0038527841679751873, Valid Loss: 0.004764394368976355\n",
      "Epoch: 4112, Train Loss: 0.003849962493404746, Valid Loss: 0.004761664662510157\n",
      "Epoch: 4113, Train Loss: 0.0038471396546810865, Valid Loss: 0.004758938681334257\n",
      "Epoch: 4114, Train Loss: 0.0038443254306912422, Valid Loss: 0.004756266251206398\n",
      "Epoch: 4115, Train Loss: 0.003841505851596594, Valid Loss: 0.0047535365447402\n",
      "Epoch: 4116, Train Loss: 0.003838689299300313, Valid Loss: 0.004750789608806372\n",
      "Epoch: 4117, Train Loss: 0.0038358867168426514, Valid Loss: 0.004748099949210882\n",
      "Epoch: 4118, Train Loss: 0.0038330762181431055, Valid Loss: 0.0047453599981963634\n",
      "Epoch: 4119, Train Loss: 0.0038302738685160875, Valid Loss: 0.004742635414004326\n",
      "Epoch: 4120, Train Loss: 0.0038274682592600584, Valid Loss: 0.004739933647215366\n",
      "Epoch: 4121, Train Loss: 0.0038246670737862587, Valid Loss: 0.004737203940749168\n",
      "Epoch: 4122, Train Loss: 0.0038218763656914234, Valid Loss: 0.004734456539154053\n",
      "Epoch: 4123, Train Loss: 0.003819080302491784, Valid Loss: 0.004731724504381418\n",
      "Epoch: 4124, Train Loss: 0.0038162879645824432, Valid Loss: 0.004729020409286022\n",
      "Epoch: 4125, Train Loss: 0.003813500516116619, Valid Loss: 0.004726305603981018\n",
      "Epoch: 4126, Train Loss: 0.00381071656011045, Valid Loss: 0.004723553545773029\n",
      "Epoch: 4127, Train Loss: 0.003807931672781706, Valid Loss: 0.0047207907773554325\n",
      "Epoch: 4128, Train Loss: 0.0038051577284932137, Valid Loss: 0.004718089010566473\n",
      "Epoch: 4129, Train Loss: 0.003802381455898285, Valid Loss: 0.004715367686003447\n",
      "Epoch: 4130, Train Loss: 0.0037996089085936546, Valid Loss: 0.004712605848908424\n",
      "Epoch: 4131, Train Loss: 0.0037968286778777838, Valid Loss: 0.004709855653345585\n",
      "Epoch: 4132, Train Loss: 0.003794062649831176, Valid Loss: 0.004707107320427895\n",
      "Epoch: 4133, Train Loss: 0.003791287774220109, Valid Loss: 0.004704368766397238\n",
      "Epoch: 4134, Train Loss: 0.003788539906963706, Valid Loss: 0.00470165116712451\n",
      "Epoch: 4135, Train Loss: 0.003785776672884822, Valid Loss: 0.004698879551142454\n",
      "Epoch: 4136, Train Loss: 0.003783016698434949, Valid Loss: 0.004696153569966555\n",
      "Epoch: 4137, Train Loss: 0.003780258586630225, Valid Loss: 0.004693412687629461\n",
      "Epoch: 4138, Train Loss: 0.003777500707656145, Valid Loss: 0.004690640140324831\n",
      "Epoch: 4139, Train Loss: 0.0037747561000287533, Valid Loss: 0.004687913227826357\n",
      "Epoch: 4140, Train Loss: 0.00377200567163527, Valid Loss: 0.004685159772634506\n",
      "Epoch: 4141, Train Loss: 0.003769263857975602, Valid Loss: 0.004682403057813644\n",
      "Epoch: 4142, Train Loss: 0.0037665199488401413, Valid Loss: 0.004679650533944368\n",
      "Epoch: 4143, Train Loss: 0.0037637909408658743, Valid Loss: 0.004676912445574999\n",
      "Epoch: 4144, Train Loss: 0.003761048661544919, Valid Loss: 0.004674148745834827\n",
      "Epoch: 4145, Train Loss: 0.0037583159282803535, Valid Loss: 0.00467136362567544\n",
      "Epoch: 4146, Train Loss: 0.003755581332370639, Valid Loss: 0.004668616224080324\n",
      "Epoch: 4147, Train Loss: 0.0037528558168560266, Valid Loss: 0.004665907472372055\n",
      "Epoch: 4148, Train Loss: 0.003750131232663989, Valid Loss: 0.004663136787712574\n",
      "Epoch: 4149, Train Loss: 0.003747403621673584, Valid Loss: 0.0046603442169725895\n",
      "Epoch: 4150, Train Loss: 0.003744684159755707, Valid Loss: 0.004657594952732325\n",
      "Epoch: 4151, Train Loss: 0.003741965629160404, Valid Loss: 0.004654862452298403\n",
      "Epoch: 4152, Train Loss: 0.003739249659702182, Valid Loss: 0.004652094561606646\n",
      "Epoch: 4153, Train Loss: 0.003736539278179407, Valid Loss: 0.004649327602237463\n",
      "Epoch: 4154, Train Loss: 0.0037338288966566324, Valid Loss: 0.004646556917577982\n",
      "Epoch: 4155, Train Loss: 0.0037311220075935125, Valid Loss: 0.004643795546144247\n",
      "Epoch: 4156, Train Loss: 0.0037284179124981165, Valid Loss: 0.00464104488492012\n",
      "Epoch: 4157, Train Loss: 0.0037257203366607428, Valid Loss: 0.0046382928267121315\n",
      "Epoch: 4158, Train Loss: 0.0037230157759040594, Valid Loss: 0.0046355240046978\n",
      "Epoch: 4159, Train Loss: 0.003720319364219904, Valid Loss: 0.004632730036973953\n",
      "Epoch: 4160, Train Loss: 0.0037176276091486216, Valid Loss: 0.004629950039088726\n",
      "Epoch: 4161, Train Loss: 0.0037149342242628336, Valid Loss: 0.004627197049558163\n",
      "Epoch: 4162, Train Loss: 0.0037122447974979877, Valid Loss: 0.004624446388334036\n",
      "Epoch: 4163, Train Loss: 0.0037095581647008657, Valid Loss: 0.004621652886271477\n",
      "Epoch: 4164, Train Loss: 0.003706875955685973, Valid Loss: 0.004618869628757238\n",
      "Epoch: 4165, Train Loss: 0.003704201430082321, Valid Loss: 0.004616150166839361\n",
      "Epoch: 4166, Train Loss: 0.003701521549373865, Valid Loss: 0.004613368306308985\n",
      "Epoch: 4167, Train Loss: 0.003698833752423525, Valid Loss: 0.004610572010278702\n",
      "Epoch: 4168, Train Loss: 0.003696167841553688, Valid Loss: 0.004607814364135265\n",
      "Epoch: 4169, Train Loss: 0.0036934956442564726, Valid Loss: 0.004605036228895187\n",
      "Epoch: 4170, Train Loss: 0.0036908299662172794, Valid Loss: 0.004602264612913132\n",
      "Epoch: 4171, Train Loss: 0.003688160562887788, Valid Loss: 0.004599486477673054\n",
      "Epoch: 4172, Train Loss: 0.0036854941863566637, Valid Loss: 0.004596723709255457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4173, Train Loss: 0.0036828394513577223, Valid Loss: 0.004593945108354092\n",
      "Epoch: 4174, Train Loss: 0.003680178429931402, Valid Loss: 0.00459113996475935\n",
      "Epoch: 4175, Train Loss: 0.0036775246262550354, Valid Loss: 0.004588422831147909\n",
      "Epoch: 4176, Train Loss: 0.003674873849377036, Valid Loss: 0.0045856605283916\n",
      "Epoch: 4177, Train Loss: 0.0036722198128700256, Valid Loss: 0.0045828367583453655\n",
      "Epoch: 4178, Train Loss: 0.0036695757880806923, Valid Loss: 0.004580060951411724\n",
      "Epoch: 4179, Train Loss: 0.0036669301334768534, Valid Loss: 0.004577286075800657\n",
      "Epoch: 4180, Train Loss: 0.0036642856430262327, Valid Loss: 0.004574536811560392\n",
      "Epoch: 4181, Train Loss: 0.003661646507680416, Valid Loss: 0.004571765195578337\n",
      "Epoch: 4182, Train Loss: 0.0036590052768588066, Valid Loss: 0.004568959586322308\n",
      "Epoch: 4183, Train Loss: 0.0036563670728355646, Valid Loss: 0.0045661828480660915\n",
      "Epoch: 4184, Train Loss: 0.003653742838650942, Valid Loss: 0.004563430789858103\n",
      "Epoch: 4185, Train Loss: 0.0036511127837002277, Valid Loss: 0.004560631699860096\n",
      "Epoch: 4186, Train Loss: 0.0036484806332737207, Valid Loss: 0.004557863809168339\n",
      "Epoch: 4187, Train Loss: 0.0036458575632423162, Valid Loss: 0.004555097781121731\n",
      "Epoch: 4188, Train Loss: 0.003643232164904475, Valid Loss: 0.004552294500172138\n",
      "Epoch: 4189, Train Loss: 0.0036406151484698057, Valid Loss: 0.004549524746835232\n",
      "Epoch: 4190, Train Loss: 0.0036379972007125616, Valid Loss: 0.004546785261482\n",
      "Epoch: 4191, Train Loss: 0.0036353811156004667, Valid Loss: 0.004543982446193695\n",
      "Epoch: 4192, Train Loss: 0.003632768290117383, Valid Loss: 0.004541207104921341\n",
      "Epoch: 4193, Train Loss: 0.0036301573272794485, Valid Loss: 0.0045384131371974945\n",
      "Epoch: 4194, Train Loss: 0.003627549856901169, Valid Loss: 0.004535676911473274\n",
      "Epoch: 4195, Train Loss: 0.003624947974458337, Valid Loss: 0.004532889928668737\n",
      "Epoch: 4196, Train Loss: 0.0036223391070961952, Valid Loss: 0.0045300875790417194\n",
      "Epoch: 4197, Train Loss: 0.0036197472363710403, Valid Loss: 0.004527302924543619\n",
      "Epoch: 4198, Train Loss: 0.0036171467509120703, Valid Loss: 0.004524548538029194\n",
      "Epoch: 4199, Train Loss: 0.0036145481280982494, Valid Loss: 0.004521782044321299\n",
      "Epoch: 4200, Train Loss: 0.0036119555588811636, Valid Loss: 0.004518996924161911\n",
      "Epoch: 4201, Train Loss: 0.0036093639209866524, Valid Loss: 0.00451618991792202\n",
      "Epoch: 4202, Train Loss: 0.003606776474043727, Valid Loss: 0.004513449501246214\n",
      "Epoch: 4203, Train Loss: 0.0036041955463588238, Valid Loss: 0.004510678816586733\n",
      "Epoch: 4204, Train Loss: 0.0036016099620610476, Valid Loss: 0.004507873672991991\n",
      "Epoch: 4205, Train Loss: 0.003599027870222926, Valid Loss: 0.00450512720271945\n",
      "Epoch: 4206, Train Loss: 0.0035964481066912413, Valid Loss: 0.00450233044102788\n",
      "Epoch: 4207, Train Loss: 0.0035938755609095097, Valid Loss: 0.004499560687690973\n",
      "Epoch: 4208, Train Loss: 0.003591303713619709, Valid Loss: 0.00449678348377347\n",
      "Epoch: 4209, Train Loss: 0.003588728606700897, Valid Loss: 0.00449402816593647\n",
      "Epoch: 4210, Train Loss: 0.0035861635114997625, Valid Loss: 0.004491257481276989\n",
      "Epoch: 4211, Train Loss: 0.0035835937596857548, Valid Loss: 0.004488429985940456\n",
      "Epoch: 4212, Train Loss: 0.00358102610334754, Valid Loss: 0.004485697485506535\n",
      "Epoch: 4213, Train Loss: 0.003578469855710864, Valid Loss: 0.0044829463586211205\n",
      "Epoch: 4214, Train Loss: 0.0035759068559855223, Valid Loss: 0.004480155650526285\n",
      "Epoch: 4215, Train Loss: 0.003573350142687559, Valid Loss: 0.004477381240576506\n",
      "Epoch: 4216, Train Loss: 0.00357079622335732, Valid Loss: 0.004474625922739506\n",
      "Epoch: 4217, Train Loss: 0.0035682443995028734, Valid Loss: 0.0044718231074512005\n",
      "Epoch: 4218, Train Loss: 0.003565699327737093, Valid Loss: 0.004469056148082018\n",
      "Epoch: 4219, Train Loss: 0.0035631514620035887, Valid Loss: 0.004466304089874029\n",
      "Epoch: 4220, Train Loss: 0.003560607321560383, Valid Loss: 0.004463558085262775\n",
      "Epoch: 4221, Train Loss: 0.0035580615513026714, Valid Loss: 0.004460758529603481\n",
      "Epoch: 4222, Train Loss: 0.0035555248614400625, Valid Loss: 0.004457992501556873\n",
      "Epoch: 4223, Train Loss: 0.0035529863089323044, Valid Loss: 0.004455253016203642\n",
      "Epoch: 4224, Train Loss: 0.0035504489205777645, Valid Loss: 0.004452475346624851\n",
      "Epoch: 4225, Train Loss: 0.0035479157231748104, Valid Loss: 0.00444970466196537\n",
      "Epoch: 4226, Train Loss: 0.003545386716723442, Valid Loss: 0.004446931648999453\n",
      "Epoch: 4227, Train Loss: 0.003542863065376878, Valid Loss: 0.0044441791251301765\n",
      "Epoch: 4228, Train Loss: 0.003540337784215808, Valid Loss: 0.004441410303115845\n",
      "Epoch: 4229, Train Loss: 0.0035378101747483015, Valid Loss: 0.00443863682448864\n",
      "Epoch: 4230, Train Loss: 0.0035352937411516905, Valid Loss: 0.004435896407812834\n",
      "Epoch: 4231, Train Loss: 0.003532773582264781, Valid Loss: 0.0044331420212984085\n",
      "Epoch: 4232, Train Loss: 0.0035302555188536644, Valid Loss: 0.004430348053574562\n",
      "Epoch: 4233, Train Loss: 0.0035277390852570534, Valid Loss: 0.004427576437592506\n",
      "Epoch: 4234, Train Loss: 0.0035252333618700504, Valid Loss: 0.004424856510013342\n",
      "Epoch: 4235, Train Loss: 0.003522719256579876, Valid Loss: 0.00442209467291832\n",
      "Epoch: 4236, Train Loss: 0.0035202105063945055, Valid Loss: 0.0044192965142428875\n",
      "Epoch: 4237, Train Loss: 0.0035177115350961685, Valid Loss: 0.004416563082486391\n",
      "Epoch: 4238, Train Loss: 0.003515210235491395, Valid Loss: 0.004413818009197712\n",
      "Epoch: 4239, Train Loss: 0.003512708703055978, Valid Loss: 0.00441106129437685\n",
      "Epoch: 4240, Train Loss: 0.003510212991386652, Valid Loss: 0.004408307373523712\n",
      "Epoch: 4241, Train Loss: 0.0035077137872576714, Valid Loss: 0.004405560437589884\n",
      "Epoch: 4242, Train Loss: 0.003505214350298047, Valid Loss: 0.004402802791446447\n",
      "Epoch: 4243, Train Loss: 0.003502732142806053, Valid Loss: 0.004400020465254784\n",
      "Epoch: 4244, Train Loss: 0.0035002445802092552, Valid Loss: 0.004397280979901552\n",
      "Epoch: 4245, Train Loss: 0.003497755154967308, Valid Loss: 0.004394568968564272\n",
      "Epoch: 4246, Train Loss: 0.0034952708519995213, Valid Loss: 0.004391808994114399\n",
      "Epoch: 4247, Train Loss: 0.0034927844535559416, Valid Loss: 0.004389015957713127\n",
      "Epoch: 4248, Train Loss: 0.003490307368338108, Valid Loss: 0.004386309999972582\n",
      "Epoch: 4249, Train Loss: 0.0034878356382250786, Valid Loss: 0.004383570980280638\n",
      "Epoch: 4250, Train Loss: 0.003485361346974969, Valid Loss: 0.004380819853395224\n",
      "Epoch: 4251, Train Loss: 0.00348288775421679, Valid Loss: 0.004378071054816246\n",
      "Epoch: 4252, Train Loss: 0.003480415791273117, Valid Loss: 0.004375329241156578\n",
      "Epoch: 4253, Train Loss: 0.003477955237030983, Valid Loss: 0.0043725925497710705\n",
      "Epoch: 4254, Train Loss: 0.0034754883963614702, Valid Loss: 0.004369843751192093\n",
      "Epoch: 4255, Train Loss: 0.0034730215556919575, Valid Loss: 0.004367101937532425\n",
      "Epoch: 4256, Train Loss: 0.003470558673143387, Valid Loss: 0.0043643685057759285\n",
      "Epoch: 4257, Train Loss: 0.003468104638159275, Valid Loss: 0.004361608996987343\n",
      "Epoch: 4258, Train Loss: 0.0034656485076993704, Valid Loss: 0.0043588606640696526\n",
      "Epoch: 4259, Train Loss: 0.0034631884191185236, Valid Loss: 0.004356153309345245\n",
      "Epoch: 4260, Train Loss: 0.0034607406705617905, Valid Loss: 0.004353422671556473\n",
      "Epoch: 4261, Train Loss: 0.0034582889638841152, Valid Loss: 0.004350666422396898\n",
      "Epoch: 4262, Train Loss: 0.003455845871940255, Valid Loss: 0.0043479278683662415\n",
      "Epoch: 4263, Train Loss: 0.003453390207141638, Valid Loss: 0.0043452149257063866\n",
      "Epoch: 4264, Train Loss: 0.003450951538980007, Valid Loss: 0.004342508502304554\n",
      "Epoch: 4265, Train Loss: 0.0034485117066651583, Valid Loss: 0.004339741542935371\n",
      "Epoch: 4266, Train Loss: 0.003446076298132539, Valid Loss: 0.0043370225466787815\n",
      "Epoch: 4267, Train Loss: 0.003443636931478977, Valid Loss: 0.004334303550422192\n",
      "Epoch: 4268, Train Loss: 0.003441206179559231, Valid Loss: 0.004331577103585005\n",
      "Epoch: 4269, Train Loss: 0.0034387714695185423, Valid Loss: 0.004328855779021978\n",
      "Epoch: 4270, Train Loss: 0.0034363444428890944, Valid Loss: 0.004326111637055874\n",
      "Epoch: 4271, Train Loss: 0.00343391764909029, Valid Loss: 0.004323407541960478\n",
      "Epoch: 4272, Train Loss: 0.003431488759815693, Valid Loss: 0.004320679232478142\n",
      "Epoch: 4273, Train Loss: 0.003429069882258773, Valid Loss: 0.004317959770560265\n",
      "Epoch: 4274, Train Loss: 0.0034266472794115543, Valid Loss: 0.004315235186368227\n",
      "Epoch: 4275, Train Loss: 0.003424227237701416, Valid Loss: 0.004312526434659958\n",
      "Epoch: 4276, Train Loss: 0.003421818371862173, Valid Loss: 0.004309796262532473\n",
      "Epoch: 4277, Train Loss: 0.003419397631660104, Valid Loss: 0.0043070935644209385\n",
      "Epoch: 4278, Train Loss: 0.003416984109207988, Valid Loss: 0.004304368048906326\n",
      "Epoch: 4279, Train Loss: 0.003414576407521963, Valid Loss: 0.004301678389310837\n",
      "Epoch: 4280, Train Loss: 0.0034121712669730186, Valid Loss: 0.004298961255699396\n",
      "Epoch: 4281, Train Loss: 0.0034097624011337757, Valid Loss: 0.004296251572668552\n",
      "Epoch: 4282, Train Loss: 0.003407364245504141, Valid Loss: 0.004293527919799089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4283, Train Loss: 0.003404958639293909, Valid Loss: 0.004290832206606865\n",
      "Epoch: 4284, Train Loss: 0.0034025616478174925, Valid Loss: 0.004288144875317812\n",
      "Epoch: 4285, Train Loss: 0.003400167217478156, Valid Loss: 0.004285435192286968\n",
      "Epoch: 4286, Train Loss: 0.0033977702260017395, Valid Loss: 0.004282709211111069\n",
      "Epoch: 4287, Train Loss: 0.003395378589630127, Valid Loss: 0.004280019085854292\n",
      "Epoch: 4288, Train Loss: 0.0033929944038391113, Valid Loss: 0.004277345724403858\n",
      "Epoch: 4289, Train Loss: 0.0033905974123626947, Valid Loss: 0.004274636972695589\n",
      "Epoch: 4290, Train Loss: 0.0033882141578942537, Valid Loss: 0.004271915182471275\n",
      "Epoch: 4291, Train Loss: 0.0033858311362564564, Valid Loss: 0.004269230179488659\n",
      "Epoch: 4292, Train Loss: 0.0033834497444331646, Valid Loss: 0.004266503732651472\n",
      "Epoch: 4293, Train Loss: 0.0033810667227953672, Valid Loss: 0.004263826180249453\n",
      "Epoch: 4294, Train Loss: 0.0033786955755203962, Valid Loss: 0.004261159338057041\n",
      "Epoch: 4295, Train Loss: 0.0033763207029551268, Valid Loss: 0.004258482251316309\n",
      "Epoch: 4296, Train Loss: 0.003373946063220501, Valid Loss: 0.004255769774317741\n",
      "Epoch: 4297, Train Loss: 0.0033715732861310244, Valid Loss: 0.004253057762980461\n",
      "Epoch: 4298, Train Loss: 0.0033692053984850645, Valid Loss: 0.0042504011653363705\n",
      "Epoch: 4299, Train Loss: 0.003366839373484254, Valid Loss: 0.0042477380484342575\n",
      "Epoch: 4300, Train Loss: 0.0033644731156527996, Valid Loss: 0.004245011135935783\n",
      "Epoch: 4301, Train Loss: 0.0033621119800955057, Valid Loss: 0.004242324270308018\n",
      "Epoch: 4302, Train Loss: 0.0033597557339817286, Valid Loss: 0.00423969654366374\n",
      "Epoch: 4303, Train Loss: 0.0033573920372873545, Valid Loss: 0.0042369975708425045\n",
      "Epoch: 4304, Train Loss: 0.003355042077600956, Valid Loss: 0.0042343297973275185\n",
      "Epoch: 4305, Train Loss: 0.003352684900164604, Valid Loss: 0.004231625236570835\n",
      "Epoch: 4306, Train Loss: 0.0033503372687846422, Valid Loss: 0.004228958394378424\n",
      "Epoch: 4307, Train Loss: 0.003347987774759531, Valid Loss: 0.0042262994684278965\n",
      "Epoch: 4308, Train Loss: 0.003345632925629616, Valid Loss: 0.004223608877509832\n",
      "Epoch: 4309, Train Loss: 0.003343295305967331, Valid Loss: 0.004220945294946432\n",
      "Epoch: 4310, Train Loss: 0.0033409511670470238, Valid Loss: 0.004218276124447584\n",
      "Epoch: 4311, Train Loss: 0.003338610753417015, Valid Loss: 0.004215626046061516\n",
      "Epoch: 4312, Train Loss: 0.003336267778649926, Valid Loss: 0.0042129443027079105\n",
      "Epoch: 4313, Train Loss: 0.003333938540890813, Valid Loss: 0.004210291896015406\n",
      "Epoch: 4314, Train Loss: 0.0033315967302769423, Valid Loss: 0.004207635298371315\n",
      "Epoch: 4315, Train Loss: 0.0033292656298726797, Valid Loss: 0.004204954952001572\n",
      "Epoch: 4316, Train Loss: 0.0033269328996539116, Valid Loss: 0.004202297888696194\n",
      "Epoch: 4317, Train Loss: 0.0033246022649109364, Valid Loss: 0.004199635237455368\n",
      "Epoch: 4318, Train Loss: 0.003322287229821086, Valid Loss: 0.00419699028134346\n",
      "Epoch: 4319, Train Loss: 0.003319957060739398, Valid Loss: 0.004194328095763922\n",
      "Epoch: 4320, Train Loss: 0.0033176341094076633, Valid Loss: 0.004191685933619738\n",
      "Epoch: 4321, Train Loss: 0.003315317677333951, Valid Loss: 0.004189027473330498\n",
      "Epoch: 4322, Train Loss: 0.0033129937946796417, Valid Loss: 0.0041863699443638325\n",
      "Epoch: 4323, Train Loss: 0.0033106792252510786, Valid Loss: 0.004183741752058268\n",
      "Epoch: 4324, Train Loss: 0.0033083613961935043, Valid Loss: 0.00418107071891427\n",
      "Epoch: 4325, Train Loss: 0.003306053578853607, Valid Loss: 0.004178435076028109\n",
      "Epoch: 4326, Train Loss: 0.0033037466928362846, Valid Loss: 0.004175798501819372\n",
      "Epoch: 4327, Train Loss: 0.0033014367800205946, Valid Loss: 0.0041731889359653\n",
      "Epoch: 4328, Train Loss: 0.0032991296611726284, Valid Loss: 0.004170513711869717\n",
      "Epoch: 4329, Train Loss: 0.003296829294413328, Valid Loss: 0.004167868755757809\n",
      "Epoch: 4330, Train Loss: 0.0032945279963314533, Valid Loss: 0.004165257792919874\n",
      "Epoch: 4331, Train Loss: 0.003292231122031808, Valid Loss: 0.004162622615695\n",
      "Epoch: 4332, Train Loss: 0.003289933316409588, Valid Loss: 0.00415996927767992\n",
      "Epoch: 4333, Train Loss: 0.0032876364421099424, Valid Loss: 0.004157336428761482\n",
      "Epoch: 4334, Train Loss: 0.003285340964794159, Valid Loss: 0.004154701717197895\n",
      "Epoch: 4335, Train Loss: 0.0032830520067363977, Valid Loss: 0.004152096342295408\n",
      "Epoch: 4336, Train Loss: 0.00328076328150928, Valid Loss: 0.004149476531893015\n",
      "Epoch: 4337, Train Loss: 0.003278476884588599, Valid Loss: 0.004146824590861797\n",
      "Epoch: 4338, Train Loss: 0.0032761897891759872, Valid Loss: 0.004144188482314348\n",
      "Epoch: 4339, Train Loss: 0.003273902228102088, Valid Loss: 0.00414157472550869\n",
      "Epoch: 4340, Train Loss: 0.0032716263085603714, Valid Loss: 0.004138980060815811\n",
      "Epoch: 4341, Train Loss: 0.0032693452667444944, Valid Loss: 0.004136359319090843\n",
      "Epoch: 4342, Train Loss: 0.00326707074418664, Valid Loss: 0.004133717622607946\n",
      "Epoch: 4343, Train Loss: 0.003264795523136854, Valid Loss: 0.004131112713366747\n",
      "Epoch: 4344, Train Loss: 0.003262520534917712, Valid Loss: 0.004128504544496536\n",
      "Epoch: 4345, Train Loss: 0.0032602488063275814, Valid Loss: 0.00412590429186821\n",
      "Epoch: 4346, Train Loss: 0.003257979638874531, Valid Loss: 0.004123265389353037\n",
      "Epoch: 4347, Train Loss: 0.0032557155936956406, Valid Loss: 0.004120650701224804\n",
      "Epoch: 4348, Train Loss: 0.003253448288887739, Valid Loss: 0.004118067212402821\n",
      "Epoch: 4349, Train Loss: 0.003251184243708849, Valid Loss: 0.004115466959774494\n",
      "Epoch: 4350, Train Loss: 0.003248924622312188, Valid Loss: 0.004112853202968836\n",
      "Epoch: 4351, Train Loss: 0.0032466689590364695, Valid Loss: 0.004110228270292282\n",
      "Epoch: 4352, Train Loss: 0.003244411898776889, Valid Loss: 0.0041076382622122765\n",
      "Epoch: 4353, Train Loss: 0.003242156468331814, Valid Loss: 0.004105068277567625\n",
      "Epoch: 4354, Train Loss: 0.003239897545427084, Valid Loss: 0.004102473147213459\n",
      "Epoch: 4355, Train Loss: 0.003237648867070675, Valid Loss: 0.004099838901311159\n",
      "Epoch: 4356, Train Loss: 0.003235398791730404, Valid Loss: 0.004097227472811937\n",
      "Epoch: 4357, Train Loss: 0.0032331557013094425, Valid Loss: 0.004094669595360756\n",
      "Epoch: 4358, Train Loss: 0.003230908652767539, Valid Loss: 0.004092095419764519\n",
      "Epoch: 4359, Train Loss: 0.003228666726499796, Valid Loss: 0.0040894970297813416\n",
      "Epoch: 4360, Train Loss: 0.0032264275941997766, Valid Loss: 0.0040869093500077724\n",
      "Epoch: 4361, Train Loss: 0.0032241870649158955, Valid Loss: 0.004084327258169651\n",
      "Epoch: 4362, Train Loss: 0.0032219516579061747, Valid Loss: 0.00408175028860569\n",
      "Epoch: 4363, Train Loss: 0.0032197164837270975, Valid Loss: 0.004079170059412718\n",
      "Epoch: 4364, Train Loss: 0.003217478282749653, Valid Loss: 0.004076577257364988\n",
      "Epoch: 4365, Train Loss: 0.0032152486965060234, Valid Loss: 0.0040740021504461765\n",
      "Epoch: 4366, Train Loss: 0.0032130221370607615, Valid Loss: 0.004071441479027271\n",
      "Epoch: 4367, Train Loss: 0.0032107909210026264, Valid Loss: 0.0040688603185117245\n",
      "Epoch: 4368, Train Loss: 0.003208567388355732, Valid Loss: 0.004066298715770245\n",
      "Epoch: 4369, Train Loss: 0.003206342225894332, Valid Loss: 0.004063700325787067\n",
      "Epoch: 4370, Train Loss: 0.0032041200902312994, Valid Loss: 0.004061106592416763\n",
      "Epoch: 4371, Train Loss: 0.0032019002828747034, Valid Loss: 0.0040585617534816265\n",
      "Epoch: 4372, Train Loss: 0.003199688158929348, Valid Loss: 0.0040560029447078705\n",
      "Epoch: 4373, Train Loss: 0.0031974702142179012, Valid Loss: 0.004053426440805197\n",
      "Epoch: 4374, Train Loss: 0.0031952555291354656, Valid Loss: 0.004050862044095993\n",
      "Epoch: 4375, Train Loss: 0.003193042241036892, Valid Loss: 0.004048319533467293\n",
      "Epoch: 4376, Train Loss: 0.003190832445397973, Valid Loss: 0.0040457602590322495\n",
      "Epoch: 4377, Train Loss: 0.0031886252108961344, Valid Loss: 0.004043187480419874\n",
      "Epoch: 4378, Train Loss: 0.003186419140547514, Valid Loss: 0.004040636587888002\n",
      "Epoch: 4379, Train Loss: 0.0031842156313359737, Valid Loss: 0.004038091748952866\n",
      "Epoch: 4380, Train Loss: 0.003182017244398594, Valid Loss: 0.004035529680550098\n",
      "Epoch: 4381, Train Loss: 0.0031798183917999268, Valid Loss: 0.0040329862385988235\n",
      "Epoch: 4382, Train Loss: 0.0031776134856045246, Valid Loss: 0.004030432552099228\n",
      "Epoch: 4383, Train Loss: 0.003175420919433236, Valid Loss: 0.004027902614325285\n",
      "Epoch: 4384, Train Loss: 0.0031732204370200634, Valid Loss: 0.004025352653115988\n",
      "Epoch: 4385, Train Loss: 0.0031710334587842226, Valid Loss: 0.004022802226245403\n",
      "Epoch: 4386, Train Loss: 0.0031688411254435778, Valid Loss: 0.004020264837890863\n",
      "Epoch: 4387, Train Loss: 0.003166652750223875, Valid Loss: 0.004017708823084831\n",
      "Epoch: 4388, Train Loss: 0.0031644622795283794, Valid Loss: 0.004015169572085142\n",
      "Epoch: 4389, Train Loss: 0.003162284381687641, Valid Loss: 0.004012653604149818\n",
      "Epoch: 4390, Train Loss: 0.0031600957736372948, Valid Loss: 0.004010113421827555\n",
      "Epoch: 4391, Train Loss: 0.0031579178757965565, Valid Loss: 0.004007592331618071\n",
      "Epoch: 4392, Train Loss: 0.0031557388138026, Valid Loss: 0.00400506192818284\n",
      "Epoch: 4393, Train Loss: 0.00315356208011508, Valid Loss: 0.00400250731036067\n",
      "Epoch: 4394, Train Loss: 0.003151383949443698, Valid Loss: 0.003999997396022081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4395, Train Loss: 0.003149209776893258, Valid Loss: 0.00399748096242547\n",
      "Epoch: 4396, Train Loss: 0.0031470356043428183, Valid Loss: 0.003994939383119345\n",
      "Epoch: 4397, Train Loss: 0.0031448686495423317, Valid Loss: 0.003992412704974413\n",
      "Epoch: 4398, Train Loss: 0.003142702393233776, Valid Loss: 0.0039899046532809734\n",
      "Epoch: 4399, Train Loss: 0.0031405342742800713, Valid Loss: 0.00398739380761981\n",
      "Epoch: 4400, Train Loss: 0.0031383729074150324, Valid Loss: 0.003984872251749039\n",
      "Epoch: 4401, Train Loss: 0.003136207815259695, Valid Loss: 0.003982354886829853\n",
      "Epoch: 4402, Train Loss: 0.0031340450514107943, Valid Loss: 0.003979810979217291\n",
      "Epoch: 4403, Train Loss: 0.0031318925321102142, Valid Loss: 0.003977305255830288\n",
      "Epoch: 4404, Train Loss: 0.0031297383829951286, Valid Loss: 0.003974806517362595\n",
      "Epoch: 4405, Train Loss: 0.0031275786459445953, Valid Loss: 0.003972299862653017\n",
      "Epoch: 4406, Train Loss: 0.0031254307832568884, Valid Loss: 0.003969796467572451\n",
      "Epoch: 4407, Train Loss: 0.003123269183561206, Valid Loss: 0.003967298660427332\n",
      "Epoch: 4408, Train Loss: 0.0031211203895509243, Valid Loss: 0.003964802250266075\n",
      "Epoch: 4409, Train Loss: 0.003118973458185792, Valid Loss: 0.003962292801588774\n",
      "Epoch: 4410, Train Loss: 0.0031168332789093256, Valid Loss: 0.003959795460104942\n",
      "Epoch: 4411, Train Loss: 0.0031146882101893425, Valid Loss: 0.003957299515604973\n",
      "Epoch: 4412, Train Loss: 0.003112550126388669, Valid Loss: 0.003954807296395302\n",
      "Epoch: 4413, Train Loss: 0.003110405057668686, Valid Loss: 0.003952289465814829\n",
      "Epoch: 4414, Train Loss: 0.0031082704663276672, Valid Loss: 0.003949818667024374\n",
      "Epoch: 4415, Train Loss: 0.003106130287051201, Valid Loss: 0.003947327844798565\n",
      "Epoch: 4416, Train Loss: 0.003103996627032757, Valid Loss: 0.003944833762943745\n",
      "Epoch: 4417, Train Loss: 0.003101859474554658, Valid Loss: 0.003942327108234167\n",
      "Epoch: 4418, Train Loss: 0.003099736524745822, Valid Loss: 0.003939865622669458\n",
      "Epoch: 4419, Train Loss: 0.0030976051930338144, Valid Loss: 0.003937393892556429\n",
      "Epoch: 4420, Train Loss: 0.0030954740941524506, Valid Loss: 0.003934869542717934\n",
      "Epoch: 4421, Train Loss: 0.0030933532398194075, Valid Loss: 0.0039324210956692696\n",
      "Epoch: 4422, Train Loss: 0.003091229125857353, Valid Loss: 0.003929974045604467\n",
      "Epoch: 4423, Train Loss: 0.0030891092028468847, Valid Loss: 0.003927466459572315\n",
      "Epoch: 4424, Train Loss: 0.003086985321715474, Valid Loss: 0.003924964461475611\n",
      "Epoch: 4425, Train Loss: 0.003084869123995304, Valid Loss: 0.003922519739717245\n",
      "Epoch: 4426, Train Loss: 0.003082751529291272, Valid Loss: 0.003920063376426697\n",
      "Epoch: 4427, Train Loss: 0.0030806369613856077, Valid Loss: 0.003917567897588015\n",
      "Epoch: 4428, Train Loss: 0.0030785277485847473, Valid Loss: 0.003915101755410433\n",
      "Epoch: 4429, Train Loss: 0.003076417138800025, Valid Loss: 0.003912667278200388\n",
      "Epoch: 4430, Train Loss: 0.00307430955581367, Valid Loss: 0.0039101820439100266\n",
      "Epoch: 4431, Train Loss: 0.003072202205657959, Valid Loss: 0.003907693549990654\n",
      "Epoch: 4432, Train Loss: 0.003070095321163535, Valid Loss: 0.003905265359207988\n",
      "Epoch: 4433, Train Loss: 0.0030679884366691113, Valid Loss: 0.0039028171449899673\n",
      "Epoch: 4434, Train Loss: 0.0030658848118036985, Valid Loss: 0.0039003356359899044\n",
      "Epoch: 4435, Train Loss: 0.003063794458284974, Valid Loss: 0.0038978680968284607\n",
      "Epoch: 4436, Train Loss: 0.0030616954900324345, Valid Loss: 0.0038954531773924828\n",
      "Epoch: 4437, Train Loss: 0.003059599082916975, Valid Loss: 0.003893026150763035\n",
      "Epoch: 4438, Train Loss: 0.0030575047712773085, Valid Loss: 0.003890518331900239\n",
      "Epoch: 4439, Train Loss: 0.0030554095283150673, Valid Loss: 0.0038880587089806795\n",
      "Epoch: 4440, Train Loss: 0.003053320338949561, Valid Loss: 0.0038856605533510447\n",
      "Epoch: 4441, Train Loss: 0.0030512246303260326, Valid Loss: 0.0038832135032862425\n",
      "Epoch: 4442, Train Loss: 0.0030491387005895376, Valid Loss: 0.003880748525261879\n",
      "Epoch: 4443, Train Loss: 0.003047056496143341, Valid Loss: 0.003878326155245304\n",
      "Epoch: 4444, Train Loss: 0.0030449731275439262, Valid Loss: 0.00387587514705956\n",
      "Epoch: 4445, Train Loss: 0.003042888129130006, Valid Loss: 0.0038734280969947577\n",
      "Epoch: 4446, Train Loss: 0.0030408091843128204, Valid Loss: 0.0038709971122443676\n",
      "Epoch: 4447, Train Loss: 0.003038730937987566, Valid Loss: 0.0038685721810907125\n",
      "Epoch: 4448, Train Loss: 0.0030366487335413694, Valid Loss: 0.0038661134894937277\n",
      "Epoch: 4449, Train Loss: 0.00303457397967577, Valid Loss: 0.0038636892568320036\n",
      "Epoch: 4450, Train Loss: 0.003032503416761756, Valid Loss: 0.003861295059323311\n",
      "Epoch: 4451, Train Loss: 0.0030304291285574436, Valid Loss: 0.00385885126888752\n",
      "Epoch: 4452, Train Loss: 0.003028362523764372, Valid Loss: 0.0038564165588468313\n",
      "Epoch: 4453, Train Loss: 0.0030262961518019438, Valid Loss: 0.0038539874367415905\n",
      "Epoch: 4454, Train Loss: 0.0030242311768233776, Valid Loss: 0.003851579735055566\n",
      "Epoch: 4455, Train Loss: 0.0030221662018448114, Valid Loss: 0.003849170170724392\n",
      "Epoch: 4456, Train Loss: 0.003020099364221096, Valid Loss: 0.003846724983304739\n",
      "Epoch: 4457, Train Loss: 0.0030180413741618395, Valid Loss: 0.00384434312582016\n",
      "Epoch: 4458, Train Loss: 0.0030159824527800083, Valid Loss: 0.0038419219199568033\n",
      "Epoch: 4459, Train Loss: 0.0030139258597046137, Valid Loss: 0.0038394900038838387\n",
      "Epoch: 4460, Train Loss: 0.0030118715949356556, Valid Loss: 0.0038371041882783175\n",
      "Epoch: 4461, Train Loss: 0.003009818261489272, Valid Loss: 0.003834686940535903\n",
      "Epoch: 4462, Train Loss: 0.0030077637638896704, Valid Loss: 0.003832258516922593\n",
      "Epoch: 4463, Train Loss: 0.0030057153198868036, Valid Loss: 0.0038298743311315775\n",
      "Epoch: 4464, Train Loss: 0.003003664081916213, Valid Loss: 0.003827477339655161\n",
      "Epoch: 4465, Train Loss: 0.003001617733389139, Valid Loss: 0.0038250654470175505\n",
      "Epoch: 4466, Train Loss: 0.0029995760414749384, Valid Loss: 0.0038226558826863766\n",
      "Epoch: 4467, Train Loss: 0.0029975275974720716, Valid Loss: 0.0038202733267098665\n",
      "Epoch: 4468, Train Loss: 0.002995486604049802, Valid Loss: 0.003817854216322303\n",
      "Epoch: 4469, Train Loss: 0.002993450965732336, Valid Loss: 0.0038154807407408953\n",
      "Epoch: 4470, Train Loss: 0.002991409506648779, Valid Loss: 0.003813093528151512\n",
      "Epoch: 4471, Train Loss: 0.002989372704178095, Valid Loss: 0.0038106876891106367\n",
      "Epoch: 4472, Train Loss: 0.0029873382300138474, Valid Loss: 0.003808272536844015\n",
      "Epoch: 4473, Train Loss: 0.0029853058513253927, Valid Loss: 0.0038058904465287924\n",
      "Epoch: 4474, Train Loss: 0.0029832767322659492, Valid Loss: 0.003803541650995612\n",
      "Epoch: 4475, Train Loss: 0.0029812422581017017, Valid Loss: 0.0038011702708899975\n",
      "Epoch: 4476, Train Loss: 0.0029792161658406258, Valid Loss: 0.003798732068389654\n",
      "Epoch: 4477, Train Loss: 0.002977187978103757, Valid Loss: 0.003796360455453396\n",
      "Epoch: 4478, Train Loss: 0.0029751653783023357, Valid Loss: 0.0037939974572509527\n",
      "Epoch: 4479, Train Loss: 0.002973138587549329, Valid Loss: 0.0037916230503469706\n",
      "Epoch: 4480, Train Loss: 0.002971119014546275, Valid Loss: 0.0037892425898462534\n",
      "Epoch: 4481, Train Loss: 0.0029690975788980722, Valid Loss: 0.003786863060668111\n",
      "Epoch: 4482, Train Loss: 0.0029670821968466043, Valid Loss: 0.0037844968028366566\n",
      "Epoch: 4483, Train Loss: 0.002965066581964493, Valid Loss: 0.003782110521569848\n",
      "Epoch: 4484, Train Loss: 0.0029630479402840137, Valid Loss: 0.0037797586992383003\n",
      "Epoch: 4485, Train Loss: 0.002961039077490568, Valid Loss: 0.0037774189841002226\n",
      "Epoch: 4486, Train Loss: 0.0029590297490358353, Valid Loss: 0.003775016637519002\n",
      "Epoch: 4487, Train Loss: 0.0029570155311375856, Valid Loss: 0.0037726385053247213\n",
      "Epoch: 4488, Train Loss: 0.0029550069011747837, Valid Loss: 0.003770293202251196\n",
      "Epoch: 4489, Train Loss: 0.0029530019965022802, Valid Loss: 0.0037679632660001516\n",
      "Epoch: 4490, Train Loss: 0.002951002214103937, Valid Loss: 0.003765592584386468\n",
      "Epoch: 4491, Train Loss: 0.0029489954467862844, Valid Loss: 0.0037631860468536615\n",
      "Epoch: 4492, Train Loss: 0.002946994500234723, Valid Loss: 0.0037608484271913767\n",
      "Epoch: 4493, Train Loss: 0.002944996813312173, Valid Loss: 0.0037585285026580095\n",
      "Epoch: 4494, Train Loss: 0.002943000290542841, Valid Loss: 0.003756171790882945\n",
      "Epoch: 4495, Train Loss: 0.0029410049319267273, Valid Loss: 0.0037538022734224796\n",
      "Epoch: 4496, Train Loss: 0.002939007943496108, Valid Loss: 0.003751454409211874\n",
      "Epoch: 4497, Train Loss: 0.002937018172815442, Valid Loss: 0.003749112132936716\n",
      "Epoch: 4498, Train Loss: 0.0029350267723202705, Valid Loss: 0.0037467663642019033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4499, Train Loss: 0.002933036768808961, Valid Loss: 0.0037444077897816896\n",
      "Epoch: 4500, Train Loss: 0.0029310439713299274, Valid Loss: 0.0037420871667563915\n",
      "Epoch: 4501, Train Loss: 0.0029290614183992147, Valid Loss: 0.0037397351115942\n",
      "Epoch: 4502, Train Loss: 0.0029270732775330544, Valid Loss: 0.0037373679224401712\n",
      "Epoch: 4503, Train Loss: 0.002925093052908778, Valid Loss: 0.0037350805941969156\n",
      "Epoch: 4504, Train Loss: 0.0029231130611151457, Valid Loss: 0.0037327685859054327\n",
      "Epoch: 4505, Train Loss: 0.0029211295768618584, Valid Loss: 0.0037303983699530363\n",
      "Epoch: 4506, Train Loss: 0.0029191537760198116, Valid Loss: 0.003728036768734455\n",
      "Epoch: 4507, Train Loss: 0.0029171817004680634, Valid Loss: 0.0037257468793541193\n",
      "Epoch: 4508, Train Loss: 0.0029152012430131435, Valid Loss: 0.003723433008417487\n",
      "Epoch: 4509, Train Loss: 0.002913230797275901, Valid Loss: 0.00372108886949718\n",
      "Epoch: 4510, Train Loss: 0.002911260584369302, Valid Loss: 0.0037187549751251936\n",
      "Epoch: 4511, Train Loss: 0.0029092903714627028, Valid Loss: 0.0037164189852774143\n",
      "Epoch: 4512, Train Loss: 0.0029073229525238276, Valid Loss: 0.0037141444627195597\n",
      "Epoch: 4513, Train Loss: 0.0029053562320768833, Valid Loss: 0.003711818717420101\n",
      "Epoch: 4514, Train Loss: 0.002903392305597663, Valid Loss: 0.0037094857543706894\n",
      "Epoch: 4515, Train Loss: 0.0029014325700700283, Valid Loss: 0.003707152558490634\n",
      "Epoch: 4516, Train Loss: 0.0028994688764214516, Valid Loss: 0.0037048524245619774\n",
      "Epoch: 4517, Train Loss: 0.00289751123636961, Valid Loss: 0.0037025404162704945\n",
      "Epoch: 4518, Train Loss: 0.0028955501038581133, Valid Loss: 0.0037002386525273323\n",
      "Epoch: 4519, Train Loss: 0.002893594093620777, Valid Loss: 0.003697918727993965\n",
      "Epoch: 4520, Train Loss: 0.0028916397131979465, Valid Loss: 0.003695604857057333\n",
      "Epoch: 4521, Train Loss: 0.002889686729758978, Valid Loss: 0.003693301696330309\n",
      "Epoch: 4522, Train Loss: 0.0028877342119812965, Valid Loss: 0.0036910278722643852\n",
      "Epoch: 4523, Train Loss: 0.0028857856523245573, Valid Loss: 0.0036887109745293856\n",
      "Epoch: 4524, Train Loss: 0.002883839188143611, Valid Loss: 0.0036863822024315596\n",
      "Epoch: 4525, Train Loss: 0.0028818866703659296, Valid Loss: 0.0036840764805674553\n",
      "Epoch: 4526, Train Loss: 0.0028799446299672127, Valid Loss: 0.0036818229127675295\n",
      "Epoch: 4527, Train Loss: 0.0028779988642781973, Valid Loss: 0.0036795225460082293\n",
      "Epoch: 4528, Train Loss: 0.0028760582208633423, Valid Loss: 0.003677213564515114\n",
      "Epoch: 4529, Train Loss: 0.0028741226997226477, Valid Loss: 0.0036749127320945263\n",
      "Epoch: 4530, Train Loss: 0.002872180426493287, Valid Loss: 0.003672634018585086\n",
      "Epoch: 4531, Train Loss: 0.002870244439691305, Valid Loss: 0.003670341335237026\n",
      "Epoch: 4532, Train Loss: 0.0028683056589215994, Valid Loss: 0.003668065182864666\n",
      "Epoch: 4533, Train Loss: 0.0028663743287324905, Valid Loss: 0.0036657648161053658\n",
      "Epoch: 4534, Train Loss: 0.002864440670236945, Valid Loss: 0.0036634623538702726\n",
      "Epoch: 4535, Train Loss: 0.0028625105042010546, Valid Loss: 0.0036611943505704403\n",
      "Epoch: 4536, Train Loss: 0.002860582899302244, Valid Loss: 0.0036589428782463074\n",
      "Epoch: 4537, Train Loss: 0.0028586566913872957, Valid Loss: 0.003656654851511121\n",
      "Epoch: 4538, Train Loss: 0.002856727922335267, Valid Loss: 0.003654338652268052\n",
      "Epoch: 4539, Train Loss: 0.002854804275557399, Valid Loss: 0.0036520767025649548\n",
      "Epoch: 4540, Train Loss: 0.0028528780676424503, Valid Loss: 0.0036498152185231447\n",
      "Epoch: 4541, Train Loss: 0.0028509635012596846, Valid Loss: 0.0036475611850619316\n",
      "Epoch: 4542, Train Loss: 0.002849036129191518, Valid Loss: 0.003645288059487939\n",
      "Epoch: 4543, Train Loss: 0.002847123658284545, Valid Loss: 0.00364298140630126\n",
      "Epoch: 4544, Train Loss: 0.0028452060651034117, Valid Loss: 0.0036407297011464834\n",
      "Epoch: 4545, Train Loss: 0.0028432877734303474, Valid Loss: 0.003638496622443199\n",
      "Epoch: 4546, Train Loss: 0.0028413785621523857, Valid Loss: 0.0036362051032483578\n",
      "Epoch: 4547, Train Loss: 0.0028394635301083326, Valid Loss: 0.003633922664448619\n",
      "Epoch: 4548, Train Loss: 0.0028375571127980947, Valid Loss: 0.0036316756159067154\n",
      "Epoch: 4549, Train Loss: 0.002835645107552409, Valid Loss: 0.003629441373050213\n",
      "Epoch: 4550, Train Loss: 0.0028337386902421713, Valid Loss: 0.003627185709774494\n",
      "Epoch: 4551, Train Loss: 0.0028318343684077263, Valid Loss: 0.0036249032709747553\n",
      "Epoch: 4552, Train Loss: 0.002829932374879718, Valid Loss: 0.003622650168836117\n",
      "Epoch: 4553, Train Loss: 0.0028280296828597784, Valid Loss: 0.0036204124335199594\n",
      "Epoch: 4554, Train Loss: 0.002826128387823701, Valid Loss: 0.0036181623581796885\n",
      "Epoch: 4555, Train Loss: 0.0028242298867553473, Valid Loss: 0.0036159157752990723\n",
      "Epoch: 4556, Train Loss: 0.0028223306871950626, Valid Loss: 0.003613655921071768\n",
      "Epoch: 4557, Train Loss: 0.0028204305563122034, Valid Loss: 0.003611417952924967\n",
      "Epoch: 4558, Train Loss: 0.0028185390401631594, Valid Loss: 0.003609154839068651\n",
      "Epoch: 4559, Train Loss: 0.002816645195707679, Valid Loss: 0.003606923157349229\n",
      "Epoch: 4560, Train Loss: 0.0028147578705102205, Valid Loss: 0.0036047142930328846\n",
      "Epoch: 4561, Train Loss: 0.0028128656558692455, Valid Loss: 0.003602436510846019\n",
      "Epoch: 4562, Train Loss: 0.002810976468026638, Valid Loss: 0.0036001820117235184\n",
      "Epoch: 4563, Train Loss: 0.0028090886771678925, Valid Loss: 0.003597972681745887\n",
      "Epoch: 4564, Train Loss: 0.0028072085697203875, Valid Loss: 0.003595764050260186\n",
      "Epoch: 4565, Train Loss: 0.0028053217101842165, Valid Loss: 0.003593512810766697\n",
      "Epoch: 4566, Train Loss: 0.002803442534059286, Valid Loss: 0.003591271350160241\n",
      "Epoch: 4567, Train Loss: 0.0028015614952892065, Valid Loss: 0.0035890513099730015\n",
      "Epoch: 4568, Train Loss: 0.0027996839489787817, Valid Loss: 0.003586810315027833\n",
      "Epoch: 4569, Train Loss: 0.0027977994177490473, Valid Loss: 0.0035845895763486624\n",
      "Epoch: 4570, Train Loss: 0.0027959258295595646, Valid Loss: 0.003582381410524249\n",
      "Epoch: 4571, Train Loss: 0.0027940492145717144, Valid Loss: 0.003580140881240368\n",
      "Epoch: 4572, Train Loss: 0.002792180282995105, Valid Loss: 0.0035779057070612907\n",
      "Epoch: 4573, Train Loss: 0.002790310885757208, Valid Loss: 0.003575710579752922\n",
      "Epoch: 4574, Train Loss: 0.002788437996059656, Valid Loss: 0.0035735229030251503\n",
      "Epoch: 4575, Train Loss: 0.0027865672018378973, Valid Loss: 0.003571282373741269\n",
      "Epoch: 4576, Train Loss: 0.0027847010642290115, Valid Loss: 0.0035690367221832275\n",
      "Epoch: 4577, Train Loss: 0.0027828370220959187, Valid Loss: 0.0035668364726006985\n",
      "Epoch: 4578, Train Loss: 0.0027809732127934694, Valid Loss: 0.0035646178293973207\n",
      "Epoch: 4579, Train Loss: 0.0027791073080152273, Valid Loss: 0.003562420606613159\n",
      "Epoch: 4580, Train Loss: 0.002777250949293375, Valid Loss: 0.003560215001925826\n",
      "Epoch: 4581, Train Loss: 0.0027753913309425116, Valid Loss: 0.003557997988536954\n",
      "Epoch: 4582, Train Loss: 0.00277353310957551, Valid Loss: 0.003555798437446356\n",
      "Epoch: 4583, Train Loss: 0.002771677216514945, Valid Loss: 0.003553601913154125\n",
      "Epoch: 4584, Train Loss: 0.0027698196936398745, Valid Loss: 0.0035514039918780327\n",
      "Epoch: 4585, Train Loss: 0.002767964731901884, Valid Loss: 0.003549181157723069\n",
      "Epoch: 4586, Train Loss: 0.0027661174535751343, Valid Loss: 0.003546975553035736\n",
      "Epoch: 4587, Train Loss: 0.0027642613276839256, Valid Loss: 0.003544790204614401\n",
      "Epoch: 4588, Train Loss: 0.002762417308986187, Valid Loss: 0.0035426001995801926\n",
      "Epoch: 4589, Train Loss: 0.0027605732902884483, Valid Loss: 0.0035404022783041\n",
      "Epoch: 4590, Train Loss: 0.0027587227523326874, Valid Loss: 0.0035382146015763283\n",
      "Epoch: 4591, Train Loss: 0.002756881294772029, Valid Loss: 0.0035360166803002357\n",
      "Epoch: 4592, Train Loss: 0.0027550405357033014, Valid Loss: 0.003533841110765934\n",
      "Epoch: 4593, Train Loss: 0.002753195120021701, Valid Loss: 0.0035316599532961845\n",
      "Epoch: 4594, Train Loss: 0.002751358551904559, Valid Loss: 0.0035294583067297935\n",
      "Epoch: 4595, Train Loss: 0.002749519655480981, Valid Loss: 0.0035272580571472645\n",
      "Epoch: 4596, Train Loss: 0.0027476809918880463, Valid Loss: 0.0035250759683549404\n",
      "Epoch: 4597, Train Loss: 0.0027458500117063522, Valid Loss: 0.003522929735481739\n",
      "Epoch: 4598, Train Loss: 0.002744011813774705, Valid Loss: 0.0035207283217459917\n",
      "Epoch: 4599, Train Loss: 0.0027421810664236546, Valid Loss: 0.0035185592714697123\n",
      "Epoch: 4600, Train Loss: 0.0027403486892580986, Valid Loss: 0.003516359254717827\n",
      "Epoch: 4601, Train Loss: 0.0027385219000279903, Valid Loss: 0.0035141995176672935\n",
      "Epoch: 4602, Train Loss: 0.0027366953436285257, Valid Loss: 0.0035120516549795866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4603, Train Loss: 0.0027348678559064865, Valid Loss: 0.00350984837859869\n",
      "Epoch: 4604, Train Loss: 0.002733042696490884, Valid Loss: 0.0035076739732176065\n",
      "Epoch: 4605, Train Loss: 0.0027312180027365685, Valid Loss: 0.0035055303014814854\n",
      "Epoch: 4606, Train Loss: 0.0027293963357806206, Valid Loss: 0.003503369400277734\n",
      "Epoch: 4607, Train Loss: 0.00272757513448596, Valid Loss: 0.0035011766012758017\n",
      "Epoch: 4608, Train Loss: 0.002725753001868725, Valid Loss: 0.00349900359287858\n",
      "Epoch: 4609, Train Loss: 0.002723936690017581, Valid Loss: 0.003496876684948802\n",
      "Epoch: 4610, Train Loss: 0.0027221227064728737, Valid Loss: 0.003494691802188754\n",
      "Epoch: 4611, Train Loss: 0.0027203115168958902, Valid Loss: 0.0034925523214042187\n",
      "Epoch: 4612, Train Loss: 0.0027184952050447464, Valid Loss: 0.003490380011498928\n",
      "Epoch: 4613, Train Loss: 0.0027166828513145447, Valid Loss: 0.0034882298205047846\n",
      "Epoch: 4614, Train Loss: 0.0027148714289069176, Valid Loss: 0.003486068220809102\n",
      "Epoch: 4615, Train Loss: 0.0027130634989589453, Valid Loss: 0.0034839201252907515\n",
      "Epoch: 4616, Train Loss: 0.002711257664486766, Valid Loss: 0.0034817904233932495\n",
      "Epoch: 4617, Train Loss: 0.0027094490360468626, Valid Loss: 0.003479614155367017\n",
      "Epoch: 4618, Train Loss: 0.002707645995542407, Valid Loss: 0.0034774672240018845\n",
      "Epoch: 4619, Train Loss: 0.0027058455161750317, Valid Loss: 0.003475324483588338\n",
      "Epoch: 4620, Train Loss: 0.002704042475670576, Valid Loss: 0.0034731863997876644\n",
      "Epoch: 4621, Train Loss: 0.0027022429276257753, Valid Loss: 0.003471055533736944\n",
      "Epoch: 4622, Train Loss: 0.0027004415169358253, Valid Loss: 0.0034688818268477917\n",
      "Epoch: 4623, Train Loss: 0.0026986447628587484, Valid Loss: 0.003466738387942314\n",
      "Epoch: 4624, Train Loss: 0.002696847543120384, Valid Loss: 0.003464602865278721\n",
      "Epoch: 4625, Train Loss: 0.0026950554456561804, Valid Loss: 0.003462486667558551\n",
      "Epoch: 4626, Train Loss: 0.002693263813853264, Valid Loss: 0.003460338106378913\n",
      "Epoch: 4627, Train Loss: 0.002691472414880991, Valid Loss: 0.0034581793006509542\n",
      "Epoch: 4628, Train Loss: 0.002689681015908718, Valid Loss: 0.0034560721833258867\n",
      "Epoch: 4629, Train Loss: 0.0026878935750573874, Valid Loss: 0.003453948302194476\n",
      "Epoch: 4630, Train Loss: 0.002686104504391551, Valid Loss: 0.0034518155734986067\n",
      "Epoch: 4631, Train Loss: 0.0026843214873224497, Valid Loss: 0.0034496886655688286\n",
      "Epoch: 4632, Train Loss: 0.002682538703083992, Valid Loss: 0.003447564784437418\n",
      "Epoch: 4633, Train Loss: 0.002680751495063305, Valid Loss: 0.0034454152919352055\n",
      "Epoch: 4634, Train Loss: 0.00267897080630064, Valid Loss: 0.0034433132968842983\n",
      "Epoch: 4635, Train Loss: 0.0026771905831992626, Valid Loss: 0.0034411924425512552\n",
      "Epoch: 4636, Train Loss: 0.0026754147838801146, Valid Loss: 0.003439069027081132\n",
      "Epoch: 4637, Train Loss: 0.002673635259270668, Valid Loss: 0.0034369402565062046\n",
      "Epoch: 4638, Train Loss: 0.0026718585286289454, Valid Loss: 0.003434824990108609\n",
      "Epoch: 4639, Train Loss: 0.0026700834278017282, Valid Loss: 0.0034327281173318624\n",
      "Epoch: 4640, Train Loss: 0.0026683148462325335, Valid Loss: 0.0034305956214666367\n",
      "Epoch: 4641, Train Loss: 0.00266654253937304, Valid Loss: 0.0034284836146980524\n",
      "Epoch: 4642, Train Loss: 0.002664771629497409, Valid Loss: 0.003426364390179515\n",
      "Epoch: 4643, Train Loss: 0.0026630035135895014, Valid Loss: 0.003424277063459158\n",
      "Epoch: 4644, Train Loss: 0.0026612342335283756, Valid Loss: 0.003422145266085863\n",
      "Epoch: 4645, Train Loss: 0.0026594691444188356, Valid Loss: 0.00342003651894629\n",
      "Epoch: 4646, Train Loss: 0.002657705219462514, Valid Loss: 0.003417950589209795\n",
      "Epoch: 4647, Train Loss: 0.0026559405960142612, Valid Loss: 0.003415836486965418\n",
      "Epoch: 4648, Train Loss: 0.0026541801635175943, Valid Loss: 0.0034137340262532234\n",
      "Epoch: 4649, Train Loss: 0.002652416005730629, Valid Loss: 0.003411645069718361\n",
      "Epoch: 4650, Train Loss: 0.002650661626830697, Valid Loss: 0.00340955494903028\n",
      "Epoch: 4651, Train Loss: 0.0026489044539630413, Valid Loss: 0.003407418727874756\n",
      "Epoch: 4652, Train Loss: 0.002647147746756673, Valid Loss: 0.003405320690944791\n",
      "Epoch: 4653, Train Loss: 0.0026453970931470394, Valid Loss: 0.0034032664261758327\n",
      "Epoch: 4654, Train Loss: 0.002643640385940671, Valid Loss: 0.003401160938665271\n",
      "Epoch: 4655, Train Loss: 0.00264188926666975, Valid Loss: 0.0033990538213402033\n",
      "Epoch: 4656, Train Loss: 0.0026401400100439787, Valid Loss: 0.0033969483338296413\n",
      "Epoch: 4657, Train Loss: 0.0026383872609585524, Valid Loss: 0.0033948933705687523\n",
      "Epoch: 4658, Train Loss: 0.0026366428937762976, Valid Loss: 0.003392804181203246\n",
      "Epoch: 4659, Train Loss: 0.002634894335642457, Valid Loss: 0.003390689380466938\n",
      "Epoch: 4660, Train Loss: 0.0026331504341214895, Valid Loss: 0.0033886136952787638\n",
      "Epoch: 4661, Train Loss: 0.0026314083952456713, Valid Loss: 0.0033865473233163357\n",
      "Epoch: 4662, Train Loss: 0.002629670314490795, Valid Loss: 0.003384452546015382\n",
      "Epoch: 4663, Train Loss: 0.0026279259473085403, Valid Loss: 0.0033823742996901274\n",
      "Epoch: 4664, Train Loss: 0.002626186702400446, Valid Loss: 0.0033803137484937906\n",
      "Epoch: 4665, Train Loss: 0.002624446526169777, Valid Loss: 0.003378257155418396\n",
      "Epoch: 4666, Train Loss: 0.002622711006551981, Valid Loss: 0.0033761165104806423\n",
      "Epoch: 4667, Train Loss: 0.002620977582409978, Valid Loss: 0.003374061081558466\n",
      "Epoch: 4668, Train Loss: 0.0026192443910986185, Valid Loss: 0.0033720401115715504\n",
      "Epoch: 4669, Train Loss: 0.0026175109669566154, Valid Loss: 0.003369949758052826\n",
      "Epoch: 4670, Train Loss: 0.0026157747488468885, Valid Loss: 0.003367829602211714\n",
      "Epoch: 4671, Train Loss: 0.0026140441186726093, Valid Loss: 0.0033657827880233526\n",
      "Epoch: 4672, Train Loss: 0.0026123204734176397, Valid Loss: 0.003363757161423564\n",
      "Epoch: 4673, Train Loss: 0.00261059682816267, Valid Loss: 0.003361679846420884\n",
      "Epoch: 4674, Train Loss: 0.002608867362141609, Valid Loss: 0.003359589260071516\n",
      "Epoch: 4675, Train Loss: 0.0026071425527334213, Valid Loss: 0.003357523586601019\n",
      "Epoch: 4676, Train Loss: 0.002605422865599394, Valid Loss: 0.003355470485985279\n",
      "Epoch: 4677, Train Loss: 0.0026036961935460567, Valid Loss: 0.0033534273970872164\n",
      "Epoch: 4678, Train Loss: 0.002601983956992626, Valid Loss: 0.003351380815729499\n",
      "Epoch: 4679, Train Loss: 0.0026002589147537947, Valid Loss: 0.0033493160735815763\n",
      "Epoch: 4680, Train Loss: 0.002598544815555215, Valid Loss: 0.003347243880853057\n",
      "Epoch: 4681, Train Loss: 0.002596829319372773, Valid Loss: 0.0033451938070356846\n",
      "Epoch: 4682, Train Loss: 0.0025951119605451822, Valid Loss: 0.00334316142834723\n",
      "Epoch: 4683, Train Loss: 0.002593400189653039, Valid Loss: 0.0033411162439733744\n",
      "Epoch: 4684, Train Loss: 0.0025916858576238155, Valid Loss: 0.0033390370663255453\n",
      "Epoch: 4685, Train Loss: 0.002589971525594592, Valid Loss: 0.003336985595524311\n",
      "Epoch: 4686, Train Loss: 0.002588271163403988, Valid Loss: 0.003334958804771304\n",
      "Epoch: 4687, Train Loss: 0.0025865596253424883, Valid Loss: 0.0033329285215586424\n",
      "Epoch: 4688, Train Loss: 0.002584853209555149, Valid Loss: 0.0033308693673461676\n",
      "Epoch: 4689, Train Loss: 0.0025831463281065226, Valid Loss: 0.0033288116101175547\n",
      "Epoch: 4690, Train Loss: 0.0025814392138272524, Valid Loss: 0.0033267789985984564\n",
      "Epoch: 4691, Train Loss: 0.002579740947112441, Valid Loss: 0.0033247480168938637\n",
      "Epoch: 4692, Train Loss: 0.0025780401192605495, Valid Loss: 0.003322714939713478\n",
      "Epoch: 4693, Train Loss: 0.0025763395242393017, Valid Loss: 0.0033206818625330925\n",
      "Epoch: 4694, Train Loss: 0.0025746417231857777, Valid Loss: 0.003318623872473836\n",
      "Epoch: 4695, Train Loss: 0.002572945784777403, Valid Loss: 0.0033166122157126665\n",
      "Epoch: 4696, Train Loss: 0.0025712503120303154, Valid Loss: 0.0033145875204354525\n",
      "Epoch: 4697, Train Loss: 0.0025695532094687223, Valid Loss: 0.003312549088150263\n",
      "Epoch: 4698, Train Loss: 0.0025678600650280714, Valid Loss: 0.0033104976173490286\n",
      "Epoch: 4699, Train Loss: 0.0025661648251116276, Valid Loss: 0.0033084845636039972\n",
      "Epoch: 4700, Train Loss: 0.0025644823908805847, Valid Loss: 0.003306486876681447\n",
      "Epoch: 4701, Train Loss: 0.0025627855211496353, Valid Loss: 0.003304446116089821\n",
      "Epoch: 4702, Train Loss: 0.0025611012242734432, Valid Loss: 0.0033024135045707226\n",
      "Epoch: 4703, Train Loss: 0.0025594171602278948, Valid Loss: 0.0033004116266965866\n",
      "Epoch: 4704, Train Loss: 0.002557731932029128, Valid Loss: 0.003298393450677395\n",
      "Epoch: 4705, Train Loss: 0.0025560425128787756, Valid Loss: 0.0032963601406663656\n",
      "Epoch: 4706, Train Loss: 0.0025543642695993185, Valid Loss: 0.00329433660954237\n",
      "Epoch: 4707, Train Loss: 0.0025526825338602066, Valid Loss: 0.0032923377584666014\n",
      "Epoch: 4708, Train Loss: 0.0025510021951049566, Valid Loss: 0.003290314693003893\n",
      "Epoch: 4709, Train Loss: 0.002549322322010994, Valid Loss: 0.003288285806775093\n",
      "Epoch: 4710, Train Loss: 0.002547645475715399, Valid Loss: 0.0032862857915461063\n",
      "Epoch: 4711, Train Loss: 0.0025459693279117346, Valid Loss: 0.0032843106891959906\n",
      "Epoch: 4712, Train Loss: 0.002544294111430645, Valid Loss: 0.003282267367467284\n",
      "Epoch: 4713, Train Loss: 0.0025426247157156467, Valid Loss: 0.003280241973698139\n",
      "Epoch: 4714, Train Loss: 0.0025409457739442587, Valid Loss: 0.003278271062299609\n",
      "Epoch: 4715, Train Loss: 0.002539275446906686, Valid Loss: 0.0032762682531028986\n",
      "Epoch: 4716, Train Loss: 0.0025376102421432734, Valid Loss: 0.003274250077083707\n",
      "Epoch: 4717, Train Loss: 0.0025359410792589188, Valid Loss: 0.0032722281757742167\n",
      "Epoch: 4718, Train Loss: 0.002534274710342288, Valid Loss: 0.003270271234214306\n",
      "Epoch: 4719, Train Loss: 0.0025326127652078867, Valid Loss: 0.003268265165388584\n",
      "Epoch: 4720, Train Loss: 0.0025309454649686813, Valid Loss: 0.003266245825216174\n",
      "Epoch: 4721, Train Loss: 0.002529281424358487, Valid Loss: 0.003264273516833782\n",
      "Epoch: 4722, Train Loss: 0.0025276176165789366, Valid Loss: 0.0032622949220240116\n",
      "Epoch: 4723, Train Loss: 0.0025259582325816154, Valid Loss: 0.003260258352383971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4724, Train Loss: 0.002524296985939145, Valid Loss: 0.003258282784372568\n",
      "Epoch: 4725, Train Loss: 0.0025226387660950422, Valid Loss: 0.0032563074491918087\n",
      "Epoch: 4726, Train Loss: 0.0025209870655089617, Valid Loss: 0.00325430603697896\n",
      "Epoch: 4727, Train Loss: 0.0025193290784955025, Valid Loss: 0.0032522983383387327\n",
      "Epoch: 4728, Train Loss: 0.0025176762137562037, Valid Loss: 0.003250329988077283\n",
      "Epoch: 4729, Train Loss: 0.002516024513170123, Valid Loss: 0.0032483721151947975\n",
      "Epoch: 4730, Train Loss: 0.0025143728125840425, Valid Loss: 0.0032463676761835814\n",
      "Epoch: 4731, Train Loss: 0.002512723207473755, Valid Loss: 0.003244375577196479\n",
      "Epoch: 4732, Train Loss: 0.002511074999347329, Valid Loss: 0.003242391860112548\n",
      "Epoch: 4733, Train Loss: 0.0025094288866966963, Valid Loss: 0.0032404311932623386\n",
      "Epoch: 4734, Train Loss: 0.0025077806785702705, Valid Loss: 0.003238455858081579\n",
      "Epoch: 4735, Train Loss: 0.002506132237613201, Valid Loss: 0.0032364632934331894\n",
      "Epoch: 4736, Train Loss: 0.00250449450686574, Valid Loss: 0.0032345119398087263\n",
      "Epoch: 4737, Train Loss: 0.002502845600247383, Valid Loss: 0.0032325240317732096\n",
      "Epoch: 4738, Train Loss: 0.0025012074038386345, Valid Loss: 0.0032305640634149313\n",
      "Epoch: 4739, Train Loss: 0.0024995668791234493, Valid Loss: 0.003228578018024564\n",
      "Epoch: 4740, Train Loss: 0.0024979282170534134, Valid Loss: 0.0032265998888760805\n",
      "Epoch: 4741, Train Loss: 0.002496291883289814, Valid Loss: 0.0032246632035821676\n",
      "Epoch: 4742, Train Loss: 0.0024946569465100765, Valid Loss: 0.0032227032352238894\n",
      "Epoch: 4743, Train Loss: 0.0024930189829319715, Valid Loss: 0.003220711834728718\n",
      "Epoch: 4744, Train Loss: 0.002491391496732831, Valid Loss: 0.0032187483739107847\n",
      "Epoch: 4745, Train Loss: 0.002489754930138588, Valid Loss: 0.003216811455786228\n",
      "Epoch: 4746, Train Loss: 0.0024881234858185053, Valid Loss: 0.003214829368516803\n",
      "Epoch: 4747, Train Loss: 0.0024864976294338703, Valid Loss: 0.0032128808088600636\n",
      "Epoch: 4748, Train Loss: 0.0024848682805895805, Valid Loss: 0.0032109159510582685\n",
      "Epoch: 4749, Train Loss: 0.0024832431226968765, Valid Loss: 0.003208976471796632\n",
      "Epoch: 4750, Train Loss: 0.002481614239513874, Valid Loss: 0.00320700416341424\n",
      "Epoch: 4751, Train Loss: 0.002479988383129239, Valid Loss: 0.0032050611916929483\n",
      "Epoch: 4752, Train Loss: 0.0024783643893897533, Valid Loss: 0.0032031123992055655\n",
      "Epoch: 4753, Train Loss: 0.0024767424911260605, Valid Loss: 0.0032011426519602537\n",
      "Epoch: 4754, Train Loss: 0.002475122921168804, Valid Loss: 0.0031992068979889154\n",
      "Epoch: 4755, Train Loss: 0.0024735049810260534, Valid Loss: 0.0031972534488886595\n",
      "Epoch: 4756, Train Loss: 0.0024718851782381535, Valid Loss: 0.003195330733433366\n",
      "Epoch: 4757, Train Loss: 0.00247026770375669, Valid Loss: 0.003193374490365386\n",
      "Epoch: 4758, Train Loss: 0.0024686530232429504, Valid Loss: 0.003191400784999132\n",
      "Epoch: 4759, Train Loss: 0.002467030193656683, Valid Loss: 0.0031894808635115623\n",
      "Epoch: 4760, Train Loss: 0.0024654248263686895, Valid Loss: 0.0031875446438789368\n",
      "Epoch: 4761, Train Loss: 0.0024638113100081682, Valid Loss: 0.0031856184359639883\n",
      "Epoch: 4762, Train Loss: 0.002462199656292796, Valid Loss: 0.0031836526468396187\n",
      "Epoch: 4763, Train Loss: 0.0024605889338999987, Valid Loss: 0.0031817290000617504\n",
      "Epoch: 4764, Train Loss: 0.002458981703966856, Valid Loss: 0.00317978928796947\n",
      "Epoch: 4765, Train Loss: 0.002457377500832081, Valid Loss: 0.003177840495482087\n",
      "Epoch: 4766, Train Loss: 0.0024557674769312143, Valid Loss: 0.0031759338453412056\n",
      "Epoch: 4767, Train Loss: 0.0024541656021028757, Valid Loss: 0.0031739783007651567\n",
      "Epoch: 4768, Train Loss: 0.002452561864629388, Valid Loss: 0.003172066994011402\n",
      "Epoch: 4769, Train Loss: 0.0024509625509381294, Valid Loss: 0.003170113079249859\n",
      "Epoch: 4770, Train Loss: 0.0024493602104485035, Valid Loss: 0.0031682229600846767\n",
      "Epoch: 4771, Train Loss: 0.002447758335620165, Valid Loss: 0.0031662762630730867\n",
      "Epoch: 4772, Train Loss: 0.0024461618158966303, Valid Loss: 0.0031643498223274946\n",
      "Epoch: 4773, Train Loss: 0.0024445648305118084, Valid Loss: 0.0031624475959688425\n",
      "Epoch: 4774, Train Loss: 0.002442967612296343, Valid Loss: 0.0031605141703039408\n",
      "Epoch: 4775, Train Loss: 0.0024413703940808773, Valid Loss: 0.0031585919205099344\n",
      "Epoch: 4776, Train Loss: 0.0024397792294621468, Valid Loss: 0.003156651509925723\n",
      "Epoch: 4777, Train Loss: 0.0024381871335208416, Valid Loss: 0.0031547697726637125\n",
      "Epoch: 4778, Train Loss: 0.002436598064377904, Valid Loss: 0.0031528398394584656\n",
      "Epoch: 4779, Train Loss: 0.0024350075982511044, Valid Loss: 0.0031509152613580227\n",
      "Epoch: 4780, Train Loss: 0.0024334194604307413, Valid Loss: 0.0031490009278059006\n",
      "Epoch: 4781, Train Loss: 0.002431832952424884, Valid Loss: 0.0031471061520278454\n",
      "Epoch: 4782, Train Loss: 0.0024302443489432335, Valid Loss: 0.0031451862305402756\n",
      "Epoch: 4783, Train Loss: 0.0024286587722599506, Valid Loss: 0.0031432670075446367\n",
      "Epoch: 4784, Train Loss: 0.0024270773865282536, Valid Loss: 0.003141367807984352\n",
      "Epoch: 4785, Train Loss: 0.0024254939053207636, Valid Loss: 0.0031394578982144594\n",
      "Epoch: 4786, Train Loss: 0.0024239104241132736, Valid Loss: 0.0031375386752188206\n",
      "Epoch: 4787, Train Loss: 0.002422330202534795, Valid Loss: 0.0031356520485132933\n",
      "Epoch: 4788, Train Loss: 0.0024207523092627525, Valid Loss: 0.0031337463296949863\n",
      "Epoch: 4789, Train Loss: 0.0024191702250391245, Valid Loss: 0.003131845034658909\n",
      "Epoch: 4790, Train Loss: 0.0024175976868718863, Valid Loss: 0.003129930468276143\n",
      "Epoch: 4791, Train Loss: 0.002416023053228855, Valid Loss: 0.003128061071038246\n",
      "Epoch: 4792, Train Loss: 0.002414450980722904, Valid Loss: 0.003126172348856926\n",
      "Epoch: 4793, Train Loss: 0.002412877045571804, Valid Loss: 0.003124249167740345\n",
      "Epoch: 4794, Train Loss: 0.002411307068541646, Valid Loss: 0.0031223627738654613\n",
      "Epoch: 4795, Train Loss: 0.0024097352288663387, Valid Loss: 0.0031204659026116133\n",
      "Epoch: 4796, Train Loss: 0.002408167812973261, Valid Loss: 0.0031185955740511417\n",
      "Epoch: 4797, Train Loss: 0.0024066006299108267, Valid Loss: 0.003116677515208721\n",
      "Epoch: 4798, Train Loss: 0.002405029721558094, Valid Loss: 0.003114788793027401\n",
      "Epoch: 4799, Train Loss: 0.002403464401140809, Valid Loss: 0.0031129091512411833\n",
      "Epoch: 4800, Train Loss: 0.002401902573183179, Valid Loss: 0.003111022524535656\n",
      "Epoch: 4801, Train Loss: 0.002400337252765894, Valid Loss: 0.0031091407872736454\n",
      "Epoch: 4802, Train Loss: 0.002398773329332471, Valid Loss: 0.0031072362326085567\n",
      "Epoch: 4803, Train Loss: 0.002397215226665139, Valid Loss: 0.00310536939650774\n",
      "Epoch: 4804, Train Loss: 0.0023956531658768654, Valid Loss: 0.0031034820713102818\n",
      "Epoch: 4805, Train Loss: 0.0023940957617014647, Valid Loss: 0.0031016094144433737\n",
      "Epoch: 4806, Train Loss: 0.0023925392888486385, Valid Loss: 0.003099714871495962\n",
      "Epoch: 4807, Train Loss: 0.002390981651842594, Valid Loss: 0.0030978554859757423\n",
      "Epoch: 4808, Train Loss: 0.0023894289042800665, Valid Loss: 0.0030959746800363064\n",
      "Epoch: 4809, Train Loss: 0.0023878752253949642, Valid Loss: 0.003094102256000042\n",
      "Epoch: 4810, Train Loss: 0.002386325504630804, Valid Loss: 0.003092234954237938\n",
      "Epoch: 4811, Train Loss: 0.002384773688390851, Valid Loss: 0.003090348793193698\n",
      "Epoch: 4812, Train Loss: 0.002383220475167036, Valid Loss: 0.0030884845182299614\n",
      "Epoch: 4813, Train Loss: 0.0023816705215722322, Valid Loss: 0.0030866041779518127\n",
      "Epoch: 4814, Train Loss: 0.0023801180068403482, Valid Loss: 0.0030847426969558\n",
      "Epoch: 4815, Train Loss: 0.0023785759694874287, Valid Loss: 0.003082870738580823\n",
      "Epoch: 4816, Train Loss: 0.00237703463062644, Valid Loss: 0.0030810143798589706\n",
      "Epoch: 4817, Train Loss: 0.0023754877038300037, Valid Loss: 0.0030791452154517174\n",
      "Epoch: 4818, Train Loss: 0.002373944502323866, Valid Loss: 0.003077284200116992\n",
      "Epoch: 4819, Train Loss: 0.0023724036291241646, Valid Loss: 0.0030754385516047478\n",
      "Epoch: 4820, Train Loss: 0.002370864152908325, Valid Loss: 0.00307355634868145\n",
      "Epoch: 4821, Train Loss: 0.002369317691773176, Valid Loss: 0.003071695799008012\n",
      "Epoch: 4822, Train Loss: 0.002367784269154072, Valid Loss: 0.003069863887503743\n",
      "Epoch: 4823, Train Loss: 0.002366249216720462, Valid Loss: 0.0030680077616125345\n",
      "Epoch: 4824, Train Loss: 0.00236471276730299, Valid Loss: 0.003066132077947259\n",
      "Epoch: 4825, Train Loss: 0.002363176317885518, Valid Loss: 0.003064266638830304\n",
      "Epoch: 4826, Train Loss: 0.00236164266243577, Valid Loss: 0.0030624561477452517\n",
      "Epoch: 4827, Train Loss: 0.0023601094726473093, Valid Loss: 0.003060570452362299\n",
      "Epoch: 4828, Train Loss: 0.002358577447012067, Valid Loss: 0.003058732720091939\n",
      "Epoch: 4829, Train Loss: 0.002357048448175192, Valid Loss: 0.0030568691436201334\n",
      "Epoch: 4830, Train Loss: 0.0023555217776447535, Valid Loss: 0.003055035136640072\n",
      "Epoch: 4831, Train Loss: 0.0023539913818240166, Valid Loss: 0.00305318646132946\n",
      "Epoch: 4832, Train Loss: 0.0023524619173258543, Valid Loss: 0.0030513452365994453\n",
      "Epoch: 4833, Train Loss: 0.0023509373422712088, Valid Loss: 0.003049522638320923\n",
      "Epoch: 4834, Train Loss: 0.002349412301555276, Valid Loss: 0.0030476406682282686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4835, Train Loss: 0.0023478874936699867, Valid Loss: 0.0030457996763288975\n",
      "Epoch: 4836, Train Loss: 0.0023463675752282143, Valid Loss: 0.003043980337679386\n",
      "Epoch: 4837, Train Loss: 0.002344846958294511, Valid Loss: 0.0030421572737395763\n",
      "Epoch: 4838, Train Loss: 0.002343330532312393, Valid Loss: 0.003040304174646735\n",
      "Epoch: 4839, Train Loss: 0.0023418115451931953, Valid Loss: 0.0030384426936507225\n",
      "Epoch: 4840, Train Loss: 0.002340293023735285, Valid Loss: 0.0030366352293640375\n",
      "Epoch: 4841, Train Loss: 0.002338775899261236, Valid Loss: 0.0030348198488354683\n",
      "Epoch: 4842, Train Loss: 0.0023372566793113947, Valid Loss: 0.003032970940694213\n",
      "Epoch: 4843, Train Loss: 0.0023357467725872993, Valid Loss: 0.003031110391020775\n",
      "Epoch: 4844, Train Loss: 0.002334233373403549, Valid Loss: 0.0030293005984276533\n",
      "Epoch: 4845, Train Loss: 0.002332717413082719, Valid Loss: 0.003027477068826556\n",
      "Epoch: 4846, Train Loss: 0.0023312109988182783, Valid Loss: 0.0030256554018706083\n",
      "Epoch: 4847, Train Loss: 0.0023297048173844814, Valid Loss: 0.0030238288454711437\n",
      "Epoch: 4848, Train Loss: 0.002328191651031375, Valid Loss: 0.003021995536983013\n",
      "Epoch: 4849, Train Loss: 0.002326688263565302, Valid Loss: 0.0030201799236238003\n",
      "Epoch: 4850, Train Loss: 0.002325180685147643, Valid Loss: 0.003018354531377554\n",
      "Epoch: 4851, Train Loss: 0.0023236775305122137, Valid Loss: 0.003016565926373005\n",
      "Epoch: 4852, Train Loss: 0.0023221676237881184, Valid Loss: 0.0030147123616188765\n",
      "Epoch: 4853, Train Loss: 0.002320666331797838, Valid Loss: 0.0030128948856145144\n",
      "Epoch: 4854, Train Loss: 0.002319167833775282, Valid Loss: 0.0030110764782875776\n",
      "Epoch: 4855, Train Loss: 0.0023176674731075764, Valid Loss: 0.0030092948582023382\n",
      "Epoch: 4856, Train Loss: 0.002316167810931802, Valid Loss: 0.0030074610840529203\n",
      "Epoch: 4857, Train Loss: 0.0023146693129092455, Valid Loss: 0.0030056280083954334\n",
      "Epoch: 4858, Train Loss: 0.002313170349225402, Valid Loss: 0.003003836376592517\n",
      "Epoch: 4859, Train Loss: 0.0023116774391382933, Valid Loss: 0.0030020400881767273\n",
      "Epoch: 4860, Train Loss: 0.002310182200744748, Valid Loss: 0.0030002249404788017\n",
      "Epoch: 4861, Train Loss: 0.0023086885921657085, Valid Loss: 0.0029983900021761656\n",
      "Epoch: 4862, Train Loss: 0.0023071966134011745, Valid Loss: 0.0029966142028570175\n",
      "Epoch: 4863, Train Loss: 0.0023057034704834223, Valid Loss: 0.0029947853181511164\n",
      "Epoch: 4864, Train Loss: 0.002304213121533394, Valid Loss: 0.0029930011369287968\n",
      "Epoch: 4865, Train Loss: 0.002302724402397871, Valid Loss: 0.002991192741319537\n",
      "Epoch: 4866, Train Loss: 0.0023012394085526466, Valid Loss: 0.002989390166476369\n",
      "Epoch: 4867, Train Loss: 0.0022997483611106873, Valid Loss: 0.0029875957407057285\n",
      "Epoch: 4868, Train Loss: 0.0022982636000961065, Valid Loss: 0.002985789440572262\n",
      "Epoch: 4869, Train Loss: 0.0022967830300331116, Valid Loss: 0.002983994549140334\n",
      "Epoch: 4870, Train Loss: 0.0022952950093895197, Valid Loss: 0.002982203382998705\n",
      "Epoch: 4871, Train Loss: 0.002293812343850732, Valid Loss: 0.002980415243655443\n",
      "Epoch: 4872, Train Loss: 0.0022923334036022425, Valid Loss: 0.0029786014929413795\n",
      "Epoch: 4873, Train Loss: 0.0022908553946763277, Valid Loss: 0.002976821968331933\n",
      "Epoch: 4874, Train Loss: 0.0022893757559359074, Valid Loss: 0.0029750405810773373\n",
      "Epoch: 4875, Train Loss: 0.0022878949530422688, Valid Loss: 0.0029732424300163984\n",
      "Epoch: 4876, Train Loss: 0.0022864192724227905, Valid Loss: 0.0029714535921812057\n",
      "Epoch: 4877, Train Loss: 0.002284940565004945, Valid Loss: 0.002969658700749278\n",
      "Epoch: 4878, Train Loss: 0.0022834697738289833, Valid Loss: 0.002967881504446268\n",
      "Epoch: 4879, Train Loss: 0.002281998051330447, Valid Loss: 0.0029660833533853292\n",
      "Epoch: 4880, Train Loss: 0.0022805205080658197, Valid Loss: 0.0029643159359693527\n",
      "Epoch: 4881, Train Loss: 0.002279050648212433, Valid Loss: 0.002962528495118022\n",
      "Epoch: 4882, Train Loss: 0.0022775817196816206, Valid Loss: 0.0029607422184199095\n",
      "Epoch: 4883, Train Loss: 0.002276113722473383, Valid Loss: 0.0029589480254799128\n",
      "Epoch: 4884, Train Loss: 0.002274642698466778, Valid Loss: 0.002957206917926669\n",
      "Epoch: 4885, Train Loss: 0.0022731784265488386, Valid Loss: 0.0029554227367043495\n",
      "Epoch: 4886, Train Loss: 0.002271712524816394, Valid Loss: 0.0029536127112805843\n",
      "Epoch: 4887, Train Loss: 0.0022702491842210293, Valid Loss: 0.0029518522787839174\n",
      "Epoch: 4888, Train Loss: 0.0022687821183353662, Valid Loss: 0.0029500939417630434\n",
      "Epoch: 4889, Train Loss: 0.0022673180792480707, Valid Loss: 0.0029483267571777105\n",
      "Epoch: 4890, Train Loss: 0.0022658617235720158, Valid Loss: 0.002946526976302266\n",
      "Epoch: 4891, Train Loss: 0.0022643988486379385, Valid Loss: 0.0029447865672409534\n",
      "Epoch: 4892, Train Loss: 0.002262938069179654, Valid Loss: 0.0029430091381073\n",
      "Epoch: 4893, Train Loss: 0.002261478453874588, Valid Loss: 0.0029412400908768177\n",
      "Epoch: 4894, Train Loss: 0.0022600246593356133, Valid Loss: 0.002939476864412427\n",
      "Epoch: 4895, Train Loss: 0.0022585662081837654, Valid Loss: 0.00293770432472229\n",
      "Epoch: 4896, Train Loss: 0.00225711427628994, Valid Loss: 0.0029359478503465652\n",
      "Epoch: 4897, Train Loss: 0.002255660016089678, Valid Loss: 0.002934186952188611\n",
      "Epoch: 4898, Train Loss: 0.002254209015518427, Valid Loss: 0.0029324248898774385\n",
      "Epoch: 4899, Train Loss: 0.0022527549881488085, Valid Loss: 0.002930658869445324\n",
      "Epoch: 4900, Train Loss: 0.0022513042204082012, Valid Loss: 0.0029288954101502895\n",
      "Epoch: 4901, Train Loss: 0.002249855548143387, Valid Loss: 0.002927156398072839\n",
      "Epoch: 4902, Train Loss: 0.00224840990267694, Valid Loss: 0.002925381064414978\n",
      "Epoch: 4903, Train Loss: 0.002246960299089551, Valid Loss: 0.0029236332047730684\n",
      "Epoch: 4904, Train Loss: 0.0022455155849456787, Valid Loss: 0.0029218769632279873\n",
      "Epoch: 4905, Train Loss: 0.0022440673783421516, Valid Loss: 0.002920132363215089\n",
      "Epoch: 4906, Train Loss: 0.002242624992504716, Valid Loss: 0.0029183689039200544\n",
      "Epoch: 4907, Train Loss: 0.00224118260666728, Valid Loss: 0.0029166354797780514\n",
      "Epoch: 4908, Train Loss: 0.0022397413849830627, Valid Loss: 0.0029148778412491083\n",
      "Epoch: 4909, Train Loss: 0.0022383020259439945, Valid Loss: 0.002913118340075016\n",
      "Epoch: 4910, Train Loss: 0.002236860804259777, Valid Loss: 0.0029113800264894962\n",
      "Epoch: 4911, Train Loss: 0.002235420048236847, Valid Loss: 0.002909634495154023\n",
      "Epoch: 4912, Train Loss: 0.0022339806891977787, Valid Loss: 0.0029079029336571693\n",
      "Epoch: 4913, Train Loss: 0.0022325452882796526, Valid Loss: 0.0029061350505799055\n",
      "Epoch: 4914, Train Loss: 0.002231112914159894, Valid Loss: 0.0029044116381555796\n",
      "Epoch: 4915, Train Loss: 0.0022296791430562735, Valid Loss: 0.0029026803094893694\n",
      "Epoch: 4916, Train Loss: 0.0022282449062913656, Valid Loss: 0.0029009345453232527\n",
      "Epoch: 4917, Train Loss: 0.002226812532171607, Valid Loss: 0.0028991797007620335\n",
      "Epoch: 4918, Train Loss: 0.0022253829520195723, Valid Loss: 0.0028974665328860283\n",
      "Epoch: 4919, Train Loss: 0.002223947551101446, Valid Loss: 0.0028957354370504618\n",
      "Epoch: 4920, Train Loss: 0.0022225205320864916, Valid Loss: 0.0028939861804246902\n",
      "Epoch: 4921, Train Loss: 0.002221094211563468, Valid Loss: 0.002892256947234273\n",
      "Epoch: 4922, Train Loss: 0.0022196669597178698, Valid Loss: 0.0028905195649713278\n",
      "Epoch: 4923, Train Loss: 0.0022182425018399954, Valid Loss: 0.002888800809159875\n",
      "Epoch: 4924, Train Loss: 0.0022168150171637535, Valid Loss: 0.002887068083509803\n",
      "Epoch: 4925, Train Loss: 0.0022153938189148903, Valid Loss: 0.0028853595722466707\n",
      "Epoch: 4926, Train Loss: 0.0022139698266983032, Valid Loss: 0.0028836089186370373\n",
      "Epoch: 4927, Train Loss: 0.00221254606731236, Valid Loss: 0.0028818717692047358\n",
      "Epoch: 4928, Train Loss: 0.0022111274302005768, Valid Loss: 0.002880167681723833\n",
      "Epoch: 4929, Train Loss: 0.0022097087930887938, Valid Loss: 0.0028784507885575294\n",
      "Epoch: 4930, Train Loss: 0.002208289224654436, Valid Loss: 0.0028767180629074574\n",
      "Epoch: 4931, Train Loss: 0.0022068701218813658, Valid Loss: 0.002874980913475156\n",
      "Epoch: 4932, Train Loss: 0.0022054584696888924, Valid Loss: 0.0028732905630022287\n",
      "Epoch: 4933, Train Loss: 0.0022040402982383966, Valid Loss: 0.0028715517837554216\n",
      "Epoch: 4934, Train Loss: 0.0022026263177394867, Valid Loss: 0.002869840245693922\n",
      "Epoch: 4935, Train Loss: 0.0022012137342244387, Valid Loss: 0.002868121489882469\n",
      "Epoch: 4936, Train Loss: 0.0021998011507093906, Valid Loss: 0.0028664246201515198\n",
      "Epoch: 4937, Train Loss: 0.0021983906626701355, Valid Loss: 0.0028646981809288263\n",
      "Epoch: 4938, Train Loss: 0.0021969815716147423, Valid Loss: 0.002862975699827075\n",
      "Epoch: 4939, Train Loss: 0.0021955729462206364, Valid Loss: 0.002861274406313896\n",
      "Epoch: 4940, Train Loss: 0.002194163855165243, Valid Loss: 0.002859562635421753\n",
      "Epoch: 4941, Train Loss: 0.0021927535999566317, Valid Loss: 0.002857846673578024\n",
      "Epoch: 4942, Train Loss: 0.002191350096836686, Valid Loss: 0.0028561297804117203\n",
      "Epoch: 4943, Train Loss: 0.0021899465937167406, Valid Loss: 0.0028544485103338957\n",
      "Epoch: 4944, Train Loss: 0.0021885382011532784, Valid Loss: 0.0028527318499982357\n",
      "Epoch: 4945, Train Loss: 0.002187139820307493, Valid Loss: 0.0028510328847914934\n",
      "Epoch: 4946, Train Loss: 0.002185736782848835, Valid Loss: 0.002849305048584938\n",
      "Epoch: 4947, Train Loss: 0.0021843360736966133, Valid Loss: 0.0028476333245635033\n",
      "Epoch: 4948, Train Loss: 0.0021829342003911734, Valid Loss: 0.002845926908776164\n",
      "Epoch: 4949, Train Loss: 0.002181540708988905, Valid Loss: 0.0028442407492548227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4950, Train Loss: 0.002180139534175396, Valid Loss: 0.0028425336349755526\n",
      "Epoch: 4951, Train Loss: 0.0021787420846521854, Valid Loss: 0.002840836066752672\n",
      "Epoch: 4952, Train Loss: 0.0021773476619273424, Valid Loss: 0.0028391398955136538\n",
      "Epoch: 4953, Train Loss: 0.0021759578958153725, Valid Loss: 0.002837450010702014\n",
      "Epoch: 4954, Train Loss: 0.002174557652324438, Valid Loss: 0.0028357557021081448\n",
      "Epoch: 4955, Train Loss: 0.002173168119043112, Valid Loss: 0.0028340541757643223\n",
      "Epoch: 4956, Train Loss: 0.0021717757917940617, Valid Loss: 0.002832360565662384\n",
      "Epoch: 4957, Train Loss: 0.0021703848615288734, Valid Loss: 0.0028306616004556417\n",
      "Epoch: 4958, Train Loss: 0.002168998820707202, Valid Loss: 0.0028290092013776302\n",
      "Epoch: 4959, Train Loss: 0.0021676071919500828, Valid Loss: 0.0028272729832679033\n",
      "Epoch: 4960, Train Loss: 0.0021662211511284113, Valid Loss: 0.0028256243094801903\n",
      "Epoch: 4961, Train Loss: 0.002164834411814809, Valid Loss: 0.002823921851813793\n",
      "Epoch: 4962, Train Loss: 0.002163451164960861, Valid Loss: 0.0028222843538969755\n",
      "Epoch: 4963, Train Loss: 0.0021620639599859715, Valid Loss: 0.0028205374255776405\n",
      "Epoch: 4964, Train Loss: 0.0021606830414384604, Valid Loss: 0.002818887820467353\n",
      "Epoch: 4965, Train Loss: 0.0021593002602458, Valid Loss: 0.002817201428115368\n",
      "Epoch: 4966, Train Loss: 0.002157921902835369, Valid Loss: 0.002815557410940528\n",
      "Epoch: 4967, Train Loss: 0.0021565360948443413, Valid Loss: 0.0028138323687016964\n",
      "Epoch: 4968, Train Loss: 0.0021551596000790596, Valid Loss: 0.0028121431823819876\n",
      "Epoch: 4969, Train Loss: 0.0021537800785154104, Valid Loss: 0.0028104959055781364\n",
      "Epoch: 4970, Train Loss: 0.002152402186766267, Valid Loss: 0.002808821154758334\n",
      "Epoch: 4971, Train Loss: 0.0021510280203074217, Valid Loss: 0.0028071438428014517\n",
      "Epoch: 4972, Train Loss: 0.0021496519912034273, Valid Loss: 0.002805445808917284\n",
      "Epoch: 4973, Train Loss: 0.0021482782904058695, Valid Loss: 0.0028038108721375465\n",
      "Epoch: 4974, Train Loss: 0.002146904356777668, Valid Loss: 0.002802122849971056\n",
      "Epoch: 4975, Train Loss: 0.002145532751455903, Valid Loss: 0.0028004657942801714\n",
      "Epoch: 4976, Train Loss: 0.002144161146134138, Valid Loss: 0.0027987754438072443\n",
      "Epoch: 4977, Train Loss: 0.0021427911706268787, Valid Loss: 0.002797142369672656\n",
      "Epoch: 4978, Train Loss: 0.0021414204966276884, Valid Loss: 0.0027954629622399807\n",
      "Epoch: 4979, Train Loss: 0.0021400542464107275, Valid Loss: 0.0027937949635088444\n",
      "Epoch: 4980, Train Loss: 0.002138687763363123, Valid Loss: 0.002792157931253314\n",
      "Epoch: 4981, Train Loss: 0.00213731755502522, Valid Loss: 0.0027904731687158346\n",
      "Epoch: 4982, Train Loss: 0.0021359529346227646, Valid Loss: 0.002788819372653961\n",
      "Epoch: 4983, Train Loss: 0.002134593203663826, Valid Loss: 0.0027871544007211924\n",
      "Epoch: 4984, Train Loss: 0.002133226953446865, Valid Loss: 0.0027855115476995707\n",
      "Epoch: 4985, Train Loss: 0.0021318665239959955, Valid Loss: 0.0027838253881782293\n",
      "Epoch: 4986, Train Loss: 0.0021305051632225513, Valid Loss: 0.002782189752906561\n",
      "Epoch: 4987, Train Loss: 0.0021291489247232676, Valid Loss: 0.002780524780973792\n",
      "Epoch: 4988, Train Loss: 0.002127788495272398, Valid Loss: 0.002778882160782814\n",
      "Epoch: 4989, Train Loss: 0.0021264248061925173, Valid Loss: 0.0027772006578743458\n",
      "Epoch: 4990, Train Loss: 0.0021250725258141756, Valid Loss: 0.0027755810879170895\n",
      "Epoch: 4991, Train Loss: 0.0021237158216536045, Valid Loss: 0.0027739296201616526\n",
      "Epoch: 4992, Train Loss: 0.0021223609801381826, Valid Loss: 0.0027722662780433893\n",
      "Epoch: 4993, Train Loss: 0.0021210049744695425, Valid Loss: 0.002770625753328204\n",
      "Epoch: 4994, Train Loss: 0.0021196540910750628, Valid Loss: 0.0027689605485647917\n",
      "Epoch: 4995, Train Loss: 0.0021183022763580084, Valid Loss: 0.0027673456352204084\n",
      "Epoch: 4996, Train Loss: 0.0021169506944715977, Valid Loss: 0.002765677636489272\n",
      "Epoch: 4997, Train Loss: 0.00211560120806098, Valid Loss: 0.002764059929177165\n",
      "Epoch: 4998, Train Loss: 0.0021142503246665, Valid Loss: 0.002762370742857456\n",
      "Epoch: 4999, Train Loss: 0.0021129013039171696, Valid Loss: 0.002760769799351692\n",
      "Epoch: 5000, Train Loss: 0.0021115567069500685, Valid Loss: 0.0027591127436608076\n",
      "Epoch: 5001, Train Loss: 0.0021102086175233126, Valid Loss: 0.002757508074864745\n",
      "Epoch: 5002, Train Loss: 0.0021088633220642805, Valid Loss: 0.00275582168251276\n",
      "Epoch: 5003, Train Loss: 0.002107519656419754, Valid Loss: 0.002754224929958582\n",
      "Epoch: 5004, Train Loss: 0.0021061759907752275, Valid Loss: 0.0027525729965418577\n",
      "Epoch: 5005, Train Loss: 0.0021048327907919884, Valid Loss: 0.0027509531937539577\n",
      "Epoch: 5006, Train Loss: 0.0021034872625023127, Valid Loss: 0.002749283565208316\n",
      "Epoch: 5007, Train Loss: 0.0021021519787609577, Valid Loss: 0.0027476816903799772\n",
      "Epoch: 5008, Train Loss: 0.0021008120384067297, Valid Loss: 0.0027460316196084023\n",
      "Epoch: 5009, Train Loss: 0.002099476521834731, Valid Loss: 0.002744416706264019\n",
      "Epoch: 5010, Train Loss: 0.0020981356501579285, Valid Loss: 0.0027427896857261658\n",
      "Epoch: 5011, Train Loss: 0.002096801996231079, Valid Loss: 0.002741168485954404\n",
      "Epoch: 5012, Train Loss: 0.002095468109473586, Valid Loss: 0.0027395254001021385\n",
      "Epoch: 5013, Train Loss: 0.002094128169119358, Valid Loss: 0.0027378927916288376\n",
      "Epoch: 5014, Train Loss: 0.002092801034450531, Valid Loss: 0.002736296970397234\n",
      "Epoch: 5015, Train Loss: 0.0020914659835398197, Valid Loss: 0.0027346741408109665\n",
      "Epoch: 5016, Train Loss: 0.002090136520564556, Valid Loss: 0.002733033848926425\n",
      "Epoch: 5017, Train Loss: 0.0020888035651296377, Valid Loss: 0.002731401240453124\n",
      "Epoch: 5018, Train Loss: 0.0020874703768640757, Valid Loss: 0.0027297972701489925\n",
      "Epoch: 5019, Train Loss: 0.002086146967485547, Valid Loss: 0.002728177234530449\n",
      "Epoch: 5020, Train Loss: 0.002084819134324789, Valid Loss: 0.002726563485339284\n",
      "Epoch: 5021, Train Loss: 0.002083491999655962, Valid Loss: 0.002724952297285199\n",
      "Epoch: 5022, Train Loss: 0.0020821657963097095, Valid Loss: 0.002723325276747346\n",
      "Epoch: 5023, Train Loss: 0.00208083912730217, Valid Loss: 0.0027217031456530094\n",
      "Epoch: 5024, Train Loss: 0.002079515252262354, Valid Loss: 0.0027201082557439804\n",
      "Epoch: 5025, Train Loss: 0.002078193938359618, Valid Loss: 0.002718517556786537\n",
      "Epoch: 5026, Train Loss: 0.0020768747199326754, Valid Loss: 0.0027168712113052607\n",
      "Epoch: 5027, Train Loss: 0.0020755508448928595, Valid Loss: 0.0027152555994689465\n",
      "Epoch: 5028, Train Loss: 0.002074233256280422, Valid Loss: 0.00271366024389863\n",
      "Epoch: 5029, Train Loss: 0.002072912408038974, Valid Loss: 0.002712060697376728\n",
      "Epoch: 5030, Train Loss: 0.0020715936552733183, Valid Loss: 0.002710457658395171\n",
      "Epoch: 5031, Train Loss: 0.0020702786277979612, Valid Loss: 0.0027088457718491554\n",
      "Epoch: 5032, Train Loss: 0.0020689605735242367, Valid Loss: 0.0027072415687143803\n",
      "Epoch: 5033, Train Loss: 0.0020676436834037304, Valid Loss: 0.002705644117668271\n",
      "Epoch: 5034, Train Loss: 0.002066331682726741, Valid Loss: 0.002704059472307563\n",
      "Epoch: 5035, Train Loss: 0.002065015956759453, Valid Loss: 0.0027024392038583755\n",
      "Epoch: 5036, Train Loss: 0.002063703490421176, Valid Loss: 0.0027008226606994867\n",
      "Epoch: 5037, Train Loss: 0.002062396612018347, Valid Loss: 0.0026992433704435825\n",
      "Epoch: 5038, Train Loss: 0.0020610825158655643, Valid Loss: 0.0026976533699780703\n",
      "Epoch: 5039, Train Loss: 0.0020597719121724367, Valid Loss: 0.0026960568502545357\n",
      "Epoch: 5040, Train Loss: 0.0020584657322615385, Valid Loss: 0.0026944505516439676\n",
      "Epoch: 5041, Train Loss: 0.0020571602508425713, Valid Loss: 0.0026928496081382036\n",
      "Epoch: 5042, Train Loss: 0.002055850112810731, Valid Loss: 0.002691273344680667\n",
      "Epoch: 5043, Train Loss: 0.0020545474253594875, Valid Loss: 0.002689692424610257\n",
      "Epoch: 5044, Train Loss: 0.002053240081295371, Valid Loss: 0.0026880884543061256\n",
      "Epoch: 5045, Train Loss: 0.002051936462521553, Valid Loss: 0.0026864868123084307\n",
      "Epoch: 5046, Train Loss: 0.0020506340079009533, Valid Loss: 0.002684909151867032\n",
      "Epoch: 5047, Train Loss: 0.002049329923465848, Valid Loss: 0.002683333121240139\n",
      "Epoch: 5048, Train Loss: 0.002048030961304903, Valid Loss: 0.002681736834347248\n",
      "Epoch: 5049, Train Loss: 0.0020467317663133144, Valid Loss: 0.002680141944438219\n",
      "Epoch: 5050, Train Loss: 0.002045434433966875, Valid Loss: 0.002678565913811326\n",
      "Epoch: 5051, Train Loss: 0.0020441338419914246, Valid Loss: 0.0026769794058054686\n",
      "Epoch: 5052, Train Loss: 0.002042840700596571, Valid Loss: 0.0026754147838801146\n",
      "Epoch: 5053, Train Loss: 0.002041543833911419, Valid Loss: 0.0026738124433904886\n",
      "Epoch: 5054, Train Loss: 0.002040247432887554, Valid Loss: 0.0026722517795860767\n",
      "Epoch: 5055, Train Loss: 0.0020389496348798275, Valid Loss: 0.0026706550270318985\n",
      "Epoch: 5056, Train Loss: 0.002037659753113985, Valid Loss: 0.0026690957602113485\n",
      "Epoch: 5057, Train Loss: 0.002036365447565913, Valid Loss: 0.002667501335963607\n",
      "Epoch: 5058, Train Loss: 0.002035073935985565, Valid Loss: 0.0026659369468688965\n",
      "Epoch: 5059, Train Loss: 0.0020337789319455624, Valid Loss: 0.002664349740371108\n",
      "Epoch: 5060, Train Loss: 0.0020324939396232367, Valid Loss: 0.002662799321115017\n",
      "Epoch: 5061, Train Loss: 0.0020312026608735323, Valid Loss: 0.002661205129697919\n",
      "Epoch: 5062, Train Loss: 0.00202991277910769, Valid Loss: 0.002659645164385438\n",
      "Epoch: 5063, Train Loss: 0.0020286322105675936, Valid Loss: 0.0026580726262181997\n",
      "Epoch: 5064, Train Loss: 0.002027344424277544, Valid Loss: 0.0026564979925751686\n",
      "Epoch: 5065, Train Loss: 0.0020260585006326437, Valid Loss: 0.0026549145113676786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5066, Train Loss: 0.0020247758366167545, Valid Loss: 0.002653376664966345\n",
      "Epoch: 5067, Train Loss: 0.002023492706939578, Valid Loss: 0.0026518034283071756\n",
      "Epoch: 5068, Train Loss: 0.0020222095772624016, Valid Loss: 0.0026502355467528105\n",
      "Epoch: 5069, Train Loss: 0.0020209301728755236, Valid Loss: 0.002648673951625824\n",
      "Epoch: 5070, Train Loss: 0.002019644482061267, Valid Loss: 0.00264712143689394\n",
      "Epoch: 5071, Train Loss: 0.0020183674059808254, Valid Loss: 0.0026455542538315058\n",
      "Epoch: 5072, Train Loss: 0.002017089631408453, Valid Loss: 0.0026439903303980827\n",
      "Epoch: 5073, Train Loss: 0.002015811624005437, Valid Loss: 0.002642426174134016\n",
      "Epoch: 5074, Train Loss: 0.0020145352464169264, Valid Loss: 0.0026408901903778315\n",
      "Epoch: 5075, Train Loss: 0.0020132598001509905, Valid Loss: 0.0026393223088234663\n",
      "Epoch: 5076, Train Loss: 0.002011985518038273, Valid Loss: 0.0026377737522125244\n",
      "Epoch: 5077, Train Loss: 0.0020107089076191187, Valid Loss: 0.0026361923664808273\n",
      "Epoch: 5078, Train Loss: 0.002009438117966056, Valid Loss: 0.0026346591766923666\n",
      "Epoch: 5079, Train Loss: 0.00200816267170012, Valid Loss: 0.0026331087574362755\n",
      "Epoch: 5080, Train Loss: 0.0020068942103534937, Valid Loss: 0.002631557174026966\n",
      "Epoch: 5081, Train Loss: 0.0020056236535310745, Valid Loss: 0.002629972295835614\n",
      "Epoch: 5082, Train Loss: 0.0020043530967086554, Valid Loss: 0.0026284686755388975\n",
      "Epoch: 5083, Train Loss: 0.0020030855666846037, Valid Loss: 0.002626904519274831\n",
      "Epoch: 5084, Train Loss: 0.0020018192008137703, Valid Loss: 0.002625367371365428\n",
      "Epoch: 5085, Train Loss: 0.0020005512051284313, Valid Loss: 0.0026237780693918467\n",
      "Epoch: 5086, Train Loss: 0.001999284140765667, Valid Loss: 0.0026222874876111746\n",
      "Epoch: 5087, Train Loss: 0.001998020801693201, Valid Loss: 0.0026206981856375933\n",
      "Epoch: 5088, Train Loss: 0.0019967558328062296, Valid Loss: 0.0026192087680101395\n",
      "Epoch: 5089, Train Loss: 0.0019954920280724764, Valid Loss: 0.0026176092214882374\n",
      "Epoch: 5090, Train Loss: 0.001994232414290309, Valid Loss: 0.002616127021610737\n",
      "Epoch: 5091, Train Loss: 0.001992970472201705, Valid Loss: 0.0026145116426050663\n",
      "Epoch: 5092, Train Loss: 0.0019917108584195375, Valid Loss: 0.00261306413449347\n",
      "Epoch: 5093, Train Loss: 0.001990450080484152, Valid Loss: 0.0026114427018910646\n",
      "Epoch: 5094, Train Loss: 0.0019891918636858463, Valid Loss: 0.002609980758279562\n",
      "Epoch: 5095, Train Loss: 0.0019879324827343225, Valid Loss: 0.0026083504781126976\n",
      "Epoch: 5096, Train Loss: 0.001986678224056959, Valid Loss: 0.002606930211186409\n",
      "Epoch: 5097, Train Loss: 0.0019854221027344465, Valid Loss: 0.002605271292850375\n",
      "Epoch: 5098, Train Loss: 0.001984168542549014, Valid Loss: 0.0026038545183837414\n",
      "Epoch: 5099, Train Loss: 0.0019829124212265015, Valid Loss: 0.0026022163219749928\n",
      "Epoch: 5100, Train Loss: 0.0019816558342427015, Valid Loss: 0.002600821666419506\n",
      "Epoch: 5101, Train Loss: 0.001980405766516924, Valid Loss: 0.0025991180445998907\n",
      "Epoch: 5102, Train Loss: 0.001979156630113721, Valid Loss: 0.0025977648328989744\n",
      "Epoch: 5103, Train Loss: 0.0019779072608798742, Valid Loss: 0.0025960763450711966\n",
      "Epoch: 5104, Train Loss: 0.001976658357307315, Valid Loss: 0.002594755031168461\n",
      "Epoch: 5105, Train Loss: 0.001975406426936388, Valid Loss: 0.002592983888462186\n",
      "Epoch: 5106, Train Loss: 0.0019741596188396215, Valid Loss: 0.002591704949736595\n",
      "Epoch: 5107, Train Loss: 0.0019729137420654297, Valid Loss: 0.002589939162135124\n",
      "Epoch: 5108, Train Loss: 0.0019716694951057434, Valid Loss: 0.0025886979419738054\n",
      "Epoch: 5109, Train Loss: 0.001970423385500908, Valid Loss: 0.00258684903383255\n",
      "Epoch: 5110, Train Loss: 0.0019691786728799343, Valid Loss: 0.0025856848806142807\n",
      "Epoch: 5111, Train Loss: 0.001967939781025052, Valid Loss: 0.0025837875436991453\n",
      "Epoch: 5112, Train Loss: 0.001966695301234722, Valid Loss: 0.0025826923083513975\n",
      "Epoch: 5113, Train Loss: 0.001965452916920185, Valid Loss: 0.0025807020720094442\n",
      "Epoch: 5114, Train Loss: 0.0019642135594040155, Valid Loss: 0.0025797083508223295\n",
      "Epoch: 5115, Train Loss: 0.00196297699585557, Valid Loss: 0.002577635459601879\n",
      "Epoch: 5116, Train Loss: 0.0019617362413555384, Valid Loss: 0.002576737431809306\n",
      "Epoch: 5117, Train Loss: 0.0019605024717748165, Valid Loss: 0.0025745395105332136\n",
      "Epoch: 5118, Train Loss: 0.001959266373887658, Valid Loss: 0.002573818201199174\n",
      "Epoch: 5119, Train Loss: 0.0019580330699682236, Valid Loss: 0.0025714330840855837\n",
      "Epoch: 5120, Train Loss: 0.0019568034913390875, Valid Loss: 0.0025708884932100773\n",
      "Epoch: 5121, Train Loss: 0.0019555692560970783, Valid Loss: 0.0025683396961539984\n",
      "Epoch: 5122, Train Loss: 0.0019543427042663097, Valid Loss: 0.0025680195540189743\n",
      "Epoch: 5123, Train Loss: 0.0019531170837581158, Valid Loss: 0.0025652111507952213\n",
      "Epoch: 5124, Train Loss: 0.0019518905319273472, Valid Loss: 0.0025651264004409313\n",
      "Epoch: 5125, Train Loss: 0.0019506615353748202, Valid Loss: 0.0025621249806135893\n",
      "Epoch: 5126, Train Loss: 0.0019494366133585572, Valid Loss: 0.0025622518733143806\n",
      "Epoch: 5127, Train Loss: 0.0019482191419228911, Valid Loss: 0.002559039508923888\n",
      "Epoch: 5128, Train Loss: 0.0019469899125397205, Valid Loss: 0.002559309359639883\n",
      "Epoch: 5129, Train Loss: 0.0019457630114629865, Valid Loss: 0.0025560306385159492\n",
      "Epoch: 5130, Train Loss: 0.0019445321522653103, Valid Loss: 0.002556289779022336\n",
      "Epoch: 5131, Train Loss: 0.0019433037377893925, Valid Loss: 0.0025530648417770863\n",
      "Epoch: 5132, Train Loss: 0.001942070317454636, Valid Loss: 0.0025531298015266657\n",
      "Epoch: 5133, Train Loss: 0.0019408338703215122, Valid Loss: 0.0025502287317067385\n",
      "Epoch: 5134, Train Loss: 0.0019396012648940086, Valid Loss: 0.0025498729664832354\n",
      "Epoch: 5135, Train Loss: 0.0019383697072044015, Valid Loss: 0.002547468291595578\n",
      "Epoch: 5136, Train Loss: 0.0019371391972526908, Valid Loss: 0.002546553034335375\n",
      "Epoch: 5137, Train Loss: 0.0019359152065590024, Valid Loss: 0.0025447604712098837\n",
      "Epoch: 5138, Train Loss: 0.0019346950575709343, Valid Loss: 0.002543303184211254\n",
      "Epoch: 5139, Train Loss: 0.0019334795651957393, Valid Loss: 0.0025420146994292736\n",
      "Epoch: 5140, Train Loss: 0.0019322653533890843, Valid Loss: 0.002540116896852851\n",
      "Epoch: 5141, Train Loss: 0.0019310499774292111, Valid Loss: 0.0025392314419150352\n",
      "Epoch: 5142, Train Loss: 0.0019298401894047856, Valid Loss: 0.0025370365474373102\n",
      "Epoch: 5143, Train Loss: 0.0019286255119368434, Valid Loss: 0.0025363408494740725\n",
      "Epoch: 5144, Train Loss: 0.001927409553900361, Valid Loss: 0.002534035127609968\n",
      "Epoch: 5145, Train Loss: 0.0019261949928477407, Valid Loss: 0.002533318940550089\n",
      "Epoch: 5146, Train Loss: 0.0019249795004725456, Valid Loss: 0.0025311424396932125\n",
      "Epoch: 5147, Train Loss: 0.0019237627275288105, Valid Loss: 0.002530259545892477\n",
      "Epoch: 5148, Train Loss: 0.0019225494470447302, Valid Loss: 0.0025283051654696465\n",
      "Epoch: 5149, Train Loss: 0.0019213397754356265, Valid Loss: 0.002527149859815836\n",
      "Epoch: 5150, Train Loss: 0.0019201267277821898, Valid Loss: 0.002525483723729849\n",
      "Epoch: 5151, Train Loss: 0.0019189200829714537, Valid Loss: 0.002524063689634204\n",
      "Epoch: 5152, Train Loss: 0.0019177125068381429, Valid Loss: 0.002522677183151245\n",
      "Epoch: 5153, Train Loss: 0.0019165084231644869, Valid Loss: 0.0025210005696862936\n",
      "Epoch: 5154, Train Loss: 0.0019153018947690725, Valid Loss: 0.0025198147632181644\n",
      "Epoch: 5155, Train Loss: 0.0019140978110954165, Valid Loss: 0.002517994958907366\n",
      "Epoch: 5156, Train Loss: 0.0019128930289298296, Valid Loss: 0.0025169241707772017\n",
      "Epoch: 5157, Train Loss: 0.0019116918556392193, Valid Loss: 0.0025150380097329617\n",
      "Epoch: 5158, Train Loss: 0.0019104897510260344, Valid Loss: 0.0025139644276350737\n",
      "Epoch: 5159, Train Loss: 0.001909284619614482, Valid Loss: 0.0025121269281953573\n",
      "Epoch: 5160, Train Loss: 0.001908083911985159, Valid Loss: 0.002510986989364028\n",
      "Epoch: 5161, Train Loss: 0.001906883087940514, Valid Loss: 0.0025092409923672676\n",
      "Epoch: 5162, Train Loss: 0.0019056856399402022, Valid Loss: 0.002507978118956089\n",
      "Epoch: 5163, Train Loss: 0.001904485048726201, Valid Loss: 0.0025063788052648306\n",
      "Epoch: 5164, Train Loss: 0.001903287135064602, Valid Loss: 0.002504957839846611\n",
      "Epoch: 5165, Train Loss: 0.0019020935287699103, Valid Loss: 0.0025035173166543245\n",
      "Epoch: 5166, Train Loss: 0.0019008978269994259, Valid Loss: 0.0025019908789545298\n",
      "Epoch: 5167, Train Loss: 0.0018996999133378267, Valid Loss: 0.0025006397627294064\n",
      "Epoch: 5168, Train Loss: 0.0018985100323334336, Valid Loss: 0.0024990150704979897\n",
      "Epoch: 5169, Train Loss: 0.0018973142141476274, Valid Loss: 0.0024977552238851786\n",
      "Epoch: 5170, Train Loss: 0.001896124449558556, Valid Loss: 0.0024960970040410757\n",
      "Epoch: 5171, Train Loss: 0.0018949317745864391, Valid Loss: 0.002494828077033162\n",
      "Epoch: 5172, Train Loss: 0.0018937415443360806, Valid Loss: 0.0024931731168180704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5173, Train Loss: 0.001892550615593791, Valid Loss: 0.002491907449439168\n",
      "Epoch: 5174, Train Loss: 0.001891362015157938, Valid Loss: 0.0024903088342398405\n",
      "Epoch: 5175, Train Loss: 0.0018901739967986941, Valid Loss: 0.00248895026743412\n",
      "Epoch: 5176, Train Loss: 0.0018889856291934848, Valid Loss: 0.0024874384980648756\n",
      "Epoch: 5177, Train Loss: 0.0018878019182011485, Valid Loss: 0.0024860212579369545\n",
      "Epoch: 5178, Train Loss: 0.0018866141326725483, Valid Loss: 0.0024845493026077747\n",
      "Epoch: 5179, Train Loss: 0.0018854313530027866, Valid Loss: 0.002483073389157653\n",
      "Epoch: 5180, Train Loss: 0.0018842470599338412, Valid Loss: 0.002481696894392371\n",
      "Epoch: 5181, Train Loss: 0.0018830650951713324, Valid Loss: 0.002480168826878071\n",
      "Epoch: 5182, Train Loss: 0.0018818823155015707, Valid Loss: 0.0024787974543869495\n",
      "Epoch: 5183, Train Loss: 0.0018806997686624527, Valid Loss: 0.0024772565811872482\n",
      "Epoch: 5184, Train Loss: 0.001879518968053162, Valid Loss: 0.002475924789905548\n",
      "Epoch: 5185, Train Loss: 0.0018783374689519405, Valid Loss: 0.002474358770996332\n",
      "Epoch: 5186, Train Loss: 0.001877160626463592, Valid Loss: 0.002473018364980817\n",
      "Epoch: 5187, Train Loss: 0.0018759822705760598, Valid Loss: 0.002471487270668149\n",
      "Epoch: 5188, Train Loss: 0.0018748067086562514, Valid Loss: 0.0024701275397092104\n",
      "Epoch: 5189, Train Loss: 0.0018736273050308228, Valid Loss: 0.002468610182404518\n",
      "Epoch: 5190, Train Loss: 0.0018724543042480946, Valid Loss: 0.0024672423023730516\n",
      "Epoch: 5191, Train Loss: 0.0018712824676185846, Valid Loss: 0.002465778961777687\n",
      "Epoch: 5192, Train Loss: 0.0018701032968237996, Valid Loss: 0.0024643426295369864\n",
      "Epoch: 5193, Train Loss: 0.0018689318094402552, Valid Loss: 0.0024629072286188602\n",
      "Epoch: 5194, Train Loss: 0.001867758808657527, Valid Loss: 0.002461459720507264\n",
      "Epoch: 5195, Train Loss: 0.0018665888346731663, Valid Loss: 0.0024600462056696415\n",
      "Epoch: 5196, Train Loss: 0.0018654207233339548, Valid Loss: 0.0024585817009210587\n",
      "Epoch: 5197, Train Loss: 0.0018642457434907556, Valid Loss: 0.002457186346873641\n",
      "Epoch: 5198, Train Loss: 0.001863078330643475, Valid Loss: 0.0024557155556976795\n",
      "Epoch: 5199, Train Loss: 0.0018619108013808727, Valid Loss: 0.0024543332401663065\n",
      "Epoch: 5200, Train Loss: 0.001860744901932776, Valid Loss: 0.0024528668727725744\n",
      "Epoch: 5201, Train Loss: 0.0018595783039927483, Valid Loss: 0.002451459877192974\n",
      "Epoch: 5202, Train Loss: 0.0018584124045446515, Valid Loss: 0.002450003521516919\n",
      "Epoch: 5203, Train Loss: 0.0018572487169876695, Valid Loss: 0.0024486223701387644\n",
      "Epoch: 5204, Train Loss: 0.0018560807220637798, Valid Loss: 0.002447138074785471\n",
      "Epoch: 5205, Train Loss: 0.0018549199448898435, Valid Loss: 0.002445746213197708\n",
      "Epoch: 5206, Train Loss: 0.0018537610303610563, Valid Loss: 0.0024443063884973526\n",
      "Epoch: 5207, Train Loss: 0.0018525958294048905, Valid Loss: 0.0024429026525467634\n",
      "Epoch: 5208, Train Loss: 0.0018514386611059308, Valid Loss: 0.0024414686486124992\n",
      "Epoch: 5209, Train Loss: 0.0018502757884562016, Valid Loss: 0.002440054900944233\n",
      "Epoch: 5210, Train Loss: 0.0018491168739274144, Valid Loss: 0.002438631607219577\n",
      "Epoch: 5211, Train Loss: 0.001847956795245409, Valid Loss: 0.0024372076150029898\n",
      "Epoch: 5212, Train Loss: 0.0018468028865754604, Valid Loss: 0.002435789443552494\n",
      "Epoch: 5213, Train Loss: 0.001845645485445857, Valid Loss: 0.0024343826808035374\n",
      "Epoch: 5214, Train Loss: 0.0018444884335622191, Valid Loss: 0.002432970330119133\n",
      "Epoch: 5215, Train Loss: 0.001843334874138236, Valid Loss: 0.0024315407499670982\n",
      "Epoch: 5216, Train Loss: 0.001842178520746529, Valid Loss: 0.0024301328230649233\n",
      "Epoch: 5217, Train Loss: 0.0018410239135846496, Valid Loss: 0.002428704174235463\n",
      "Epoch: 5218, Train Loss: 0.001839871401898563, Valid Loss: 0.0024272992741316557\n",
      "Epoch: 5219, Train Loss: 0.0018387214513495564, Valid Loss: 0.002425906015560031\n",
      "Epoch: 5220, Train Loss: 0.0018375676590949297, Valid Loss: 0.0024244801606982946\n",
      "Epoch: 5221, Train Loss: 0.001836419920437038, Valid Loss: 0.0024230575654655695\n",
      "Epoch: 5222, Train Loss: 0.0018352725310251117, Valid Loss: 0.002421655459329486\n",
      "Epoch: 5223, Train Loss: 0.001834121998399496, Valid Loss: 0.0024202573113143444\n",
      "Epoch: 5224, Train Loss: 0.0018329755403101444, Valid Loss: 0.0024188600946217775\n",
      "Epoch: 5225, Train Loss: 0.001831825589761138, Valid Loss: 0.002417443785816431\n",
      "Epoch: 5226, Train Loss: 0.0018306809943169355, Valid Loss: 0.0024160321336239576\n",
      "Epoch: 5227, Train Loss: 0.001829537097364664, Valid Loss: 0.002414633519947529\n",
      "Epoch: 5228, Train Loss: 0.001828390988521278, Valid Loss: 0.0024132439866662025\n",
      "Epoch: 5229, Train Loss: 0.0018272484885528684, Valid Loss: 0.002411826280876994\n",
      "Epoch: 5230, Train Loss: 0.0018261029617860913, Valid Loss: 0.0024104297626763582\n",
      "Epoch: 5231, Train Loss: 0.0018249648855999112, Valid Loss: 0.002409033477306366\n",
      "Epoch: 5232, Train Loss: 0.0018238206394016743, Valid Loss: 0.0024076432455331087\n",
      "Epoch: 5233, Train Loss: 0.0018226791871711612, Valid Loss: 0.0024062178563326597\n",
      "Epoch: 5234, Train Loss: 0.0018215387826785445, Valid Loss: 0.002404831349849701\n",
      "Epoch: 5235, Train Loss: 0.0018204019870609045, Valid Loss: 0.00240345555357635\n",
      "Epoch: 5236, Train Loss: 0.0018192627467215061, Valid Loss: 0.0024020406417548656\n",
      "Epoch: 5237, Train Loss: 0.0018181282794103026, Valid Loss: 0.0024006443563848734\n",
      "Epoch: 5238, Train Loss: 0.0018169916002079844, Valid Loss: 0.0023992611095309258\n",
      "Epoch: 5239, Train Loss: 0.0018158552702516317, Valid Loss: 0.0023978648241609335\n",
      "Epoch: 5240, Train Loss: 0.0018147202208638191, Valid Loss: 0.002396476222202182\n",
      "Epoch: 5241, Train Loss: 0.001813588198274374, Valid Loss: 0.0023950831964612007\n",
      "Epoch: 5242, Train Loss: 0.0018124557100236416, Valid Loss: 0.002393692033365369\n",
      "Epoch: 5243, Train Loss: 0.0018113201949745417, Valid Loss: 0.0023923025000840425\n",
      "Epoch: 5244, Train Loss: 0.001810186542570591, Valid Loss: 0.0023909073788672686\n",
      "Epoch: 5245, Train Loss: 0.0018090566154569387, Valid Loss: 0.0023895339109003544\n",
      "Epoch: 5246, Train Loss: 0.0018079264555126429, Valid Loss: 0.0023881362285465\n",
      "Epoch: 5247, Train Loss: 0.0018067959463223815, Valid Loss: 0.002386766951531172\n",
      "Epoch: 5248, Train Loss: 0.001805669511668384, Valid Loss: 0.002385366940870881\n",
      "Epoch: 5249, Train Loss: 0.001804542145691812, Valid Loss: 0.002383992774412036\n",
      "Epoch: 5250, Train Loss: 0.0018034132663160563, Valid Loss: 0.002382603008300066\n",
      "Epoch: 5251, Train Loss: 0.0018022892763838172, Valid Loss: 0.002381236059591174\n",
      "Epoch: 5252, Train Loss: 0.001801160629838705, Valid Loss: 0.0023798421025276184\n",
      "Epoch: 5253, Train Loss: 0.0018000374548137188, Valid Loss: 0.002378458622843027\n",
      "Epoch: 5254, Train Loss: 0.0017989136977121234, Valid Loss: 0.0023770781699568033\n",
      "Epoch: 5255, Train Loss: 0.0017977927345782518, Valid Loss: 0.0023757072631269693\n",
      "Epoch: 5256, Train Loss: 0.0017966650193557143, Valid Loss: 0.002374321920797229\n",
      "Epoch: 5257, Train Loss: 0.0017955455696210265, Valid Loss: 0.0023729619570076466\n",
      "Epoch: 5258, Train Loss: 0.001794425304979086, Valid Loss: 0.002371584065258503\n",
      "Epoch: 5259, Train Loss: 0.0017933063209056854, Valid Loss: 0.002370203845202923\n",
      "Epoch: 5260, Train Loss: 0.0017921823309734464, Valid Loss: 0.0023688117507845163\n",
      "Epoch: 5261, Train Loss: 0.00179106870200485, Valid Loss: 0.0023674785625189543\n",
      "Epoch: 5262, Train Loss: 0.0017899497179314494, Valid Loss: 0.0023660839069634676\n",
      "Epoch: 5263, Train Loss: 0.00178883271291852, Valid Loss: 0.002364717423915863\n",
      "Epoch: 5264, Train Loss: 0.0017877155914902687, Valid Loss: 0.00236333510838449\n",
      "Epoch: 5265, Train Loss: 0.0017866023117676377, Valid Loss: 0.0023620009887963533\n",
      "Epoch: 5266, Train Loss: 0.0017854843754321337, Valid Loss: 0.002360597951337695\n",
      "Epoch: 5267, Train Loss: 0.0017843743553385139, Valid Loss: 0.0023592556826770306\n",
      "Epoch: 5268, Train Loss: 0.0017832610756158829, Valid Loss: 0.00235788244754076\n",
      "Epoch: 5269, Train Loss: 0.0017821454675868154, Valid Loss: 0.0023565152660012245\n",
      "Epoch: 5270, Train Loss: 0.0017810356803238392, Valid Loss: 0.0023551431950181723\n",
      "Epoch: 5271, Train Loss: 0.0017799208872020245, Valid Loss: 0.0023538058158010244\n",
      "Epoch: 5272, Train Loss: 0.0017788149416446686, Valid Loss: 0.0023524381686002016\n",
      "Epoch: 5273, Train Loss: 0.001777704805135727, Valid Loss: 0.002351063536480069\n",
      "Epoch: 5274, Train Loss: 0.0017765962984412909, Valid Loss: 0.0023496891371905804\n",
      "Epoch: 5275, Train Loss: 0.0017754912842065096, Valid Loss: 0.0023483552504330873\n",
      "Epoch: 5276, Train Loss: 0.001774384523741901, Valid Loss: 0.0023469850420951843\n",
      "Epoch: 5277, Train Loss: 0.0017732795095071197, Valid Loss: 0.0023456376511603594\n",
      "Epoch: 5278, Train Loss: 0.0017721698386594653, Valid Loss: 0.0023442567326128483\n",
      "Epoch: 5279, Train Loss: 0.0017710663378238678, Valid Loss: 0.0023429382126778364\n",
      "Epoch: 5280, Train Loss: 0.001769966329447925, Valid Loss: 0.0023415510077029467\n",
      "Epoch: 5281, Train Loss: 0.0017688623629510403, Valid Loss: 0.00234021688811481\n",
      "Epoch: 5282, Train Loss: 0.0017677568830549717, Valid Loss: 0.002338843420147896\n",
      "Epoch: 5283, Train Loss: 0.0017666578060016036, Valid Loss: 0.0023375176824629307\n",
      "Epoch: 5284, Train Loss: 0.0017655547708272934, Valid Loss: 0.0023361274506896734\n",
      "Epoch: 5285, Train Loss: 0.0017644549952819943, Valid Loss: 0.0023348138201981783\n",
      "Epoch: 5286, Train Loss: 0.0017633578972890973, Valid Loss: 0.002333439886569977\n",
      "Epoch: 5287, Train Loss: 0.0017622599843889475, Valid Loss: 0.0023321215994656086\n",
      "Epoch: 5288, Train Loss: 0.0017611597431823611, Valid Loss: 0.0023307318333536386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5289, Train Loss: 0.0017600638093426824, Valid Loss: 0.0023294161073863506\n",
      "Epoch: 5290, Train Loss: 0.00175896764267236, Valid Loss: 0.002328056376427412\n",
      "Epoch: 5291, Train Loss: 0.001757872523739934, Valid Loss: 0.0023267348296940327\n",
      "Epoch: 5292, Train Loss: 0.0017567768227308989, Valid Loss: 0.0023253473918884993\n",
      "Epoch: 5293, Train Loss: 0.0017556840321049094, Valid Loss: 0.00232404051348567\n",
      "Epoch: 5294, Train Loss: 0.001754589262418449, Valid Loss: 0.0023226726334542036\n",
      "Epoch: 5295, Train Loss: 0.0017534983344376087, Valid Loss: 0.0023213608656078577\n",
      "Epoch: 5296, Train Loss: 0.0017524060094729066, Valid Loss: 0.0023199922870844603\n",
      "Epoch: 5297, Train Loss: 0.0017513129860162735, Valid Loss: 0.00231868214905262\n",
      "Epoch: 5298, Train Loss: 0.0017502232221886516, Valid Loss: 0.0023173040244728327\n",
      "Epoch: 5299, Train Loss: 0.0017491368344053626, Valid Loss: 0.0023160057608038187\n",
      "Epoch: 5300, Train Loss: 0.0017480478854849935, Valid Loss: 0.0023146383464336395\n",
      "Epoch: 5301, Train Loss: 0.0017469601007178426, Valid Loss: 0.002313342411071062\n",
      "Epoch: 5302, Train Loss: 0.0017458756919950247, Valid Loss: 0.0023119584657251835\n",
      "Epoch: 5303, Train Loss: 0.0017447854625061154, Valid Loss: 0.0023106562439352274\n",
      "Epoch: 5304, Train Loss: 0.0017437018686905503, Valid Loss: 0.0023093053605407476\n",
      "Epoch: 5305, Train Loss: 0.0017426186241209507, Valid Loss: 0.0023080063983798027\n",
      "Epoch: 5306, Train Loss: 0.0017415318870916963, Valid Loss: 0.002306636655703187\n",
      "Epoch: 5307, Train Loss: 0.0017404478276148438, Valid Loss: 0.0023053190670907497\n",
      "Epoch: 5308, Train Loss: 0.0017393658636137843, Valid Loss: 0.002303964924067259\n",
      "Epoch: 5309, Train Loss: 0.001738283084705472, Valid Loss: 0.0023026817943900824\n",
      "Epoch: 5310, Train Loss: 0.001737203449010849, Valid Loss: 0.002301313215866685\n",
      "Epoch: 5311, Train Loss: 0.001736121135763824, Valid Loss: 0.0023000093642622232\n",
      "Epoch: 5312, Train Loss: 0.001735042897053063, Valid Loss: 0.002298645442351699\n",
      "Epoch: 5313, Train Loss: 0.0017339634941890836, Valid Loss: 0.0022973683662712574\n",
      "Epoch: 5314, Train Loss: 0.0017328861868008971, Valid Loss: 0.0022959988564252853\n",
      "Epoch: 5315, Train Loss: 0.0017318085301667452, Valid Loss: 0.0022947348188608885\n",
      "Epoch: 5316, Train Loss: 0.0017307313391938806, Valid Loss: 0.0022933385334908962\n",
      "Epoch: 5317, Train Loss: 0.0017296560108661652, Valid Loss: 0.002292084041982889\n",
      "Epoch: 5318, Train Loss: 0.0017285813810303807, Valid Loss: 0.0022906989324837923\n",
      "Epoch: 5319, Train Loss: 0.0017275071004405618, Valid Loss: 0.0022894556168466806\n",
      "Epoch: 5320, Train Loss: 0.001726435380987823, Valid Loss: 0.002288044197484851\n",
      "Epoch: 5321, Train Loss: 0.0017253595869988203, Valid Loss: 0.002286826027557254\n",
      "Epoch: 5322, Train Loss: 0.0017242894973605871, Valid Loss: 0.00228539714589715\n",
      "Epoch: 5323, Train Loss: 0.001723218010738492, Valid Loss: 0.0022842015605419874\n",
      "Epoch: 5324, Train Loss: 0.0017221468733623624, Valid Loss: 0.002282756380736828\n",
      "Epoch: 5325, Train Loss: 0.0017210765508934855, Valid Loss: 0.0022815903648734093\n",
      "Epoch: 5326, Train Loss: 0.0017200082074850798, Valid Loss: 0.002280103974044323\n",
      "Epoch: 5327, Train Loss: 0.001718937186524272, Valid Loss: 0.0022789910435676575\n",
      "Epoch: 5328, Train Loss: 0.0017178714042529464, Valid Loss: 0.0022774566896259785\n",
      "Epoch: 5329, Train Loss: 0.0017168038757517934, Valid Loss: 0.002276395680382848\n",
      "Epoch: 5330, Train Loss: 0.001715741935186088, Valid Loss: 0.002274795202538371\n",
      "Epoch: 5331, Train Loss: 0.0017146754544228315, Valid Loss: 0.0022738089319318533\n",
      "Epoch: 5332, Train Loss: 0.001713610254228115, Valid Loss: 0.0022721358109265566\n",
      "Epoch: 5333, Train Loss: 0.0017125457525253296, Valid Loss: 0.002271258970722556\n",
      "Epoch: 5334, Train Loss: 0.0017114881193265319, Valid Loss: 0.0022694652434438467\n",
      "Epoch: 5335, Train Loss: 0.0017104233847931027, Valid Loss: 0.0022687125019729137\n",
      "Epoch: 5336, Train Loss: 0.0017093681963160634, Valid Loss: 0.0022667809389531612\n",
      "Epoch: 5337, Train Loss: 0.0017083087004721165, Valid Loss: 0.002266207942739129\n",
      "Epoch: 5338, Train Loss: 0.0017072508344426751, Valid Loss: 0.0022640819661319256\n",
      "Epoch: 5339, Train Loss: 0.0017061978578567505, Valid Loss: 0.0022637101355940104\n",
      "Epoch: 5340, Train Loss: 0.0017051438335329294, Valid Loss: 0.0022614006884396076\n",
      "Epoch: 5341, Train Loss: 0.0017040936509147286, Valid Loss: 0.0022612586617469788\n",
      "Epoch: 5342, Train Loss: 0.0017030407907441258, Valid Loss: 0.002258690306916833\n",
      "Epoch: 5343, Train Loss: 0.00170199538115412, Valid Loss: 0.0022588090505450964\n",
      "Epoch: 5344, Train Loss: 0.0017009495059028268, Valid Loss: 0.0022560162469744682\n",
      "Epoch: 5345, Train Loss: 0.0016999025829136372, Valid Loss: 0.0022563464008271694\n",
      "Epoch: 5346, Train Loss: 0.0016988505376502872, Valid Loss: 0.0022533503361046314\n",
      "Epoch: 5347, Train Loss: 0.0016978000057861209, Valid Loss: 0.0022538003977388144\n",
      "Epoch: 5348, Train Loss: 0.0016967420233413577, Valid Loss: 0.0022507766261696815\n",
      "Epoch: 5349, Train Loss: 0.0016956798499450088, Valid Loss: 0.002251093043014407\n",
      "Epoch: 5350, Train Loss: 0.0016946166288107634, Valid Loss: 0.002248272066935897\n",
      "Epoch: 5351, Train Loss: 0.0016935430467128754, Valid Loss: 0.002248224103823304\n",
      "Epoch: 5352, Train Loss: 0.0016924822703003883, Valid Loss: 0.002245911629870534\n",
      "Epoch: 5353, Train Loss: 0.0016914226580411196, Valid Loss: 0.0022452727425843477\n",
      "Epoch: 5354, Train Loss: 0.0016903650248423219, Valid Loss: 0.002243623835965991\n",
      "Epoch: 5355, Train Loss: 0.0016893151914700866, Valid Loss: 0.0022423765622079372\n",
      "Epoch: 5356, Train Loss: 0.0016882717609405518, Valid Loss: 0.0022413372062146664\n",
      "Epoch: 5357, Train Loss: 0.00168723170645535, Valid Loss: 0.0022395749110728502\n",
      "Epoch: 5358, Train Loss: 0.0016861892072483897, Valid Loss: 0.0022389742080122232\n",
      "Epoch: 5359, Train Loss: 0.0016851508989930153, Valid Loss: 0.002236897125840187\n",
      "Epoch: 5360, Train Loss: 0.0016841028118506074, Valid Loss: 0.00223645381629467\n",
      "Epoch: 5361, Train Loss: 0.0016830571694299579, Valid Loss: 0.0022343278396874666\n",
      "Epoch: 5362, Train Loss: 0.001682011061348021, Valid Loss: 0.0022338067647069693\n",
      "Epoch: 5363, Train Loss: 0.0016809676308184862, Valid Loss: 0.0022318747360259295\n",
      "Epoch: 5364, Train Loss: 0.0016799145378172398, Valid Loss: 0.0022310628555715084\n",
      "Epoch: 5365, Train Loss: 0.0016788758803158998, Valid Loss: 0.0022294758819043636\n",
      "Epoch: 5366, Train Loss: 0.0016778373392298818, Valid Loss: 0.0022283296566456556\n",
      "Epoch: 5367, Train Loss: 0.0016767964698374271, Valid Loss: 0.0022271033376455307\n",
      "Epoch: 5368, Train Loss: 0.0016757578123360872, Valid Loss: 0.0022256236989051104\n",
      "Epoch: 5369, Train Loss: 0.0016747218323871493, Valid Loss: 0.0022246914450079203\n",
      "Epoch: 5370, Train Loss: 0.001673687482252717, Valid Loss: 0.0022230076137930155\n",
      "Epoch: 5371, Train Loss: 0.001672648242674768, Valid Loss: 0.002222188748419285\n",
      "Epoch: 5372, Train Loss: 0.0016716105164960027, Valid Loss: 0.002220443682745099\n",
      "Epoch: 5373, Train Loss: 0.001670575700700283, Valid Loss: 0.0022196010686457157\n",
      "Epoch: 5374, Train Loss: 0.001669539837166667, Valid Loss: 0.0022179586812853813\n",
      "Epoch: 5375, Train Loss: 0.0016685040900483727, Valid Loss: 0.002216964028775692\n",
      "Epoch: 5376, Train Loss: 0.0016674695070832968, Valid Loss: 0.0022155086044222116\n",
      "Epoch: 5377, Train Loss: 0.001666432828642428, Valid Loss: 0.002214317210018635\n",
      "Epoch: 5378, Train Loss: 0.0016654068604111671, Valid Loss: 0.0022130729630589485\n",
      "Epoch: 5379, Train Loss: 0.0016643748385831714, Valid Loss: 0.0022117008920758963\n",
      "Epoch: 5380, Train Loss: 0.0016633466584607959, Valid Loss: 0.0022106014657765627\n",
      "Epoch: 5381, Train Loss: 0.001662318129092455, Valid Loss: 0.0022091118153184652\n",
      "Epoch: 5382, Train Loss: 0.0016612894833087921, Valid Loss: 0.0022081017959862947\n",
      "Epoch: 5383, Train Loss: 0.001660259091295302, Valid Loss: 0.00220657791942358\n",
      "Epoch: 5384, Train Loss: 0.001659231842495501, Valid Loss: 0.002205540193244815\n",
      "Epoch: 5385, Train Loss: 0.0016582042444497347, Valid Loss: 0.002204070333391428\n",
      "Epoch: 5386, Train Loss: 0.001657179556787014, Valid Loss: 0.0022029809188097715\n",
      "Epoch: 5387, Train Loss: 0.0016561506781727076, Valid Loss: 0.0022015918511897326\n",
      "Epoch: 5388, Train Loss: 0.0016551247099414468, Valid Loss: 0.002200391376391053\n",
      "Epoch: 5389, Train Loss: 0.0016540999058634043, Valid Loss: 0.0021991333924233913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5390, Train Loss: 0.0016530770808458328, Valid Loss: 0.002197819296270609\n",
      "Epoch: 5391, Train Loss: 0.0016520555363968015, Valid Loss: 0.002196629997342825\n",
      "Epoch: 5392, Train Loss: 0.0016510328277945518, Valid Loss: 0.0021952816750854254\n",
      "Epoch: 5393, Train Loss: 0.001650013029575348, Valid Loss: 0.002194157801568508\n",
      "Epoch: 5394, Train Loss: 0.0016489903209730983, Valid Loss: 0.0021927470806986094\n",
      "Epoch: 5395, Train Loss: 0.0016479722689837217, Valid Loss: 0.0021916264668107033\n",
      "Epoch: 5396, Train Loss: 0.0016469549154862761, Valid Loss: 0.0021902581211179495\n",
      "Epoch: 5397, Train Loss: 0.001645935932174325, Valid Loss: 0.002189099555835128\n",
      "Epoch: 5398, Train Loss: 0.0016449191607534885, Valid Loss: 0.0021877684630453587\n",
      "Epoch: 5399, Train Loss: 0.0016438995953649282, Valid Loss: 0.0021865598391741514\n",
      "Epoch: 5400, Train Loss: 0.0016428858507424593, Valid Loss: 0.0021852932404726744\n",
      "Epoch: 5401, Train Loss: 0.0016418687300756574, Valid Loss: 0.0021840392146259546\n",
      "Epoch: 5402, Train Loss: 0.0016408526571467519, Valid Loss: 0.002182810567319393\n",
      "Epoch: 5403, Train Loss: 0.0016398411244153976, Valid Loss: 0.002181506948545575\n",
      "Epoch: 5404, Train Loss: 0.0016388223739340901, Valid Loss: 0.0021803388372063637\n",
      "Epoch: 5405, Train Loss: 0.0016378124710172415, Valid Loss: 0.0021789981983602047\n",
      "Epoch: 5406, Train Loss: 0.0016368000069633126, Valid Loss: 0.0021778366062790155\n",
      "Epoch: 5407, Train Loss: 0.0016357895219698548, Valid Loss: 0.002176526002585888\n",
      "Epoch: 5408, Train Loss: 0.0016347767086699605, Valid Loss: 0.0021753457840532064\n",
      "Epoch: 5409, Train Loss: 0.001633764710277319, Valid Loss: 0.0021740198135375977\n",
      "Epoch: 5410, Train Loss: 0.0016327622579410672, Valid Loss: 0.0021728372666984797\n",
      "Epoch: 5411, Train Loss: 0.0016317496774718165, Valid Loss: 0.002171560190618038\n",
      "Epoch: 5412, Train Loss: 0.0016307401238009334, Valid Loss: 0.0021703315433114767\n",
      "Epoch: 5413, Train Loss: 0.0016297351103276014, Valid Loss: 0.0021690831054002047\n",
      "Epoch: 5414, Train Loss: 0.0016287253238260746, Valid Loss: 0.002167839789763093\n",
      "Epoch: 5415, Train Loss: 0.0016277204267680645, Valid Loss: 0.0021666253451257944\n",
      "Epoch: 5416, Train Loss: 0.0016267173923552036, Valid Loss: 0.00216533406637609\n",
      "Epoch: 5417, Train Loss: 0.001625708770006895, Valid Loss: 0.0021641566418111324\n",
      "Epoch: 5418, Train Loss: 0.0016247067833319306, Valid Loss: 0.002162870718166232\n",
      "Epoch: 5419, Train Loss: 0.001623705611564219, Valid Loss: 0.0021616772282868624\n",
      "Epoch: 5420, Train Loss: 0.0016227018786594272, Valid Loss: 0.0021603936329483986\n",
      "Epoch: 5421, Train Loss: 0.0016216988442465663, Valid Loss: 0.002159212017431855\n",
      "Epoch: 5422, Train Loss: 0.0016206980217248201, Valid Loss: 0.002157939597964287\n",
      "Epoch: 5423, Train Loss: 0.0016196989454329014, Valid Loss: 0.002156718634068966\n",
      "Epoch: 5424, Train Loss: 0.0016186970751732588, Valid Loss: 0.0021554799750447273\n",
      "Epoch: 5425, Train Loss: 0.0016176963690668344, Valid Loss: 0.0021542489994317293\n",
      "Epoch: 5426, Train Loss: 0.001616697059944272, Valid Loss: 0.002153016161173582\n",
      "Epoch: 5427, Train Loss: 0.0016157036880031228, Valid Loss: 0.002151783322915435\n",
      "Epoch: 5428, Train Loss: 0.0016147017013281584, Valid Loss: 0.0021505639888346195\n",
      "Epoch: 5429, Train Loss: 0.0016137075144797564, Valid Loss: 0.0021493101958185434\n",
      "Epoch: 5430, Train Loss: 0.0016127130948007107, Valid Loss: 0.002148103667423129\n",
      "Epoch: 5431, Train Loss: 0.0016117180930450559, Valid Loss: 0.0021468759514391422\n",
      "Epoch: 5432, Train Loss: 0.0016107233241200447, Valid Loss: 0.0021456631366163492\n",
      "Epoch: 5433, Train Loss: 0.0016097286716103554, Valid Loss: 0.0021444077137857676\n",
      "Epoch: 5434, Train Loss: 0.0016087328549474478, Valid Loss: 0.0021431883797049522\n",
      "Epoch: 5435, Train Loss: 0.001607740530744195, Valid Loss: 0.00214197370223701\n",
      "Epoch: 5436, Train Loss: 0.0016067527467384934, Valid Loss: 0.002140747383236885\n",
      "Epoch: 5437, Train Loss: 0.0016057599568739533, Valid Loss: 0.0021395236253738403\n",
      "Epoch: 5438, Train Loss: 0.001604769960977137, Valid Loss: 0.002138289622962475\n",
      "Epoch: 5439, Train Loss: 0.0016037797322496772, Valid Loss: 0.002137100324034691\n",
      "Epoch: 5440, Train Loss: 0.0016027913661673665, Valid Loss: 0.0021358542144298553\n",
      "Epoch: 5441, Train Loss: 0.0016018013702705503, Valid Loss: 0.0021346479188650846\n",
      "Epoch: 5442, Train Loss: 0.001600812654942274, Valid Loss: 0.0021334150806069374\n",
      "Epoch: 5443, Train Loss: 0.0015998251037672162, Valid Loss: 0.002132213208824396\n",
      "Epoch: 5444, Train Loss: 0.0015988386003300548, Valid Loss: 0.0021309787407517433\n",
      "Epoch: 5445, Train Loss: 0.0015978518640622497, Valid Loss: 0.0021297759376466274\n",
      "Epoch: 5446, Train Loss: 0.0015968703664839268, Valid Loss: 0.002128565451130271\n",
      "Epoch: 5447, Train Loss: 0.0015958849107846618, Valid Loss: 0.0021273368038237095\n",
      "Epoch: 5448, Train Loss: 0.001594900037162006, Valid Loss: 0.0021261232905089855\n",
      "Epoch: 5449, Train Loss: 0.0015939195873215795, Valid Loss: 0.0021249139681458473\n",
      "Epoch: 5450, Train Loss: 0.0015929359942674637, Valid Loss: 0.0021237190812826157\n",
      "Epoch: 5451, Train Loss: 0.0015919533325359225, Valid Loss: 0.0021224827505648136\n",
      "Epoch: 5452, Train Loss: 0.0015909733483567834, Valid Loss: 0.0021212799474596977\n",
      "Epoch: 5453, Train Loss: 0.001589990220963955, Valid Loss: 0.0021200606133788824\n",
      "Epoch: 5454, Train Loss: 0.0015890112845227122, Valid Loss: 0.002118876203894615\n",
      "Epoch: 5455, Train Loss: 0.0015880343271419406, Valid Loss: 0.0021176482550799847\n",
      "Epoch: 5456, Train Loss: 0.001587055274285376, Valid Loss: 0.0021164563950151205\n",
      "Epoch: 5457, Train Loss: 0.0015860750572755933, Valid Loss: 0.0021152314729988575\n",
      "Epoch: 5458, Train Loss: 0.0015851003117859364, Valid Loss: 0.002114039147272706\n",
      "Epoch: 5459, Train Loss: 0.001584123121574521, Valid Loss: 0.002112817484885454\n",
      "Epoch: 5460, Train Loss: 0.0015831455821171403, Valid Loss: 0.0021116205025464296\n",
      "Epoch: 5461, Train Loss: 0.0015821709530428052, Valid Loss: 0.0021104146726429462\n",
      "Epoch: 5462, Train Loss: 0.0015811985358595848, Valid Loss: 0.0021092125680297613\n",
      "Epoch: 5463, Train Loss: 0.001580223091877997, Valid Loss: 0.0021080058068037033\n",
      "Epoch: 5464, Train Loss: 0.0015792489284649491, Valid Loss: 0.002106809290125966\n",
      "Epoch: 5465, Train Loss: 0.001578278373926878, Valid Loss: 0.002105612540617585\n",
      "Epoch: 5466, Train Loss: 0.0015773052582517266, Valid Loss: 0.002104389015585184\n",
      "Epoch: 5467, Train Loss: 0.0015763354022055864, Valid Loss: 0.0021032150834798813\n",
      "Epoch: 5468, Train Loss: 0.001575366361066699, Valid Loss: 0.0021020150743424892\n",
      "Epoch: 5469, Train Loss: 0.0015743927797302604, Valid Loss: 0.0021008295007050037\n",
      "Epoch: 5470, Train Loss: 0.0015734272310510278, Valid Loss: 0.0020996048115193844\n",
      "Epoch: 5471, Train Loss: 0.0015724559780210257, Valid Loss: 0.0020984201692044735\n",
      "Epoch: 5472, Train Loss: 0.0015714862383902073, Valid Loss: 0.0020972222555428743\n",
      "Epoch: 5473, Train Loss: 0.0015705192927271128, Valid Loss: 0.0020960476249456406\n",
      "Epoch: 5474, Train Loss: 0.0015695526963099837, Valid Loss: 0.0020948199089616537\n",
      "Epoch: 5475, Train Loss: 0.0015685855178162456, Valid Loss: 0.0020936361979693174\n",
      "Epoch: 5476, Train Loss: 0.001567620551213622, Valid Loss: 0.0020924615673720837\n",
      "Epoch: 5477, Train Loss: 0.0015666579129174352, Valid Loss: 0.002091269241645932\n",
      "Epoch: 5478, Train Loss: 0.0015656928298994899, Valid Loss: 0.0020900610834360123\n",
      "Epoch: 5479, Train Loss: 0.0015647329855710268, Valid Loss: 0.0020888710860162973\n",
      "Epoch: 5480, Train Loss: 0.0015637683682143688, Valid Loss: 0.0020877060014754534\n",
      "Epoch: 5481, Train Loss: 0.0015628061955794692, Valid Loss: 0.002086494816467166\n",
      "Epoch: 5482, Train Loss: 0.001561842393130064, Valid Loss: 0.0020853227470070124\n",
      "Epoch: 5483, Train Loss: 0.0015608794055879116, Valid Loss: 0.0020841239020228386\n",
      "Epoch: 5484, Train Loss: 0.0015599253820255399, Valid Loss: 0.002082951134070754\n",
      "Epoch: 5485, Train Loss: 0.0015589626273140311, Valid Loss: 0.002081727609038353\n",
      "Epoch: 5486, Train Loss: 0.0015580046456307173, Valid Loss: 0.0020805797539651394\n",
      "Epoch: 5487, Train Loss: 0.001557045616209507, Valid Loss: 0.0020793918520212173\n",
      "Epoch: 5488, Train Loss: 0.0015560892643406987, Valid Loss: 0.002078214194625616\n",
      "Epoch: 5489, Train Loss: 0.001555129885673523, Valid Loss: 0.002077000215649605\n",
      "Epoch: 5490, Train Loss: 0.0015541781904175878, Valid Loss: 0.0020758367609232664\n",
      "Epoch: 5491, Train Loss: 0.001553220790810883, Valid Loss: 0.0020746691152453423\n",
      "Epoch: 5492, Train Loss: 0.001552264904603362, Valid Loss: 0.002073479350656271\n",
      "Epoch: 5493, Train Loss: 0.0015513106482103467, Valid Loss: 0.002072286792099476\n",
      "Epoch: 5494, Train Loss: 0.0015503558097407222, Valid Loss: 0.002071117050945759\n",
      "Epoch: 5495, Train Loss: 0.001549402717500925, Valid Loss: 0.002069949870929122\n",
      "Epoch: 5496, Train Loss: 0.0015484521863982081, Valid Loss: 0.0020687535870820284\n",
      "Epoch: 5497, Train Loss: 0.0015474994434043765, Valid Loss: 0.00206759013235569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5498, Train Loss: 0.001546548563055694, Valid Loss: 0.002066405024379492\n",
      "Epoch: 5499, Train Loss: 0.0015455982647836208, Valid Loss: 0.0020652508828788996\n",
      "Epoch: 5500, Train Loss: 0.0015446459874510765, Valid Loss: 0.0020640569273382425\n",
      "Epoch: 5501, Train Loss: 0.0015436961548402905, Valid Loss: 0.00206289766356349\n",
      "Epoch: 5502, Train Loss: 0.0015427485341206193, Valid Loss: 0.0020617193076759577\n",
      "Epoch: 5503, Train Loss: 0.0015418017283082008, Valid Loss: 0.0020605484023690224\n",
      "Epoch: 5504, Train Loss: 0.0015408553881570697, Valid Loss: 0.0020593691151589155\n",
      "Epoch: 5505, Train Loss: 0.0015399071853607893, Valid Loss: 0.0020582154393196106\n",
      "Epoch: 5506, Train Loss: 0.0015389610780403018, Valid Loss: 0.002057044766843319\n",
      "Epoch: 5507, Train Loss: 0.0015380166005343199, Valid Loss: 0.002055867575109005\n",
      "Epoch: 5508, Train Loss: 0.0015370720066130161, Valid Loss: 0.0020546873565763235\n",
      "Epoch: 5509, Train Loss: 0.0015361285768449306, Valid Loss: 0.0020535392686724663\n",
      "Epoch: 5510, Train Loss: 0.0015351843321695924, Valid Loss: 0.0020523627754300833\n",
      "Epoch: 5511, Train Loss: 0.001534240203909576, Valid Loss: 0.0020511874463409185\n",
      "Epoch: 5512, Train Loss: 0.001533293747343123, Valid Loss: 0.0020500244572758675\n",
      "Epoch: 5513, Train Loss: 0.0015323582338169217, Valid Loss: 0.002048863796517253\n",
      "Epoch: 5514, Train Loss: 0.0015314146876335144, Valid Loss: 0.00204769941046834\n",
      "Epoch: 5515, Train Loss: 0.0015304762637242675, Valid Loss: 0.002046542940661311\n",
      "Epoch: 5516, Train Loss: 0.0015295332996174693, Valid Loss: 0.00204537739045918\n",
      "Epoch: 5517, Train Loss: 0.001528597087599337, Valid Loss: 0.0020442064851522446\n",
      "Epoch: 5518, Train Loss: 0.001527656801044941, Valid Loss: 0.002043037908151746\n",
      "Epoch: 5519, Train Loss: 0.0015267195412889123, Valid Loss: 0.0020418984349817038\n",
      "Epoch: 5520, Train Loss: 0.0015257826307788491, Valid Loss: 0.002040732651948929\n",
      "Epoch: 5521, Train Loss: 0.0015248459530994296, Valid Loss: 0.002039565471932292\n",
      "Epoch: 5522, Train Loss: 0.0015239091590046883, Valid Loss: 0.0020384229719638824\n",
      "Epoch: 5523, Train Loss: 0.0015229748096317053, Valid Loss: 0.002037264872342348\n",
      "Epoch: 5524, Train Loss: 0.0015220370842143893, Valid Loss: 0.0020361102651804686\n",
      "Epoch: 5525, Train Loss: 0.0015211080899462104, Valid Loss: 0.0020349430851638317\n",
      "Epoch: 5526, Train Loss: 0.0015201735077425838, Valid Loss: 0.0020337917376309633\n",
      "Epoch: 5527, Train Loss: 0.0015192386927083135, Valid Loss: 0.0020326331723481417\n",
      "Epoch: 5528, Train Loss: 0.001518308068625629, Valid Loss: 0.00203148415312171\n",
      "Epoch: 5529, Train Loss: 0.001517375698313117, Valid Loss: 0.0020303332712501287\n",
      "Epoch: 5530, Train Loss: 0.001516443444415927, Valid Loss: 0.002029186114668846\n",
      "Epoch: 5531, Train Loss: 0.001515513053163886, Valid Loss: 0.0020280303433537483\n",
      "Epoch: 5532, Train Loss: 0.0015145817305892706, Valid Loss: 0.002026882953941822\n",
      "Epoch: 5533, Train Loss: 0.0015136559959501028, Valid Loss: 0.0020257439464330673\n",
      "Epoch: 5534, Train Loss: 0.0015127233928069472, Valid Loss: 0.002024577697739005\n",
      "Epoch: 5535, Train Loss: 0.0015117990551516414, Valid Loss: 0.002023441717028618\n",
      "Epoch: 5536, Train Loss: 0.001510870410129428, Valid Loss: 0.0020222878083586693\n",
      "Epoch: 5537, Train Loss: 0.001509945490397513, Valid Loss: 0.0020211583469063044\n",
      "Epoch: 5538, Train Loss: 0.001509021152742207, Valid Loss: 0.0020199904683977365\n",
      "Epoch: 5539, Train Loss: 0.0015080939047038555, Valid Loss: 0.0020188563503324986\n",
      "Epoch: 5540, Train Loss: 0.0015071701491251588, Valid Loss: 0.002017711056396365\n",
      "Epoch: 5541, Train Loss: 0.0015062454622238874, Valid Loss: 0.0020165855530649424\n",
      "Epoch: 5542, Train Loss: 0.001505324267782271, Valid Loss: 0.0020154030062258244\n",
      "Epoch: 5543, Train Loss: 0.001504399231635034, Valid Loss: 0.002014286583289504\n",
      "Epoch: 5544, Train Loss: 0.001503473031334579, Valid Loss: 0.0020131347700953484\n",
      "Epoch: 5545, Train Loss: 0.0015025574248284101, Valid Loss: 0.002012013690546155\n",
      "Epoch: 5546, Train Loss: 0.0015016347169876099, Valid Loss: 0.002010833006352186\n",
      "Epoch: 5547, Train Loss: 0.0015007138717919588, Valid Loss: 0.0020097289234399796\n",
      "Epoch: 5548, Train Loss: 0.0014997913967818022, Valid Loss: 0.00200855964794755\n",
      "Epoch: 5549, Train Loss: 0.001498870668001473, Valid Loss: 0.0020074525382369757\n",
      "Epoch: 5550, Train Loss: 0.001497953780926764, Valid Loss: 0.0020062883850187063\n",
      "Epoch: 5551, Train Loss: 0.0014970366610214114, Valid Loss: 0.002005168702453375\n",
      "Epoch: 5552, Train Loss: 0.001496119424700737, Valid Loss: 0.002004012232646346\n",
      "Epoch: 5553, Train Loss: 0.001495202537626028, Valid Loss: 0.002002903027459979\n",
      "Epoch: 5554, Train Loss: 0.0014942878624424338, Valid Loss: 0.002001752844080329\n",
      "Epoch: 5555, Train Loss: 0.0014933694619685411, Valid Loss: 0.0020006271079182625\n",
      "Epoch: 5556, Train Loss: 0.001492454786784947, Valid Loss: 0.0019994720350950956\n",
      "Epoch: 5557, Train Loss: 0.0014915434876456857, Valid Loss: 0.001998365158215165\n",
      "Epoch: 5558, Train Loss: 0.001490625785663724, Valid Loss: 0.001997211016714573\n",
      "Epoch: 5559, Train Loss: 0.001489713555201888, Valid Loss: 0.0019961080979555845\n",
      "Epoch: 5560, Train Loss: 0.0014888044679537416, Valid Loss: 0.0019949486013501883\n",
      "Epoch: 5561, Train Loss: 0.001487890025600791, Valid Loss: 0.0019938454497605562\n",
      "Epoch: 5562, Train Loss: 0.0014869808219373226, Valid Loss: 0.0019926950335502625\n",
      "Epoch: 5563, Train Loss: 0.0014860688243061304, Valid Loss: 0.00199159886687994\n",
      "Epoch: 5564, Train Loss: 0.001485158340074122, Valid Loss: 0.0019904302898794413\n",
      "Epoch: 5565, Train Loss: 0.0014842491364106536, Valid Loss: 0.0019893385469913483\n",
      "Epoch: 5566, Train Loss: 0.0014833398163318634, Valid Loss: 0.0019881674088537693\n",
      "Epoch: 5567, Train Loss: 0.0014824338722974062, Valid Loss: 0.0019870998803526163\n",
      "Epoch: 5568, Train Loss: 0.001481523271650076, Valid Loss: 0.001985931070521474\n",
      "Epoch: 5569, Train Loss: 0.0014806156978011131, Valid Loss: 0.0019848498050123453\n",
      "Epoch: 5570, Train Loss: 0.0014797092881053686, Valid Loss: 0.001983669586479664\n",
      "Epoch: 5571, Train Loss: 0.001478804973885417, Valid Loss: 0.001982614630833268\n",
      "Epoch: 5572, Train Loss: 0.0014778990298509598, Valid Loss: 0.0019814427942037582\n",
      "Epoch: 5573, Train Loss: 0.0014769937843084335, Valid Loss: 0.0019803703762590885\n",
      "Epoch: 5574, Train Loss: 0.0014760897029191256, Valid Loss: 0.0019791775848716497\n",
      "Epoch: 5575, Train Loss: 0.0014751867856830359, Valid Loss: 0.0019781298469752073\n",
      "Epoch: 5576, Train Loss: 0.0014742843341082335, Valid Loss: 0.001976948231458664\n",
      "Epoch: 5577, Train Loss: 0.0014733796706423163, Valid Loss: 0.0019758979324251413\n",
      "Epoch: 5578, Train Loss: 0.0014724807115271688, Valid Loss: 0.0019746930338442326\n",
      "Epoch: 5579, Train Loss: 0.0014715774450451136, Valid Loss: 0.001973673701286316\n",
      "Epoch: 5580, Train Loss: 0.0014706788351759315, Valid Loss: 0.0019724518060684204\n",
      "Epoch: 5581, Train Loss: 0.001469781156629324, Valid Loss: 0.001971463905647397\n",
      "Epoch: 5582, Train Loss: 0.00146888114977628, Valid Loss: 0.001970214070752263\n",
      "Epoch: 5583, Train Loss: 0.0014679793966934085, Valid Loss: 0.001969223842024803\n",
      "Epoch: 5584, Train Loss: 0.0014670826494693756, Valid Loss: 0.0019679723773151636\n",
      "Epoch: 5585, Train Loss: 0.00146618508733809, Valid Loss: 0.001967007527127862\n",
      "Epoch: 5586, Train Loss: 0.0014652896206825972, Valid Loss: 0.001965750241652131\n",
      "Epoch: 5587, Train Loss: 0.0014643921749666333, Valid Loss: 0.0019647986628115177\n",
      "Epoch: 5588, Train Loss: 0.0014634978724643588, Valid Loss: 0.0019635080825537443\n",
      "Epoch: 5589, Train Loss: 0.0014626020565629005, Valid Loss: 0.0019626044668257236\n",
      "Epoch: 5590, Train Loss: 0.0014617117121815681, Valid Loss: 0.001961278496310115\n",
      "Epoch: 5591, Train Loss: 0.0014608170604333282, Valid Loss: 0.001960401888936758\n",
      "Epoch: 5592, Train Loss: 0.0014599234564229846, Valid Loss: 0.0019590368028730154\n",
      "Epoch: 5593, Train Loss: 0.0014590317150577903, Valid Loss: 0.0019582172390073538\n",
      "Epoch: 5594, Train Loss: 0.0014581382274627686, Valid Loss: 0.0019568023271858692\n",
      "Epoch: 5595, Train Loss: 0.0014572485815733671, Valid Loss: 0.0019560239743441343\n",
      "Epoch: 5596, Train Loss: 0.001456356723792851, Valid Loss: 0.0019545755349099636\n",
      "Epoch: 5597, Train Loss: 0.0014554691733792424, Valid Loss: 0.0019538505002856255\n",
      "Epoch: 5598, Train Loss: 0.0014545792946591973, Valid Loss: 0.0019523375667631626\n",
      "Epoch: 5599, Train Loss: 0.0014536925591528416, Valid Loss: 0.0019516838947311044\n",
      "Epoch: 5600, Train Loss: 0.0014528053579851985, Valid Loss: 0.0019501064671203494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5601, Train Loss: 0.0014519167598336935, Valid Loss: 0.0019495375454425812\n",
      "Epoch: 5602, Train Loss: 0.0014510340988636017, Valid Loss: 0.001947872806340456\n",
      "Epoch: 5603, Train Loss: 0.0014501463156193495, Valid Loss: 0.001947376411408186\n",
      "Epoch: 5604, Train Loss: 0.001449264818802476, Valid Loss: 0.0019456282025203109\n",
      "Epoch: 5605, Train Loss: 0.001448380178771913, Valid Loss: 0.0019452348351478577\n",
      "Epoch: 5606, Train Loss: 0.0014474974013864994, Valid Loss: 0.0019434012938290834\n",
      "Epoch: 5607, Train Loss: 0.001446615788154304, Valid Loss: 0.0019430720712989569\n",
      "Epoch: 5608, Train Loss: 0.001445735339075327, Valid Loss: 0.0019411714747548103\n",
      "Epoch: 5609, Train Loss: 0.001444852794520557, Valid Loss: 0.0019409203669056296\n",
      "Epoch: 5610, Train Loss: 0.0014439699007198215, Valid Loss: 0.0019389685476198792\n",
      "Epoch: 5611, Train Loss: 0.001443087705411017, Valid Loss: 0.0019387310603633523\n",
      "Epoch: 5612, Train Loss: 0.0014422049280256033, Valid Loss: 0.001936793327331543\n",
      "Epoch: 5613, Train Loss: 0.0014413213357329369, Valid Loss: 0.0019365140469744802\n",
      "Epoch: 5614, Train Loss: 0.0014404394896700978, Valid Loss: 0.001934621948748827\n",
      "Epoch: 5615, Train Loss: 0.001439556828700006, Valid Loss: 0.001934254658408463\n",
      "Epoch: 5616, Train Loss: 0.0014386727707460523, Valid Loss: 0.0019324965542182326\n",
      "Epoch: 5617, Train Loss: 0.0014377902261912823, Valid Loss: 0.0019319838611409068\n",
      "Epoch: 5618, Train Loss: 0.0014369104756042361, Valid Loss: 0.0019303925801068544\n",
      "Epoch: 5619, Train Loss: 0.0014360294444486499, Valid Loss: 0.0019296911777928472\n",
      "Epoch: 5620, Train Loss: 0.001435150858014822, Valid Loss: 0.001928307581692934\n",
      "Epoch: 5621, Train Loss: 0.0014342713402584195, Valid Loss: 0.0019274099031463265\n",
      "Epoch: 5622, Train Loss: 0.001433394500054419, Valid Loss: 0.0019262181594967842\n",
      "Epoch: 5623, Train Loss: 0.0014325197553262115, Valid Loss: 0.0019251331686973572\n",
      "Epoch: 5624, Train Loss: 0.0014316478045657277, Valid Loss: 0.0019241481786593795\n",
      "Epoch: 5625, Train Loss: 0.0014307711971923709, Valid Loss: 0.0019228867022320628\n",
      "Epoch: 5626, Train Loss: 0.0014299011090770364, Valid Loss: 0.0019220253452658653\n",
      "Epoch: 5627, Train Loss: 0.0014290291583165526, Valid Loss: 0.0019206873839721084\n",
      "Epoch: 5628, Train Loss: 0.0014281581388786435, Valid Loss: 0.0019199076341465116\n",
      "Epoch: 5629, Train Loss: 0.001427283394150436, Valid Loss: 0.0019185004057362676\n",
      "Epoch: 5630, Train Loss: 0.001426414237357676, Valid Loss: 0.0019177563954144716\n",
      "Epoch: 5631, Train Loss: 0.0014255439164116979, Valid Loss: 0.0019163703545928001\n",
      "Epoch: 5632, Train Loss: 0.001424672780558467, Valid Loss: 0.0019155717454850674\n",
      "Epoch: 5633, Train Loss: 0.0014238037401810288, Valid Loss: 0.0019142155069857836\n",
      "Epoch: 5634, Train Loss: 0.0014229337684810162, Valid Loss: 0.0019133969908580184\n",
      "Epoch: 5635, Train Loss: 0.0014220655430108309, Valid Loss: 0.001912101055495441\n",
      "Epoch: 5636, Train Loss: 0.001421197666786611, Valid Loss: 0.0019111850997433066\n",
      "Epoch: 5637, Train Loss: 0.001420330605469644, Valid Loss: 0.0019099840428680182\n",
      "Epoch: 5638, Train Loss: 0.0014194607501849532, Valid Loss: 0.0019090068526566029\n",
      "Epoch: 5639, Train Loss: 0.0014185965992510319, Valid Loss: 0.0019078765762969851\n",
      "Epoch: 5640, Train Loss: 0.0014177319826558232, Valid Loss: 0.0019068173132836819\n",
      "Epoch: 5641, Train Loss: 0.00141686771530658, Valid Loss: 0.0019057636382058263\n",
      "Epoch: 5642, Train Loss: 0.001416001352481544, Valid Loss: 0.001904649194329977\n",
      "Epoch: 5643, Train Loss: 0.0014151372015476227, Valid Loss: 0.0019036352168768644\n",
      "Epoch: 5644, Train Loss: 0.0014142771251499653, Valid Loss: 0.0019024718785658479\n",
      "Epoch: 5645, Train Loss: 0.0014134139055386186, Valid Loss: 0.0019015200668945909\n",
      "Epoch: 5646, Train Loss: 0.0014125527814030647, Valid Loss: 0.0019003315828740597\n",
      "Epoch: 5647, Train Loss: 0.0014116913080215454, Valid Loss: 0.0018993726698681712\n",
      "Epoch: 5648, Train Loss: 0.0014108280884101987, Valid Loss: 0.0018981763860210776\n",
      "Epoch: 5649, Train Loss: 0.0014099683612585068, Valid Loss: 0.0018972513498738408\n",
      "Epoch: 5650, Train Loss: 0.0014091089833527803, Valid Loss: 0.00189606670755893\n",
      "Epoch: 5651, Train Loss: 0.0014082511188462377, Valid Loss: 0.001895078457891941\n",
      "Epoch: 5652, Train Loss: 0.0014073927886784077, Valid Loss: 0.0018939253641292453\n",
      "Epoch: 5653, Train Loss: 0.0014065310824662447, Valid Loss: 0.001892943517304957\n",
      "Epoch: 5654, Train Loss: 0.0014056776417419314, Valid Loss: 0.0018918159184977412\n",
      "Epoch: 5655, Train Loss: 0.0014048207085579634, Valid Loss: 0.0018907877383753657\n",
      "Epoch: 5656, Train Loss: 0.001403963309712708, Valid Loss: 0.0018896874971687794\n",
      "Epoch: 5657, Train Loss: 0.0014031098689883947, Valid Loss: 0.0018886440666392446\n",
      "Epoch: 5658, Train Loss: 0.0014022521208971739, Valid Loss: 0.0018875873647630215\n",
      "Epoch: 5659, Train Loss: 0.0014013969339430332, Valid Loss: 0.0018865171587094665\n",
      "Epoch: 5660, Train Loss: 0.0014005459379404783, Valid Loss: 0.0018854744266718626\n",
      "Epoch: 5661, Train Loss: 0.0013996909838169813, Valid Loss: 0.0018843705765902996\n",
      "Epoch: 5662, Train Loss: 0.0013988373102620244, Valid Loss: 0.0018833614885807037\n",
      "Epoch: 5663, Train Loss: 0.0013979870127514005, Valid Loss: 0.0018822522833943367\n",
      "Epoch: 5664, Train Loss: 0.0013971340376883745, Valid Loss: 0.001881241099908948\n",
      "Epoch: 5665, Train Loss: 0.0013962824596092105, Valid Loss: 0.0018801252590492368\n",
      "Epoch: 5666, Train Loss: 0.001395430532284081, Valid Loss: 0.0018791385227814317\n",
      "Epoch: 5667, Train Loss: 0.0013945797691121697, Valid Loss: 0.0018780188402161002\n",
      "Epoch: 5668, Train Loss: 0.001393732731230557, Valid Loss: 0.0018770149908959866\n",
      "Epoch: 5669, Train Loss: 0.0013928834814578295, Valid Loss: 0.0018759132362902164\n",
      "Epoch: 5670, Train Loss: 0.0013920338824391365, Valid Loss: 0.0018749064765870571\n",
      "Epoch: 5671, Train Loss: 0.0013911876594647765, Valid Loss: 0.001873791334219277\n",
      "Epoch: 5672, Train Loss: 0.0013903420185670257, Valid Loss: 0.001872779568657279\n",
      "Epoch: 5673, Train Loss: 0.0013894939329475164, Valid Loss: 0.0018717146012932062\n",
      "Epoch: 5674, Train Loss: 0.0013886447995901108, Valid Loss: 0.0018706836272031069\n",
      "Epoch: 5675, Train Loss: 0.0013878026511520147, Valid Loss: 0.0018696039915084839\n",
      "Epoch: 5676, Train Loss: 0.0013869564281776547, Valid Loss: 0.0018685618415474892\n",
      "Epoch: 5677, Train Loss: 0.0013861102052032948, Valid Loss: 0.0018675028113648295\n",
      "Epoch: 5678, Train Loss: 0.001385269220918417, Valid Loss: 0.0018664693925529718\n",
      "Epoch: 5679, Train Loss: 0.0013844252098351717, Valid Loss: 0.0018654142040759325\n",
      "Epoch: 5680, Train Loss: 0.0013835825957357883, Valid Loss: 0.0018643540097400546\n",
      "Epoch: 5681, Train Loss: 0.001382737304084003, Valid Loss: 0.0018633065046742558\n",
      "Epoch: 5682, Train Loss: 0.0013818969018757343, Valid Loss: 0.0018622658681124449\n",
      "Epoch: 5683, Train Loss: 0.001381055568344891, Valid Loss: 0.001861231168732047\n",
      "Epoch: 5684, Train Loss: 0.0013802149333059788, Valid Loss: 0.0018601736519485712\n",
      "Epoch: 5685, Train Loss: 0.0013793744146823883, Valid Loss: 0.0018591333646327257\n",
      "Epoch: 5686, Train Loss: 0.001378534478135407, Valid Loss: 0.0018580775940790772\n",
      "Epoch: 5687, Train Loss: 0.0013776953564956784, Valid Loss: 0.0018570598913356662\n",
      "Epoch: 5688, Train Loss: 0.0013768593780696392, Valid Loss: 0.0018559991149231791\n",
      "Epoch: 5689, Train Loss: 0.0013760202564299107, Valid Loss: 0.0018549701198935509\n",
      "Epoch: 5690, Train Loss: 0.0013751831138506532, Valid Loss: 0.0018538987496867776\n",
      "Epoch: 5691, Train Loss: 0.001374347135424614, Valid Loss: 0.0018528916407376528\n",
      "Epoch: 5692, Train Loss: 0.0013735115062445402, Valid Loss: 0.0018518355209380388\n",
      "Epoch: 5693, Train Loss: 0.0013726777397096157, Valid Loss: 0.0018508071079850197\n",
      "Epoch: 5694, Train Loss: 0.0013718415284529328, Valid Loss: 0.0018497440032660961\n",
      "Epoch: 5695, Train Loss: 0.0013710063649341464, Valid Loss: 0.001848713611252606\n",
      "Epoch: 5696, Train Loss: 0.0013701715506613255, Valid Loss: 0.0018476840341463685\n",
      "Epoch: 5697, Train Loss: 0.0013693375512957573, Valid Loss: 0.0018466496840119362\n",
      "Epoch: 5698, Train Loss: 0.0013685047160834074, Valid Loss: 0.0018456001998856664\n",
      "Epoch: 5699, Train Loss: 0.0013676738599315286, Valid Loss: 0.0018445599125698209\n",
      "Epoch: 5700, Train Loss: 0.0013668403262272477, Valid Loss: 0.00184352055657655\n",
      "Epoch: 5701, Train Loss: 0.0013660109834745526, Valid Loss: 0.0018424978479743004\n",
      "Epoch: 5702, Train Loss: 0.0013651777990162373, Valid Loss: 0.001841468270868063\n",
      "Epoch: 5703, Train Loss: 0.0013643491547554731, Valid Loss: 0.0018404220463708043\n",
      "Epoch: 5704, Train Loss: 0.0013635176001116633, Valid Loss: 0.0018393871141597629\n",
      "Epoch: 5705, Train Loss: 0.0013626879081130028, Valid Loss: 0.0018383637070655823\n",
      "Epoch: 5706, Train Loss: 0.0013618580996990204, Valid Loss: 0.0018373376224189997\n",
      "Epoch: 5707, Train Loss: 0.0013610310852527618, Valid Loss: 0.0018362939590588212\n",
      "Epoch: 5708, Train Loss: 0.001360203605145216, Valid Loss: 0.0018352699698880315\n",
      "Epoch: 5709, Train Loss: 0.0013593772891908884, Valid Loss: 0.0018342401599511504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5710, Train Loss: 0.0013585507404059172, Valid Loss: 0.0018332216423004866\n",
      "Epoch: 5711, Train Loss: 0.0013577260542660952, Valid Loss: 0.0018321764655411243\n",
      "Epoch: 5712, Train Loss: 0.001356900087557733, Valid Loss: 0.0018311664462089539\n",
      "Epoch: 5713, Train Loss: 0.0013560749357566237, Valid Loss: 0.0018301213858649135\n",
      "Epoch: 5714, Train Loss: 0.00135525269433856, Valid Loss: 0.001829097280278802\n",
      "Epoch: 5715, Train Loss: 0.0013544269604608417, Valid Loss: 0.0018280791118741035\n",
      "Epoch: 5716, Train Loss: 0.0013536041369661689, Valid Loss: 0.001827058382332325\n",
      "Epoch: 5717, Train Loss: 0.0013527817791327834, Valid Loss: 0.0018260166980326176\n",
      "Epoch: 5718, Train Loss: 0.0013519589556381106, Valid Loss: 0.001825006795115769\n",
      "Epoch: 5719, Train Loss: 0.0013511385768651962, Valid Loss: 0.001823973492719233\n",
      "Epoch: 5720, Train Loss: 0.0013503169175237417, Valid Loss: 0.0018229599809274077\n",
      "Epoch: 5721, Train Loss: 0.0013494982849806547, Valid Loss: 0.0018219348276033998\n",
      "Epoch: 5722, Train Loss: 0.0013486768584698439, Valid Loss: 0.0018209180561825633\n",
      "Epoch: 5723, Train Loss: 0.0013478536857292056, Valid Loss: 0.001819896511733532\n",
      "Epoch: 5724, Train Loss: 0.0013470390113070607, Valid Loss: 0.001818877412006259\n",
      "Epoch: 5725, Train Loss: 0.0013462200295180082, Valid Loss: 0.0018178471364080906\n",
      "Epoch: 5726, Train Loss: 0.0013454013969749212, Valid Loss: 0.001816825126297772\n",
      "Epoch: 5727, Train Loss: 0.0013445846270769835, Valid Loss: 0.001815822091884911\n",
      "Epoch: 5728, Train Loss: 0.0013437673915177584, Valid Loss: 0.0018147906521335244\n",
      "Epoch: 5729, Train Loss: 0.0013429548125714064, Valid Loss: 0.0018137965817004442\n",
      "Epoch: 5730, Train Loss: 0.001342135015875101, Valid Loss: 0.0018127545481547713\n",
      "Epoch: 5731, Train Loss: 0.001341320457868278, Valid Loss: 0.0018117481376975775\n",
      "Epoch: 5732, Train Loss: 0.0013405054342001677, Valid Loss: 0.0018107248470187187\n",
      "Epoch: 5733, Train Loss: 0.0013396949507296085, Valid Loss: 0.0018097241409122944\n",
      "Epoch: 5734, Train Loss: 0.0013388789957389235, Valid Loss: 0.001808689790777862\n",
      "Epoch: 5735, Train Loss: 0.0013380678137764335, Valid Loss: 0.0018076858250424266\n",
      "Epoch: 5736, Train Loss: 0.0013372538378462195, Valid Loss: 0.0018066756892949343\n",
      "Epoch: 5737, Train Loss: 0.001336441608145833, Valid Loss: 0.0018056753324344754\n",
      "Epoch: 5738, Train Loss: 0.001335630309768021, Valid Loss: 0.001804645056836307\n",
      "Epoch: 5739, Train Loss: 0.0013348201755434275, Valid Loss: 0.001803641440346837\n",
      "Epoch: 5740, Train Loss: 0.0013340075965970755, Valid Loss: 0.0018026180332526565\n",
      "Epoch: 5741, Train Loss: 0.0013332023518159986, Valid Loss: 0.001801639678888023\n",
      "Epoch: 5742, Train Loss: 0.0013323896564543247, Valid Loss: 0.001800603000447154\n",
      "Epoch: 5743, Train Loss: 0.0013315820833668113, Valid Loss: 0.0017996197566390038\n",
      "Epoch: 5744, Train Loss: 0.0013307740446180105, Valid Loss: 0.0017985762096941471\n",
      "Epoch: 5745, Train Loss: 0.0013299648417159915, Valid Loss: 0.0017976030940189958\n",
      "Epoch: 5746, Train Loss: 0.0013291584327816963, Valid Loss: 0.0017965754959732294\n",
      "Epoch: 5747, Train Loss: 0.0013283512089401484, Valid Loss: 0.0017955980729311705\n",
      "Epoch: 5748, Train Loss: 0.0013275470118969679, Valid Loss: 0.0017945473082363605\n",
      "Epoch: 5749, Train Loss: 0.0013267409522086382, Valid Loss: 0.001793591771274805\n",
      "Epoch: 5750, Train Loss: 0.0013259369879961014, Valid Loss: 0.0017925479914993048\n",
      "Epoch: 5751, Train Loss: 0.0013251312775537372, Valid Loss: 0.0017915864009410143\n",
      "Epoch: 5752, Train Loss: 0.0013243294088169932, Valid Loss: 0.0017905329586938024\n",
      "Epoch: 5753, Train Loss: 0.0013235220685601234, Valid Loss: 0.0017895804485306144\n",
      "Epoch: 5754, Train Loss: 0.0013227193849161267, Valid Loss: 0.0017885263077914715\n",
      "Epoch: 5755, Train Loss: 0.001321917399764061, Valid Loss: 0.0017875883495435119\n",
      "Epoch: 5756, Train Loss: 0.0013211136683821678, Valid Loss: 0.0017865195404738188\n",
      "Epoch: 5757, Train Loss: 0.0013203151756897569, Valid Loss: 0.001785576925612986\n",
      "Epoch: 5758, Train Loss: 0.0013195137726143003, Valid Loss: 0.0017845109105110168\n",
      "Epoch: 5759, Train Loss: 0.0013187130680307746, Valid Loss: 0.001783603336662054\n",
      "Epoch: 5760, Train Loss: 0.0013179131783545017, Valid Loss: 0.0017825125250965357\n",
      "Epoch: 5761, Train Loss: 0.001317114569246769, Valid Loss: 0.0017816013423725963\n",
      "Epoch: 5762, Train Loss: 0.0013163128169253469, Valid Loss: 0.0017805063398554921\n",
      "Epoch: 5763, Train Loss: 0.0013155160704627633, Valid Loss: 0.0017796190222725272\n",
      "Epoch: 5764, Train Loss: 0.0013147182762622833, Valid Loss: 0.0017785229720175266\n",
      "Epoch: 5765, Train Loss: 0.0013139208313077688, Valid Loss: 0.0017776301829144359\n",
      "Epoch: 5766, Train Loss: 0.00131312757730484, Valid Loss: 0.0017765187658369541\n",
      "Epoch: 5767, Train Loss: 0.0013123302487656474, Valid Loss: 0.001775663928128779\n",
      "Epoch: 5768, Train Loss: 0.0013115344336256385, Valid Loss: 0.0017745334189385176\n",
      "Epoch: 5769, Train Loss: 0.0013107380364090204, Valid Loss: 0.0017736831214278936\n",
      "Epoch: 5770, Train Loss: 0.0013099440839141607, Valid Loss: 0.0017725250218063593\n",
      "Epoch: 5771, Train Loss: 0.0013091496657580137, Valid Loss: 0.0017717129085212946\n",
      "Epoch: 5772, Train Loss: 0.001308357808738947, Valid Loss: 0.0017705403733998537\n",
      "Epoch: 5773, Train Loss: 0.0013075638562440872, Valid Loss: 0.0017697479343041778\n",
      "Epoch: 5774, Train Loss: 0.0013067733962088823, Valid Loss: 0.0017685346538200974\n",
      "Epoch: 5775, Train Loss: 0.001305983285419643, Valid Loss: 0.0017678039148449898\n",
      "Epoch: 5776, Train Loss: 0.0013051923597231507, Valid Loss: 0.001766545814462006\n",
      "Epoch: 5777, Train Loss: 0.0013044006191194057, Valid Loss: 0.0017658505821600556\n",
      "Epoch: 5778, Train Loss: 0.0013036129530519247, Valid Loss: 0.0017645384650677443\n",
      "Epoch: 5779, Train Loss: 0.0013028250541538, Valid Loss: 0.0017639127327129245\n",
      "Epoch: 5780, Train Loss: 0.001302035991102457, Valid Loss: 0.00176254624966532\n",
      "Epoch: 5781, Train Loss: 0.0013012461131438613, Valid Loss: 0.001761971740052104\n",
      "Epoch: 5782, Train Loss: 0.0013004620559513569, Valid Loss: 0.0017605406465008855\n",
      "Epoch: 5783, Train Loss: 0.001299674273468554, Valid Loss: 0.0017600696301087737\n",
      "Epoch: 5784, Train Loss: 0.0012988884700462222, Valid Loss: 0.0017585483146831393\n",
      "Epoch: 5785, Train Loss: 0.0012981048785150051, Valid Loss: 0.0017581331776455045\n",
      "Epoch: 5786, Train Loss: 0.0012973223347216845, Valid Loss: 0.0017565367743372917\n",
      "Epoch: 5787, Train Loss: 0.001296536298468709, Valid Loss: 0.0017562240827828646\n",
      "Epoch: 5788, Train Loss: 0.0012957523576915264, Valid Loss: 0.0017545584123581648\n",
      "Epoch: 5789, Train Loss: 0.0012949708616361022, Valid Loss: 0.0017543045105412602\n",
      "Epoch: 5790, Train Loss: 0.0012941883178427815, Valid Loss: 0.0017525709699839354\n",
      "Epoch: 5791, Train Loss: 0.0012934062397107482, Valid Loss: 0.001752357929944992\n",
      "Epoch: 5792, Train Loss: 0.0012926231138408184, Valid Loss: 0.001750620431266725\n",
      "Epoch: 5793, Train Loss: 0.0012918382417410612, Valid Loss: 0.0017503886483609676\n",
      "Epoch: 5794, Train Loss: 0.0012910531368106604, Valid Loss: 0.001748683862388134\n",
      "Epoch: 5795, Train Loss: 0.0012902672169730067, Valid Loss: 0.001748364418745041\n",
      "Epoch: 5796, Train Loss: 0.0012894830433651805, Valid Loss: 0.001746768830344081\n",
      "Epoch: 5797, Train Loss: 0.0012886958429589868, Valid Loss: 0.0017463313415646553\n",
      "Epoch: 5798, Train Loss: 0.0012879129499197006, Valid Loss: 0.001744883949868381\n",
      "Epoch: 5799, Train Loss: 0.0012871291255578399, Valid Loss: 0.0017442555399611592\n",
      "Epoch: 5800, Train Loss: 0.0012863450683653355, Valid Loss: 0.0017430143197998405\n",
      "Epoch: 5801, Train Loss: 0.0012855629902333021, Valid Loss: 0.0017422193195670843\n",
      "Epoch: 5802, Train Loss: 0.001284787431359291, Valid Loss: 0.001741176936775446\n",
      "Epoch: 5803, Train Loss: 0.001284005236811936, Valid Loss: 0.0017401668010279536\n",
      "Epoch: 5804, Train Loss: 0.0012832296779379249, Valid Loss: 0.0017392970621585846\n",
      "Epoch: 5805, Train Loss: 0.001282454701140523, Valid Loss: 0.0017381766811013222\n",
      "Epoch: 5806, Train Loss: 0.0012816796079277992, Valid Loss: 0.0017374299932271242\n",
      "Epoch: 5807, Train Loss: 0.001280904863961041, Valid Loss: 0.0017361831851303577\n",
      "Epoch: 5808, Train Loss: 0.001280131982639432, Valid Loss: 0.0017355189193040133\n",
      "Epoch: 5809, Train Loss: 0.0012793567730113864, Valid Loss: 0.0017342439386993647\n",
      "Epoch: 5810, Train Loss: 0.0012785844737663865, Valid Loss: 0.0017335967859253287\n",
      "Epoch: 5811, Train Loss: 0.0012778086820617318, Valid Loss: 0.0017323191277682781\n",
      "Epoch: 5812, Train Loss: 0.0012770348694175482, Valid Loss: 0.001731640426442027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5813, Train Loss: 0.00127626012545079, Valid Loss: 0.0017304158536717296\n",
      "Epoch: 5814, Train Loss: 0.00127548782620579, Valid Loss: 0.0017296698642894626\n",
      "Epoch: 5815, Train Loss: 0.0012747147120535374, Valid Loss: 0.001728532020933926\n",
      "Epoch: 5816, Train Loss: 0.0012739421799778938, Valid Loss: 0.0017277050064876676\n",
      "Epoch: 5817, Train Loss: 0.001273173256777227, Valid Loss: 0.0017266449285671115\n",
      "Epoch: 5818, Train Loss: 0.0012724007247015834, Valid Loss: 0.0017257300205528736\n",
      "Epoch: 5819, Train Loss: 0.0012716308701783419, Valid Loss: 0.001724767847917974\n",
      "Epoch: 5820, Train Loss: 0.0012708629947155714, Valid Loss: 0.001723774941638112\n",
      "Epoch: 5821, Train Loss: 0.0012700920924544334, Valid Loss: 0.0017228667857125401\n",
      "Epoch: 5822, Train Loss: 0.0012693253811448812, Valid Loss: 0.0017218203283846378\n",
      "Epoch: 5823, Train Loss: 0.00126855808775872, Valid Loss: 0.0017209770157933235\n",
      "Epoch: 5824, Train Loss: 0.001267791842110455, Valid Loss: 0.0017198935383930802\n",
      "Epoch: 5825, Train Loss: 0.0012670244323089719, Valid Loss: 0.0017190654762089252\n",
      "Epoch: 5826, Train Loss: 0.0012662539957091212, Valid Loss: 0.0017179708229377866\n",
      "Epoch: 5827, Train Loss: 0.0012654907768592238, Valid Loss: 0.0017171379877254367\n",
      "Epoch: 5828, Train Loss: 0.00126472651027143, Valid Loss: 0.0017160666175186634\n",
      "Epoch: 5829, Train Loss: 0.0012639620108529925, Valid Loss: 0.0017152230720967054\n",
      "Epoch: 5830, Train Loss: 0.001263198908418417, Valid Loss: 0.0017141663702204823\n",
      "Epoch: 5831, Train Loss: 0.0012624319642782211, Valid Loss: 0.001713281380943954\n",
      "Epoch: 5832, Train Loss: 0.0012616697931662202, Valid Loss: 0.001712265657261014\n",
      "Epoch: 5833, Train Loss: 0.0012609073892235756, Valid Loss: 0.0017113570356741548\n",
      "Epoch: 5834, Train Loss: 0.0012601459166035056, Valid Loss: 0.0017103755380958319\n",
      "Epoch: 5835, Train Loss: 0.001259384211152792, Valid Loss: 0.0017094408394768834\n",
      "Epoch: 5836, Train Loss: 0.0012586218072101474, Valid Loss: 0.0017084836727008224\n",
      "Epoch: 5837, Train Loss: 0.0012578604510053992, Valid Loss: 0.0017075102077797055\n",
      "Epoch: 5838, Train Loss: 0.0012570982798933983, Valid Loss: 0.001706599141471088\n",
      "Epoch: 5839, Train Loss: 0.001256341114640236, Valid Loss: 0.0017056034412235022\n",
      "Epoch: 5840, Train Loss: 0.0012555825524032116, Valid Loss: 0.0017046933062374592\n",
      "Epoch: 5841, Train Loss: 0.0012548222439363599, Valid Loss: 0.0017036914359778166\n",
      "Epoch: 5842, Train Loss: 0.0012540635652840137, Valid Loss: 0.0017028034199029207\n",
      "Epoch: 5843, Train Loss: 0.0012533048866316676, Valid Loss: 0.0017018060898408294\n",
      "Epoch: 5844, Train Loss: 0.0012525491183623672, Valid Loss: 0.0017008974682539701\n",
      "Epoch: 5845, Train Loss: 0.0012517905561253428, Valid Loss: 0.0016999037470668554\n",
      "Epoch: 5846, Train Loss: 0.0012510374654084444, Valid Loss: 0.001699001993983984\n",
      "Epoch: 5847, Train Loss: 0.0012502800673246384, Valid Loss: 0.0016980161890387535\n",
      "Epoch: 5848, Train Loss: 0.0012495239498093724, Valid Loss: 0.0016971142031252384\n",
      "Epoch: 5849, Train Loss: 0.0012487692292779684, Valid Loss: 0.0016961409710347652\n",
      "Epoch: 5850, Train Loss: 0.001248014043085277, Valid Loss: 0.0016952097648754716\n",
      "Epoch: 5851, Train Loss: 0.0012472606031224132, Valid Loss: 0.0016942480579018593\n",
      "Epoch: 5852, Train Loss: 0.0012465080944821239, Valid Loss: 0.0016933229053393006\n",
      "Epoch: 5853, Train Loss: 0.0012457555858418345, Valid Loss: 0.0016923800576478243\n",
      "Epoch: 5854, Train Loss: 0.001245001214556396, Valid Loss: 0.0016914269654080272\n",
      "Epoch: 5855, Train Loss: 0.0012442508013918996, Valid Loss: 0.0016904842341318727\n",
      "Epoch: 5856, Train Loss: 0.0012434974778443575, Valid Loss: 0.0016895529115572572\n",
      "Epoch: 5857, Train Loss: 0.001242747763171792, Valid Loss: 0.0016886143712326884\n",
      "Epoch: 5858, Train Loss: 0.0012419966515153646, Valid Loss: 0.0016876584850251675\n",
      "Epoch: 5859, Train Loss: 0.0012412500800564885, Valid Loss: 0.0016867386875674129\n",
      "Epoch: 5860, Train Loss: 0.00124049698933959, Valid Loss: 0.0016857858281582594\n",
      "Epoch: 5861, Train Loss: 0.0012397471582517028, Valid Loss: 0.0016848549712449312\n",
      "Epoch: 5862, Train Loss: 0.0012390000047162175, Valid Loss: 0.0016838983865454793\n",
      "Epoch: 5863, Train Loss: 0.0012382501736283302, Valid Loss: 0.001682993141002953\n",
      "Epoch: 5864, Train Loss: 0.0012375038350000978, Valid Loss: 0.0016820435412228107\n",
      "Epoch: 5865, Train Loss: 0.0012367552844807506, Valid Loss: 0.0016810995293781161\n",
      "Epoch: 5866, Train Loss: 0.00123601034283638, Valid Loss: 0.0016801614547148347\n",
      "Epoch: 5867, Train Loss: 0.0012352626072242856, Valid Loss: 0.0016792522510513663\n",
      "Epoch: 5868, Train Loss: 0.0012345168506726623, Valid Loss: 0.0016782917082309723\n",
      "Epoch: 5869, Train Loss: 0.0012337713269516826, Valid Loss: 0.0016773536335676908\n",
      "Epoch: 5870, Train Loss: 0.0012330260360613465, Valid Loss: 0.0016764267347753048\n",
      "Epoch: 5871, Train Loss: 0.0012322813272476196, Valid Loss: 0.001675513805821538\n",
      "Epoch: 5872, Train Loss: 0.0012315374333411455, Valid Loss: 0.0016745558241382241\n",
      "Epoch: 5873, Train Loss: 0.0012307934230193496, Valid Loss: 0.0016736265970394015\n",
      "Epoch: 5874, Train Loss: 0.0012300553498789668, Valid Loss: 0.0016727009788155556\n",
      "Epoch: 5875, Train Loss: 0.0012293115723878145, Valid Loss: 0.0016717920079827309\n",
      "Epoch: 5876, Train Loss: 0.001228568609803915, Valid Loss: 0.0016708390321582556\n",
      "Epoch: 5877, Train Loss: 0.0012278270442038774, Valid Loss: 0.0016699202824383974\n",
      "Epoch: 5878, Train Loss: 0.0012270852457731962, Valid Loss: 0.0016689940821379423\n",
      "Epoch: 5879, Train Loss: 0.001226347521878779, Valid Loss: 0.0016680588014423847\n",
      "Epoch: 5880, Train Loss: 0.0012256065383553505, Valid Loss: 0.0016671250341460109\n",
      "Epoch: 5881, Train Loss: 0.0012248653220012784, Valid Loss: 0.0016662065172567964\n",
      "Epoch: 5882, Train Loss: 0.0012241273652762175, Valid Loss: 0.00166528660338372\n",
      "Epoch: 5883, Train Loss: 0.0012233868474140763, Valid Loss: 0.0016643500421196222\n",
      "Epoch: 5884, Train Loss: 0.0012226514518260956, Valid Loss: 0.0016634330386295915\n",
      "Epoch: 5885, Train Loss: 0.0012219116324558854, Valid Loss: 0.0016625060234218836\n",
      "Epoch: 5886, Train Loss: 0.0012211755383759737, Valid Loss: 0.0016615836648270488\n",
      "Epoch: 5887, Train Loss: 0.0012204383965581656, Valid Loss: 0.0016606503631919622\n",
      "Epoch: 5888, Train Loss: 0.0012197013711556792, Valid Loss: 0.0016597408102825284\n",
      "Epoch: 5889, Train Loss: 0.0012189685367047787, Valid Loss: 0.0016588077414780855\n",
      "Epoch: 5890, Train Loss: 0.0012182302307337523, Valid Loss: 0.0016578903887420893\n",
      "Epoch: 5891, Train Loss: 0.0012174963485449553, Valid Loss: 0.0016569634899497032\n",
      "Epoch: 5892, Train Loss: 0.0012167601380497217, Valid Loss: 0.0016560549847781658\n",
      "Epoch: 5893, Train Loss: 0.001216028816998005, Valid Loss: 0.0016551230801269412\n",
      "Epoch: 5894, Train Loss: 0.0012152933049947023, Valid Loss: 0.0016541992081329226\n",
      "Epoch: 5895, Train Loss: 0.0012145639630034566, Valid Loss: 0.0016532824374735355\n",
      "Epoch: 5896, Train Loss: 0.001213830430060625, Valid Loss: 0.0016523819649592042\n",
      "Epoch: 5897, Train Loss: 0.0012130987597629428, Valid Loss: 0.0016514596063643694\n",
      "Epoch: 5898, Train Loss: 0.0012123675551265478, Valid Loss: 0.0016505294479429722\n",
      "Epoch: 5899, Train Loss: 0.001211637514643371, Valid Loss: 0.0016496102325618267\n",
      "Epoch: 5900, Train Loss: 0.0012109053786844015, Valid Loss: 0.0016487069660797715\n",
      "Epoch: 5901, Train Loss: 0.0012101751053705812, Valid Loss: 0.0016477885656058788\n",
      "Epoch: 5902, Train Loss: 0.0012094465782865882, Valid Loss: 0.0016468710964545608\n",
      "Epoch: 5903, Train Loss: 0.0012087152572348714, Valid Loss: 0.001645944663323462\n",
      "Epoch: 5904, Train Loss: 0.0012079874286428094, Valid Loss: 0.0016450476832687855\n",
      "Epoch: 5905, Train Loss: 0.0012072586687281728, Valid Loss: 0.0016441234620288014\n",
      "Epoch: 5906, Train Loss: 0.0012065344490110874, Valid Loss: 0.0016432177508249879\n",
      "Epoch: 5907, Train Loss: 0.0012058042921125889, Valid Loss: 0.0016422959743067622\n",
      "Epoch: 5908, Train Loss: 0.0012050758814439178, Valid Loss: 0.0016413874691352248\n",
      "Epoch: 5909, Train Loss: 0.001204350613988936, Valid Loss: 0.0016404790803790092\n",
      "Epoch: 5910, Train Loss: 0.001203624065965414, Valid Loss: 0.0016395602142438293\n",
      "Epoch: 5911, Train Loss: 0.001202899613417685, Valid Loss: 0.0016386545030400157\n",
      "Epoch: 5912, Train Loss: 0.0012021752772852778, Valid Loss: 0.0016377465799450874\n",
      "Epoch: 5913, Train Loss: 0.0012014505919069052, Valid Loss: 0.0016368338838219643\n",
      "Epoch: 5914, Train Loss: 0.0012007277691736817, Valid Loss: 0.0016359324799850583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5915, Train Loss: 0.0012000009883195162, Valid Loss: 0.001635025255382061\n",
      "Epoch: 5916, Train Loss: 0.0011992809595540166, Valid Loss: 0.0016341080190613866\n",
      "Epoch: 5917, Train Loss: 0.0011985580204054713, Valid Loss: 0.0016332116210833192\n",
      "Epoch: 5918, Train Loss: 0.0011978355469182134, Valid Loss: 0.001632298924960196\n",
      "Epoch: 5919, Train Loss: 0.0011971157509833574, Valid Loss: 0.0016313897212967277\n",
      "Epoch: 5920, Train Loss: 0.0011963930446654558, Valid Loss: 0.0016304884338751435\n",
      "Epoch: 5921, Train Loss: 0.001195672433823347, Valid Loss: 0.0016295877285301685\n",
      "Epoch: 5922, Train Loss: 0.0011949521722272038, Valid Loss: 0.0016286823665723205\n",
      "Epoch: 5923, Train Loss: 0.0011942313285544515, Valid Loss: 0.0016277774702757597\n",
      "Epoch: 5924, Train Loss: 0.0011935130460187793, Valid Loss: 0.001626872457563877\n",
      "Epoch: 5925, Train Loss: 0.0011927930172532797, Valid Loss: 0.0016259709373116493\n",
      "Epoch: 5926, Train Loss: 0.0011920727556571364, Valid Loss: 0.0016250553308054805\n",
      "Epoch: 5927, Train Loss: 0.0011913576163351536, Valid Loss: 0.0016241747653111815\n",
      "Epoch: 5928, Train Loss: 0.0011906377039849758, Valid Loss: 0.001623267657123506\n",
      "Epoch: 5929, Train Loss: 0.0011899212840944529, Valid Loss: 0.0016223718412220478\n",
      "Epoch: 5930, Train Loss: 0.0011892035836353898, Valid Loss: 0.0016214505303651094\n",
      "Epoch: 5931, Train Loss: 0.0011884898412972689, Valid Loss: 0.001620564959011972\n",
      "Epoch: 5932, Train Loss: 0.0011877716751769185, Valid Loss: 0.0016196721699088812\n",
      "Epoch: 5933, Train Loss: 0.0011870553717017174, Valid Loss: 0.0016187712317332625\n",
      "Epoch: 5934, Train Loss: 0.0011863447725772858, Valid Loss: 0.0016178557416424155\n",
      "Epoch: 5935, Train Loss: 0.0011856264900416136, Valid Loss: 0.00161698367446661\n",
      "Epoch: 5936, Train Loss: 0.001184915890917182, Valid Loss: 0.0016160692321136594\n",
      "Epoch: 5937, Train Loss: 0.0011842009844258428, Valid Loss: 0.0016151918098330498\n",
      "Epoch: 5938, Train Loss: 0.0011834871256724, Valid Loss: 0.0016142692184075713\n",
      "Epoch: 5939, Train Loss: 0.0011827766429632902, Valid Loss: 0.0016134005272760987\n",
      "Epoch: 5940, Train Loss: 0.0011820655781775713, Valid Loss: 0.0016125004040077329\n",
      "Epoch: 5941, Train Loss: 0.0011813491582870483, Valid Loss: 0.001611618441529572\n",
      "Epoch: 5942, Train Loss: 0.0011806420516222715, Valid Loss: 0.00161068351007998\n",
      "Epoch: 5943, Train Loss: 0.0011799297062680125, Valid Loss: 0.0016098374035209417\n",
      "Epoch: 5944, Train Loss: 0.0011792188743129373, Valid Loss: 0.0016089178388938308\n",
      "Epoch: 5945, Train Loss: 0.001178512116894126, Valid Loss: 0.001608056016266346\n",
      "Epoch: 5946, Train Loss: 0.0011778016341850162, Valid Loss: 0.0016071199206635356\n",
      "Epoch: 5947, Train Loss: 0.0011770938290283084, Valid Loss: 0.0016062733484432101\n",
      "Epoch: 5948, Train Loss: 0.0011763883521780372, Valid Loss: 0.00160535192117095\n",
      "Epoch: 5949, Train Loss: 0.001175675424747169, Valid Loss: 0.001604486140422523\n",
      "Epoch: 5950, Train Loss: 0.0011749682016670704, Valid Loss: 0.0016035581938922405\n",
      "Epoch: 5951, Train Loss: 0.0011742626084014773, Valid Loss: 0.001602726522833109\n",
      "Epoch: 5952, Train Loss: 0.0011735549196600914, Valid Loss: 0.0016017764573916793\n",
      "Epoch: 5953, Train Loss: 0.0011728504905477166, Valid Loss: 0.0016009291866794229\n",
      "Epoch: 5954, Train Loss: 0.00117214466445148, Valid Loss: 0.001600012183189392\n",
      "Epoch: 5955, Train Loss: 0.0011714400025084615, Valid Loss: 0.001599169336259365\n",
      "Epoch: 5956, Train Loss: 0.0011707345256581903, Valid Loss: 0.0015982284676283598\n",
      "Epoch: 5957, Train Loss: 0.00117003102786839, Valid Loss: 0.0015974033158272505\n",
      "Epoch: 5958, Train Loss: 0.00116932753007859, Valid Loss: 0.0015964600024744868\n",
      "Epoch: 5959, Train Loss: 0.0011686249636113644, Valid Loss: 0.0015956253046169877\n",
      "Epoch: 5960, Train Loss: 0.001167919603176415, Valid Loss: 0.0015946924686431885\n",
      "Epoch: 5961, Train Loss: 0.0011672177352011204, Valid Loss: 0.001593863358721137\n",
      "Epoch: 5962, Train Loss: 0.0011665147030726075, Valid Loss: 0.0015929213259369135\n",
      "Epoch: 5963, Train Loss: 0.0011658142320811749, Valid Loss: 0.001592095592059195\n",
      "Epoch: 5964, Train Loss: 0.0011651137610897422, Valid Loss: 0.001591167994774878\n",
      "Epoch: 5965, Train Loss: 0.0011644145706668496, Valid Loss: 0.0015903429593890905\n",
      "Epoch: 5966, Train Loss: 0.0011637139832600951, Valid Loss: 0.0015893944073468447\n",
      "Epoch: 5967, Train Loss: 0.0011630122317001224, Valid Loss: 0.0015885840402916074\n",
      "Epoch: 5968, Train Loss: 0.0011623133905231953, Valid Loss: 0.0015876309480518103\n",
      "Epoch: 5969, Train Loss: 0.0011616143165156245, Valid Loss: 0.0015868352493271232\n",
      "Epoch: 5970, Train Loss: 0.0011609141947701573, Valid Loss: 0.0015858742408454418\n",
      "Epoch: 5971, Train Loss: 0.0011602162849158049, Valid Loss: 0.0015850727213546634\n",
      "Epoch: 5972, Train Loss: 0.0011595204705372453, Valid Loss: 0.0015841011190786958\n",
      "Epoch: 5973, Train Loss: 0.0011588253546506166, Valid Loss: 0.001583342906087637\n",
      "Epoch: 5974, Train Loss: 0.0011581259313970804, Valid Loss: 0.0015823498833924532\n",
      "Epoch: 5975, Train Loss: 0.0011574304662644863, Valid Loss: 0.0015815849183127284\n",
      "Epoch: 5976, Train Loss: 0.0011567361652851105, Valid Loss: 0.0015805724542587996\n",
      "Epoch: 5977, Train Loss: 0.0011560404673218727, Valid Loss: 0.0015798509120941162\n",
      "Epoch: 5978, Train Loss: 0.0011553443036973476, Valid Loss: 0.001578834024257958\n",
      "Epoch: 5979, Train Loss: 0.0011546493042260408, Valid Loss: 0.0015781119000166655\n",
      "Epoch: 5980, Train Loss: 0.001153956283815205, Valid Loss: 0.00157706078607589\n",
      "Epoch: 5981, Train Loss: 0.0011532651260495186, Valid Loss: 0.0015763837145641446\n",
      "Epoch: 5982, Train Loss: 0.0011525724548846483, Valid Loss: 0.0015753144398331642\n",
      "Epoch: 5983, Train Loss: 0.0011518803657963872, Valid Loss: 0.001574664143845439\n",
      "Epoch: 5984, Train Loss: 0.0011511878110468388, Valid Loss: 0.0015735453926026821\n",
      "Epoch: 5985, Train Loss: 0.0011504959547892213, Valid Loss: 0.0015729401493445039\n",
      "Epoch: 5986, Train Loss: 0.0011498074745759368, Valid Loss: 0.0015717903152108192\n",
      "Epoch: 5987, Train Loss: 0.0011491162003949285, Valid Loss: 0.0015712369931861758\n",
      "Epoch: 5988, Train Loss: 0.0011484287679195404, Valid Loss: 0.0015700358198955655\n",
      "Epoch: 5989, Train Loss: 0.001147738192230463, Valid Loss: 0.0015695199836045504\n",
      "Epoch: 5990, Train Loss: 0.0011470509925857186, Valid Loss: 0.0015682808589190245\n",
      "Epoch: 5991, Train Loss: 0.0011463611153885722, Valid Loss: 0.0015678155468776822\n",
      "Epoch: 5992, Train Loss: 0.0011456729844212532, Valid Loss: 0.0015665250830352306\n",
      "Epoch: 5993, Train Loss: 0.0011449893936514854, Valid Loss: 0.0015661028446629643\n",
      "Epoch: 5994, Train Loss: 0.0011443027760833502, Valid Loss: 0.0015647708205506206\n",
      "Epoch: 5995, Train Loss: 0.0011436165077611804, Valid Loss: 0.001564403879456222\n",
      "Epoch: 5996, Train Loss: 0.0011429291917011142, Valid Loss: 0.0015630366979166865\n",
      "Epoch: 5997, Train Loss: 0.0011422442039474845, Valid Loss: 0.0015626788372173905\n",
      "Epoch: 5998, Train Loss: 0.0011415582848712802, Valid Loss: 0.0015612818533554673\n",
      "Epoch: 5999, Train Loss: 0.0011408721329644322, Valid Loss: 0.0015609635738655925\n",
      "Epoch: 6000, Train Loss: 0.0011401856318116188, Valid Loss: 0.0015595756703987718\n",
      "Epoch: 6001, Train Loss: 0.001139500760473311, Valid Loss: 0.0015591998817399144\n",
      "Epoch: 6002, Train Loss: 0.0011388148413971066, Valid Loss: 0.0015578658785670996\n",
      "Epoch: 6003, Train Loss: 0.001138128456659615, Valid Loss: 0.0015574456192553043\n",
      "Epoch: 6004, Train Loss: 0.0011374402092769742, Valid Loss: 0.001556172501295805\n",
      "Epoch: 6005, Train Loss: 0.0011367547558620572, Valid Loss: 0.001555657247081399\n",
      "Epoch: 6006, Train Loss: 0.001136070815846324, Valid Loss: 0.001554507645778358\n",
      "Epoch: 6007, Train Loss: 0.0011353834997862577, Valid Loss: 0.0015538770239800215\n",
      "Epoch: 6008, Train Loss: 0.0011347036343067884, Valid Loss: 0.001552823232486844\n",
      "Epoch: 6009, Train Loss: 0.001134018413722515, Valid Loss: 0.001552085974253714\n",
      "Epoch: 6010, Train Loss: 0.0011333385482430458, Valid Loss: 0.001551169785670936\n",
      "Epoch: 6011, Train Loss: 0.0011326567037031054, Valid Loss: 0.0015503235626965761\n",
      "Epoch: 6012, Train Loss: 0.0011319785844534636, Valid Loss: 0.0015494978288188577\n",
      "Epoch: 6013, Train Loss: 0.001131298951804638, Valid Loss: 0.0015485723270103335\n",
      "Epoch: 6014, Train Loss: 0.0011306210653856397, Valid Loss: 0.0015478251734748483\n",
      "Epoch: 6015, Train Loss: 0.0011299416655674577, Valid Loss: 0.0015468153869733214\n",
      "Epoch: 6016, Train Loss: 0.001129264710471034, Valid Loss: 0.0015461407601833344\n",
      "Epoch: 6017, Train Loss: 0.0011285885702818632, Valid Loss: 0.0015451190993189812\n",
      "Epoch: 6018, Train Loss: 0.0011279091704636812, Valid Loss: 0.0015444522723555565\n",
      "Epoch: 6019, Train Loss: 0.001127232681028545, Valid Loss: 0.0015433934750035405\n",
      "Epoch: 6020, Train Loss: 0.0011265567736700177, Valid Loss: 0.0015427422476932406\n",
      "Epoch: 6021, Train Loss: 0.0011258795857429504, Valid Loss: 0.0015417162794619799\n",
      "Epoch: 6022, Train Loss: 0.0011252046097069979, Valid Loss: 0.0015410312917083502\n",
      "Epoch: 6023, Train Loss: 0.001124527771025896, Valid Loss: 0.0015400206902995706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6024, Train Loss: 0.0011238526785746217, Valid Loss: 0.0015393119538202882\n",
      "Epoch: 6025, Train Loss: 0.0011231773532927036, Valid Loss: 0.0015383507125079632\n",
      "Epoch: 6026, Train Loss: 0.00112250167876482, Valid Loss: 0.0015375822549685836\n",
      "Epoch: 6027, Train Loss: 0.0011218308936804533, Valid Loss: 0.0015366687439382076\n",
      "Epoch: 6028, Train Loss: 0.0011211576638743281, Valid Loss: 0.001535870018415153\n",
      "Epoch: 6029, Train Loss: 0.0011204839684069157, Valid Loss: 0.0015349991153925657\n",
      "Epoch: 6030, Train Loss: 0.001119811087846756, Valid Loss: 0.00153414870146662\n",
      "Epoch: 6031, Train Loss: 0.0011191407684236765, Valid Loss: 0.0015333277406170964\n",
      "Epoch: 6032, Train Loss: 0.0011184662580490112, Valid Loss: 0.0015324401902034879\n",
      "Epoch: 6033, Train Loss: 0.0011177966371178627, Valid Loss: 0.0015316397184506059\n",
      "Epoch: 6034, Train Loss: 0.0011171259684488177, Valid Loss: 0.0015307475114241242\n",
      "Epoch: 6035, Train Loss: 0.0011164535535499454, Valid Loss: 0.0015299555379897356\n",
      "Epoch: 6036, Train Loss: 0.0011157854460179806, Valid Loss: 0.0015290436567738652\n",
      "Epoch: 6037, Train Loss: 0.0011151190847158432, Valid Loss: 0.001528276246972382\n",
      "Epoch: 6038, Train Loss: 0.0011144516756758094, Valid Loss: 0.0015273545868694782\n",
      "Epoch: 6039, Train Loss: 0.001113779260776937, Valid Loss: 0.00152659323066473\n",
      "Epoch: 6040, Train Loss: 0.0011131122009828687, Valid Loss: 0.001525670988485217\n",
      "Epoch: 6041, Train Loss: 0.0011124442098662257, Valid Loss: 0.0015248868148773909\n",
      "Epoch: 6042, Train Loss: 0.0011117757530882955, Valid Loss: 0.0015239915810525417\n",
      "Epoch: 6043, Train Loss: 0.001111111487261951, Valid Loss: 0.0015232112491503358\n",
      "Epoch: 6044, Train Loss: 0.0011104466393589973, Valid Loss: 0.0015223207883536816\n",
      "Epoch: 6045, Train Loss: 0.0011097784154117107, Valid Loss: 0.00152151461225003\n",
      "Epoch: 6046, Train Loss: 0.0011091131018474698, Valid Loss: 0.0015206418465822935\n",
      "Epoch: 6047, Train Loss: 0.0011084473226219416, Valid Loss: 0.0015198307810351253\n",
      "Epoch: 6048, Train Loss: 0.001107782474718988, Valid Loss: 0.001518988166935742\n",
      "Epoch: 6049, Train Loss: 0.0011071179760619998, Valid Loss: 0.0015181463677436113\n",
      "Epoch: 6050, Train Loss: 0.00110645464155823, Valid Loss: 0.001517303753644228\n",
      "Epoch: 6051, Train Loss: 0.0011057923547923565, Valid Loss: 0.001516455435194075\n",
      "Epoch: 6052, Train Loss: 0.0011051270412281156, Valid Loss: 0.0015156425070017576\n",
      "Epoch: 6053, Train Loss: 0.001104465569369495, Valid Loss: 0.0015147875528782606\n",
      "Epoch: 6054, Train Loss: 0.001103802933357656, Valid Loss: 0.0015139718307182193\n",
      "Epoch: 6055, Train Loss: 0.0011031418107450008, Valid Loss: 0.0015131101245060563\n",
      "Epoch: 6056, Train Loss: 0.0011024827836081386, Valid Loss: 0.0015123093035072088\n",
      "Epoch: 6057, Train Loss: 0.0011018227087333798, Valid Loss: 0.001511446083895862\n",
      "Epoch: 6058, Train Loss: 0.0011011596070602536, Valid Loss: 0.0015106428181752563\n",
      "Epoch: 6059, Train Loss: 0.0011005005799233913, Valid Loss: 0.0015097733121365309\n",
      "Epoch: 6060, Train Loss: 0.0010998421348631382, Valid Loss: 0.0015089772641658783\n",
      "Epoch: 6061, Train Loss: 0.0010991807794198394, Valid Loss: 0.0015081088058650494\n",
      "Epoch: 6062, Train Loss: 0.0010985233820974827, Valid Loss: 0.00150730786845088\n",
      "Epoch: 6063, Train Loss: 0.0010978634236380458, Valid Loss: 0.001506448956206441\n",
      "Epoch: 6064, Train Loss: 0.0010972053278237581, Valid Loss: 0.0015056465053930879\n",
      "Epoch: 6065, Train Loss: 0.0010965469991788268, Valid Loss: 0.0015047957422211766\n",
      "Epoch: 6066, Train Loss: 0.001095890998840332, Valid Loss: 0.0015039821155369282\n",
      "Epoch: 6067, Train Loss: 0.0010952349985018373, Valid Loss: 0.0015031392686069012\n",
      "Epoch: 6068, Train Loss: 0.001094577950425446, Valid Loss: 0.0015023264568299055\n",
      "Epoch: 6069, Train Loss: 0.0010939226485788822, Valid Loss: 0.0015014781383797526\n",
      "Epoch: 6070, Train Loss: 0.0010932680452242494, Valid Loss: 0.0015006709145382047\n",
      "Epoch: 6071, Train Loss: 0.0010926109971478581, Valid Loss: 0.0014998348196968436\n",
      "Epoch: 6072, Train Loss: 0.0010919608175754547, Valid Loss: 0.00149901257827878\n",
      "Epoch: 6073, Train Loss: 0.001091302023269236, Valid Loss: 0.0014981706626713276\n",
      "Epoch: 6074, Train Loss: 0.0010906500974670053, Valid Loss: 0.0014973549405112863\n",
      "Epoch: 6075, Train Loss: 0.0010899953776970506, Valid Loss: 0.0014965267619118094\n",
      "Epoch: 6076, Train Loss: 0.001089343219064176, Valid Loss: 0.0014957094099372625\n",
      "Epoch: 6077, Train Loss: 0.0010886925738304853, Valid Loss: 0.0014948700554668903\n",
      "Epoch: 6078, Train Loss: 0.0010880404151976109, Valid Loss: 0.001494053634814918\n",
      "Epoch: 6079, Train Loss: 0.0010873888386413455, Valid Loss: 0.0014932304620742798\n",
      "Epoch: 6080, Train Loss: 0.0010867358651012182, Valid Loss: 0.001492415089160204\n",
      "Epoch: 6081, Train Loss: 0.0010860876645892859, Valid Loss: 0.0014915865613147616\n",
      "Epoch: 6082, Train Loss: 0.001085435040295124, Valid Loss: 0.001490769675001502\n",
      "Epoch: 6083, Train Loss: 0.0010847834637388587, Valid Loss: 0.0014899378875270486\n",
      "Epoch: 6084, Train Loss: 0.0010841344483196735, Valid Loss: 0.0014891211176291108\n",
      "Epoch: 6085, Train Loss: 0.0010834858985617757, Valid Loss: 0.001488302368670702\n",
      "Epoch: 6086, Train Loss: 0.001082835835404694, Valid Loss: 0.0014874881599098444\n",
      "Epoch: 6087, Train Loss: 0.0010821876348927617, Valid Loss: 0.0014866547426208854\n",
      "Epoch: 6088, Train Loss: 0.0010815399000421166, Valid Loss: 0.0014858414651826024\n",
      "Epoch: 6089, Train Loss: 0.0010808930965140462, Valid Loss: 0.0014850222505629063\n",
      "Epoch: 6090, Train Loss: 0.0010802445467561483, Valid Loss: 0.0014842227101325989\n",
      "Epoch: 6091, Train Loss: 0.001079597626812756, Valid Loss: 0.00148337974678725\n",
      "Epoch: 6092, Train Loss: 0.001078953966498375, Valid Loss: 0.001482566585764289\n",
      "Epoch: 6093, Train Loss: 0.00107830879278481, Valid Loss: 0.0014817616902291775\n",
      "Epoch: 6094, Train Loss: 0.0010776619892567396, Valid Loss: 0.0014809526037424803\n",
      "Epoch: 6095, Train Loss: 0.0010770183289423585, Valid Loss: 0.0014801138313487172\n",
      "Epoch: 6096, Train Loss: 0.0010763716418296099, Valid Loss: 0.001479312777519226\n",
      "Epoch: 6097, Train Loss: 0.0010757270501926541, Valid Loss: 0.0014784985687583685\n",
      "Epoch: 6098, Train Loss: 0.001075084786862135, Valid Loss: 0.0014776976313441992\n",
      "Epoch: 6099, Train Loss: 0.0010744414757937193, Valid Loss: 0.0014768594410270452\n",
      "Epoch: 6100, Train Loss: 0.0010737980483099818, Valid Loss: 0.001476060482673347\n",
      "Epoch: 6101, Train Loss: 0.0010731529910117388, Valid Loss: 0.001475245808251202\n",
      "Epoch: 6102, Train Loss: 0.001072510494850576, Valid Loss: 0.0014744342770427465\n",
      "Epoch: 6103, Train Loss: 0.0010718716075643897, Valid Loss: 0.0014736111043021083\n",
      "Epoch: 6104, Train Loss: 0.0010712291114032269, Valid Loss: 0.0014728106325492263\n",
      "Epoch: 6105, Train Loss: 0.0010705891763791442, Valid Loss: 0.0014719940954819322\n",
      "Epoch: 6106, Train Loss: 0.0010699471458792686, Valid Loss: 0.0014711902476847172\n",
      "Epoch: 6107, Train Loss: 0.0010693076765164733, Valid Loss: 0.0014703732449561357\n",
      "Epoch: 6108, Train Loss: 0.0010686683235689998, Valid Loss: 0.0014695795252919197\n",
      "Epoch: 6109, Train Loss: 0.0010680294362828135, Valid Loss: 0.0014687549555674195\n",
      "Epoch: 6110, Train Loss: 0.0010673884535208344, Valid Loss: 0.0014679462183266878\n",
      "Epoch: 6111, Train Loss: 0.0010667521273717284, Valid Loss: 0.0014671391109004617\n",
      "Epoch: 6112, Train Loss: 0.001066112075932324, Valid Loss: 0.0014663467882201076\n",
      "Epoch: 6113, Train Loss: 0.0010654738871380687, Valid Loss: 0.0014655222184956074\n",
      "Epoch: 6114, Train Loss: 0.0010648381430655718, Valid Loss: 0.0014647241914644837\n",
      "Epoch: 6115, Train Loss: 0.0010641991393640637, Valid Loss: 0.0014639165019616485\n",
      "Epoch: 6116, Train Loss: 0.001063564675860107, Valid Loss: 0.0014631161466240883\n",
      "Epoch: 6117, Train Loss: 0.0010629259049892426, Valid Loss: 0.0014623061288148165\n",
      "Epoch: 6118, Train Loss: 0.0010622908594086766, Valid Loss: 0.0014615037944167852\n",
      "Epoch: 6119, Train Loss: 0.0010616593062877655, Valid Loss: 0.0014606957556679845\n",
      "Epoch: 6120, Train Loss: 0.001061020651832223, Valid Loss: 0.00145989959128201\n",
      "Epoch: 6121, Train Loss: 0.0010603867704048753, Valid Loss: 0.001459090388379991\n",
      "Epoch: 6122, Train Loss: 0.0010597538203001022, Valid Loss: 0.001458294689655304\n",
      "Epoch: 6123, Train Loss: 0.0010591186583042145, Valid Loss: 0.0014574909582734108\n",
      "Epoch: 6124, Train Loss: 0.0010584862902760506, Valid Loss: 0.0014566901372745633\n",
      "Epoch: 6125, Train Loss: 0.0010578534565865993, Valid Loss: 0.0014558874536305666\n",
      "Epoch: 6126, Train Loss: 0.0010572210885584354, Valid Loss: 0.0014550888445228338\n",
      "Epoch: 6127, Train Loss: 0.0010565874399617314, Valid Loss: 0.0014542937278747559\n",
      "Epoch: 6128, Train Loss: 0.0010559551883488894, Valid Loss: 0.0014534816145896912\n",
      "Epoch: 6129, Train Loss: 0.0010553242173045874, Valid Loss: 0.0014526891754940152\n",
      "Epoch: 6130, Train Loss: 0.0010546916164457798, Valid Loss: 0.001451890799216926\n",
      "Epoch: 6131, Train Loss: 0.0010540622752159834, Valid Loss: 0.001451091724447906\n",
      "Epoch: 6132, Train Loss: 0.001053433632478118, Valid Loss: 0.001450283918529749\n",
      "Epoch: 6133, Train Loss: 0.0010528038255870342, Valid Loss: 0.0014494991628453135\n",
      "Epoch: 6134, Train Loss: 0.0010521732037886977, Valid Loss: 0.0014487009029835463\n",
      "Epoch: 6135, Train Loss: 0.0010515437461435795, Valid Loss: 0.0014479015953838825\n",
      "Epoch: 6136, Train Loss: 0.001050916500389576, Valid Loss: 0.0014470990281552076\n",
      "Epoch: 6137, Train Loss: 0.0010502890218049288, Valid Loss: 0.001446317881345749\n",
      "Epoch: 6138, Train Loss: 0.001049660611897707, Valid Loss: 0.0014455115888267756\n",
      "Epoch: 6139, Train Loss: 0.0010490319691598415, Valid Loss: 0.0014447285793721676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6140, Train Loss: 0.0010484046069905162, Valid Loss: 0.0014439154183492064\n",
      "Epoch: 6141, Train Loss: 0.0010477766627445817, Valid Loss: 0.0014431379968300462\n",
      "Epoch: 6142, Train Loss: 0.001047152909450233, Valid Loss: 0.0014423415996134281\n",
      "Epoch: 6143, Train Loss: 0.0010465268278494477, Valid Loss: 0.001441562781110406\n",
      "Epoch: 6144, Train Loss: 0.001045899116434157, Valid Loss: 0.0014407397247850895\n",
      "Epoch: 6145, Train Loss: 0.0010452779242768884, Valid Loss: 0.0014399717329069972\n",
      "Epoch: 6146, Train Loss: 0.0010446530068293214, Valid Loss: 0.001439167419448495\n",
      "Epoch: 6147, Train Loss: 0.001044030417688191, Valid Loss: 0.001438393839634955\n",
      "Epoch: 6148, Train Loss: 0.0010434039868414402, Valid Loss: 0.001437572529539466\n",
      "Epoch: 6149, Train Loss: 0.001042778487317264, Valid Loss: 0.0014368194388225675\n",
      "Epoch: 6150, Train Loss: 0.0010421568294987082, Valid Loss: 0.0014359987108036876\n",
      "Epoch: 6151, Train Loss: 0.0010415323777124286, Valid Loss: 0.0014352418947964907\n",
      "Epoch: 6152, Train Loss: 0.0010409116512164474, Valid Loss: 0.0014344119699671865\n",
      "Epoch: 6153, Train Loss: 0.0010402919724583626, Valid Loss: 0.0014336658641695976\n",
      "Epoch: 6154, Train Loss: 0.0010396689176559448, Valid Loss: 0.0014328380348160863\n",
      "Epoch: 6155, Train Loss: 0.001039046561345458, Valid Loss: 0.0014320940244942904\n",
      "Epoch: 6156, Train Loss: 0.0010384268825873733, Valid Loss: 0.0014312613056972623\n",
      "Epoch: 6157, Train Loss: 0.0010378059232607484, Valid Loss: 0.0014305232325568795\n",
      "Epoch: 6158, Train Loss: 0.0010371837997809052, Valid Loss: 0.00142968213185668\n",
      "Epoch: 6159, Train Loss: 0.0010365665657445788, Valid Loss: 0.0014289560494944453\n",
      "Epoch: 6160, Train Loss: 0.0010359497973695397, Valid Loss: 0.0014281176263466477\n",
      "Epoch: 6161, Train Loss: 0.0010353296529501677, Valid Loss: 0.00142738688737154\n",
      "Epoch: 6162, Train Loss: 0.0010347113711759448, Valid Loss: 0.0014265408972278237\n",
      "Epoch: 6163, Train Loss: 0.0010340939043089747, Valid Loss: 0.0014258245937526226\n",
      "Epoch: 6164, Train Loss: 0.0010334773687645793, Valid Loss: 0.0014249705709517002\n",
      "Epoch: 6165, Train Loss: 0.0010328586213290691, Valid Loss: 0.0014242721954360604\n",
      "Epoch: 6166, Train Loss: 0.00103224185295403, Valid Loss: 0.0014234046684578061\n",
      "Epoch: 6167, Train Loss: 0.0010316258994862437, Valid Loss: 0.001422716653905809\n",
      "Epoch: 6168, Train Loss: 0.0010310100624337792, Valid Loss: 0.0014218310825526714\n",
      "Epoch: 6169, Train Loss: 0.0010303952731192112, Valid Loss: 0.0014211637899279594\n",
      "Epoch: 6170, Train Loss: 0.0010297782719135284, Valid Loss: 0.0014202706515789032\n",
      "Epoch: 6171, Train Loss: 0.0010291633661836386, Valid Loss: 0.0014196066185832024\n",
      "Epoch: 6172, Train Loss: 0.0010285505559295416, Valid Loss: 0.0014187043998390436\n",
      "Epoch: 6173, Train Loss: 0.0010279358830302954, Valid Loss: 0.001418060390278697\n",
      "Epoch: 6174, Train Loss: 0.001027323305606842, Valid Loss: 0.0014171350048854947\n",
      "Epoch: 6175, Train Loss: 0.0010267089819535613, Valid Loss: 0.0014165111351758242\n",
      "Epoch: 6176, Train Loss: 0.001026097685098648, Valid Loss: 0.0014155714306980371\n",
      "Epoch: 6177, Train Loss: 0.001025483594276011, Valid Loss: 0.001414970145560801\n",
      "Epoch: 6178, Train Loss: 0.0010248726466670632, Valid Loss: 0.0014140033163130283\n",
      "Epoch: 6179, Train Loss: 0.001024262048304081, Valid Loss: 0.0014134332304820418\n",
      "Epoch: 6180, Train Loss: 0.0010236514499410987, Valid Loss: 0.0014124432345852256\n",
      "Epoch: 6181, Train Loss: 0.0010230388725176454, Valid Loss: 0.0014119013212621212\n",
      "Epoch: 6182, Train Loss: 0.0010224318830296397, Valid Loss: 0.001410874305292964\n",
      "Epoch: 6183, Train Loss: 0.0010218237293884158, Valid Loss: 0.0014103695284575224\n",
      "Epoch: 6184, Train Loss: 0.0010212123161181808, Valid Loss: 0.0014093199279159307\n",
      "Epoch: 6185, Train Loss: 0.0010206049773842096, Valid Loss: 0.0014088479802012444\n",
      "Epoch: 6186, Train Loss: 0.0010199963580816984, Valid Loss: 0.001407759147696197\n",
      "Epoch: 6187, Train Loss: 0.0010193880880251527, Valid Loss: 0.001407315139658749\n",
      "Epoch: 6188, Train Loss: 0.001018783077597618, Valid Loss: 0.0014062157133594155\n",
      "Epoch: 6189, Train Loss: 0.0010181738762184978, Valid Loss: 0.0014057940570637584\n",
      "Epoch: 6190, Train Loss: 0.0010175661882385612, Valid Loss: 0.0014046499272808433\n",
      "Epoch: 6191, Train Loss: 0.0010169618763029575, Valid Loss: 0.001404264592565596\n",
      "Epoch: 6192, Train Loss: 0.0010163567494601011, Valid Loss: 0.001403103582561016\n",
      "Epoch: 6193, Train Loss: 0.0010157498763874173, Valid Loss: 0.001402728259563446\n",
      "Epoch: 6194, Train Loss: 0.0010151421884074807, Valid Loss: 0.0014015623601153493\n",
      "Epoch: 6195, Train Loss: 0.0010145367123186588, Valid Loss: 0.001401171670295298\n",
      "Epoch: 6196, Train Loss: 0.0010139299556612968, Valid Loss: 0.0014000411611050367\n",
      "Epoch: 6197, Train Loss: 0.0010133233154192567, Valid Loss: 0.0013996124034747481\n",
      "Epoch: 6198, Train Loss: 0.0010127171408385038, Valid Loss: 0.001398520777001977\n",
      "Epoch: 6199, Train Loss: 0.0010121111990883946, Valid Loss: 0.0013980327639728785\n",
      "Epoch: 6200, Train Loss: 0.00101150490809232, Valid Loss: 0.0013970148283988237\n",
      "Epoch: 6201, Train Loss: 0.0010108978021889925, Valid Loss: 0.0013964666286483407\n",
      "Epoch: 6202, Train Loss: 0.0010102950036525726, Valid Loss: 0.0013955055037513375\n",
      "Epoch: 6203, Train Loss: 0.0010096908081322908, Valid Loss: 0.0013948791893199086\n",
      "Epoch: 6204, Train Loss: 0.0010090870782732964, Valid Loss: 0.001394013175740838\n",
      "Epoch: 6205, Train Loss: 0.0010084827663376927, Valid Loss: 0.001393320388160646\n",
      "Epoch: 6206, Train Loss: 0.0010078820632770658, Valid Loss: 0.0013925262028351426\n",
      "Epoch: 6207, Train Loss: 0.0010072801960632205, Valid Loss: 0.00139174098148942\n",
      "Epoch: 6208, Train Loss: 0.0010066807735711336, Valid Loss: 0.00139102921821177\n",
      "Epoch: 6209, Train Loss: 0.0010060806525871158, Valid Loss: 0.001390213961713016\n",
      "Epoch: 6210, Train Loss: 0.0010054820450022817, Valid Loss: 0.001389527227729559\n",
      "Epoch: 6211, Train Loss: 0.0010048826225101948, Valid Loss: 0.0013886566739529371\n",
      "Epoch: 6212, Train Loss: 0.001004284480586648, Valid Loss: 0.0013880272163078189\n",
      "Epoch: 6213, Train Loss: 0.001003683777526021, Valid Loss: 0.0013871450209990144\n",
      "Epoch: 6214, Train Loss: 0.0010030862176790833, Valid Loss: 0.001386510324664414\n",
      "Epoch: 6215, Train Loss: 0.0010024873772636056, Valid Loss: 0.0013856202131137252\n",
      "Epoch: 6216, Train Loss: 0.0010018890025094151, Valid Loss: 0.001384992036037147\n",
      "Epoch: 6217, Train Loss: 0.0010012940037995577, Valid Loss: 0.0013841161271557212\n",
      "Epoch: 6218, Train Loss: 0.0010006990050897002, Valid Loss: 0.0013834760757163167\n",
      "Epoch: 6219, Train Loss: 0.001000098534859717, Valid Loss: 0.001382612157613039\n",
      "Epoch: 6220, Train Loss: 0.000999504467472434, Valid Loss: 0.0013819383457303047\n",
      "Epoch: 6221, Train Loss: 0.0009989038808271289, Valid Loss: 0.0013811030657961965\n",
      "Epoch: 6222, Train Loss: 0.000998309114947915, Valid Loss: 0.0013804211048409343\n",
      "Epoch: 6223, Train Loss: 0.0009977143490687013, Valid Loss: 0.0013796042185276747\n",
      "Epoch: 6224, Train Loss: 0.0009971210965886712, Valid Loss: 0.0013788935029879212\n",
      "Epoch: 6225, Train Loss: 0.0009965270292013884, Valid Loss: 0.0013781131710857153\n",
      "Epoch: 6226, Train Loss: 0.000995928538031876, Valid Loss: 0.0013773669488728046\n",
      "Epoch: 6227, Train Loss: 0.0009953362168744206, Valid Loss: 0.001376611297018826\n",
      "Epoch: 6228, Train Loss: 0.0009947442449629307, Valid Loss: 0.001375843770802021\n",
      "Epoch: 6229, Train Loss: 0.0009941515745595098, Valid Loss: 0.0013751062797382474\n",
      "Epoch: 6230, Train Loss: 0.0009935579728335142, Valid Loss: 0.001374335028231144\n",
      "Epoch: 6231, Train Loss: 0.0009929657680913806, Valid Loss: 0.0013736117398366332\n",
      "Epoch: 6232, Train Loss: 0.0009923734469339252, Valid Loss: 0.0013728067278862\n",
      "Epoch: 6233, Train Loss: 0.0009917825227603316, Valid Loss: 0.0013721056748181581\n",
      "Epoch: 6234, Train Loss: 0.000991194392554462, Valid Loss: 0.001371323480270803\n",
      "Epoch: 6235, Train Loss: 0.0009906033519655466, Valid Loss: 0.0013706103200092912\n",
      "Epoch: 6236, Train Loss: 0.000990012544207275, Valid Loss: 0.0013698082184419036\n",
      "Epoch: 6237, Train Loss: 0.000989421852864325, Valid Loss: 0.0013691014610230923\n",
      "Epoch: 6238, Train Loss: 0.000988831277936697, Valid Loss: 0.0013683235738426447\n",
      "Epoch: 6239, Train Loss: 0.0009882439626380801, Valid Loss: 0.0013676099479198456\n",
      "Epoch: 6240, Train Loss: 0.000987656763754785, Valid Loss: 0.0013668150641024113\n",
      "Epoch: 6241, Train Loss: 0.0009870673529803753, Valid Loss: 0.0013661045813933015\n",
      "Epoch: 6242, Train Loss: 0.0009864798048511147, Valid Loss: 0.00136533472687006\n",
      "Epoch: 6243, Train Loss: 0.0009858893463388085, Valid Loss: 0.001364613650366664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6244, Train Loss: 0.0009853041265159845, Valid Loss: 0.0013638332020491362\n",
      "Epoch: 6245, Train Loss: 0.0009847156470641494, Valid Loss: 0.0013631093315780163\n",
      "Epoch: 6246, Train Loss: 0.0009841292630881071, Valid Loss: 0.0013623523991554976\n",
      "Epoch: 6247, Train Loss: 0.000983542762696743, Valid Loss: 0.0013616220094263554\n",
      "Epoch: 6248, Train Loss: 0.0009829552145674825, Valid Loss: 0.0013608629815280437\n",
      "Epoch: 6249, Train Loss: 0.000982371624559164, Valid Loss: 0.0013601281680166721\n",
      "Epoch: 6250, Train Loss: 0.00098178640473634, Valid Loss: 0.001359364832751453\n",
      "Epoch: 6251, Train Loss: 0.0009812024654820561, Valid Loss: 0.00135863630566746\n",
      "Epoch: 6252, Train Loss: 0.0009806161979213357, Valid Loss: 0.0013578874059021473\n",
      "Epoch: 6253, Train Loss: 0.0009800324914976954, Valid Loss: 0.0013571415329352021\n",
      "Epoch: 6254, Train Loss: 0.000979450298473239, Valid Loss: 0.0013563957763835788\n",
      "Epoch: 6255, Train Loss: 0.0009788660099729896, Valid Loss: 0.0013556599151343107\n",
      "Epoch: 6256, Train Loss: 0.0009782847482711077, Valid Loss: 0.0013549304567277431\n",
      "Epoch: 6257, Train Loss: 0.0009777001105248928, Valid Loss: 0.001354170497506857\n",
      "Epoch: 6258, Train Loss: 0.0009771191980689764, Valid Loss: 0.0013534369645640254\n",
      "Epoch: 6259, Train Loss: 0.0009765363647602499, Valid Loss: 0.0013526832917705178\n",
      "Epoch: 6260, Train Loss: 0.0009759549284353852, Valid Loss: 0.001351960701867938\n",
      "Epoch: 6261, Train Loss: 0.0009753751801326871, Valid Loss: 0.0013512090081349015\n",
      "Epoch: 6262, Train Loss: 0.0009747926378622651, Valid Loss: 0.0013504780363291502\n",
      "Epoch: 6263, Train Loss: 0.0009742133552208543, Valid Loss: 0.0013497286709025502\n",
      "Epoch: 6264, Train Loss: 0.0009736333158798516, Valid Loss: 0.0013489997945725918\n",
      "Epoch: 6265, Train Loss: 0.0009730538004077971, Valid Loss: 0.0013482527574524283\n",
      "Epoch: 6266, Train Loss: 0.0009724746341817081, Valid Loss: 0.0013475357554852962\n",
      "Epoch: 6267, Train Loss: 0.0009718938381411135, Valid Loss: 0.0013467815006151795\n",
      "Epoch: 6268, Train Loss: 0.0009713167091831565, Valid Loss: 0.0013460534391924739\n",
      "Epoch: 6269, Train Loss: 0.000970738532487303, Valid Loss: 0.0013453110586851835\n",
      "Epoch: 6270, Train Loss: 0.0009701601811684668, Valid Loss: 0.0013445866061374545\n",
      "Epoch: 6271, Train Loss: 0.0009695814223960042, Valid Loss: 0.0013438474852591753\n",
      "Epoch: 6272, Train Loss: 0.0009690042352303863, Valid Loss: 0.0013431053375825286\n",
      "Epoch: 6273, Train Loss: 0.000968429259955883, Valid Loss: 0.0013423709897324443\n",
      "Epoch: 6274, Train Loss: 0.0009678530623205006, Valid Loss: 0.0013416489819064736\n",
      "Epoch: 6275, Train Loss: 0.0009672763990238309, Valid Loss: 0.0013409104431048036\n",
      "Epoch: 6276, Train Loss: 0.0009667001431807876, Valid Loss: 0.001340168877504766\n",
      "Epoch: 6277, Train Loss: 0.0009661223739385605, Valid Loss: 0.0013394402340054512\n",
      "Epoch: 6278, Train Loss: 0.0009655500180087984, Valid Loss: 0.0013387065846472979\n",
      "Epoch: 6279, Train Loss: 0.0009649747516959906, Valid Loss: 0.0013379871379584074\n",
      "Epoch: 6280, Train Loss: 0.0009643985540606081, Valid Loss: 0.0013372424291446805\n",
      "Epoch: 6281, Train Loss: 0.0009638280607759953, Valid Loss: 0.001336513552814722\n",
      "Epoch: 6282, Train Loss: 0.0009632519795559347, Valid Loss: 0.0013357795542106032\n",
      "Epoch: 6283, Train Loss: 0.0009626817773096263, Valid Loss: 0.0013350555673241615\n",
      "Epoch: 6284, Train Loss: 0.0009621059871278703, Valid Loss: 0.0013343228492885828\n",
      "Epoch: 6285, Train Loss: 0.0009615336894057691, Valid Loss: 0.0013335898984223604\n",
      "Epoch: 6286, Train Loss: 0.0009609618573449552, Valid Loss: 0.001332853571511805\n",
      "Epoch: 6287, Train Loss: 0.0009603908401913941, Valid Loss: 0.0013321329606696963\n",
      "Epoch: 6288, Train Loss: 0.0009598194737918675, Valid Loss: 0.0013314135139808059\n",
      "Epoch: 6289, Train Loss: 0.0009592503192834556, Valid Loss: 0.0013306806795299053\n",
      "Epoch: 6290, Train Loss: 0.0009586779051460326, Valid Loss: 0.0013299547135829926\n",
      "Epoch: 6291, Train Loss: 0.000958109216298908, Valid Loss: 0.0013292197836562991\n",
      "Epoch: 6292, Train Loss: 0.000957536802161485, Valid Loss: 0.0013285021996125579\n",
      "Epoch: 6293, Train Loss: 0.0009569684625603259, Valid Loss: 0.0013277718098834157\n",
      "Epoch: 6294, Train Loss: 0.0009563990170136094, Valid Loss: 0.0013270600466057658\n",
      "Epoch: 6295, Train Loss: 0.0009558286401443183, Valid Loss: 0.0013263188302516937\n",
      "Epoch: 6296, Train Loss: 0.0009552628616802394, Valid Loss: 0.0013256003148853779\n",
      "Epoch: 6297, Train Loss: 0.0009546918445266783, Valid Loss: 0.0013248698087409139\n",
      "Epoch: 6298, Train Loss: 0.000954120943788439, Valid Loss: 0.0013241638662293553\n",
      "Epoch: 6299, Train Loss: 0.0009535577846691012, Valid Loss: 0.0013234202051535249\n",
      "Epoch: 6300, Train Loss: 0.0009529887465760112, Valid Loss: 0.0013227106537669897\n",
      "Epoch: 6301, Train Loss: 0.0009524244233034551, Valid Loss: 0.0013219774700701237\n",
      "Epoch: 6302, Train Loss: 0.0009518575388938189, Valid Loss: 0.001321272226050496\n",
      "Epoch: 6303, Train Loss: 0.000951291702222079, Valid Loss: 0.001320532988756895\n",
      "Epoch: 6304, Train Loss: 0.0009507242939434946, Valid Loss: 0.0013198198284953833\n",
      "Epoch: 6305, Train Loss: 0.000950160319916904, Valid Loss: 0.0013190853642299771\n",
      "Epoch: 6306, Train Loss: 0.000949593260884285, Valid Loss: 0.0013183881528675556\n",
      "Epoch: 6307, Train Loss: 0.0009490317897871137, Valid Loss: 0.0013176390202715993\n",
      "Epoch: 6308, Train Loss: 0.0009484667680226266, Valid Loss: 0.001316944370046258\n",
      "Epoch: 6309, Train Loss: 0.0009479036089032888, Valid Loss: 0.0013162068789824843\n",
      "Epoch: 6310, Train Loss: 0.0009473413228988647, Valid Loss: 0.0013155100168660283\n",
      "Epoch: 6311, Train Loss: 0.0009467742638662457, Valid Loss: 0.0013147614663466811\n",
      "Epoch: 6312, Train Loss: 0.0009462125017307699, Valid Loss: 0.0013140722876414657\n",
      "Epoch: 6313, Train Loss: 0.0009456486441195011, Valid Loss: 0.001313330722041428\n",
      "Epoch: 6314, Train Loss: 0.0009450894431211054, Valid Loss: 0.0013126422418281436\n",
      "Epoch: 6315, Train Loss: 0.000944527389947325, Valid Loss: 0.0013118850765749812\n",
      "Epoch: 6316, Train Loss: 0.0009439653367735445, Valid Loss: 0.0013112127780914307\n",
      "Epoch: 6317, Train Loss: 0.0009434051462449133, Valid Loss: 0.0013104614336043596\n",
      "Epoch: 6318, Train Loss: 0.0009428422781638801, Valid Loss: 0.0013097778428345919\n",
      "Epoch: 6319, Train Loss: 0.0009422839502803981, Valid Loss: 0.0013090294087305665\n",
      "Epoch: 6320, Train Loss: 0.0009417202090844512, Valid Loss: 0.0013083529192954302\n",
      "Epoch: 6321, Train Loss: 0.0009411631035618484, Valid Loss: 0.0013076019240543246\n",
      "Epoch: 6322, Train Loss: 0.0009406031458638608, Valid Loss: 0.001306923571974039\n",
      "Epoch: 6323, Train Loss: 0.0009400444105267525, Valid Loss: 0.001306167570874095\n",
      "Epoch: 6324, Train Loss: 0.0009394840453751385, Valid Loss: 0.0013054960872977972\n",
      "Epoch: 6325, Train Loss: 0.000938925426453352, Valid Loss: 0.0013047431129962206\n",
      "Epoch: 6326, Train Loss: 0.0009383688447996974, Valid Loss: 0.001304076169617474\n",
      "Epoch: 6327, Train Loss: 0.00093781144823879, Valid Loss: 0.0013033144641667604\n",
      "Epoch: 6328, Train Loss: 0.0009372543427161872, Valid Loss: 0.0013026598608121276\n",
      "Epoch: 6329, Train Loss: 0.0009366962476633489, Valid Loss: 0.001301900134421885\n",
      "Epoch: 6330, Train Loss: 0.0009361418196931481, Valid Loss: 0.0013012278359383345\n",
      "Epoch: 6331, Train Loss: 0.0009355838992632926, Valid Loss: 0.0013004766078665853\n",
      "Epoch: 6332, Train Loss: 0.0009350287145934999, Valid Loss: 0.001299817580729723\n",
      "Epoch: 6333, Train Loss: 0.0009344734717160463, Valid Loss: 0.0012990571558475494\n",
      "Epoch: 6334, Train Loss: 0.0009339176467619836, Valid Loss: 0.001298395567573607\n",
      "Epoch: 6335, Train Loss: 0.0009333622292615473, Valid Loss: 0.0012976357247680426\n",
      "Epoch: 6336, Train Loss: 0.0009328080341219902, Valid Loss: 0.0012969947420060635\n",
      "Epoch: 6337, Train Loss: 0.0009322537807747722, Valid Loss: 0.0012962231412529945\n",
      "Epoch: 6338, Train Loss: 0.0009317021467722952, Valid Loss: 0.0012955756392329931\n",
      "Epoch: 6339, Train Loss: 0.0009311457397416234, Valid Loss: 0.001294800196774304\n",
      "Epoch: 6340, Train Loss: 0.0009305927087552845, Valid Loss: 0.0012941601453348994\n",
      "Epoch: 6341, Train Loss: 0.0009300426463596523, Valid Loss: 0.0012933850521221757\n",
      "Epoch: 6342, Train Loss: 0.0009294880437664688, Valid Loss: 0.0012927560601383448\n",
      "Epoch: 6343, Train Loss: 0.0009289371082559228, Valid Loss: 0.0012919777072966099\n",
      "Epoch: 6344, Train Loss: 0.0009283843683078885, Valid Loss: 0.0012913404498249292\n",
      "Epoch: 6345, Train Loss: 0.0009278323268517852, Valid Loss: 0.0012905708281323314\n",
      "Epoch: 6346, Train Loss: 0.0009272818570025265, Valid Loss: 0.0012899498688057065\n",
      "Epoch: 6347, Train Loss: 0.0009267320274375379, Valid Loss: 0.001289159175939858\n",
      "Epoch: 6348, Train Loss: 0.0009261809755116701, Valid Loss: 0.0012885231990367174\n",
      "Epoch: 6349, Train Loss: 0.0009256325429305434, Valid Loss: 0.0012877524131909013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6350, Train Loss: 0.0009250809671357274, Valid Loss: 0.0012871393701061606\n",
      "Epoch: 6351, Train Loss: 0.0009245307301171124, Valid Loss: 0.0012863375013694167\n",
      "Epoch: 6352, Train Loss: 0.0009239816572517157, Valid Loss: 0.0012857209658250213\n",
      "Epoch: 6353, Train Loss: 0.0009234331082552671, Valid Loss: 0.0012849324848502874\n",
      "Epoch: 6354, Train Loss: 0.0009228873532265425, Valid Loss: 0.0012843416770920157\n",
      "Epoch: 6355, Train Loss: 0.0009223389788530767, Valid Loss: 0.0012835238594561815\n",
      "Epoch: 6356, Train Loss: 0.0009217921760864556, Valid Loss: 0.0012829327024519444\n",
      "Epoch: 6357, Train Loss: 0.0009212442091666162, Valid Loss: 0.001282138517126441\n",
      "Epoch: 6358, Train Loss: 0.0009206962422467768, Valid Loss: 0.0012815494555979967\n",
      "Epoch: 6359, Train Loss: 0.0009201528737321496, Valid Loss: 0.0012807238381356\n",
      "Epoch: 6360, Train Loss: 0.0009196033352054656, Valid Loss: 0.001280148164369166\n",
      "Epoch: 6361, Train Loss: 0.0009190578130073845, Valid Loss: 0.0012793266214430332\n",
      "Epoch: 6362, Train Loss: 0.0009185134549625218, Valid Loss: 0.0012787645682692528\n",
      "Epoch: 6363, Train Loss: 0.0009179679327644408, Valid Loss: 0.0012779313838109374\n",
      "Epoch: 6364, Train Loss: 0.0009174218866974115, Valid Loss: 0.0012773688649758697\n",
      "Epoch: 6365, Train Loss: 0.0009168789838440716, Valid Loss: 0.0012765387073159218\n",
      "Epoch: 6366, Train Loss: 0.000916333869099617, Valid Loss: 0.0012759855017066002\n",
      "Epoch: 6367, Train Loss: 0.0009157888125628233, Valid Loss: 0.0012751276372000575\n",
      "Epoch: 6368, Train Loss: 0.0009152478887699544, Valid Loss: 0.0012746023712679744\n",
      "Epoch: 6369, Train Loss: 0.0009147037053480744, Valid Loss: 0.0012737443903461099\n",
      "Epoch: 6370, Train Loss: 0.0009141617920249701, Valid Loss: 0.0012732164468616247\n",
      "Epoch: 6371, Train Loss: 0.0009136184235103428, Valid Loss: 0.0012723526451736689\n",
      "Epoch: 6372, Train Loss: 0.0009130776743404567, Valid Loss: 0.001271838671527803\n",
      "Epoch: 6373, Train Loss: 0.0009125330252572894, Valid Loss: 0.0012709674192592502\n",
      "Epoch: 6374, Train Loss: 0.0009119941969402134, Valid Loss: 0.0012704667169600725\n",
      "Epoch: 6375, Train Loss: 0.0009114553686231375, Valid Loss: 0.0012695767218247056\n",
      "Epoch: 6376, Train Loss: 0.000910911534447223, Valid Loss: 0.0012690774165093899\n",
      "Epoch: 6377, Train Loss: 0.000910373346414417, Valid Loss: 0.0012681972002610564\n",
      "Epoch: 6378, Train Loss: 0.0009098309092223644, Valid Loss: 0.0012677029008045793\n",
      "Epoch: 6379, Train Loss: 0.0009092924883589149, Valid Loss: 0.0012668132549151778\n",
      "Epoch: 6380, Train Loss: 0.0009087498765438795, Valid Loss: 0.0012663101078942418\n",
      "Epoch: 6381, Train Loss: 0.0009082121541723609, Valid Loss: 0.0012654386227950454\n",
      "Epoch: 6382, Train Loss: 0.0009076738497242332, Valid Loss: 0.0012649293057620525\n",
      "Epoch: 6383, Train Loss: 0.0009071346139535308, Valid Loss: 0.0012640547938644886\n",
      "Epoch: 6384, Train Loss: 0.0009065947961062193, Valid Loss: 0.0012635434977710247\n",
      "Epoch: 6385, Train Loss: 0.0009060577722266316, Valid Loss: 0.0012626907555386424\n",
      "Epoch: 6386, Train Loss: 0.0009055196424014866, Valid Loss: 0.0012621574569493532\n",
      "Epoch: 6387, Train Loss: 0.0009049820946529508, Valid Loss: 0.0012613225262612104\n",
      "Epoch: 6388, Train Loss: 0.0009044446633197367, Valid Loss: 0.0012607740936800838\n",
      "Epoch: 6389, Train Loss: 0.0009039085125550628, Valid Loss: 0.001259955344721675\n",
      "Epoch: 6390, Train Loss: 0.0009033721871674061, Valid Loss: 0.0012593907304108143\n",
      "Epoch: 6391, Train Loss: 0.0009028335334733129, Valid Loss: 0.0012585935182869434\n",
      "Epoch: 6392, Train Loss: 0.00090230000205338, Valid Loss: 0.0012580030597746372\n",
      "Epoch: 6393, Train Loss: 0.0009017620468512177, Valid Loss: 0.001257230993360281\n",
      "Epoch: 6394, Train Loss: 0.0009012263035401702, Valid Loss: 0.0012566172517836094\n",
      "Epoch: 6395, Train Loss: 0.0009006948093883693, Valid Loss: 0.0012558758025988936\n",
      "Epoch: 6396, Train Loss: 0.0009001577855087817, Valid Loss: 0.0012552466941997409\n",
      "Epoch: 6397, Train Loss: 0.0008996258256956935, Valid Loss: 0.001254517468623817\n",
      "Epoch: 6398, Train Loss: 0.0008990882779471576, Valid Loss: 0.0012538704322651029\n",
      "Epoch: 6399, Train Loss: 0.0008985574822872877, Valid Loss: 0.0012531642569229007\n",
      "Epoch: 6400, Train Loss: 0.0008980244165286422, Valid Loss: 0.0012525090714916587\n",
      "Epoch: 6401, Train Loss: 0.0008974907686933875, Valid Loss: 0.00125180184841156\n",
      "Epoch: 6402, Train Loss: 0.0008969595073722303, Valid Loss: 0.0012511309469118714\n",
      "Epoch: 6403, Train Loss: 0.000896426266990602, Valid Loss: 0.0012504461919888854\n",
      "Epoch: 6404, Train Loss: 0.0008958949474617839, Valid Loss: 0.0012497686548158526\n",
      "Epoch: 6405, Train Loss: 0.0008953655487857759, Valid Loss: 0.0012490976369008422\n",
      "Epoch: 6406, Train Loss: 0.0008948341128416359, Valid Loss: 0.001248407643288374\n",
      "Epoch: 6407, Train Loss: 0.0008943030261434615, Valid Loss: 0.0012477299897000194\n",
      "Epoch: 6408, Train Loss: 0.0008937727543525398, Valid Loss: 0.001247044070623815\n",
      "Epoch: 6409, Train Loss: 0.0008932434720918536, Valid Loss: 0.0012463863240554929\n",
      "Epoch: 6410, Train Loss: 0.000892714480869472, Valid Loss: 0.0012456781696528196\n",
      "Epoch: 6411, Train Loss: 0.0008921847911551595, Valid Loss: 0.001245024031959474\n",
      "Epoch: 6412, Train Loss: 0.0008916552760638297, Valid Loss: 0.0012443354353308678\n",
      "Epoch: 6413, Train Loss: 0.0008911272743716836, Valid Loss: 0.001243679434992373\n",
      "Epoch: 6414, Train Loss: 0.000890598283149302, Valid Loss: 0.0012429676717147231\n",
      "Epoch: 6415, Train Loss: 0.0008900710963644087, Valid Loss: 0.0012423262232914567\n",
      "Epoch: 6416, Train Loss: 0.0008895421051420271, Valid Loss: 0.0012416292447596788\n",
      "Epoch: 6417, Train Loss: 0.0008890150929801166, Valid Loss: 0.0012409629998728633\n",
      "Epoch: 6418, Train Loss: 0.0008884876151569188, Valid Loss: 0.0012402681168168783\n",
      "Epoch: 6419, Train Loss: 0.0008879617671482265, Valid Loss: 0.0012396142119541764\n",
      "Epoch: 6420, Train Loss: 0.0008874332997947931, Valid Loss: 0.001238920260220766\n",
      "Epoch: 6421, Train Loss: 0.0008869115263223648, Valid Loss: 0.0012382714776322246\n",
      "Epoch: 6422, Train Loss: 0.0008863845723681152, Valid Loss: 0.001237566932104528\n",
      "Epoch: 6423, Train Loss: 0.0008858585497364402, Valid Loss: 0.0012369219912216067\n",
      "Epoch: 6424, Train Loss: 0.0008853340987116098, Valid Loss: 0.0012362237321212888\n",
      "Epoch: 6425, Train Loss: 0.0008848091820254922, Valid Loss: 0.001235577859915793\n",
      "Epoch: 6426, Train Loss: 0.0008842831011861563, Valid Loss: 0.0012348751770332456\n",
      "Epoch: 6427, Train Loss: 0.0008837591740302742, Valid Loss: 0.00123423186596483\n",
      "Epoch: 6428, Train Loss: 0.0008832354214973748, Valid Loss: 0.001233534887433052\n",
      "Epoch: 6429, Train Loss: 0.0008827134734019637, Valid Loss: 0.0012328899465501308\n",
      "Epoch: 6430, Train Loss: 0.0008821871597319841, Valid Loss: 0.0012321914546191692\n",
      "Epoch: 6431, Train Loss: 0.0008816671324893832, Valid Loss: 0.001231550588272512\n",
      "Epoch: 6432, Train Loss: 0.0008811430307105184, Valid Loss: 0.0012308504665270448\n",
      "Epoch: 6433, Train Loss: 0.000880621955730021, Valid Loss: 0.0012302089016884565\n",
      "Epoch: 6434, Train Loss: 0.000880099949426949, Valid Loss: 0.0012295172782614827\n",
      "Epoch: 6435, Train Loss: 0.0008795781759545207, Valid Loss: 0.001228871289640665\n",
      "Epoch: 6436, Train Loss: 0.0008790578576736152, Valid Loss: 0.0012281727977097034\n",
      "Epoch: 6437, Train Loss: 0.0008785371901467443, Valid Loss: 0.0012275445042178035\n",
      "Epoch: 6438, Train Loss: 0.0008780169300734997, Valid Loss: 0.0012268460122868419\n",
      "Epoch: 6439, Train Loss: 0.000877496728207916, Valid Loss: 0.0012261999072507024\n",
      "Epoch: 6440, Train Loss: 0.0008769757696427405, Valid Loss: 0.0012255038600414991\n",
      "Epoch: 6441, Train Loss: 0.0008764553931541741, Valid Loss: 0.0012248795246705413\n",
      "Epoch: 6442, Train Loss: 0.0008759359479881823, Valid Loss: 0.0012241792865097523\n",
      "Epoch: 6443, Train Loss: 0.0008754200534895062, Valid Loss: 0.0012235468020662665\n",
      "Epoch: 6444, Train Loss: 0.0008748988038860261, Valid Loss: 0.0012228498235344887\n",
      "Epoch: 6445, Train Loss: 0.0008743825601413846, Valid Loss: 0.0012222196673974395\n",
      "Epoch: 6446, Train Loss: 0.000873864977620542, Valid Loss: 0.0012215152382850647\n",
      "Epoch: 6447, Train Loss: 0.0008733482100069523, Valid Loss: 0.001220886828377843\n",
      "Epoch: 6448, Train Loss: 0.0008728275424800813, Valid Loss: 0.0012201936915516853\n",
      "Epoch: 6449, Train Loss: 0.0008723131031729281, Valid Loss: 0.001219555619172752\n",
      "Epoch: 6450, Train Loss: 0.0008717927266843617, Valid Loss: 0.0012188616674393415\n",
      "Epoch: 6451, Train Loss: 0.0008712787530384958, Valid Loss: 0.0012182403588667512\n",
      "Epoch: 6452, Train Loss: 0.0008707631495781243, Valid Loss: 0.0012175439624115825\n",
      "Epoch: 6453, Train Loss: 0.0008702455088496208, Valid Loss: 0.0012169063556939363\n",
      "Epoch: 6454, Train Loss: 0.0008697332814335823, Valid Loss: 0.001216221135109663\n",
      "Epoch: 6455, Train Loss: 0.0008692166302353144, Valid Loss: 0.0012155950535088778\n",
      "Epoch: 6456, Train Loss: 0.0008687021327205002, Valid Loss: 0.0012148976093158126\n",
      "Epoch: 6457, Train Loss: 0.0008681889157742262, Valid Loss: 0.0012142644263803959\n",
      "Epoch: 6458, Train Loss: 0.0008676732541061938, Valid Loss: 0.0012135797878727317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6459, Train Loss: 0.0008671604446135461, Valid Loss: 0.0012129545211791992\n",
      "Epoch: 6460, Train Loss: 0.0008666478679515421, Valid Loss: 0.0012122553307563066\n",
      "Epoch: 6461, Train Loss: 0.0008661318570375443, Valid Loss: 0.001211632159538567\n",
      "Epoch: 6462, Train Loss: 0.0008656193967908621, Valid Loss: 0.001210943330079317\n",
      "Epoch: 6463, Train Loss: 0.0008651077514514327, Valid Loss: 0.0012103241169825196\n",
      "Epoch: 6464, Train Loss: 0.0008645974448882043, Valid Loss: 0.0012096159625798464\n",
      "Epoch: 6465, Train Loss: 0.0008640865562483668, Valid Loss: 0.0012090107193216681\n",
      "Epoch: 6466, Train Loss: 0.0008635730482637882, Valid Loss: 0.0012083156034350395\n",
      "Epoch: 6467, Train Loss: 0.0008630600641481578, Valid Loss: 0.00120769371278584\n",
      "Epoch: 6468, Train Loss: 0.0008625504560768604, Valid Loss: 0.0012069937074556947\n",
      "Epoch: 6469, Train Loss: 0.0008620392181910574, Valid Loss: 0.001206390792503953\n",
      "Epoch: 6470, Train Loss: 0.0008615308906883001, Valid Loss: 0.0012056847335770726\n",
      "Epoch: 6471, Train Loss: 0.0008610186050646007, Valid Loss: 0.00120506901293993\n",
      "Epoch: 6472, Train Loss: 0.0008605095790699124, Valid Loss: 0.0012043686583638191\n",
      "Epoch: 6473, Train Loss: 0.0008600028231739998, Valid Loss: 0.0012037730775773525\n",
      "Epoch: 6474, Train Loss: 0.000859492109157145, Valid Loss: 0.0012030620127916336\n",
      "Epoch: 6475, Train Loss: 0.0008589837816543877, Valid Loss: 0.001202461076900363\n",
      "Epoch: 6476, Train Loss: 0.0008584751631133258, Valid Loss: 0.0012017607223242521\n",
      "Epoch: 6477, Train Loss: 0.0008579670102335513, Valid Loss: 0.0012011612998321652\n",
      "Epoch: 6478, Train Loss: 0.0008574596140533686, Valid Loss: 0.0012004513991996646\n",
      "Epoch: 6479, Train Loss: 0.0008569518686272204, Valid Loss: 0.0011998575646430254\n",
      "Epoch: 6480, Train Loss: 0.0008564454037696123, Valid Loss: 0.0011991449864581227\n",
      "Epoch: 6481, Train Loss: 0.0008559381822124124, Valid Loss: 0.0011985569726675749\n",
      "Epoch: 6482, Train Loss: 0.0008554319501854479, Valid Loss: 0.0011978369439020753\n",
      "Epoch: 6483, Train Loss: 0.0008549239137209952, Valid Loss: 0.0011972620850428939\n",
      "Epoch: 6484, Train Loss: 0.0008544177981093526, Valid Loss: 0.0011965356534346938\n",
      "Epoch: 6485, Train Loss: 0.0008539111586287618, Valid Loss: 0.0011959580006077886\n",
      "Epoch: 6486, Train Loss: 0.0008534083608537912, Valid Loss: 0.001195245422422886\n",
      "Epoch: 6487, Train Loss: 0.000852903351187706, Valid Loss: 0.0011946731247007847\n",
      "Epoch: 6488, Train Loss: 0.0008523996802978218, Valid Loss: 0.0011939287651330233\n",
      "Epoch: 6489, Train Loss: 0.0008518946124240756, Valid Loss: 0.0011933784699067473\n",
      "Epoch: 6490, Train Loss: 0.0008513900684192777, Valid Loss: 0.001192643539980054\n",
      "Epoch: 6491, Train Loss: 0.0008508869213983417, Valid Loss: 0.0011920832330361009\n",
      "Epoch: 6492, Train Loss: 0.0008503825520165265, Valid Loss: 0.0011913263006135821\n",
      "Epoch: 6493, Train Loss: 0.0008498805691488087, Valid Loss: 0.001190800336189568\n",
      "Epoch: 6494, Train Loss: 0.0008493800996802747, Valid Loss: 0.0011900500394403934\n",
      "Epoch: 6495, Train Loss: 0.0008488765452057123, Valid Loss: 0.0011895104544237256\n",
      "Epoch: 6496, Train Loss: 0.000848374969791621, Valid Loss: 0.001188732567243278\n",
      "Epoch: 6497, Train Loss: 0.0008478718809783459, Valid Loss: 0.0011882352409884334\n",
      "Epoch: 6498, Train Loss: 0.0008473719353787601, Valid Loss: 0.001187457237392664\n",
      "Epoch: 6499, Train Loss: 0.0008468708256259561, Valid Loss: 0.0011869457084685564\n",
      "Epoch: 6500, Train Loss: 0.0008463703561574221, Valid Loss: 0.0011861535022035241\n",
      "Epoch: 6501, Train Loss: 0.0008458690717816353, Valid Loss: 0.0011856710771098733\n",
      "Epoch: 6502, Train Loss: 0.0008453697082586586, Valid Loss: 0.0011848711874336004\n",
      "Epoch: 6503, Train Loss: 0.0008448701119050384, Valid Loss: 0.0011843867832794785\n",
      "Epoch: 6504, Train Loss: 0.0008443715050816536, Valid Loss: 0.0011835801415145397\n",
      "Epoch: 6505, Train Loss: 0.0008438726072199643, Valid Loss: 0.0011831100564450026\n",
      "Epoch: 6506, Train Loss: 0.0008433744078502059, Valid Loss: 0.0011822986416518688\n",
      "Epoch: 6507, Train Loss: 0.000842875917442143, Valid Loss: 0.0011818240163847804\n",
      "Epoch: 6508, Train Loss: 0.0008423765539191663, Valid Loss: 0.0011810180731117725\n",
      "Epoch: 6509, Train Loss: 0.0008418770739808679, Valid Loss: 0.0011805453104898334\n",
      "Epoch: 6510, Train Loss: 0.0008413818432018161, Valid Loss: 0.001179728889837861\n",
      "Epoch: 6511, Train Loss: 0.0008408828289248049, Valid Loss: 0.0011792625300586224\n",
      "Epoch: 6512, Train Loss: 0.0008403845713473856, Valid Loss: 0.0011784533271566033\n",
      "Epoch: 6513, Train Loss: 0.0008398903300985694, Valid Loss: 0.0011779710184782743\n",
      "Epoch: 6514, Train Loss: 0.0008393907337449491, Valid Loss: 0.0011771749705076218\n",
      "Epoch: 6515, Train Loss: 0.0008388941641896963, Valid Loss: 0.0011766942916437984\n",
      "Epoch: 6516, Train Loss: 0.0008383988169953227, Valid Loss: 0.001175912912003696\n",
      "Epoch: 6517, Train Loss: 0.0008379006176255643, Valid Loss: 0.0011753960279747844\n",
      "Epoch: 6518, Train Loss: 0.0008374047465622425, Valid Loss: 0.0011746385134756565\n",
      "Epoch: 6519, Train Loss: 0.0008369100978597999, Valid Loss: 0.0011741162743419409\n",
      "Epoch: 6520, Train Loss: 0.0008364148670807481, Valid Loss: 0.0011733737774193287\n",
      "Epoch: 6521, Train Loss: 0.0008359180064871907, Valid Loss: 0.0011728163808584213\n",
      "Epoch: 6522, Train Loss: 0.0008354241726920009, Valid Loss: 0.0011721104383468628\n",
      "Epoch: 6523, Train Loss: 0.0008349299314431846, Valid Loss: 0.0011715508298948407\n",
      "Epoch: 6524, Train Loss: 0.0008344351081177592, Valid Loss: 0.0011708509409800172\n",
      "Epoch: 6525, Train Loss: 0.0008339423802681267, Valid Loss: 0.0011702482588589191\n",
      "Epoch: 6526, Train Loss: 0.0008334514568559825, Valid Loss: 0.0011695967987179756\n",
      "Epoch: 6527, Train Loss: 0.0008329543052241206, Valid Loss: 0.0011689852690324187\n",
      "Epoch: 6528, Train Loss: 0.0008324635564349592, Valid Loss: 0.0011683308985084295\n",
      "Epoch: 6529, Train Loss: 0.0008319708285853267, Valid Loss: 0.001167697599157691\n",
      "Epoch: 6530, Train Loss: 0.0008314804290421307, Valid Loss: 0.001167078036814928\n",
      "Epoch: 6531, Train Loss: 0.0008309889817610383, Valid Loss: 0.00116643775254488\n",
      "Epoch: 6532, Train Loss: 0.0008304977673105896, Valid Loss: 0.001165822264738381\n",
      "Epoch: 6533, Train Loss: 0.0008300070185214281, Valid Loss: 0.0011651635868474841\n",
      "Epoch: 6534, Train Loss: 0.000829515396617353, Valid Loss: 0.0011645600898191333\n",
      "Epoch: 6535, Train Loss: 0.0008290252299048007, Valid Loss: 0.0011639109579846263\n",
      "Epoch: 6536, Train Loss: 0.0008285376825369895, Valid Loss: 0.001163307810202241\n",
      "Epoch: 6537, Train Loss: 0.0008280456531792879, Valid Loss: 0.001162635162472725\n",
      "Epoch: 6538, Train Loss: 0.0008275585132651031, Valid Loss: 0.0011620506411418319\n",
      "Epoch: 6539, Train Loss: 0.0008270691032521427, Valid Loss: 0.0011613847455009818\n",
      "Epoch: 6540, Train Loss: 0.0008265798096545041, Valid Loss: 0.0011607971973717213\n",
      "Epoch: 6541, Train Loss: 0.0008260891772806644, Valid Loss: 0.0011601130245253444\n",
      "Epoch: 6542, Train Loss: 0.0008256040746346116, Valid Loss: 0.0011595304822549224\n",
      "Epoch: 6543, Train Loss: 0.0008251155377365649, Valid Loss: 0.0011588750639930367\n",
      "Epoch: 6544, Train Loss: 0.00082462775753811, Valid Loss: 0.0011582872830331326\n",
      "Epoch: 6545, Train Loss: 0.0008241405012086034, Valid Loss: 0.0011576059041544795\n",
      "Epoch: 6546, Train Loss: 0.0008236551657319069, Valid Loss: 0.0011570197530090809\n",
      "Epoch: 6547, Train Loss: 0.0008231673273257911, Valid Loss: 0.001156352460384369\n",
      "Epoch: 6548, Train Loss: 0.0008226805948652327, Valid Loss: 0.001155764446593821\n",
      "Epoch: 6549, Train Loss: 0.0008221949101425707, Valid Loss: 0.001155107282102108\n",
      "Epoch: 6550, Train Loss: 0.0008217069553211331, Valid Loss: 0.0011545114684849977\n",
      "Epoch: 6551, Train Loss: 0.0008212231332436204, Valid Loss: 0.0011538449907675385\n",
      "Epoch: 6552, Train Loss: 0.0008207388455048203, Valid Loss: 0.001153254066593945\n",
      "Epoch: 6553, Train Loss: 0.0008202525787055492, Valid Loss: 0.0011526078451424837\n",
      "Epoch: 6554, Train Loss: 0.0008197678253054619, Valid Loss: 0.0011520100524649024\n",
      "Epoch: 6555, Train Loss: 0.0008192828390747309, Valid Loss: 0.0011513573117554188\n",
      "Epoch: 6556, Train Loss: 0.000818799075204879, Valid Loss: 0.0011507509043440223\n",
      "Epoch: 6557, Train Loss: 0.0008183150202967227, Valid Loss: 0.0011501144617795944\n",
      "Epoch: 6558, Train Loss: 0.0008178339339792728, Valid Loss: 0.0011495070066303015\n",
      "Epoch: 6559, Train Loss: 0.000817351508885622, Valid Loss: 0.0011488671880215406\n",
      "Epoch: 6560, Train Loss: 0.0008168669301085174, Valid Loss: 0.0011482522822916508\n",
      "Epoch: 6561, Train Loss: 0.000816386251244694, Valid Loss: 0.0011476335348561406\n",
      "Epoch: 6562, Train Loss: 0.0008159024873748422, Valid Loss: 0.0011470173485577106\n",
      "Epoch: 6563, Train Loss: 0.0008154203533194959, Valid Loss: 0.0011463849805295467\n",
      "Epoch: 6564, Train Loss: 0.0008149399072863162, Valid Loss: 0.0011457629734650254\n",
      "Epoch: 6565, Train Loss: 0.0008144587045535445, Valid Loss: 0.0011451567988842726\n",
      "Epoch: 6566, Train Loss: 0.0008139776182360947, Valid Loss: 0.0011445259442552924\n",
      "Epoch: 6567, Train Loss: 0.0008134968811646104, Valid Loss: 0.0011439104564487934\n",
      "Epoch: 6568, Train Loss: 0.0008130170172080398, Valid Loss: 0.0011432847240939736\n",
      "Epoch: 6569, Train Loss: 0.0008125386666506529, Valid Loss: 0.0011426890268921852\n",
      "Epoch: 6570, Train Loss: 0.0008120572310872376, Valid Loss: 0.0011420475784689188\n",
      "Epoch: 6571, Train Loss: 0.000811575970146805, Valid Loss: 0.0011414311593398452\n",
      "Epoch: 6572, Train Loss: 0.0008110971539281309, Valid Loss: 0.0011408034479245543\n",
      "Epoch: 6573, Train Loss: 0.0008106176974251866, Valid Loss: 0.001140219159424305\n",
      "Epoch: 6574, Train Loss: 0.0008101394050754607, Valid Loss: 0.0011395798064768314\n",
      "Epoch: 6575, Train Loss: 0.0008096603560261428, Valid Loss: 0.0011389738647267222\n",
      "Epoch: 6576, Train Loss: 0.0008091838681139052, Valid Loss: 0.0011383399832993746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6577, Train Loss: 0.0008087038295343518, Valid Loss: 0.0011377441696822643\n",
      "Epoch: 6578, Train Loss: 0.0008082276326604187, Valid Loss: 0.0011371050495654345\n",
      "Epoch: 6579, Train Loss: 0.0008077490492723882, Valid Loss: 0.0011365181999281049\n",
      "Epoch: 6580, Train Loss: 0.0008072745986282825, Valid Loss: 0.001135877799242735\n",
      "Epoch: 6581, Train Loss: 0.0008067981689237058, Valid Loss: 0.0011352812871336937\n",
      "Epoch: 6582, Train Loss: 0.000806322495918721, Valid Loss: 0.0011346469400450587\n",
      "Epoch: 6583, Train Loss: 0.0008058439125306904, Valid Loss: 0.0011340586934238672\n",
      "Epoch: 6584, Train Loss: 0.0008053709752857685, Valid Loss: 0.0011334199225530028\n",
      "Epoch: 6585, Train Loss: 0.0008048937888815999, Valid Loss: 0.001132822479121387\n",
      "Epoch: 6586, Train Loss: 0.0008044182322919369, Valid Loss: 0.0011321924393996596\n",
      "Epoch: 6587, Train Loss: 0.000803945236839354, Valid Loss: 0.0011316124582663178\n",
      "Epoch: 6588, Train Loss: 0.00080346770118922, Valid Loss: 0.001130971941165626\n",
      "Epoch: 6589, Train Loss: 0.0008029962191358209, Valid Loss: 0.0011303661158308387\n",
      "Epoch: 6590, Train Loss: 0.0008025226998142898, Valid Loss: 0.0011297479504719377\n",
      "Epoch: 6591, Train Loss: 0.000802046968601644, Valid Loss: 0.0011291602859273553\n",
      "Epoch: 6592, Train Loss: 0.0008015773491933942, Valid Loss: 0.0011285222135484219\n",
      "Epoch: 6593, Train Loss: 0.0008011017343960702, Valid Loss: 0.0011279251193627715\n",
      "Epoch: 6594, Train Loss: 0.0008006290881894529, Valid Loss: 0.0011273100972175598\n",
      "Epoch: 6595, Train Loss: 0.00080015609273687, Valid Loss: 0.0011267189402133226\n",
      "Epoch: 6596, Train Loss: 0.0007996857166290283, Valid Loss: 0.0011260822648182511\n",
      "Epoch: 6597, Train Loss: 0.0007992132450453937, Valid Loss: 0.0011254913406446576\n",
      "Epoch: 6598, Train Loss: 0.0007987412391230464, Valid Loss: 0.0011248714290559292\n",
      "Epoch: 6599, Train Loss: 0.0007982692332006991, Valid Loss: 0.0011242837645113468\n",
      "Epoch: 6600, Train Loss: 0.0007977994391694665, Valid Loss: 0.0011236428981646895\n",
      "Epoch: 6601, Train Loss: 0.0007973281317390501, Valid Loss: 0.0011230596574023366\n",
      "Epoch: 6602, Train Loss: 0.0007968569989316165, Valid Loss: 0.0011224381159991026\n",
      "Epoch: 6603, Train Loss: 0.0007963865646161139, Valid Loss: 0.001121839857660234\n",
      "Epoch: 6604, Train Loss: 0.0007959168287925422, Valid Loss: 0.001121220295317471\n",
      "Epoch: 6605, Train Loss: 0.0007954483735375106, Valid Loss: 0.0011206354247406125\n",
      "Epoch: 6606, Train Loss: 0.0007949788123369217, Valid Loss: 0.0011200099252164364\n",
      "Epoch: 6607, Train Loss: 0.0007945097167976201, Valid Loss: 0.0011194214457646012\n",
      "Epoch: 6608, Train Loss: 0.0007940399809740484, Valid Loss: 0.0011187954805791378\n",
      "Epoch: 6609, Train Loss: 0.0007935722242109478, Valid Loss: 0.0011182097950950265\n",
      "Epoch: 6610, Train Loss: 0.0007931050495244563, Valid Loss: 0.0011175873223692179\n",
      "Epoch: 6611, Train Loss: 0.0007926372345536947, Valid Loss: 0.0011170057114213705\n",
      "Epoch: 6612, Train Loss: 0.000792168197222054, Valid Loss: 0.0011163789313286543\n",
      "Epoch: 6613, Train Loss: 0.0007917014881968498, Valid Loss: 0.001115790568292141\n",
      "Epoch: 6614, Train Loss: 0.0007912341970950365, Valid Loss: 0.0011151671642437577\n",
      "Epoch: 6615, Train Loss: 0.0007907668477855623, Valid Loss: 0.001114586484618485\n",
      "Epoch: 6616, Train Loss: 0.0007903013029135764, Valid Loss: 0.0011139643611386418\n",
      "Epoch: 6617, Train Loss: 0.0007898348849266768, Valid Loss: 0.0011133761145174503\n",
      "Epoch: 6618, Train Loss: 0.0007893681759014726, Valid Loss: 0.0011127596953883767\n",
      "Epoch: 6619, Train Loss: 0.0007889036205597222, Valid Loss: 0.0011121805291622877\n",
      "Epoch: 6620, Train Loss: 0.0007884380174800754, Valid Loss: 0.0011115545639768243\n",
      "Epoch: 6621, Train Loss: 0.000787973462138325, Valid Loss: 0.0011109774932265282\n",
      "Epoch: 6622, Train Loss: 0.0007875083247199655, Valid Loss: 0.0011103515280410647\n",
      "Epoch: 6623, Train Loss: 0.0007870438857935369, Valid Loss: 0.0011097794631496072\n",
      "Epoch: 6624, Train Loss: 0.0007865793886594474, Valid Loss: 0.001109151286073029\n",
      "Epoch: 6625, Train Loss: 0.0007861161138862371, Valid Loss: 0.0011085807345807552\n",
      "Epoch: 6626, Train Loss: 0.0007856515003368258, Valid Loss: 0.0011079568648710847\n",
      "Epoch: 6627, Train Loss: 0.0007851897971704602, Valid Loss: 0.0011073864297941327\n",
      "Epoch: 6628, Train Loss: 0.00078472780296579, Valid Loss: 0.0011067631421610713\n",
      "Epoch: 6629, Train Loss: 0.0007842630730010569, Valid Loss: 0.001106187468394637\n",
      "Epoch: 6630, Train Loss: 0.0007838019519113004, Valid Loss: 0.001105561968870461\n",
      "Epoch: 6631, Train Loss: 0.0007833381532691419, Valid Loss: 0.001104990136809647\n",
      "Epoch: 6632, Train Loss: 0.0007828777306713164, Valid Loss: 0.00110436393879354\n",
      "Epoch: 6633, Train Loss: 0.0007824157946743071, Valid Loss: 0.0011037953663617373\n",
      "Epoch: 6634, Train Loss: 0.0007819529855623841, Valid Loss: 0.0011031668400391936\n",
      "Epoch: 6635, Train Loss: 0.0007814932032488286, Valid Loss: 0.001102598849684\n",
      "Epoch: 6636, Train Loss: 0.0007810338283888996, Valid Loss: 0.0011019776575267315\n",
      "Epoch: 6637, Train Loss: 0.000780571426730603, Valid Loss: 0.001101412228308618\n",
      "Epoch: 6638, Train Loss: 0.0007801126921549439, Valid Loss: 0.0011007823050022125\n",
      "Epoch: 6639, Train Loss: 0.0007796520949341357, Valid Loss: 0.0011002252576872706\n",
      "Epoch: 6640, Train Loss: 0.0007791920215822756, Valid Loss: 0.0010996002238243818\n",
      "Epoch: 6641, Train Loss: 0.000778733694460243, Valid Loss: 0.0010990352602675557\n",
      "Epoch: 6642, Train Loss: 0.0007782754837535322, Valid Loss: 0.0010984090622514486\n",
      "Epoch: 6643, Train Loss: 0.0007778169820085168, Valid Loss: 0.0010978559730574489\n",
      "Epoch: 6644, Train Loss: 0.0007773569086566567, Valid Loss: 0.0010972198797389865\n",
      "Epoch: 6645, Train Loss: 0.0007768974755890667, Valid Loss: 0.0010966636473312974\n",
      "Epoch: 6646, Train Loss: 0.0007764404872432351, Valid Loss: 0.001096038264222443\n",
      "Epoch: 6647, Train Loss: 0.0007759827421978116, Valid Loss: 0.001095494139008224\n",
      "Epoch: 6648, Train Loss: 0.0007755262777209282, Valid Loss: 0.0010948515264317393\n",
      "Epoch: 6649, Train Loss: 0.0007750695222057402, Valid Loss: 0.001094306819140911\n",
      "Epoch: 6650, Train Loss: 0.0007746129995211959, Valid Loss: 0.0010936614125967026\n",
      "Epoch: 6651, Train Loss: 0.000774156826082617, Valid Loss: 0.0010931282304227352\n",
      "Epoch: 6652, Train Loss: 0.0007737022824585438, Valid Loss: 0.0010924864327535033\n",
      "Epoch: 6653, Train Loss: 0.0007732476224191487, Valid Loss: 0.0010919494088739157\n",
      "Epoch: 6654, Train Loss: 0.000772787956520915, Valid Loss: 0.0010912941070273519\n",
      "Epoch: 6655, Train Loss: 0.0007723334711045027, Valid Loss: 0.0010907805990427732\n",
      "Epoch: 6656, Train Loss: 0.0007718770066276193, Valid Loss: 0.001090122968889773\n",
      "Epoch: 6657, Train Loss: 0.000771424500271678, Valid Loss: 0.0010896074818447232\n",
      "Epoch: 6658, Train Loss: 0.0007709702476859093, Valid Loss: 0.0010889256373047829\n",
      "Epoch: 6659, Train Loss: 0.0007705193129368126, Valid Loss: 0.0010884300572797656\n",
      "Epoch: 6660, Train Loss: 0.0007700610440224409, Valid Loss: 0.0010877617169171572\n",
      "Epoch: 6661, Train Loss: 0.0007696083630435169, Valid Loss: 0.0010872705606743693\n",
      "Epoch: 6662, Train Loss: 0.0007691566715948284, Valid Loss: 0.0010865717194974422\n",
      "Epoch: 6663, Train Loss: 0.0007687039906159043, Valid Loss: 0.0010860918555408716\n",
      "Epoch: 6664, Train Loss: 0.0007682497380301356, Valid Loss: 0.001085402094759047\n",
      "Epoch: 6665, Train Loss: 0.0007677985122427344, Valid Loss: 0.0010849355021491647\n",
      "Epoch: 6666, Train Loss: 0.0007673457730561495, Valid Loss: 0.0010842252522706985\n",
      "Epoch: 6667, Train Loss: 0.0007668964681215584, Valid Loss: 0.0010837732115760446\n",
      "Epoch: 6668, Train Loss: 0.0007664447766728699, Valid Loss: 0.0010830459650605917\n",
      "Epoch: 6669, Train Loss: 0.0007659932016395032, Valid Loss: 0.001082605100236833\n",
      "Epoch: 6670, Train Loss: 0.0007655432564206421, Valid Loss: 0.0010818797163665295\n",
      "Epoch: 6671, Train Loss: 0.0007650924962945282, Valid Loss: 0.0010814527049660683\n",
      "Epoch: 6672, Train Loss: 0.0007646424928680062, Valid Loss: 0.001080706831999123\n",
      "Epoch: 6673, Train Loss: 0.000764192664064467, Valid Loss: 0.001080287853255868\n",
      "Epoch: 6674, Train Loss: 0.0007637413800694048, Valid Loss: 0.0010795395355671644\n",
      "Epoch: 6675, Train Loss: 0.0007632914348505437, Valid Loss: 0.001079133478924632\n",
      "Epoch: 6676, Train Loss: 0.0007628430030308664, Valid Loss: 0.0010783750331029296\n",
      "Epoch: 6677, Train Loss: 0.0007623926503583789, Valid Loss: 0.0010779501171782613\n",
      "Epoch: 6678, Train Loss: 0.0007619430543854833, Valid Loss: 0.0010772064561024308\n",
      "Epoch: 6679, Train Loss: 0.000761494564358145, Valid Loss: 0.0010767888743430376\n",
      "Epoch: 6680, Train Loss: 0.0007610441534779966, Valid Loss: 0.0010760597651824355\n",
      "Epoch: 6681, Train Loss: 0.0007605943828821182, Valid Loss: 0.0010755988769233227\n",
      "Epoch: 6682, Train Loss: 0.000760145834647119, Valid Loss: 0.0010748897911980748\n",
      "Epoch: 6683, Train Loss: 0.0007596973446197808, Valid Loss: 0.0010744291357696056\n",
      "Epoch: 6684, Train Loss: 0.0007592476322315633, Valid Loss: 0.0010737518314272165\n",
      "Epoch: 6685, Train Loss: 0.0007588000735267997, Valid Loss: 0.0010732469381764531\n",
      "Epoch: 6686, Train Loss: 0.0007583519909530878, Valid Loss: 0.0010725926840677857\n",
      "Epoch: 6687, Train Loss: 0.000757904548663646, Valid Loss: 0.0010720692807808518\n",
      "Epoch: 6688, Train Loss: 0.0007574566407129169, Valid Loss: 0.0010714598465710878\n",
      "Epoch: 6689, Train Loss: 0.0007570120505988598, Valid Loss: 0.0010708943009376526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6690, Train Loss: 0.0007565657724626362, Valid Loss: 0.001070306054316461\n",
      "Epoch: 6691, Train Loss: 0.0007561210659332573, Valid Loss: 0.0010697264224290848\n",
      "Epoch: 6692, Train Loss: 0.0007556751952506602, Valid Loss: 0.0010691648349165916\n",
      "Epoch: 6693, Train Loss: 0.0007552316528744996, Valid Loss: 0.001068570651113987\n",
      "Epoch: 6694, Train Loss: 0.000754785374738276, Valid Loss: 0.0010680335108190775\n",
      "Epoch: 6695, Train Loss: 0.0007543423562310636, Valid Loss: 0.0010674085933715105\n",
      "Epoch: 6696, Train Loss: 0.000753898115362972, Valid Loss: 0.0010668742470443249\n",
      "Epoch: 6697, Train Loss: 0.000753457541577518, Valid Loss: 0.0010662623681128025\n",
      "Epoch: 6698, Train Loss: 0.0007530119619332254, Valid Loss: 0.0010657340753823519\n",
      "Epoch: 6699, Train Loss: 0.0007525678374804556, Valid Loss: 0.0010651114862412214\n",
      "Epoch: 6700, Train Loss: 0.0007521258085034788, Valid Loss: 0.0010645862203091383\n",
      "Epoch: 6701, Train Loss: 0.0007516827899962664, Valid Loss: 0.0010639694519340992\n",
      "Epoch: 6702, Train Loss: 0.0007512408192269504, Valid Loss: 0.001063443487510085\n",
      "Epoch: 6703, Train Loss: 0.0007507955888286233, Valid Loss: 0.0010628304444253445\n",
      "Epoch: 6704, Train Loss: 0.0007503555389121175, Valid Loss: 0.0010622949339449406\n",
      "Epoch: 6705, Train Loss: 0.0007499140338040888, Valid Loss: 0.0010616863146424294\n",
      "Epoch: 6706, Train Loss: 0.0007494715973734856, Valid Loss: 0.0010611391626298428\n",
      "Epoch: 6707, Train Loss: 0.0007490315474569798, Valid Loss: 0.001060549053363502\n",
      "Epoch: 6708, Train Loss: 0.0007485920796170831, Valid Loss: 0.0010599966626614332\n",
      "Epoch: 6709, Train Loss: 0.000748149526771158, Valid Loss: 0.001059411559253931\n",
      "Epoch: 6710, Train Loss: 0.0007477077888324857, Valid Loss: 0.001058845198713243\n",
      "Epoch: 6711, Train Loss: 0.000747268961276859, Valid Loss: 0.0010582651011645794\n",
      "Epoch: 6712, Train Loss: 0.0007468279218301177, Valid Loss: 0.0010577011853456497\n",
      "Epoch: 6713, Train Loss: 0.0007463893853127956, Valid Loss: 0.0010571382008492947\n",
      "Epoch: 6714, Train Loss: 0.0007459482876583934, Valid Loss: 0.0010565576376393437\n",
      "Epoch: 6715, Train Loss: 0.0007455103914253414, Valid Loss: 0.0010559882503002882\n",
      "Epoch: 6716, Train Loss: 0.0007450714474543929, Valid Loss: 0.001055407803505659\n",
      "Epoch: 6717, Train Loss: 0.0007446322124451399, Valid Loss: 0.0010548584396019578\n",
      "Epoch: 6718, Train Loss: 0.0007441960624419153, Valid Loss: 0.0010542772943153977\n",
      "Epoch: 6719, Train Loss: 0.0007437574677169323, Valid Loss: 0.001053724903613329\n",
      "Epoch: 6720, Train Loss: 0.0007433205610141158, Valid Loss: 0.001053134212270379\n",
      "Epoch: 6721, Train Loss: 0.0007428844692185521, Valid Loss: 0.001052587991580367\n",
      "Epoch: 6722, Train Loss: 0.0007424460491165519, Valid Loss: 0.0010520090581849217\n",
      "Epoch: 6723, Train Loss: 0.0007420104229822755, Valid Loss: 0.0010514562018215656\n",
      "Epoch: 6724, Train Loss: 0.0007415733416564763, Valid Loss: 0.0010508719133213162\n",
      "Epoch: 6725, Train Loss: 0.0007411361439153552, Valid Loss: 0.001050313701853156\n",
      "Epoch: 6726, Train Loss: 0.0007407012744806707, Valid Loss: 0.0010497363982722163\n",
      "Epoch: 6727, Train Loss: 0.0007402637857012451, Valid Loss: 0.001049185055308044\n",
      "Epoch: 6728, Train Loss: 0.0007398287416435778, Valid Loss: 0.0010486054234206676\n",
      "Epoch: 6729, Train Loss: 0.0007393935811705887, Valid Loss: 0.0010480545461177826\n",
      "Epoch: 6730, Train Loss: 0.000738958187866956, Valid Loss: 0.0010474722366780043\n",
      "Epoch: 6731, Train Loss: 0.0007385237258858979, Valid Loss: 0.0010469182161614299\n",
      "Epoch: 6732, Train Loss: 0.000738089787773788, Valid Loss: 0.0010463495273143053\n",
      "Epoch: 6733, Train Loss: 0.0007376541616395116, Valid Loss: 0.0010457929456606507\n",
      "Epoch: 6734, Train Loss: 0.0007372208638116717, Valid Loss: 0.0010452191345393658\n",
      "Epoch: 6735, Train Loss: 0.0007367868674919009, Valid Loss: 0.0010446584783494473\n",
      "Epoch: 6736, Train Loss: 0.0007363538024947047, Valid Loss: 0.0010440944461151958\n",
      "Epoch: 6737, Train Loss: 0.0007359200972132385, Valid Loss: 0.0010435348376631737\n",
      "Epoch: 6738, Train Loss: 0.0007354883127845824, Valid Loss: 0.0010429711546748877\n",
      "Epoch: 6739, Train Loss: 0.0007350548985414207, Valid Loss: 0.0010424081701785326\n",
      "Epoch: 6740, Train Loss: 0.0007346226484514773, Valid Loss: 0.001041847513988614\n",
      "Epoch: 6741, Train Loss: 0.0007341919117607176, Valid Loss: 0.0010412897681817412\n",
      "Epoch: 6742, Train Loss: 0.0007337579736486077, Valid Loss: 0.001040731556713581\n",
      "Epoch: 6743, Train Loss: 0.0007333263056352735, Valid Loss: 0.0010401700856164098\n",
      "Epoch: 6744, Train Loss: 0.0007328963256441057, Valid Loss: 0.0010396079160273075\n",
      "Epoch: 6745, Train Loss: 0.0007324641919694841, Valid Loss: 0.0010390406241640449\n",
      "Epoch: 6746, Train Loss: 0.0007320341537706554, Valid Loss: 0.0010384854394942522\n",
      "Epoch: 6747, Train Loss: 0.000731603940948844, Valid Loss: 0.0010379275772720575\n",
      "Epoch: 6748, Train Loss: 0.0007311721565201879, Valid Loss: 0.0010373682016506791\n",
      "Epoch: 6749, Train Loss: 0.0007307433988898993, Valid Loss: 0.0010368109215050936\n",
      "Epoch: 6750, Train Loss: 0.0007303145248442888, Valid Loss: 0.0010362598113715649\n",
      "Epoch: 6751, Train Loss: 0.0007298858254216611, Valid Loss: 0.0010356936836615205\n",
      "Epoch: 6752, Train Loss: 0.0007294563692994416, Valid Loss: 0.0010351313976570964\n",
      "Epoch: 6753, Train Loss: 0.0007290259236469865, Valid Loss: 0.0010345707414671779\n",
      "Epoch: 6754, Train Loss: 0.0007285961764864624, Valid Loss: 0.0010340193985030055\n",
      "Epoch: 6755, Train Loss: 0.0007281688740476966, Valid Loss: 0.001033466076478362\n",
      "Epoch: 6756, Train Loss: 0.0007277415716089308, Valid Loss: 0.0010329061187803745\n",
      "Epoch: 6757, Train Loss: 0.0007273119990713894, Valid Loss: 0.0010323472088202834\n",
      "Epoch: 6758, Train Loss: 0.0007268855697475374, Valid Loss: 0.0010317956330254674\n",
      "Epoch: 6759, Train Loss: 0.0007264577434398234, Valid Loss: 0.0010312394006177783\n",
      "Epoch: 6760, Train Loss: 0.0007260300917550921, Valid Loss: 0.0010306816548109055\n",
      "Epoch: 6761, Train Loss: 0.000725604360923171, Valid Loss: 0.001030133687891066\n",
      "Epoch: 6762, Train Loss: 0.0007251783972606063, Valid Loss: 0.0010295710526406765\n",
      "Epoch: 6763, Train Loss: 0.0007247527246363461, Valid Loss: 0.0010290195932611823\n",
      "Epoch: 6764, Train Loss: 0.0007243253639899194, Valid Loss: 0.0010284666204825044\n",
      "Epoch: 6765, Train Loss: 0.0007239010883495212, Valid Loss: 0.0010279123671352863\n",
      "Epoch: 6766, Train Loss: 0.0007234731456264853, Valid Loss: 0.001027359627187252\n",
      "Epoch: 6767, Train Loss: 0.0007230493938550353, Valid Loss: 0.0010268059559166431\n",
      "Epoch: 6768, Train Loss: 0.0007226248853839934, Valid Loss: 0.0010262503055855632\n",
      "Epoch: 6769, Train Loss: 0.0007221985724754632, Valid Loss: 0.001025698147714138\n",
      "Epoch: 6770, Train Loss: 0.0007217750535346568, Valid Loss: 0.0010251520434394479\n",
      "Epoch: 6771, Train Loss: 0.0007213510107249022, Valid Loss: 0.001024603727273643\n",
      "Epoch: 6772, Train Loss: 0.0007209263276308775, Valid Loss: 0.0010240459814667702\n",
      "Epoch: 6773, Train Loss: 0.0007205032161436975, Valid Loss: 0.0010234885849058628\n",
      "Epoch: 6774, Train Loss: 0.0007200788240879774, Valid Loss: 0.0010229434119537473\n",
      "Epoch: 6775, Train Loss: 0.0007196548394858837, Valid Loss: 0.0010223991703242064\n",
      "Epoch: 6776, Train Loss: 0.0007192329503595829, Valid Loss: 0.0010218506213277578\n",
      "Epoch: 6777, Train Loss: 0.0007188103627413511, Valid Loss: 0.0010213027708232403\n",
      "Epoch: 6778, Train Loss: 0.0007183870184235275, Valid Loss: 0.00102074327878654\n",
      "Epoch: 6779, Train Loss: 0.0007179658859968185, Valid Loss: 0.0010201896075159311\n",
      "Epoch: 6780, Train Loss: 0.0007175421924330294, Valid Loss: 0.001019650953821838\n",
      "Epoch: 6781, Train Loss: 0.0007171217002905905, Valid Loss: 0.0010191039182245731\n",
      "Epoch: 6782, Train Loss: 0.0007167002186179161, Valid Loss: 0.0010185540886595845\n",
      "Epoch: 6783, Train Loss: 0.0007162809488363564, Valid Loss: 0.001017998205497861\n",
      "Epoch: 6784, Train Loss: 0.0007158598164096475, Valid Loss: 0.0010174569906666875\n",
      "Epoch: 6785, Train Loss: 0.0007154381019063294, Valid Loss: 0.001016913098283112\n",
      "Epoch: 6786, Train Loss: 0.0007150171441026032, Valid Loss: 0.001016360241919756\n",
      "Epoch: 6787, Train Loss: 0.0007145989220589399, Valid Loss: 0.0010158080840483308\n",
      "Epoch: 6788, Train Loss: 0.0007141774985939264, Valid Loss: 0.0010152698960155249\n",
      "Epoch: 6789, Train Loss: 0.0007137582870200276, Valid Loss: 0.0010147136636078358\n",
      "Epoch: 6790, Train Loss: 0.0007133404142223299, Valid Loss: 0.0010141729144379497\n",
      "Epoch: 6791, Train Loss: 0.0007129205041565001, Valid Loss: 0.001013621804304421\n",
      "Epoch: 6792, Train Loss: 0.0007125007687136531, Valid Loss: 0.0010130875743925571\n",
      "Epoch: 6793, Train Loss: 0.000712083128746599, Valid Loss: 0.0010125365806743503\n",
      "Epoch: 6794, Train Loss: 0.0007116650813259184, Valid Loss: 0.0010119928047060966\n",
      "Epoch: 6795, Train Loss: 0.0007112461025826633, Valid Loss: 0.0010114394826814532\n",
      "Epoch: 6796, Train Loss: 0.0007108290446922183, Valid Loss: 0.0010109073482453823\n",
      "Epoch: 6797, Train Loss: 0.0007104102987796068, Valid Loss: 0.0010103497188538313\n",
      "Epoch: 6798, Train Loss: 0.000709992425981909, Valid Loss: 0.0010098195634782314\n",
      "Epoch: 6799, Train Loss: 0.0007095756591297686, Valid Loss: 0.0010092661250382662\n",
      "Epoch: 6800, Train Loss: 0.0007091594743542373, Valid Loss: 0.0010087329428642988\n",
      "Epoch: 6801, Train Loss: 0.0007087435224093497, Valid Loss: 0.0010081828804686666\n",
      "Epoch: 6802, Train Loss: 0.0007083261152729392, Valid Loss: 0.0010076503967866302\n",
      "Epoch: 6803, Train Loss: 0.0007079116767272353, Valid Loss: 0.0010070973075926304\n",
      "Epoch: 6804, Train Loss: 0.0007074946188367903, Valid Loss: 0.0010065670358017087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6805, Train Loss: 0.0007070782012306154, Valid Loss: 0.0010060174390673637\n",
      "Epoch: 6806, Train Loss: 0.0007066655089147389, Valid Loss: 0.0010054853046312928\n",
      "Epoch: 6807, Train Loss: 0.0007062502554617822, Valid Loss: 0.0010049393167719245\n",
      "Epoch: 6808, Train Loss: 0.0007058343617245555, Valid Loss: 0.0010044099763035774\n",
      "Epoch: 6809, Train Loss: 0.0007054212619550526, Valid Loss: 0.0010038602631539106\n",
      "Epoch: 6810, Train Loss: 0.0007050058338791132, Valid Loss: 0.0010033277794718742\n",
      "Epoch: 6811, Train Loss: 0.0007045919774100184, Valid Loss: 0.001002779696136713\n",
      "Epoch: 6812, Train Loss: 0.0007041770149953663, Valid Loss: 0.0010022484930232167\n",
      "Epoch: 6813, Train Loss: 0.0007037657196633518, Valid Loss: 0.001001704134978354\n",
      "Epoch: 6814, Train Loss: 0.000703351222909987, Valid Loss: 0.0010011739796027541\n",
      "Epoch: 6815, Train Loss: 0.0007029396365396678, Valid Loss: 0.0010006250813603401\n",
      "Epoch: 6816, Train Loss: 0.0007025260711088777, Valid Loss: 0.001000097719952464\n",
      "Epoch: 6817, Train Loss: 0.0007021126220934093, Valid Loss: 0.0009995445143431425\n",
      "Epoch: 6818, Train Loss: 0.0007017000461928546, Valid Loss: 0.000999022158794105\n",
      "Epoch: 6819, Train Loss: 0.0007012857240624726, Valid Loss: 0.0009984772186726332\n",
      "Epoch: 6820, Train Loss: 0.0007008772809058428, Valid Loss: 0.0009979450842365623\n",
      "Epoch: 6821, Train Loss: 0.0007004644721746445, Valid Loss: 0.0009973931591957808\n",
      "Epoch: 6822, Train Loss: 0.0007000526529736817, Valid Loss: 0.0009968695230782032\n",
      "Epoch: 6823, Train Loss: 0.0006996408337727189, Valid Loss: 0.000996328773908317\n",
      "Epoch: 6824, Train Loss: 0.0006992317503318191, Valid Loss: 0.0009958031587302685\n",
      "Epoch: 6825, Train Loss: 0.0006988213863223791, Valid Loss: 0.0009952569380402565\n",
      "Epoch: 6826, Train Loss: 0.000698411138728261, Valid Loss: 0.000994727946817875\n",
      "Epoch: 6827, Train Loss: 0.0006980012985877693, Valid Loss: 0.0009941841708496213\n",
      "Epoch: 6828, Train Loss: 0.0006975919823162258, Valid Loss: 0.0009936612332239747\n",
      "Epoch: 6829, Train Loss: 0.0006971817347221076, Valid Loss: 0.0009931138483807445\n",
      "Epoch: 6830, Train Loss: 0.0006967710214667022, Valid Loss: 0.0009925923077389598\n",
      "Epoch: 6831, Train Loss: 0.0006963650230318308, Valid Loss: 0.0009920491138473153\n",
      "Epoch: 6832, Train Loss: 0.0006959539605304599, Valid Loss: 0.0009915325790643692\n",
      "Epoch: 6833, Train Loss: 0.0006955457502044737, Valid Loss: 0.0009909790242090821\n",
      "Epoch: 6834, Train Loss: 0.0006951384129934013, Valid Loss: 0.0009904633043333888\n",
      "Epoch: 6835, Train Loss: 0.0006947306683287024, Valid Loss: 0.0009899104479700327\n",
      "Epoch: 6836, Train Loss: 0.0006943234475329518, Valid Loss: 0.0009894000831991434\n",
      "Epoch: 6837, Train Loss: 0.0006939158192835748, Valid Loss: 0.000988851534202695\n",
      "Epoch: 6838, Train Loss: 0.0006935076089575887, Valid Loss: 0.000988336163572967\n",
      "Epoch: 6839, Train Loss: 0.0006930995150469244, Valid Loss: 0.0009877901757135987\n",
      "Epoch: 6840, Train Loss: 0.0006926952046342194, Valid Loss: 0.0009872816735878587\n",
      "Epoch: 6841, Train Loss: 0.0006922866450622678, Valid Loss: 0.000986728467978537\n",
      "Epoch: 6842, Train Loss: 0.0006918798317201436, Valid Loss: 0.0009862198494374752\n",
      "Epoch: 6843, Train Loss: 0.0006914756377227604, Valid Loss: 0.000985665712505579\n",
      "Epoch: 6844, Train Loss: 0.0006910685333423316, Valid Loss: 0.0009851615177467465\n",
      "Epoch: 6845, Train Loss: 0.0006906630587764084, Valid Loss: 0.0009846065659075975\n",
      "Epoch: 6846, Train Loss: 0.0006902571185491979, Valid Loss: 0.0009840965503826737\n",
      "Epoch: 6847, Train Loss: 0.0006898538558743894, Valid Loss: 0.0009835459059104323\n",
      "Epoch: 6848, Train Loss: 0.0006894469261169434, Valid Loss: 0.0009830433409661055\n",
      "Epoch: 6849, Train Loss: 0.0006890426157042384, Valid Loss: 0.0009824899025261402\n",
      "Epoch: 6850, Train Loss: 0.0006886396440677345, Valid Loss: 0.0009819903643801808\n",
      "Epoch: 6851, Train Loss: 0.0006882333545945585, Valid Loss: 0.0009814318036660552\n",
      "Epoch: 6852, Train Loss: 0.0006878303247503936, Valid Loss: 0.0009809412294998765\n",
      "Epoch: 6853, Train Loss: 0.000687427818775177, Valid Loss: 0.000980380573309958\n",
      "Epoch: 6854, Train Loss: 0.0006870247889310122, Valid Loss: 0.0009798851097002625\n",
      "Epoch: 6855, Train Loss: 0.0006866224575787783, Valid Loss: 0.0009793235221877694\n",
      "Epoch: 6856, Train Loss: 0.000686219718772918, Valid Loss: 0.0009788426104933023\n",
      "Epoch: 6857, Train Loss: 0.000685816747136414, Valid Loss: 0.0009782728739082813\n",
      "Epoch: 6858, Train Loss: 0.0006854149978607893, Valid Loss: 0.0009777845116332173\n",
      "Epoch: 6859, Train Loss: 0.0006850134232081473, Valid Loss: 0.0009772148914635181\n",
      "Epoch: 6860, Train Loss: 0.0006846108590252697, Valid Loss: 0.0009767456213012338\n",
      "Epoch: 6861, Train Loss: 0.0006842087022960186, Valid Loss: 0.0009761820547282696\n",
      "Epoch: 6862, Train Loss: 0.0006838081171736121, Valid Loss: 0.0009756881627254188\n",
      "Epoch: 6863, Train Loss: 0.0006834073574282229, Valid Loss: 0.0009751213947311044\n",
      "Epoch: 6864, Train Loss: 0.0006830066558904946, Valid Loss: 0.000974657479673624\n",
      "Epoch: 6865, Train Loss: 0.0006826064200140536, Valid Loss: 0.000974075635895133\n",
      "Epoch: 6866, Train Loss: 0.0006822036812081933, Valid Loss: 0.0009736010688357055\n",
      "Epoch: 6867, Train Loss: 0.0006818065885454416, Valid Loss: 0.000973021611571312\n",
      "Epoch: 6868, Train Loss: 0.0006814051303081214, Valid Loss: 0.0009725731797516346\n",
      "Epoch: 6869, Train Loss: 0.000681006524246186, Valid Loss: 0.0009719819063320756\n",
      "Epoch: 6870, Train Loss: 0.000680608325637877, Valid Loss: 0.0009715299238450825\n",
      "Epoch: 6871, Train Loss: 0.0006802071002312005, Valid Loss: 0.0009709367295727134\n",
      "Epoch: 6872, Train Loss: 0.0006798107642680407, Valid Loss: 0.0009704887634143233\n",
      "Epoch: 6873, Train Loss: 0.0006794126820750535, Valid Loss: 0.0009698920766822994\n",
      "Epoch: 6874, Train Loss: 0.0006790145998820662, Valid Loss: 0.00096945243421942\n",
      "Epoch: 6875, Train Loss: 0.000678613840136677, Valid Loss: 0.0009688434074632823\n",
      "Epoch: 6876, Train Loss: 0.0006782170967198908, Valid Loss: 0.0009684174438007176\n",
      "Epoch: 6877, Train Loss: 0.0006778197712264955, Valid Loss: 0.000967810454312712\n",
      "Epoch: 6878, Train Loss: 0.0006774203502573073, Valid Loss: 0.0009673847816884518\n",
      "Epoch: 6879, Train Loss: 0.0006770277977921069, Valid Loss: 0.0009667648118920624\n",
      "Epoch: 6880, Train Loss: 0.0006766275619156659, Valid Loss: 0.0009663445525802672\n",
      "Epoch: 6881, Train Loss: 0.000676231284160167, Valid Loss: 0.0009657294140197337\n",
      "Epoch: 6882, Train Loss: 0.0006758372765034437, Valid Loss: 0.0009653093875385821\n",
      "Epoch: 6883, Train Loss: 0.0006754403002560139, Valid Loss: 0.00096468924311921\n",
      "Epoch: 6884, Train Loss: 0.000675043324008584, Valid Loss: 0.0009642720106057823\n",
      "Epoch: 6885, Train Loss: 0.0006746476283296943, Valid Loss: 0.0009636615286581218\n",
      "Epoch: 6886, Train Loss: 0.0006742520490661263, Valid Loss: 0.000963230209890753\n",
      "Epoch: 6887, Train Loss: 0.0006738562369719148, Valid Loss: 0.0009626256651245058\n",
      "Epoch: 6888, Train Loss: 0.0006734615308232605, Valid Loss: 0.0009621894569136202\n",
      "Epoch: 6889, Train Loss: 0.0006730639724992216, Valid Loss: 0.0009616011520847678\n",
      "Epoch: 6890, Train Loss: 0.000672670139465481, Valid Loss: 0.0009611501009203494\n",
      "Epoch: 6891, Train Loss: 0.0006722745019942522, Valid Loss: 0.0009605687810108066\n",
      "Epoch: 6892, Train Loss: 0.0006718795630149543, Valid Loss: 0.0009601092897355556\n",
      "Epoch: 6893, Train Loss: 0.0006714834598824382, Valid Loss: 0.0009595429291948676\n",
      "Epoch: 6894, Train Loss: 0.0006710924790240824, Valid Loss: 0.0009590674308128655\n",
      "Epoch: 6895, Train Loss: 0.000670695910230279, Valid Loss: 0.0009585125953890383\n",
      "Epoch: 6896, Train Loss: 0.0006703038234263659, Valid Loss: 0.000958033197093755\n",
      "Epoch: 6897, Train Loss: 0.0006699107470922172, Valid Loss: 0.0009574956493452191\n",
      "Epoch: 6898, Train Loss: 0.0006695171468891203, Valid Loss: 0.0009570001275278628\n",
      "Epoch: 6899, Train Loss: 0.0006691261078231037, Valid Loss: 0.0009564698557369411\n",
      "Epoch: 6900, Train Loss: 0.0006687318091280758, Valid Loss: 0.0009559666505083442\n",
      "Epoch: 6901, Train Loss: 0.0006683417595922947, Valid Loss: 0.000955449475441128\n",
      "Epoch: 6902, Train Loss: 0.0006679493235424161, Valid Loss: 0.0009549382957629859\n",
      "Epoch: 6903, Train Loss: 0.0006675560143776238, Valid Loss: 0.0009544383501634002\n",
      "Epoch: 6904, Train Loss: 0.0006671673618257046, Valid Loss: 0.000953905750066042\n",
      "Epoch: 6905, Train Loss: 0.0006667756242677569, Valid Loss: 0.0009534117416478693\n",
      "Epoch: 6906, Train Loss: 0.0006663830135948956, Valid Loss: 0.0009528810041956604\n",
      "Epoch: 6907, Train Loss: 0.0006659936043433845, Valid Loss: 0.0009523970657028258\n",
      "Epoch: 6908, Train Loss: 0.0006656035548076034, Valid Loss: 0.0009518593433313072\n",
      "Epoch: 6909, Train Loss: 0.0006652133888565004, Valid Loss: 0.0009513697004877031\n",
      "Epoch: 6910, Train Loss: 0.0006648236885666847, Valid Loss: 0.0009508452494628727\n",
      "Epoch: 6911, Train Loss: 0.0006644332315772772, Valid Loss: 0.0009503503679297864\n",
      "Epoch: 6912, Train Loss: 0.0006640446954406798, Valid Loss: 0.0009498175932094455\n",
      "Epoch: 6913, Train Loss: 0.0006636552279815078, Valid Loss: 0.0009493362158536911\n",
      "Epoch: 6914, Train Loss: 0.0006632661679759622, Valid Loss: 0.0009488144423812628\n",
      "Epoch: 6915, Train Loss: 0.0006628785631619394, Valid Loss: 0.0009483199683018029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6916, Train Loss: 0.0006624878733418882, Valid Loss: 0.0009477825951762497\n",
      "Epoch: 6917, Train Loss: 0.0006621014326810837, Valid Loss: 0.0009472955134697258\n",
      "Epoch: 6918, Train Loss: 0.0006617133039981127, Valid Loss: 0.0009467785712331533\n",
      "Epoch: 6919, Train Loss: 0.0006613239529542625, Valid Loss: 0.0009462786256335676\n",
      "Epoch: 6920, Train Loss: 0.0006609383272007108, Valid Loss: 0.0009457588312216103\n",
      "Epoch: 6921, Train Loss: 0.0006605503149330616, Valid Loss: 0.000945266627240926\n",
      "Epoch: 6922, Train Loss: 0.0006601633504033089, Valid Loss: 0.0009447498596273363\n",
      "Epoch: 6923, Train Loss: 0.0006597783067263663, Valid Loss: 0.0009442543960176408\n",
      "Epoch: 6924, Train Loss: 0.0006593917496502399, Valid Loss: 0.0009437355911359191\n",
      "Epoch: 6925, Train Loss: 0.0006590025150217116, Valid Loss: 0.000943237857427448\n",
      "Epoch: 6926, Train Loss: 0.0006586169474758208, Valid Loss: 0.0009427280747331679\n",
      "Epoch: 6927, Train Loss: 0.0006582311470992863, Valid Loss: 0.0009422301664017141\n",
      "Epoch: 6928, Train Loss: 0.0006578486645594239, Valid Loss: 0.000941714970394969\n",
      "Epoch: 6929, Train Loss: 0.000657460477668792, Valid Loss: 0.0009412101935595274\n",
      "Epoch: 6930, Train Loss: 0.0006570750847458839, Valid Loss: 0.0009407052421011031\n",
      "Epoch: 6931, Train Loss: 0.0006566899246536195, Valid Loss: 0.0009402062278240919\n",
      "Epoch: 6932, Train Loss: 0.000656306219752878, Valid Loss: 0.0009396986570209265\n",
      "Epoch: 6933, Train Loss: 0.0006559235625900328, Valid Loss: 0.0009391945786774158\n",
      "Epoch: 6934, Train Loss: 0.0006555379368364811, Valid Loss: 0.000938695389777422\n",
      "Epoch: 6935, Train Loss: 0.0006551531259901822, Valid Loss: 0.0009381923009641469\n",
      "Epoch: 6936, Train Loss: 0.0006547692464664578, Valid Loss: 0.0009376878151670098\n",
      "Epoch: 6937, Train Loss: 0.0006543861236423254, Valid Loss: 0.000937181175686419\n",
      "Epoch: 6938, Train Loss: 0.0006540028261952102, Valid Loss: 0.0009366816957481205\n",
      "Epoch: 6939, Train Loss: 0.0006536190630868077, Valid Loss: 0.0009361830889247358\n",
      "Epoch: 6940, Train Loss: 0.0006532368715852499, Valid Loss: 0.0009356790687888861\n",
      "Epoch: 6941, Train Loss: 0.0006528525846078992, Valid Loss: 0.0009351819171570241\n",
      "Epoch: 6942, Train Loss: 0.0006524713826365769, Valid Loss: 0.0009346793522126973\n",
      "Epoch: 6943, Train Loss: 0.0006520911119878292, Valid Loss: 0.0009341768454760313\n",
      "Epoch: 6944, Train Loss: 0.0006517074652947485, Valid Loss: 0.0009336768998764455\n",
      "Epoch: 6945, Train Loss: 0.0006513247499242425, Valid Loss: 0.000933173461817205\n",
      "Epoch: 6946, Train Loss: 0.0006509434897452593, Valid Loss: 0.0009326760191470385\n",
      "Epoch: 6947, Train Loss: 0.0006505635101348162, Valid Loss: 0.0009321729885414243\n",
      "Epoch: 6948, Train Loss: 0.0006501817842945457, Valid Loss: 0.0009316717623732984\n",
      "Epoch: 6949, Train Loss: 0.0006498011643998325, Valid Loss: 0.0009311815956607461\n",
      "Epoch: 6950, Train Loss: 0.0006494217668659985, Valid Loss: 0.000930685258936137\n",
      "Epoch: 6951, Train Loss: 0.0006490400992333889, Valid Loss: 0.0009301759419031441\n",
      "Epoch: 6952, Train Loss: 0.0006486596539616585, Valid Loss: 0.0009296800126321614\n",
      "Epoch: 6953, Train Loss: 0.0006482793251052499, Valid Loss: 0.0009291770402342081\n",
      "Epoch: 6954, Train Loss: 0.0006479023140855134, Valid Loss: 0.0009286878048442304\n",
      "Epoch: 6955, Train Loss: 0.0006475201807916164, Valid Loss: 0.0009281823877245188\n",
      "Epoch: 6956, Train Loss: 0.0006471426459029317, Valid Loss: 0.000927695247810334\n",
      "Epoch: 6957, Train Loss: 0.0006467636558227241, Valid Loss: 0.0009271894232369959\n",
      "Epoch: 6958, Train Loss: 0.0006463847821578383, Valid Loss: 0.000926697626709938\n",
      "Epoch: 6959, Train Loss: 0.0006460064905695617, Valid Loss: 0.0009261916857212782\n",
      "Epoch: 6960, Train Loss: 0.0006456290720961988, Valid Loss: 0.0009257094352506101\n",
      "Epoch: 6961, Train Loss: 0.0006452499656006694, Valid Loss: 0.0009252040181308985\n",
      "Epoch: 6962, Train Loss: 0.0006448730709962547, Valid Loss: 0.0009247136767953634\n",
      "Epoch: 6963, Train Loss: 0.000644494837615639, Valid Loss: 0.0009242150117643178\n",
      "Epoch: 6964, Train Loss: 0.0006441196310333908, Valid Loss: 0.0009237331687472761\n",
      "Epoch: 6965, Train Loss: 0.0006437391857616603, Valid Loss: 0.0009232176817022264\n",
      "Epoch: 6966, Train Loss: 0.0006433626404032111, Valid Loss: 0.0009227321133948863\n",
      "Epoch: 6967, Train Loss: 0.0006429869099520147, Valid Loss: 0.0009222376393154263\n",
      "Epoch: 6968, Train Loss: 0.0006426110630854964, Valid Loss: 0.0009217554470524192\n",
      "Epoch: 6969, Train Loss: 0.000642233993858099, Valid Loss: 0.0009212441509589553\n",
      "Epoch: 6970, Train Loss: 0.0006418585544452071, Valid Loss: 0.0009207589318975806\n",
      "Epoch: 6971, Train Loss: 0.00064148532692343, Valid Loss: 0.0009202698129229248\n",
      "Epoch: 6972, Train Loss: 0.000641107966657728, Valid Loss: 0.0009197817998938262\n",
      "Epoch: 6973, Train Loss: 0.0006407328182831407, Valid Loss: 0.0009192771976813674\n",
      "Epoch: 6974, Train Loss: 0.0006403580191545188, Valid Loss: 0.0009187941905111074\n",
      "Epoch: 6975, Train Loss: 0.0006399819976650178, Valid Loss: 0.0009182984358631074\n",
      "Epoch: 6976, Train Loss: 0.0006396078388206661, Valid Loss: 0.0009178104228340089\n",
      "Epoch: 6977, Train Loss: 0.0006392349023371935, Valid Loss: 0.0009173074504360557\n",
      "Epoch: 6978, Train Loss: 0.0006388599867932498, Valid Loss: 0.0009168272372335196\n",
      "Epoch: 6979, Train Loss: 0.0006384852458722889, Valid Loss: 0.0009163312497548759\n",
      "Epoch: 6980, Train Loss: 0.0006381117273122072, Valid Loss: 0.0009158420725725591\n",
      "Epoch: 6981, Train Loss: 0.0006377387908287346, Valid Loss: 0.0009153402061201632\n",
      "Epoch: 6982, Train Loss: 0.0006373662035912275, Valid Loss: 0.0009148695389740169\n",
      "Epoch: 6983, Train Loss: 0.0006369916955009103, Valid Loss: 0.0009143660427071154\n",
      "Epoch: 6984, Train Loss: 0.000636617885902524, Valid Loss: 0.0009138767491094768\n",
      "Epoch: 6985, Train Loss: 0.0006362467538565397, Valid Loss: 0.000913385534659028\n",
      "Epoch: 6986, Train Loss: 0.0006358737009577453, Valid Loss: 0.0009129105601459742\n",
      "Epoch: 6987, Train Loss: 0.0006355035584419966, Valid Loss: 0.0009124070638790727\n",
      "Epoch: 6988, Train Loss: 0.0006351283518597484, Valid Loss: 0.0009119246969930828\n",
      "Epoch: 6989, Train Loss: 0.0006347585003823042, Valid Loss: 0.000911432143766433\n",
      "Epoch: 6990, Train Loss: 0.0006343869026750326, Valid Loss: 0.0009109543752856553\n",
      "Epoch: 6991, Train Loss: 0.0006340156542137265, Valid Loss: 0.0009104585624299943\n",
      "Epoch: 6992, Train Loss: 0.0006336442311294377, Valid Loss: 0.0009099726448766887\n",
      "Epoch: 6993, Train Loss: 0.0006332744378596544, Valid Loss: 0.0009094777051359415\n",
      "Epoch: 6994, Train Loss: 0.0006329030729830265, Valid Loss: 0.000909003778360784\n",
      "Epoch: 6995, Train Loss: 0.0006325316498987377, Valid Loss: 0.0009085131459869444\n",
      "Epoch: 6996, Train Loss: 0.0006321643595583737, Valid Loss: 0.0009080294403247535\n",
      "Epoch: 6997, Train Loss: 0.0006317940424196422, Valid Loss: 0.0009075361303985119\n",
      "Epoch: 6998, Train Loss: 0.0006314243655651808, Valid Loss: 0.0009070538217201829\n",
      "Epoch: 6999, Train Loss: 0.0006310543976724148, Valid Loss: 0.0009065649937838316\n",
      "Epoch: 7000, Train Loss: 0.0006306860013864934, Valid Loss: 0.0009060867014341056\n",
      "Epoch: 7001, Train Loss: 0.0006303186528384686, Valid Loss: 0.0009055991540662944\n",
      "Epoch: 7002, Train Loss: 0.0006299486849457026, Valid Loss: 0.0009051207453012466\n",
      "Epoch: 7003, Train Loss: 0.0006295792409218848, Valid Loss: 0.0009046266786754131\n",
      "Epoch: 7004, Train Loss: 0.0006292120669968426, Valid Loss: 0.0009041510638780892\n",
      "Epoch: 7005, Train Loss: 0.0006288446602411568, Valid Loss: 0.00090366555377841\n",
      "Epoch: 7006, Train Loss: 0.0006284744595177472, Valid Loss: 0.0009031844092532992\n",
      "Epoch: 7007, Train Loss: 0.0006281092064455152, Valid Loss: 0.0009026902844198048\n",
      "Epoch: 7008, Train Loss: 0.0006277416832745075, Valid Loss: 0.0009022142039611936\n",
      "Epoch: 7009, Train Loss: 0.0006273725884966552, Valid Loss: 0.0009017331758514047\n",
      "Epoch: 7010, Train Loss: 0.0006270044832490385, Valid Loss: 0.000901253311894834\n",
      "Epoch: 7011, Train Loss: 0.0006266399286687374, Valid Loss: 0.0009007604676298797\n",
      "Epoch: 7012, Train Loss: 0.000626273569650948, Valid Loss: 0.0009002875303849578\n",
      "Epoch: 7013, Train Loss: 0.0006259047077037394, Valid Loss: 0.0008998083067126572\n",
      "Epoch: 7014, Train Loss: 0.000625539745669812, Valid Loss: 0.0008993262308649719\n",
      "Epoch: 7015, Train Loss: 0.0006251737358979881, Valid Loss: 0.000898836471606046\n",
      "Epoch: 7016, Train Loss: 0.0006248088902793825, Valid Loss: 0.0008983616717159748\n",
      "Epoch: 7017, Train Loss: 0.0006244450341910124, Valid Loss: 0.0008978772675618529\n",
      "Epoch: 7018, Train Loss: 0.0006240776274353266, Valid Loss: 0.0008974021766334772\n",
      "Epoch: 7019, Train Loss: 0.0006237120251171291, Valid Loss: 0.0008969182381406426\n",
      "Epoch: 7020, Train Loss: 0.0006233477615751326, Valid Loss: 0.0008964448934420943\n",
      "Epoch: 7021, Train Loss: 0.000622982915956527, Valid Loss: 0.0008959557744674385\n",
      "Epoch: 7022, Train Loss: 0.0006226206896826625, Valid Loss: 0.0008954863878898323\n",
      "Epoch: 7023, Train Loss: 0.0006222540396265686, Valid Loss: 0.0008950063493102789\n",
      "Epoch: 7024, Train Loss: 0.0006218914058990777, Valid Loss: 0.0008945231093093753\n",
      "Epoch: 7025, Train Loss: 0.000621527957264334, Valid Loss: 0.0008940441766753793\n",
      "Epoch: 7026, Train Loss: 0.0006211629952304065, Valid Loss: 0.0008935701334849\n",
      "Epoch: 7027, Train Loss: 0.0006208008271642029, Valid Loss: 0.0008930860203690827\n",
      "Epoch: 7028, Train Loss: 0.000620440870989114, Valid Loss: 0.0008926133741624653\n",
      "Epoch: 7029, Train Loss: 0.0006200750358402729, Valid Loss: 0.0008921347325667739\n",
      "Epoch: 7030, Train Loss: 0.0006197134498506784, Valid Loss: 0.0008916551014408469\n",
      "Epoch: 7031, Train Loss: 0.0006193509907461703, Valid Loss: 0.0008911801851354539\n",
      "Epoch: 7032, Train Loss: 0.000618987949565053, Valid Loss: 0.0008907062583602965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7033, Train Loss: 0.0006186274695210159, Valid Loss: 0.0008902277331799269\n",
      "Epoch: 7034, Train Loss: 0.000618264137301594, Valid Loss: 0.0008897550287656486\n",
      "Epoch: 7035, Train Loss: 0.0006179040647111833, Valid Loss: 0.0008892737096175551\n",
      "Epoch: 7036, Train Loss: 0.0006175432354211807, Valid Loss: 0.0008888028678484261\n",
      "Epoch: 7037, Train Loss: 0.000617179844994098, Valid Loss: 0.0008883318514563143\n",
      "Epoch: 7038, Train Loss: 0.0006168188410811126, Valid Loss: 0.0008878503576852381\n",
      "Epoch: 7039, Train Loss: 0.000616459408774972, Valid Loss: 0.000887372181750834\n",
      "Epoch: 7040, Train Loss: 0.0006160983466543257, Valid Loss: 0.0008869039011187851\n",
      "Epoch: 7041, Train Loss: 0.0006157374591566622, Valid Loss: 0.0008864299743436277\n",
      "Epoch: 7042, Train Loss: 0.0006153779104351997, Valid Loss: 0.0008859537774696946\n",
      "Epoch: 7043, Train Loss: 0.0006150219705887139, Valid Loss: 0.000885471876244992\n",
      "Epoch: 7044, Train Loss: 0.000614658638369292, Valid Loss: 0.0008850040030665696\n",
      "Epoch: 7045, Train Loss: 0.0006143015343695879, Valid Loss: 0.0008845280390232801\n",
      "Epoch: 7046, Train Loss: 0.00061394227668643, Valid Loss: 0.0008840548107400537\n",
      "Epoch: 7047, Train Loss: 0.0006135822623036802, Valid Loss: 0.0008835821063257754\n",
      "Epoch: 7048, Train Loss: 0.0006132243433967233, Valid Loss: 0.0008831124869175255\n",
      "Epoch: 7049, Train Loss: 0.000612864620052278, Valid Loss: 0.0008826391422189772\n",
      "Epoch: 7050, Train Loss: 0.0006125062936916947, Valid Loss: 0.0008821682422421873\n",
      "Epoch: 7051, Train Loss: 0.0006121484912000597, Valid Loss: 0.0008816927438601851\n",
      "Epoch: 7052, Train Loss: 0.0006117926095612347, Valid Loss: 0.0008812302839942276\n",
      "Epoch: 7053, Train Loss: 0.0006114340503700078, Valid Loss: 0.0008807559497654438\n",
      "Epoch: 7054, Train Loss: 0.0006110750837251544, Valid Loss: 0.0008802828378975391\n",
      "Epoch: 7055, Train Loss: 0.0006107210065238178, Valid Loss: 0.0008798139751888812\n",
      "Epoch: 7056, Train Loss: 0.0006103620398789644, Valid Loss: 0.0008793537854216993\n",
      "Epoch: 7057, Train Loss: 0.0006100050522945821, Valid Loss: 0.0008788734558038414\n",
      "Epoch: 7058, Train Loss: 0.0006096489378251135, Valid Loss: 0.0008784042438492179\n",
      "Epoch: 7059, Train Loss: 0.0006092925905250013, Valid Loss: 0.0008779388736002147\n",
      "Epoch: 7060, Train Loss: 0.0006089364178478718, Valid Loss: 0.0008774736779741943\n",
      "Epoch: 7061, Train Loss: 0.0006085808272473514, Valid Loss: 0.0008769924752414227\n",
      "Epoch: 7062, Train Loss: 0.0006082258187234402, Valid Loss: 0.0008765325183048844\n",
      "Epoch: 7063, Train Loss: 0.0006078712176531553, Valid Loss: 0.0008760622004047036\n",
      "Epoch: 7064, Train Loss: 0.0006075134151615202, Valid Loss: 0.0008755959570407867\n",
      "Epoch: 7065, Train Loss: 0.0006071605021134019, Valid Loss: 0.0008751245331950486\n",
      "Epoch: 7066, Train Loss: 0.0006068067741580307, Valid Loss: 0.0008746678940951824\n",
      "Epoch: 7067, Train Loss: 0.0006064525805413723, Valid Loss: 0.0008741883793845773\n",
      "Epoch: 7068, Train Loss: 0.0006060966989025474, Valid Loss: 0.0008737306343391538\n",
      "Epoch: 7069, Train Loss: 0.0006057441933080554, Valid Loss: 0.0008732527494430542\n",
      "Epoch: 7070, Train Loss: 0.0006053888355381787, Valid Loss: 0.0008727965760044754\n",
      "Epoch: 7071, Train Loss: 0.0006050348747521639, Valid Loss: 0.0008723203209228814\n",
      "Epoch: 7072, Train Loss: 0.0006046821945346892, Valid Loss: 0.0008718646131455898\n",
      "Epoch: 7073, Train Loss: 0.0006043272442184389, Valid Loss: 0.0008713853894732893\n",
      "Epoch: 7074, Train Loss: 0.0006039754371158779, Valid Loss: 0.0008709380053915083\n",
      "Epoch: 7075, Train Loss: 0.000603622174821794, Valid Loss: 0.0008704513311386108\n",
      "Epoch: 7076, Train Loss: 0.0006032707751728594, Valid Loss: 0.0008700027829036117\n",
      "Epoch: 7077, Train Loss: 0.0006029160576872528, Valid Loss: 0.000869522977154702\n",
      "Epoch: 7078, Train Loss: 0.0006025638431310654, Valid Loss: 0.0008690775139257312\n",
      "Epoch: 7079, Train Loss: 0.0006022151210345328, Valid Loss: 0.0008685955544933677\n",
      "Epoch: 7080, Train Loss: 0.0006018606945872307, Valid Loss: 0.000868153409101069\n",
      "Epoch: 7081, Train Loss: 0.000601510051637888, Valid Loss: 0.0008676606230437756\n",
      "Epoch: 7082, Train Loss: 0.0006011580699123442, Valid Loss: 0.0008672235999256372\n",
      "Epoch: 7083, Train Loss: 0.0006008095224387944, Valid Loss: 0.0008667379734106362\n",
      "Epoch: 7084, Train Loss: 0.0006004582392051816, Valid Loss: 0.0008663067710585892\n",
      "Epoch: 7085, Train Loss: 0.0006001082365401089, Valid Loss: 0.0008658080478198826\n",
      "Epoch: 7086, Train Loss: 0.0005997567786835134, Valid Loss: 0.0008653835393488407\n",
      "Epoch: 7087, Train Loss: 0.000599407940171659, Valid Loss: 0.0008648853981867433\n",
      "Epoch: 7088, Train Loss: 0.0005990574136376381, Valid Loss: 0.0008644649642519653\n",
      "Epoch: 7089, Train Loss: 0.0005987081676721573, Valid Loss: 0.0008639569859951735\n",
      "Epoch: 7090, Train Loss: 0.0005983599694445729, Valid Loss: 0.0008635516278445721\n",
      "Epoch: 7091, Train Loss: 0.0005980106070637703, Valid Loss: 0.0008630415541119874\n",
      "Epoch: 7092, Train Loss: 0.0005976639222353697, Valid Loss: 0.0008626289200037718\n",
      "Epoch: 7093, Train Loss: 0.0005973142106086016, Valid Loss: 0.0008621150045655668\n",
      "Epoch: 7094, Train Loss: 0.0005969679332338274, Valid Loss: 0.0008617224521003664\n",
      "Epoch: 7095, Train Loss: 0.0005966189783066511, Valid Loss: 0.0008611917728558183\n",
      "Epoch: 7096, Train Loss: 0.0005962722352705896, Valid Loss: 0.0008608046919107437\n",
      "Epoch: 7097, Train Loss: 0.0005959243280813098, Valid Loss: 0.0008602746529504657\n",
      "Epoch: 7098, Train Loss: 0.0005955788656137884, Valid Loss: 0.0008598994463682175\n",
      "Epoch: 7099, Train Loss: 0.0005952314240857959, Valid Loss: 0.0008593563688918948\n",
      "Epoch: 7100, Train Loss: 0.0005948827019892633, Valid Loss: 0.0008589762728661299\n",
      "Epoch: 7101, Train Loss: 0.0005945356679148972, Valid Loss: 0.0008584367460571229\n",
      "Epoch: 7102, Train Loss: 0.0005941892741248012, Valid Loss: 0.0008580581052228808\n",
      "Epoch: 7103, Train Loss: 0.0005938414251431823, Valid Loss: 0.0008575216052122414\n",
      "Epoch: 7104, Train Loss: 0.0005934923538006842, Valid Loss: 0.0008571338839828968\n",
      "Epoch: 7105, Train Loss: 0.0005931444466114044, Valid Loss: 0.0008566020405851305\n",
      "Epoch: 7106, Train Loss: 0.0005927953752689064, Valid Loss: 0.0008562097791582346\n",
      "Epoch: 7107, Train Loss: 0.0005924488068558276, Valid Loss: 0.0008556845132261515\n",
      "Epoch: 7108, Train Loss: 0.0005921034025959671, Valid Loss: 0.0008552813669666648\n",
      "Epoch: 7109, Train Loss: 0.0005917539820075035, Valid Loss: 0.0008547765901312232\n",
      "Epoch: 7110, Train Loss: 0.0005914062494412065, Valid Loss: 0.0008543504518456757\n",
      "Epoch: 7111, Train Loss: 0.0005910609033890069, Valid Loss: 0.0008538611000403762\n",
      "Epoch: 7112, Train Loss: 0.0005907142185606062, Valid Loss: 0.0008534233784303069\n",
      "Epoch: 7113, Train Loss: 0.0005903699202463031, Valid Loss: 0.0008529602200724185\n",
      "Epoch: 7114, Train Loss: 0.0005900253891013563, Valid Loss: 0.0008525055018253624\n",
      "Epoch: 7115, Train Loss: 0.0005896828952245414, Valid Loss: 0.0008520495612174273\n",
      "Epoch: 7116, Train Loss: 0.0005893373163416982, Valid Loss: 0.0008515939698554575\n",
      "Epoch: 7117, Train Loss: 0.0005889926687814295, Valid Loss: 0.0008511513588018715\n",
      "Epoch: 7118, Train Loss: 0.0005886481958441436, Valid Loss: 0.0008506739977747202\n",
      "Epoch: 7119, Train Loss: 0.000588305585552007, Valid Loss: 0.0008502480923198164\n",
      "Epoch: 7120, Train Loss: 0.0005879640812054276, Valid Loss: 0.0008497755043208599\n",
      "Epoch: 7121, Train Loss: 0.0005876186769455671, Valid Loss: 0.0008493404602631927\n",
      "Epoch: 7122, Train Loss: 0.0005872784531675279, Valid Loss: 0.0008488609455525875\n",
      "Epoch: 7123, Train Loss: 0.0005869342130608857, Valid Loss: 0.0008484394638799131\n",
      "Epoch: 7124, Train Loss: 0.00058659230126068, Valid Loss: 0.0008479668758809566\n",
      "Epoch: 7125, Train Loss: 0.0005862489342689514, Valid Loss: 0.0008475352660752833\n",
      "Epoch: 7126, Train Loss: 0.0005859076627530158, Valid Loss: 0.000847059884108603\n",
      "Epoch: 7127, Train Loss: 0.0005855647614225745, Valid Loss: 0.0008466283325105906\n",
      "Epoch: 7128, Train Loss: 0.000585223431698978, Valid Loss: 0.0008461640099994838\n",
      "Epoch: 7129, Train Loss: 0.000584879016969353, Valid Loss: 0.0008457228541374207\n",
      "Epoch: 7130, Train Loss: 0.0005845386767759919, Valid Loss: 0.0008452612091787159\n",
      "Epoch: 7131, Train Loss: 0.0005841965903528035, Valid Loss: 0.0008448198204860091\n",
      "Epoch: 7132, Train Loss: 0.0005838570068590343, Valid Loss: 0.0008443697588518262\n",
      "Epoch: 7133, Train Loss: 0.0005835166666656733, Valid Loss: 0.0008439177181571722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7134, Train Loss: 0.0005831760354340076, Valid Loss: 0.0008434690535068512\n",
      "Epoch: 7135, Train Loss: 0.0005828343564644456, Valid Loss: 0.0008430223679170012\n",
      "Epoch: 7136, Train Loss: 0.0005824952968396246, Valid Loss: 0.0008425746927969158\n",
      "Epoch: 7137, Train Loss: 0.0005821557133458555, Valid Loss: 0.0008421128732152283\n",
      "Epoch: 7138, Train Loss: 0.0005818164208903909, Valid Loss: 0.0008416830096393824\n",
      "Epoch: 7139, Train Loss: 0.0005814764299429953, Valid Loss: 0.0008412176393903792\n",
      "Epoch: 7140, Train Loss: 0.0005811373121105134, Valid Loss: 0.00084078119834885\n",
      "Epoch: 7141, Train Loss: 0.0005807990091852844, Valid Loss: 0.0008403144311159849\n",
      "Epoch: 7142, Train Loss: 0.0005804603570140898, Valid Loss: 0.0008398841600865126\n",
      "Epoch: 7143, Train Loss: 0.0005801214720122516, Valid Loss: 0.0008394268224947155\n",
      "Epoch: 7144, Train Loss: 0.0005797825288027525, Valid Loss: 0.0008389821159653366\n",
      "Epoch: 7145, Train Loss: 0.0005794437602162361, Valid Loss: 0.0008385303663089871\n",
      "Epoch: 7146, Train Loss: 0.0005791074363514781, Valid Loss: 0.0008380916551686823\n",
      "Epoch: 7147, Train Loss: 0.0005787689588032663, Valid Loss: 0.0008376335608772933\n",
      "Epoch: 7148, Train Loss: 0.0005784293171018362, Valid Loss: 0.0008371949079446495\n",
      "Epoch: 7149, Train Loss: 0.0005780901410616934, Valid Loss: 0.0008367457776330411\n",
      "Epoch: 7150, Train Loss: 0.0005777559126727283, Valid Loss: 0.0008363016531802714\n",
      "Epoch: 7151, Train Loss: 0.0005774180172011256, Valid Loss: 0.0008358519989997149\n",
      "Epoch: 7152, Train Loss: 0.0005770812858827412, Valid Loss: 0.0008354118326678872\n",
      "Epoch: 7153, Train Loss: 0.0005767446127720177, Valid Loss: 0.0008349618874490261\n",
      "Epoch: 7154, Train Loss: 0.0005764091620221734, Valid Loss: 0.0008345203241333365\n",
      "Epoch: 7155, Train Loss: 0.0005760695203207433, Valid Loss: 0.0008340728236362338\n",
      "Epoch: 7156, Train Loss: 0.0005757344770245254, Valid Loss: 0.0008336247410625219\n",
      "Epoch: 7157, Train Loss: 0.0005753993173129857, Valid Loss: 0.0008331902790814638\n",
      "Epoch: 7158, Train Loss: 0.0005750657874159515, Valid Loss: 0.0008327418472617865\n",
      "Epoch: 7159, Train Loss: 0.0005747294635511935, Valid Loss: 0.0008322998182848096\n",
      "Epoch: 7160, Train Loss: 0.0005743952351622283, Valid Loss: 0.0008318437030538917\n",
      "Epoch: 7161, Train Loss: 0.000574058445636183, Valid Loss: 0.0008314084261655807\n",
      "Epoch: 7162, Train Loss: 0.0005737243336625397, Valid Loss: 0.0008309655822813511\n",
      "Epoch: 7163, Train Loss: 0.0005733895814046264, Valid Loss: 0.0008305248338729143\n",
      "Epoch: 7164, Train Loss: 0.0005730538396164775, Valid Loss: 0.0008300781482830644\n",
      "Epoch: 7165, Train Loss: 0.000572719844058156, Valid Loss: 0.0008296357118524611\n",
      "Epoch: 7166, Train Loss: 0.0005723856738768518, Valid Loss: 0.0008291937410831451\n",
      "Epoch: 7167, Train Loss: 0.000572053249925375, Valid Loss: 0.0008287470554932952\n",
      "Epoch: 7168, Train Loss: 0.0005717181484214962, Valid Loss: 0.0008283039787784219\n",
      "Epoch: 7169, Train Loss: 0.0005713855498470366, Valid Loss: 0.0008278702152892947\n",
      "Epoch: 7170, Train Loss: 0.0005710531258955598, Valid Loss: 0.0008274258580058813\n",
      "Epoch: 7171, Train Loss: 0.0005707195959985256, Valid Loss: 0.0008269783575087786\n",
      "Epoch: 7172, Train Loss: 0.0005703864153474569, Valid Loss: 0.000826542847789824\n",
      "Epoch: 7173, Train Loss: 0.0005700532346963882, Valid Loss: 0.0008261038456112146\n",
      "Epoch: 7174, Train Loss: 0.0005697208689525723, Valid Loss: 0.000825666356831789\n",
      "Epoch: 7175, Train Loss: 0.0005693883285857737, Valid Loss: 0.0008252231637015939\n",
      "Epoch: 7176, Train Loss: 0.0005690573598258197, Valid Loss: 0.0008247856749221683\n",
      "Epoch: 7177, Train Loss: 0.0005687257507815957, Valid Loss: 0.0008243449265137315\n",
      "Epoch: 7178, Train Loss: 0.0005683947238139808, Valid Loss: 0.000823910697363317\n",
      "Epoch: 7179, Train Loss: 0.0005680626491084695, Valid Loss: 0.0008234698325395584\n",
      "Epoch: 7180, Train Loss: 0.0005677308072336018, Valid Loss: 0.0008230225648730993\n",
      "Epoch: 7181, Train Loss: 0.0005673978594131768, Valid Loss: 0.0008225855999626219\n",
      "Epoch: 7182, Train Loss: 0.000567068753298372, Valid Loss: 0.0008221516036428511\n",
      "Epoch: 7183, Train Loss: 0.0005667376099154353, Valid Loss: 0.0008217160939238966\n",
      "Epoch: 7184, Train Loss: 0.0005664069904014468, Valid Loss: 0.0008212722605094314\n",
      "Epoch: 7185, Train Loss: 0.000566077942494303, Valid Loss: 0.0008208382059819996\n",
      "Epoch: 7186, Train Loss: 0.000565749011002481, Valid Loss: 0.0008204022306017578\n",
      "Epoch: 7187, Train Loss: 0.0005654189735651016, Valid Loss: 0.0008199595031328499\n",
      "Epoch: 7188, Train Loss: 0.0005650868406519294, Valid Loss: 0.0008195218397304416\n",
      "Epoch: 7189, Train Loss: 0.0005647580837830901, Valid Loss: 0.0008190925582312047\n",
      "Epoch: 7190, Train Loss: 0.0005644300254061818, Valid Loss: 0.0008186529739759862\n",
      "Epoch: 7191, Train Loss: 0.0005640994058921933, Valid Loss: 0.0008182164165191352\n",
      "Epoch: 7192, Train Loss: 0.0005637696594931185, Valid Loss: 0.0008177743293344975\n",
      "Epoch: 7193, Train Loss: 0.0005634406115859747, Valid Loss: 0.0008173449314199388\n",
      "Epoch: 7194, Train Loss: 0.0005631133099086583, Valid Loss: 0.0008169070351868868\n",
      "Epoch: 7195, Train Loss: 0.00056278525153175, Valid Loss: 0.0008164724567905068\n",
      "Epoch: 7196, Train Loss: 0.000562456960324198, Valid Loss: 0.0008160419529303908\n",
      "Epoch: 7197, Train Loss: 0.0005621284362860024, Valid Loss: 0.0008155999821610749\n",
      "Epoch: 7198, Train Loss: 0.0005618043942376971, Valid Loss: 0.0008151635411195457\n",
      "Epoch: 7199, Train Loss: 0.0005614742403849959, Valid Loss: 0.0008147296030074358\n",
      "Epoch: 7200, Train Loss: 0.0005611472297459841, Valid Loss: 0.0008143010200001299\n",
      "Epoch: 7201, Train Loss: 0.0005608210922218859, Valid Loss: 0.0008138633565977216\n",
      "Epoch: 7202, Train Loss: 0.0005604937323369086, Valid Loss: 0.0008134297095239162\n",
      "Epoch: 7203, Train Loss: 0.0005601664306595922, Valid Loss: 0.0008129936177283525\n",
      "Epoch: 7204, Train Loss: 0.0005598399438895285, Valid Loss: 0.0008125664317049086\n",
      "Epoch: 7205, Train Loss: 0.0005595139809884131, Valid Loss: 0.000812129583209753\n",
      "Epoch: 7206, Train Loss: 0.0005591880180872977, Valid Loss: 0.0008116986136883497\n",
      "Epoch: 7207, Train Loss: 0.0005588628118857741, Valid Loss: 0.0008112695650197566\n",
      "Epoch: 7208, Train Loss: 0.0005585364415310323, Valid Loss: 0.0008108349866233766\n",
      "Epoch: 7209, Train Loss: 0.0005582115845754743, Valid Loss: 0.0008104015723802149\n",
      "Epoch: 7210, Train Loss: 0.0005578859709203243, Valid Loss: 0.00080997304758057\n",
      "Epoch: 7211, Train Loss: 0.000557560590095818, Valid Loss: 0.0008095393422991037\n",
      "Epoch: 7212, Train Loss: 0.0005572358495555818, Valid Loss: 0.0008091103518381715\n",
      "Epoch: 7213, Train Loss: 0.0005569116328842938, Valid Loss: 0.000808680197224021\n",
      "Epoch: 7214, Train Loss: 0.0005565861938521266, Valid Loss: 0.000808250333648175\n",
      "Epoch: 7215, Train Loss: 0.0005562639562413096, Valid Loss: 0.0008078146493062377\n",
      "Epoch: 7216, Train Loss: 0.0005559374112635851, Valid Loss: 0.0008073854260146618\n",
      "Epoch: 7217, Train Loss: 0.0005556140094995499, Valid Loss: 0.0008069636533036828\n",
      "Epoch: 7218, Train Loss: 0.0005552880465984344, Valid Loss: 0.0008065355359576643\n",
      "Epoch: 7219, Train Loss: 0.0005549655179493129, Valid Loss: 0.0008060987456701696\n",
      "Epoch: 7220, Train Loss: 0.0005546417087316513, Valid Loss: 0.000805670628324151\n",
      "Epoch: 7221, Train Loss: 0.0005543188308365643, Valid Loss: 0.0008052440243773162\n",
      "Epoch: 7222, Train Loss: 0.0005539958947338164, Valid Loss: 0.0008048167801462114\n",
      "Epoch: 7223, Train Loss: 0.0005536742391996086, Valid Loss: 0.0008043806301429868\n",
      "Epoch: 7224, Train Loss: 0.0005533502553589642, Valid Loss: 0.0008039518725126982\n",
      "Epoch: 7225, Train Loss: 0.0005530293565243483, Valid Loss: 0.0008035299833863974\n",
      "Epoch: 7226, Train Loss: 0.0005527071189135313, Valid Loss: 0.0008031006436794996\n",
      "Epoch: 7227, Train Loss: 0.0005523851723410189, Valid Loss: 0.0008026708383113146\n",
      "Epoch: 7228, Train Loss: 0.0005520647391676903, Valid Loss: 0.0008022401598282158\n",
      "Epoch: 7229, Train Loss: 0.0005517415702342987, Valid Loss: 0.0008018179214559495\n",
      "Epoch: 7230, Train Loss: 0.0005514189251698554, Valid Loss: 0.0008013851474970579\n",
      "Epoch: 7231, Train Loss: 0.0005510997143574059, Valid Loss: 0.0008009595330804586\n",
      "Epoch: 7232, Train Loss: 0.0005507792811840773, Valid Loss: 0.0008005374693311751\n",
      "Epoch: 7233, Train Loss: 0.0005504568689502776, Valid Loss: 0.0008001125534065068\n",
      "Epoch: 7234, Train Loss: 0.0005501361447386444, Valid Loss: 0.0007996827480383217\n",
      "Epoch: 7235, Train Loss: 0.0005498163518495858, Valid Loss: 0.0007992636528797448\n",
      "Epoch: 7236, Train Loss: 0.0005494957440532744, Valid Loss: 0.0007988355355337262\n",
      "Epoch: 7237, Train Loss: 0.0005491771153174341, Valid Loss: 0.0007984053227119148\n",
      "Epoch: 7238, Train Loss: 0.0005488567985594273, Valid Loss: 0.0007979848887771368\n",
      "Epoch: 7239, Train Loss: 0.0005485349101945758, Valid Loss: 0.0007975664921104908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7240, Train Loss: 0.0005482165142893791, Valid Loss: 0.0007971394807100296\n",
      "Epoch: 7241, Train Loss: 0.0005478980019688606, Valid Loss: 0.0007967062410898507\n",
      "Epoch: 7242, Train Loss: 0.0005475798388943076, Valid Loss: 0.0007962799863889813\n",
      "Epoch: 7243, Train Loss: 0.0005472584743984044, Valid Loss: 0.0007958676433190703\n",
      "Epoch: 7244, Train Loss: 0.0005469423485919833, Valid Loss: 0.0007954413304105401\n",
      "Epoch: 7245, Train Loss: 0.0005466213333420455, Valid Loss: 0.0007950136787258089\n",
      "Epoch: 7246, Train Loss: 0.000546303519513458, Valid Loss: 0.0007945860852487385\n",
      "Epoch: 7247, Train Loss: 0.0005459844251163304, Valid Loss: 0.0007941692601889372\n",
      "Epoch: 7248, Train Loss: 0.0005456676008179784, Valid Loss: 0.0007937484770081937\n",
      "Epoch: 7249, Train Loss: 0.000545349670574069, Valid Loss: 0.0007933232118375599\n",
      "Epoch: 7250, Train Loss: 0.0005450313328765333, Valid Loss: 0.0007928985869511962\n",
      "Epoch: 7251, Train Loss: 0.0005447141593322158, Valid Loss: 0.0007924770470708609\n",
      "Epoch: 7252, Train Loss: 0.0005443962290883064, Valid Loss: 0.0007920614443719387\n",
      "Epoch: 7253, Train Loss: 0.0005440802196972072, Valid Loss: 0.000791636120993644\n",
      "Epoch: 7254, Train Loss: 0.000543764210306108, Valid Loss: 0.0007912164437584579\n",
      "Epoch: 7255, Train Loss: 0.0005434469203464687, Valid Loss: 0.0007907961262390018\n",
      "Epoch: 7256, Train Loss: 0.0005431302124634385, Valid Loss: 0.0007903770310804248\n",
      "Epoch: 7257, Train Loss: 0.0005428132717497647, Valid Loss: 0.0007899563061073422\n",
      "Epoch: 7258, Train Loss: 0.000542498950380832, Valid Loss: 0.0007895292364992201\n",
      "Epoch: 7259, Train Loss: 0.0005421833484433591, Valid Loss: 0.0007891141576692462\n",
      "Epoch: 7260, Train Loss: 0.0005418676882982254, Valid Loss: 0.0007886959356255829\n",
      "Epoch: 7261, Train Loss: 0.0005415502819232643, Valid Loss: 0.0007882742793299258\n",
      "Epoch: 7262, Train Loss: 0.0005412349128164351, Valid Loss: 0.0007878515170887113\n",
      "Epoch: 7263, Train Loss: 0.0005409204168245196, Valid Loss: 0.000787437311373651\n",
      "Epoch: 7264, Train Loss: 0.0005406056297942996, Valid Loss: 0.0007870199624449015\n",
      "Epoch: 7265, Train Loss: 0.0005402903771027923, Valid Loss: 0.0007865978986956179\n",
      "Epoch: 7266, Train Loss: 0.000539976404979825, Valid Loss: 0.0007861773483455181\n",
      "Epoch: 7267, Train Loss: 0.0005396624328568578, Valid Loss: 0.0007857642485760152\n",
      "Epoch: 7268, Train Loss: 0.0005393477622419596, Valid Loss: 0.0007853452698327601\n",
      "Epoch: 7269, Train Loss: 0.0005390350124798715, Valid Loss: 0.0007849332760088146\n",
      "Epoch: 7270, Train Loss: 0.0005387198179960251, Valid Loss: 0.0007845056243240833\n",
      "Epoch: 7271, Train Loss: 0.0005384070100262761, Valid Loss: 0.0007840905454941094\n",
      "Epoch: 7272, Train Loss: 0.0005380928050726652, Valid Loss: 0.0007836768636479974\n",
      "Epoch: 7273, Train Loss: 0.000537779473233968, Valid Loss: 0.0007832612609490752\n",
      "Epoch: 7274, Train Loss: 0.0005374671309255064, Valid Loss: 0.0007828365196473897\n",
      "Epoch: 7275, Train Loss: 0.0005371535080485046, Valid Loss: 0.0007824194617569447\n",
      "Epoch: 7276, Train Loss: 0.0005368407000787556, Valid Loss: 0.0007820112514309585\n",
      "Epoch: 7277, Train Loss: 0.0005365280085243285, Valid Loss: 0.000781596580054611\n",
      "Epoch: 7278, Train Loss: 0.0005362152005545795, Valid Loss: 0.0007811760297045112\n",
      "Epoch: 7279, Train Loss: 0.0005359029164537787, Valid Loss: 0.0007807574584148824\n",
      "Epoch: 7280, Train Loss: 0.0005355916218832135, Valid Loss: 0.0007803466287441552\n",
      "Epoch: 7281, Train Loss: 0.0005352795706130564, Valid Loss: 0.0007799320155754685\n",
      "Epoch: 7282, Train Loss: 0.0005349675775505602, Valid Loss: 0.0007795169949531555\n",
      "Epoch: 7283, Train Loss: 0.0005346583784557879, Valid Loss: 0.0007791054085828364\n",
      "Epoch: 7284, Train Loss: 0.0005343470256775618, Valid Loss: 0.0007786882924847305\n",
      "Epoch: 7285, Train Loss: 0.000534036778844893, Valid Loss: 0.0007782722823321819\n",
      "Epoch: 7286, Train Loss: 0.0005337250768207014, Valid Loss: 0.0007778588915243745\n",
      "Epoch: 7287, Train Loss: 0.0005334161687642336, Valid Loss: 0.0007774457335472107\n",
      "Epoch: 7288, Train Loss: 0.0005331035936251283, Valid Loss: 0.0007770308875478804\n",
      "Epoch: 7289, Train Loss: 0.0005327928229235113, Valid Loss: 0.0007766135968267918\n",
      "Epoch: 7290, Train Loss: 0.0005324831581674516, Valid Loss: 0.000776201777625829\n",
      "Epoch: 7291, Train Loss: 0.0005321737844496965, Valid Loss: 0.0007757917046546936\n",
      "Epoch: 7292, Train Loss: 0.0005318626062944531, Valid Loss: 0.0007753826794214547\n",
      "Epoch: 7293, Train Loss: 0.0005315524176694453, Valid Loss: 0.0007749673095531762\n",
      "Epoch: 7294, Train Loss: 0.0005312440334819257, Valid Loss: 0.0007745567127130926\n",
      "Epoch: 7295, Train Loss: 0.0005309341941028833, Valid Loss: 0.0007741453591734171\n",
      "Epoch: 7296, Train Loss: 0.0005306276143528521, Valid Loss: 0.0007737316191196442\n",
      "Epoch: 7297, Train Loss: 0.0005303185316734016, Valid Loss: 0.0007733140955679119\n",
      "Epoch: 7298, Train Loss: 0.000530008168425411, Valid Loss: 0.0007729059434495866\n",
      "Epoch: 7299, Train Loss: 0.0005296990857459605, Valid Loss: 0.0007724993629381061\n",
      "Epoch: 7300, Train Loss: 0.0005293914582580328, Valid Loss: 0.0007720836438238621\n",
      "Epoch: 7301, Train Loss: 0.0005290838307701051, Valid Loss: 0.0007716715335845947\n",
      "Epoch: 7302, Train Loss: 0.0005287752719596028, Valid Loss: 0.0007712620426900685\n",
      "Epoch: 7303, Train Loss: 0.000528469739947468, Valid Loss: 0.0007708556950092316\n",
      "Epoch: 7304, Train Loss: 0.000528159667737782, Valid Loss: 0.0007704473100602627\n",
      "Epoch: 7305, Train Loss: 0.00052785431034863, Valid Loss: 0.0007700370042584836\n",
      "Epoch: 7306, Train Loss: 0.000527544820215553, Valid Loss: 0.0007696259999647737\n",
      "Epoch: 7307, Train Loss: 0.000527240161318332, Valid Loss: 0.0007692159852012992\n",
      "Epoch: 7308, Train Loss: 0.0005269326502457261, Valid Loss: 0.0007688106852583587\n",
      "Epoch: 7309, Train Loss: 0.0005266258376650512, Valid Loss: 0.0007684066658839583\n",
      "Epoch: 7310, Train Loss: 0.00052631989819929, Valid Loss: 0.0007679929840378463\n",
      "Epoch: 7311, Train Loss: 0.0005260133184492588, Valid Loss: 0.0007675805827602744\n",
      "Epoch: 7312, Train Loss: 0.0005257080774754286, Valid Loss: 0.0007671752828173339\n",
      "Epoch: 7313, Train Loss: 0.0005254011484794319, Valid Loss: 0.0007667688187211752\n",
      "Epoch: 7314, Train Loss: 0.0005250946851447225, Valid Loss: 0.0007663590367883444\n",
      "Epoch: 7315, Train Loss: 0.000524790259078145, Valid Loss: 0.0007659491966478527\n",
      "Epoch: 7316, Train Loss: 0.0005244856583885849, Valid Loss: 0.0007655483204871416\n",
      "Epoch: 7317, Train Loss: 0.0005241800099611282, Valid Loss: 0.000765141798183322\n",
      "Epoch: 7318, Train Loss: 0.0005238748854026198, Valid Loss: 0.0007647316087968647\n",
      "Epoch: 7319, Train Loss: 0.0005235714488662779, Valid Loss: 0.0007643250282853842\n",
      "Epoch: 7320, Train Loss: 0.0005232669645920396, Valid Loss: 0.0007639193790964782\n",
      "Epoch: 7321, Train Loss: 0.0005229614907875657, Valid Loss: 0.0007635090732946992\n",
      "Epoch: 7322, Train Loss: 0.0005226574139669538, Valid Loss: 0.0007631038897670805\n",
      "Epoch: 7323, Train Loss: 0.0005223517655394971, Valid Loss: 0.0007627060986123979\n",
      "Epoch: 7324, Train Loss: 0.0005220499006099999, Valid Loss: 0.0007623048732057214\n",
      "Epoch: 7325, Train Loss: 0.0005217454163357615, Valid Loss: 0.0007618939271196723\n",
      "Epoch: 7326, Train Loss: 0.0005214422708377242, Valid Loss: 0.0007614875794388354\n",
      "Epoch: 7327, Train Loss: 0.0005211398238316178, Valid Loss: 0.0007610899046994746\n",
      "Epoch: 7328, Train Loss: 0.000520837027579546, Valid Loss: 0.0007606882718391716\n",
      "Epoch: 7329, Train Loss: 0.0005205335328355432, Valid Loss: 0.0007602727273479104\n",
      "Epoch: 7330, Train Loss: 0.0005202317843213677, Valid Loss: 0.0007598702795803547\n",
      "Epoch: 7331, Train Loss: 0.0005199288134463131, Valid Loss: 0.0007594740600325167\n",
      "Epoch: 7332, Train Loss: 0.0005196260171942413, Valid Loss: 0.0007590656750835478\n",
      "Epoch: 7333, Train Loss: 0.000519324152264744, Valid Loss: 0.0007586620049551129\n",
      "Epoch: 7334, Train Loss: 0.0005190217634662986, Valid Loss: 0.0007582607213407755\n",
      "Epoch: 7335, Train Loss: 0.0005187198985368013, Valid Loss: 0.000757858157157898\n",
      "Epoch: 7336, Train Loss: 0.0005184170440770686, Valid Loss: 0.0007574560586363077\n",
      "Epoch: 7337, Train Loss: 0.000518114713486284, Valid Loss: 0.0007570574525743723\n",
      "Epoch: 7338, Train Loss: 0.0005178172141313553, Valid Loss: 0.0007566533167846501\n",
      "Epoch: 7339, Train Loss: 0.0005175138358026743, Valid Loss: 0.0007562476675957441\n",
      "Epoch: 7340, Train Loss: 0.0005172128439880908, Valid Loss: 0.0007558460347354412\n",
      "Epoch: 7341, Train Loss: 0.0005169134237803519, Valid Loss: 0.0007554495823569596\n",
      "Epoch: 7342, Train Loss: 0.0005166112096048892, Valid Loss: 0.0007550482405349612\n",
      "Epoch: 7343, Train Loss: 0.0005163111491128802, Valid Loss: 0.000754646142013371\n",
      "Epoch: 7344, Train Loss: 0.0005160110304132104, Valid Loss: 0.000754243868868798\n",
      "Epoch: 7345, Train Loss: 0.0005157102714292705, Valid Loss: 0.0007538442150689662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7346, Train Loss: 0.000515410618390888, Valid Loss: 0.0007534439209848642\n",
      "Epoch: 7347, Train Loss: 0.0005151123041287065, Valid Loss: 0.0007530386792495847\n",
      "Epoch: 7348, Train Loss: 0.0005148123018443584, Valid Loss: 0.000752642285078764\n",
      "Epoch: 7349, Train Loss: 0.0005145127652212977, Valid Loss: 0.0007522450177930295\n",
      "Epoch: 7350, Train Loss: 0.0005142138106748462, Valid Loss: 0.0007518409402109683\n",
      "Epoch: 7351, Train Loss: 0.0005139153217896819, Valid Loss: 0.0007514436729252338\n",
      "Epoch: 7352, Train Loss: 0.000513616600073874, Valid Loss: 0.0007510440773330629\n",
      "Epoch: 7353, Train Loss: 0.0005133170052431524, Valid Loss: 0.0007506468100473285\n",
      "Epoch: 7354, Train Loss: 0.0005130181671120226, Valid Loss: 0.0007502485532313585\n",
      "Epoch: 7355, Train Loss: 0.0005127213662490249, Valid Loss: 0.0007498487830162048\n",
      "Epoch: 7356, Train Loss: 0.0005124249146319926, Valid Loss: 0.0007494543679058552\n",
      "Epoch: 7357, Train Loss: 0.0005121254944242537, Valid Loss: 0.0007490584393963218\n",
      "Epoch: 7358, Train Loss: 0.0005118279368616641, Valid Loss: 0.0007486548856832087\n",
      "Epoch: 7359, Train Loss: 0.000511531310621649, Valid Loss: 0.0007482596556656063\n",
      "Epoch: 7360, Train Loss: 0.0005112325889058411, Valid Loss: 0.0007478632614947855\n",
      "Epoch: 7361, Train Loss: 0.0005109341000206769, Valid Loss: 0.0007474645972251892\n",
      "Epoch: 7362, Train Loss: 0.0005106386379338801, Valid Loss: 0.0007470699492841959\n",
      "Epoch: 7363, Train Loss: 0.0005103418370708823, Valid Loss: 0.0007466750685125589\n",
      "Epoch: 7364, Train Loss: 0.0005100462585687637, Valid Loss: 0.0007462744251824915\n",
      "Epoch: 7365, Train Loss: 0.0005097502726130188, Valid Loss: 0.0007458843756467104\n",
      "Epoch: 7366, Train Loss: 0.0005094521911814809, Valid Loss: 0.0007454854203388095\n",
      "Epoch: 7367, Train Loss: 0.0005091550410725176, Valid Loss: 0.0007450844859704375\n",
      "Epoch: 7368, Train Loss: 0.0005088603356853127, Valid Loss: 0.0007446905365213752\n",
      "Epoch: 7369, Train Loss: 0.0005085637676529586, Valid Loss: 0.0007442992064170539\n",
      "Epoch: 7370, Train Loss: 0.0005082670832052827, Valid Loss: 0.0007439061882905662\n",
      "Epoch: 7371, Train Loss: 0.0005079729598946869, Valid Loss: 0.0007435065344907343\n",
      "Epoch: 7372, Train Loss: 0.0005076801753602922, Valid Loss: 0.0007431102567352355\n",
      "Epoch: 7373, Train Loss: 0.0005073826177977026, Valid Loss: 0.0007427166565321386\n",
      "Epoch: 7374, Train Loss: 0.000507089716847986, Valid Loss: 0.0007423271308653057\n",
      "Epoch: 7375, Train Loss: 0.000506793090607971, Valid Loss: 0.0007419291068799794\n",
      "Epoch: 7376, Train Loss: 0.0005064991419203579, Valid Loss: 0.0007415315485559404\n",
      "Epoch: 7377, Train Loss: 0.0005062041454948485, Valid Loss: 0.0007411388796754181\n",
      "Epoch: 7378, Train Loss: 0.0005059106042608619, Valid Loss: 0.0007407491793856025\n",
      "Epoch: 7379, Train Loss: 0.0005056156078353524, Valid Loss: 0.000740355986636132\n",
      "Epoch: 7380, Train Loss: 0.0005053238128311932, Valid Loss: 0.000739968498237431\n",
      "Epoch: 7381, Train Loss: 0.0005050296313129365, Valid Loss: 0.0007395746069960296\n",
      "Epoch: 7382, Train Loss: 0.0005047352169640362, Valid Loss: 0.0007391728577204049\n",
      "Epoch: 7383, Train Loss: 0.0005044422578066587, Valid Loss: 0.000738783972337842\n",
      "Epoch: 7384, Train Loss: 0.0005041487165726721, Valid Loss: 0.0007383963675238192\n",
      "Epoch: 7385, Train Loss: 0.0005038570379838347, Valid Loss: 0.0007380077149719\n",
      "Epoch: 7386, Train Loss: 0.0005035634385421872, Valid Loss: 0.000737610156647861\n",
      "Epoch: 7387, Train Loss: 0.0005032711778767407, Valid Loss: 0.0007372183608822525\n",
      "Epoch: 7388, Train Loss: 0.0005029777530580759, Valid Loss: 0.0007368326769210398\n",
      "Epoch: 7389, Train Loss: 0.0005026860744692385, Valid Loss: 0.0007364460034295917\n",
      "Epoch: 7390, Train Loss: 0.0005023955018259585, Valid Loss: 0.0007360458257608116\n",
      "Epoch: 7391, Train Loss: 0.0005021016695536673, Valid Loss: 0.0007356562418863177\n",
      "Epoch: 7392, Train Loss: 0.0005018112133257091, Valid Loss: 0.0007352664833888412\n",
      "Epoch: 7393, Train Loss: 0.0005015200586058199, Valid Loss: 0.0007348849903792143\n",
      "Epoch: 7394, Train Loss: 0.0005012270412407815, Valid Loss: 0.0007344827172346413\n",
      "Epoch: 7395, Train Loss: 0.0005009366432204843, Valid Loss: 0.000734105531591922\n",
      "Epoch: 7396, Train Loss: 0.0005006453138776124, Valid Loss: 0.0007337061106227338\n",
      "Epoch: 7397, Train Loss: 0.0005003555561415851, Valid Loss: 0.0007333233952522278\n",
      "Epoch: 7398, Train Loss: 0.0005000646924600005, Valid Loss: 0.0007329300278797746\n",
      "Epoch: 7399, Train Loss: 0.0004997753421775997, Valid Loss: 0.0007325499318540096\n",
      "Epoch: 7400, Train Loss: 0.0004994840128347278, Valid Loss: 0.0007321536540985107\n",
      "Epoch: 7401, Train Loss: 0.0004991933237761259, Valid Loss: 0.0007317694835364819\n",
      "Epoch: 7402, Train Loss: 0.0004989047884009778, Valid Loss: 0.0007313688984140754\n",
      "Epoch: 7403, Train Loss: 0.000498616136610508, Valid Loss: 0.0007309913635253906\n",
      "Epoch: 7404, Train Loss: 0.0004983243998140097, Valid Loss: 0.0007305965409614146\n",
      "Epoch: 7405, Train Loss: 0.0004980379599146545, Valid Loss: 0.0007302252925001085\n",
      "Epoch: 7406, Train Loss: 0.0004977491917088628, Valid Loss: 0.0007298263953998685\n",
      "Epoch: 7407, Train Loss: 0.0004974595503881574, Valid Loss: 0.0007294478127732873\n",
      "Epoch: 7408, Train Loss: 0.0004971716552972794, Valid Loss: 0.0007290472276508808\n",
      "Epoch: 7409, Train Loss: 0.0004968838184140623, Valid Loss: 0.000728677783627063\n",
      "Epoch: 7410, Train Loss: 0.0004965951084159315, Valid Loss: 0.0007282780134119093\n",
      "Epoch: 7411, Train Loss: 0.000496306165587157, Valid Loss: 0.000727902224753052\n",
      "Epoch: 7412, Train Loss: 0.0004960191436111927, Valid Loss: 0.0007275083917193115\n",
      "Epoch: 7413, Train Loss: 0.0004957301425747573, Valid Loss: 0.0007271382492035627\n",
      "Epoch: 7414, Train Loss: 0.0004954430623911321, Valid Loss: 0.0007267309702001512\n",
      "Epoch: 7415, Train Loss: 0.0004951552837155759, Valid Loss: 0.0007263622246682644\n",
      "Epoch: 7416, Train Loss: 0.0004948689602315426, Valid Loss: 0.0007259660051204264\n",
      "Epoch: 7417, Train Loss: 0.0004945811233483255, Valid Loss: 0.0007255941163748503\n",
      "Epoch: 7418, Train Loss: 0.0004942946252413094, Valid Loss: 0.00072519137756899\n",
      "Epoch: 7419, Train Loss: 0.0004940065555274487, Valid Loss: 0.0007248201291076839\n",
      "Epoch: 7420, Train Loss: 0.000493719067890197, Valid Loss: 0.0007244230946525931\n",
      "Epoch: 7421, Train Loss: 0.0004934321623295546, Valid Loss: 0.000724047189578414\n",
      "Epoch: 7422, Train Loss: 0.0004931440344080329, Valid Loss: 0.000723649631254375\n",
      "Epoch: 7423, Train Loss: 0.0004928561393171549, Valid Loss: 0.0007232797215692699\n",
      "Epoch: 7424, Train Loss: 0.0004925698740407825, Valid Loss: 0.0007228822796605527\n",
      "Epoch: 7425, Train Loss: 0.0004922842490486801, Valid Loss: 0.00072250678204\n",
      "Epoch: 7426, Train Loss: 0.000491997052449733, Valid Loss: 0.0007221134728752077\n",
      "Epoch: 7427, Train Loss: 0.0004917088663205504, Valid Loss: 0.0007217312813736498\n",
      "Epoch: 7428, Train Loss: 0.0004914255114272237, Valid Loss: 0.0007213426870293915\n",
      "Epoch: 7429, Train Loss: 0.0004911381984129548, Valid Loss: 0.0007209633477032185\n",
      "Epoch: 7430, Train Loss: 0.000490852864459157, Valid Loss: 0.0007205851143226027\n",
      "Epoch: 7431, Train Loss: 0.0004905668902210891, Valid Loss: 0.0007201978005468845\n",
      "Epoch: 7432, Train Loss: 0.0004902827786281705, Valid Loss: 0.0007198096718639135\n",
      "Epoch: 7433, Train Loss: 0.0004899977357126772, Valid Loss: 0.0007194338249973953\n",
      "Epoch: 7434, Train Loss: 0.0004897139733657241, Valid Loss: 0.0007190545438788831\n",
      "Epoch: 7435, Train Loss: 0.0004894298617728055, Valid Loss: 0.0007186748553067446\n",
      "Epoch: 7436, Train Loss: 0.0004891454591415823, Valid Loss: 0.0007182931294664741\n",
      "Epoch: 7437, Train Loss: 0.0004888635012321174, Valid Loss: 0.0007179143140092492\n",
      "Epoch: 7438, Train Loss: 0.0004885785165242851, Valid Loss: 0.0007175329956226051\n",
      "Epoch: 7439, Train Loss: 0.000488294055685401, Valid Loss: 0.000717148941475898\n",
      "Epoch: 7440, Train Loss: 0.00048801174852997065, Valid Loss: 0.0007167782168835402\n",
      "Epoch: 7441, Train Loss: 0.0004877289175055921, Valid Loss: 0.0007163949776440859\n",
      "Epoch: 7442, Train Loss: 0.00048744495143182576, Valid Loss: 0.0007160173263400793\n",
      "Epoch: 7443, Train Loss: 0.0004871638084296137, Valid Loss: 0.0007156384526751935\n",
      "Epoch: 7444, Train Loss: 0.0004868792020715773, Valid Loss: 0.0007152690086513758\n",
      "Epoch: 7445, Train Loss: 0.0004865958180744201, Valid Loss: 0.0007148837903514504\n",
      "Epoch: 7446, Train Loss: 0.0004863140929955989, Valid Loss: 0.0007145042764022946\n",
      "Epoch: 7447, Train Loss: 0.00048603047616779804, Valid Loss: 0.0007141262758523226\n",
      "Epoch: 7448, Train Loss: 0.0004857484018430114, Valid Loss: 0.0007137494394555688\n",
      "Epoch: 7449, Train Loss: 0.00048546690959483385, Valid Loss: 0.0007133632316254079\n",
      "Epoch: 7450, Train Loss: 0.00048518567928113043, Valid Loss: 0.0007129908190108836\n",
      "Epoch: 7451, Train Loss: 0.0004849028482567519, Valid Loss: 0.0007126147393137217\n",
      "Epoch: 7452, Train Loss: 0.0004846222582273185, Valid Loss: 0.0007122388342395425\n",
      "Epoch: 7453, Train Loss: 0.00048434099880978465, Valid Loss: 0.0007118545472621918\n",
      "Epoch: 7454, Train Loss: 0.0004840600595343858, Valid Loss: 0.0007114814361557364\n",
      "Epoch: 7455, Train Loss: 0.00048378005158156157, Valid Loss: 0.0007111009326763451\n",
      "Epoch: 7456, Train Loss: 0.00048349826829507947, Valid Loss: 0.0007107252022251487\n",
      "Epoch: 7457, Train Loss: 0.0004832171543966979, Valid Loss: 0.0007103494717739522\n",
      "Epoch: 7458, Train Loss: 0.0004829368554055691, Valid Loss: 0.0007099665235728025\n",
      "Epoch: 7459, Train Loss: 0.00048265725490637124, Valid Loss: 0.0007095903856679797\n",
      "Epoch: 7460, Train Loss: 0.00048237666487693787, Valid Loss: 0.0007092172745615244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7461, Train Loss: 0.00048209563829004765, Valid Loss: 0.0007088466081768274\n",
      "Epoch: 7462, Train Loss: 0.000481816241517663, Valid Loss: 0.0007084629032760859\n",
      "Epoch: 7463, Train Loss: 0.0004815376887563616, Valid Loss: 0.0007080851355567575\n",
      "Epoch: 7464, Train Loss: 0.00048125709872692823, Valid Loss: 0.0007077155751176178\n",
      "Epoch: 7465, Train Loss: 0.00048097758553922176, Valid Loss: 0.0007073447923175991\n",
      "Epoch: 7466, Train Loss: 0.0004806993529200554, Valid Loss: 0.0007069626590237021\n",
      "Epoch: 7467, Train Loss: 0.0004804215859621763, Valid Loss: 0.0007065862882882357\n",
      "Epoch: 7468, Train Loss: 0.0004801429167855531, Valid Loss: 0.000706214748788625\n",
      "Epoch: 7469, Train Loss: 0.0004798640438821167, Valid Loss: 0.0007058413466438651\n",
      "Epoch: 7470, Train Loss: 0.0004795832501258701, Valid Loss: 0.0007054695743136108\n",
      "Epoch: 7471, Train Loss: 0.0004793071129824966, Valid Loss: 0.0007050941931083798\n",
      "Epoch: 7472, Train Loss: 0.0004790279781445861, Valid Loss: 0.0007047204417176545\n",
      "Epoch: 7473, Train Loss: 0.0004787494835909456, Valid Loss: 0.0007043491350486875\n",
      "Epoch: 7474, Train Loss: 0.0004784729680977762, Valid Loss: 0.0007039739284664392\n",
      "Epoch: 7475, Train Loss: 0.0004781951429322362, Valid Loss: 0.0007036025053821504\n",
      "Epoch: 7476, Train Loss: 0.00047791656106710434, Valid Loss: 0.0007032291614450514\n",
      "Epoch: 7477, Train Loss: 0.00047764007467776537, Valid Loss: 0.000702851393725723\n",
      "Epoch: 7478, Train Loss: 0.00047736099804751575, Valid Loss: 0.0007024761289358139\n",
      "Epoch: 7479, Train Loss: 0.0004770849191118032, Valid Loss: 0.0007021151250228286\n",
      "Epoch: 7480, Train Loss: 0.0004768084909301251, Valid Loss: 0.0007017393363639712\n",
      "Epoch: 7481, Train Loss: 0.00047653281944803894, Valid Loss: 0.000701366865541786\n",
      "Epoch: 7482, Train Loss: 0.00047625592560507357, Valid Loss: 0.0007009969558566809\n",
      "Epoch: 7483, Train Loss: 0.0004759799048770219, Valid Loss: 0.0007006326341070235\n",
      "Epoch: 7484, Train Loss: 0.0004757041751872748, Valid Loss: 0.0007002559141255915\n",
      "Epoch: 7485, Train Loss: 0.00047542701940983534, Valid Loss: 0.0006998776807449758\n",
      "Epoch: 7486, Train Loss: 0.00047515108599327505, Valid Loss: 0.0006995134172029793\n",
      "Epoch: 7487, Train Loss: 0.00047487716074101627, Valid Loss: 0.0006991440895944834\n",
      "Epoch: 7488, Train Loss: 0.00047459988854825497, Valid Loss: 0.0006987692322582006\n",
      "Epoch: 7489, Train Loss: 0.00047432532301172614, Valid Loss: 0.0006984044448472559\n",
      "Epoch: 7490, Train Loss: 0.0004740500880870968, Valid Loss: 0.0006980358739383519\n",
      "Epoch: 7491, Train Loss: 0.00047377555165439844, Valid Loss: 0.0006976641016080976\n",
      "Epoch: 7492, Train Loss: 0.0004734995018225163, Valid Loss: 0.0006972941919229925\n",
      "Epoch: 7493, Train Loss: 0.0004732241795863956, Valid Loss: 0.0006969259702600539\n",
      "Epoch: 7494, Train Loss: 0.00047295173862949014, Valid Loss: 0.0006965547217987478\n",
      "Epoch: 7495, Train Loss: 0.00047267545596696436, Valid Loss: 0.000696180562954396\n",
      "Epoch: 7496, Train Loss: 0.0004724023165181279, Valid Loss: 0.0006958175217732787\n",
      "Epoch: 7497, Train Loss: 0.0004721276927739382, Valid Loss: 0.0006954465643502772\n",
      "Epoch: 7498, Train Loss: 0.00047185414587147534, Valid Loss: 0.000695078051649034\n",
      "Epoch: 7499, Train Loss: 0.00047158062807284296, Valid Loss: 0.0006947104702703655\n",
      "Epoch: 7500, Train Loss: 0.00047130772145465016, Valid Loss: 0.0006943474872969091\n",
      "Epoch: 7501, Train Loss: 0.00047103429096750915, Valid Loss: 0.0006939772283658385\n",
      "Epoch: 7502, Train Loss: 0.0004707598709501326, Valid Loss: 0.0006936077843420208\n",
      "Epoch: 7503, Train Loss: 0.0004704904567915946, Valid Loss: 0.0006932372343726456\n",
      "Epoch: 7504, Train Loss: 0.0004702170263044536, Valid Loss: 0.0006928684306330979\n",
      "Epoch: 7505, Train Loss: 0.00046994269359856844, Valid Loss: 0.0006925024790689349\n",
      "Epoch: 7506, Train Loss: 0.00046967004891484976, Valid Loss: 0.0006921402527950704\n",
      "Epoch: 7507, Train Loss: 0.00046939888852648437, Valid Loss: 0.0006917759892530739\n",
      "Epoch: 7508, Train Loss: 0.00046912606921978295, Valid Loss: 0.0006914066034369171\n",
      "Epoch: 7509, Train Loss: 0.00046885336632840335, Valid Loss: 0.0006910404772497714\n",
      "Epoch: 7510, Train Loss: 0.0004685805179178715, Valid Loss: 0.000690678134560585\n",
      "Epoch: 7511, Train Loss: 0.0004683099687099457, Valid Loss: 0.0006903056637383997\n",
      "Epoch: 7512, Train Loss: 0.0004680406127590686, Valid Loss: 0.0006899394211359322\n",
      "Epoch: 7513, Train Loss: 0.0004677669203374535, Valid Loss: 0.0006895789410918951\n",
      "Epoch: 7514, Train Loss: 0.0004674965748563409, Valid Loss: 0.0006892178789712489\n",
      "Epoch: 7515, Train Loss: 0.00046722457045689225, Valid Loss: 0.0006888493662700057\n",
      "Epoch: 7516, Train Loss: 0.00046695402124896646, Valid Loss: 0.0006884869653731585\n",
      "Epoch: 7517, Train Loss: 0.00046668300637975335, Valid Loss: 0.000688117987010628\n",
      "Epoch: 7518, Train Loss: 0.0004664112057071179, Valid Loss: 0.0006877516279928386\n",
      "Epoch: 7519, Train Loss: 0.000466141413198784, Valid Loss: 0.0006873924285173416\n",
      "Epoch: 7520, Train Loss: 0.00046587237739004195, Valid Loss: 0.0006870291545055807\n",
      "Epoch: 7521, Train Loss: 0.0004655995580833405, Valid Loss: 0.0006866576732136309\n",
      "Epoch: 7522, Train Loss: 0.00046532973647117615, Valid Loss: 0.0006862956797704101\n",
      "Epoch: 7523, Train Loss: 0.00046505974023602903, Valid Loss: 0.0006859363056719303\n",
      "Epoch: 7524, Train Loss: 0.0004647928581107408, Valid Loss: 0.000685571227222681\n",
      "Epoch: 7525, Train Loss: 0.00046452120295725763, Valid Loss: 0.0006852049264125526\n",
      "Epoch: 7526, Train Loss: 0.0004642530402634293, Valid Loss: 0.0006848446209914982\n",
      "Epoch: 7527, Train Loss: 0.000463984499219805, Valid Loss: 0.0006844846066087484\n",
      "Epoch: 7528, Train Loss: 0.0004637147067114711, Valid Loss: 0.0006841197609901428\n",
      "Epoch: 7529, Train Loss: 0.000463446689536795, Valid Loss: 0.0006837591645307839\n",
      "Epoch: 7530, Train Loss: 0.0004631779156625271, Valid Loss: 0.0006834006053395569\n",
      "Epoch: 7531, Train Loss: 0.0004629099275916815, Valid Loss: 0.0006830380298197269\n",
      "Epoch: 7532, Train Loss: 0.0004626428126357496, Valid Loss: 0.0006826745811849833\n",
      "Epoch: 7533, Train Loss: 0.0004623734566848725, Valid Loss: 0.0006823132280260324\n",
      "Epoch: 7534, Train Loss: 0.00046210462460294366, Valid Loss: 0.000681958394125104\n",
      "Epoch: 7535, Train Loss: 0.0004618362581823021, Valid Loss: 0.0006815976812504232\n",
      "Epoch: 7536, Train Loss: 0.00046157033648341894, Valid Loss: 0.0006812268984504044\n",
      "Epoch: 7537, Train Loss: 0.00046130368718877435, Valid Loss: 0.0006808734033256769\n",
      "Epoch: 7538, Train Loss: 0.0004610337200574577, Valid Loss: 0.0006805174634791911\n",
      "Epoch: 7539, Train Loss: 0.0004607671871781349, Valid Loss: 0.0006801578565500677\n",
      "Epoch: 7540, Train Loss: 0.00046050071250647306, Valid Loss: 0.0006797920796088874\n",
      "Epoch: 7541, Train Loss: 0.0004602339759003371, Valid Loss: 0.0006794354994781315\n",
      "Epoch: 7542, Train Loss: 0.0004599654639605433, Valid Loss: 0.0006790765910409391\n",
      "Epoch: 7543, Train Loss: 0.00045969971688464284, Valid Loss: 0.0006787133170291781\n",
      "Epoch: 7544, Train Loss: 0.0004594340280164033, Valid Loss: 0.000678354874253273\n",
      "Epoch: 7545, Train Loss: 0.00045916636008769274, Valid Loss: 0.0006780023104511201\n",
      "Epoch: 7546, Train Loss: 0.00045890072942711413, Valid Loss: 0.0006776407244615257\n",
      "Epoch: 7547, Train Loss: 0.0004586334980558604, Valid Loss: 0.0006772788474336267\n",
      "Epoch: 7548, Train Loss: 0.0004583676054608077, Valid Loss: 0.0006769225001335144\n",
      "Epoch: 7549, Train Loss: 0.0004581031098496169, Valid Loss: 0.0006765691796317697\n",
      "Epoch: 7550, Train Loss: 0.0004578365769702941, Valid Loss: 0.0006762077682651579\n",
      "Epoch: 7551, Train Loss: 0.00045757254702039063, Valid Loss: 0.0006758477538824081\n",
      "Epoch: 7552, Train Loss: 0.0004573051701299846, Valid Loss: 0.0006754914065822959\n",
      "Epoch: 7553, Train Loss: 0.00045704146032221615, Valid Loss: 0.0006751306354999542\n",
      "Epoch: 7554, Train Loss: 0.00045677722664549947, Valid Loss: 0.0006747753941453993\n",
      "Epoch: 7555, Train Loss: 0.000456510839285329, Valid Loss: 0.0006744214333593845\n",
      "Epoch: 7556, Train Loss: 0.000456247478723526, Valid Loss: 0.000674065260682255\n",
      "Epoch: 7557, Train Loss: 0.0004559827211778611, Valid Loss: 0.0006737050134688616\n",
      "Epoch: 7558, Train Loss: 0.0004557179054245353, Valid Loss: 0.0006733467453159392\n",
      "Epoch: 7559, Train Loss: 0.00045545509783551097, Valid Loss: 0.0006729891756549478\n",
      "Epoch: 7560, Train Loss: 0.0004551912425085902, Valid Loss: 0.0006726360879838467\n",
      "Epoch: 7561, Train Loss: 0.0004549271834548563, Valid Loss: 0.0006722831749357283\n",
      "Epoch: 7562, Train Loss: 0.0004546644340734929, Valid Loss: 0.0006719250231981277\n",
      "Epoch: 7563, Train Loss: 0.00045440185931511223, Valid Loss: 0.0006715664057992399\n",
      "Epoch: 7564, Train Loss: 0.000454137334600091, Valid Loss: 0.0006712137837894261\n",
      "Epoch: 7565, Train Loss: 0.0004538736247923225, Valid Loss: 0.0006708596483804286\n",
      "Epoch: 7566, Train Loss: 0.000453611311968416, Valid Loss: 0.0006704995175823569\n",
      "Epoch: 7567, Train Loss: 0.0004533483588602394, Valid Loss: 0.0006701441598124802\n",
      "Epoch: 7568, Train Loss: 0.00045308598782867193, Valid Loss: 0.0006697935750707984\n",
      "Epoch: 7569, Train Loss: 0.0004528252175077796, Valid Loss: 0.0006694374023936689\n",
      "Epoch: 7570, Train Loss: 0.0004525617405306548, Valid Loss: 0.000669084198307246\n",
      "Epoch: 7571, Train Loss: 0.0004522979143075645, Valid Loss: 0.0006687295972369611\n",
      "Epoch: 7572, Train Loss: 0.00045203714398667216, Valid Loss: 0.0006683770334348083\n",
      "Epoch: 7573, Train Loss: 0.00045177488937042654, Valid Loss: 0.0006680222577415407\n",
      "Epoch: 7574, Train Loss: 0.00045151353697292507, Valid Loss: 0.0006676691700704396\n",
      "Epoch: 7575, Train Loss: 0.00045125067117623985, Valid Loss: 0.0006673192256130278\n",
      "Epoch: 7576, Train Loss: 0.00045099089038558304, Valid Loss: 0.0006669686990790069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7577, Train Loss: 0.0004507306148298085, Valid Loss: 0.0006666083354502916\n",
      "Epoch: 7578, Train Loss: 0.0004504689131863415, Valid Loss: 0.0006662547821179032\n",
      "Epoch: 7579, Train Loss: 0.00045020674588158727, Valid Loss: 0.000665908504743129\n",
      "Epoch: 7580, Train Loss: 0.0004499477508943528, Valid Loss: 0.0006655578035861254\n",
      "Epoch: 7581, Train Loss: 0.00044968549627810717, Valid Loss: 0.0006652025622315705\n",
      "Epoch: 7582, Train Loss: 0.0004494253662414849, Valid Loss: 0.0006648520356975496\n",
      "Epoch: 7583, Train Loss: 0.00044916485785506666, Valid Loss: 0.0006645034300163388\n",
      "Epoch: 7584, Train Loss: 0.0004489042330533266, Valid Loss: 0.000664152146782726\n",
      "Epoch: 7585, Train Loss: 0.0004486442485358566, Valid Loss: 0.0006637956248596311\n",
      "Epoch: 7586, Train Loss: 0.00044838408939540386, Valid Loss: 0.0006634488818235695\n",
      "Epoch: 7587, Train Loss: 0.000448125007096678, Valid Loss: 0.0006630980060435832\n",
      "Epoch: 7588, Train Loss: 0.0004478654882404953, Valid Loss: 0.0006627498660236597\n",
      "Epoch: 7589, Train Loss: 0.000447605736553669, Valid Loss: 0.0006624006200581789\n",
      "Epoch: 7590, Train Loss: 0.00044734656694345176, Valid Loss: 0.0006620465428568423\n",
      "Epoch: 7591, Train Loss: 0.0004470885905902833, Valid Loss: 0.0006617030594497919\n",
      "Epoch: 7592, Train Loss: 0.00044682910083793104, Valid Loss: 0.0006613513687625527\n",
      "Epoch: 7593, Train Loss: 0.00044656932004727423, Valid Loss: 0.0006609983975067735\n",
      "Epoch: 7594, Train Loss: 0.00044631227501668036, Valid Loss: 0.0006606503739021719\n",
      "Epoch: 7595, Train Loss: 0.00044605403672903776, Valid Loss: 0.0006602986832149327\n",
      "Epoch: 7596, Train Loss: 0.00044579507084563375, Valid Loss: 0.0006599487387575209\n",
      "Epoch: 7597, Train Loss: 0.0004455370071809739, Valid Loss: 0.0006596014136448503\n",
      "Epoch: 7598, Train Loss: 0.0004452806315384805, Valid Loss: 0.0006592537392862141\n",
      "Epoch: 7599, Train Loss: 0.00044502070522867143, Valid Loss: 0.0006589019321836531\n",
      "Epoch: 7600, Train Loss: 0.00044476380571722984, Valid Loss: 0.000658552919048816\n",
      "Epoch: 7601, Train Loss: 0.0004445061204023659, Valid Loss: 0.0006582086789421737\n",
      "Epoch: 7602, Train Loss: 0.00044424826046451926, Valid Loss: 0.0006578580942004919\n",
      "Epoch: 7603, Train Loss: 0.00044399226317182183, Valid Loss: 0.0006575108855031431\n",
      "Epoch: 7604, Train Loss: 0.0004437345778569579, Valid Loss: 0.0006571643170900643\n",
      "Epoch: 7605, Train Loss: 0.0004434767470229417, Valid Loss: 0.0006568151875399053\n",
      "Epoch: 7606, Train Loss: 0.000443221622845158, Valid Loss: 0.0006564687355421484\n",
      "Epoch: 7607, Train Loss: 0.0004429635009728372, Valid Loss: 0.0006561298505403101\n",
      "Epoch: 7608, Train Loss: 0.0004427066014613956, Valid Loss: 0.0006557800807058811\n",
      "Epoch: 7609, Train Loss: 0.00044245109893381596, Valid Loss: 0.0006554353167302907\n",
      "Epoch: 7610, Train Loss: 0.00044219294795766473, Valid Loss: 0.0006550808902829885\n",
      "Epoch: 7611, Train Loss: 0.00044193933717906475, Valid Loss: 0.0006547404336743057\n",
      "Epoch: 7612, Train Loss: 0.0004416833398863673, Valid Loss: 0.0006543929921463132\n",
      "Epoch: 7613, Train Loss: 0.00044142737169750035, Valid Loss: 0.0006540492177009583\n",
      "Epoch: 7614, Train Loss: 0.00044117201468907297, Valid Loss: 0.000653703638818115\n",
      "Epoch: 7615, Train Loss: 0.0004409154353197664, Valid Loss: 0.0006533609121106565\n",
      "Epoch: 7616, Train Loss: 0.00044066214468330145, Valid Loss: 0.0006530105601996183\n",
      "Epoch: 7617, Train Loss: 0.00044040620559826493, Valid Loss: 0.00065266975434497\n",
      "Epoch: 7618, Train Loss: 0.00044014950981363654, Valid Loss: 0.0006523206830024719\n",
      "Epoch: 7619, Train Loss: 0.0004398977616801858, Valid Loss: 0.0006519747548736632\n",
      "Epoch: 7620, Train Loss: 0.00043964190990664065, Valid Loss: 0.0006516312714666128\n",
      "Epoch: 7621, Train Loss: 0.00043938675662502646, Valid Loss: 0.0006512901745736599\n",
      "Epoch: 7622, Train Loss: 0.0004391326510813087, Valid Loss: 0.000650945061352104\n",
      "Epoch: 7623, Train Loss: 0.0004388779925648123, Valid Loss: 0.0006506022182293236\n",
      "Epoch: 7624, Train Loss: 0.00043862152961082757, Valid Loss: 0.0006502525648102164\n",
      "Epoch: 7625, Train Loss: 0.0004383687046356499, Valid Loss: 0.0006499143200926483\n",
      "Epoch: 7626, Train Loss: 0.00043811678187921643, Valid Loss: 0.0006495707202702761\n",
      "Epoch: 7627, Train Loss: 0.0004378624144010246, Valid Loss: 0.0006492254906333983\n",
      "Epoch: 7628, Train Loss: 0.00043760964763350785, Valid Loss: 0.0006488793296739459\n",
      "Epoch: 7629, Train Loss: 0.00043735638610087335, Valid Loss: 0.0006485381745733321\n",
      "Epoch: 7630, Train Loss: 0.00043710280442610383, Valid Loss: 0.0006481949239969254\n",
      "Epoch: 7631, Train Loss: 0.000436850794358179, Valid Loss: 0.0006478596478700638\n",
      "Epoch: 7632, Train Loss: 0.0004365979111753404, Valid Loss: 0.0006475140689872205\n",
      "Epoch: 7633, Train Loss: 0.0004363449406810105, Valid Loss: 0.0006471723318099976\n",
      "Epoch: 7634, Train Loss: 0.0004360928724054247, Valid Loss: 0.0006468280334956944\n",
      "Epoch: 7635, Train Loss: 0.0004358395526651293, Valid Loss: 0.0006464895559474826\n",
      "Epoch: 7636, Train Loss: 0.0004355874552857131, Valid Loss: 0.0006461465964093804\n",
      "Epoch: 7637, Train Loss: 0.0004353365220595151, Valid Loss: 0.0006458068382926285\n",
      "Epoch: 7638, Train Loss: 0.0004350832605268806, Valid Loss: 0.0006454579997807741\n",
      "Epoch: 7639, Train Loss: 0.00043483288027346134, Valid Loss: 0.0006451216177083552\n",
      "Epoch: 7640, Train Loss: 0.0004345806082710624, Valid Loss: 0.0006447852938435972\n",
      "Epoch: 7641, Train Loss: 0.00043432856909930706, Valid Loss: 0.0006444465252570808\n",
      "Epoch: 7642, Train Loss: 0.0004340755403973162, Valid Loss: 0.0006441000150516629\n",
      "Epoch: 7643, Train Loss: 0.0004338267317507416, Valid Loss: 0.0006437667179852724\n",
      "Epoch: 7644, Train Loss: 0.00043357565300539136, Valid Loss: 0.0006434190436266363\n",
      "Epoch: 7645, Train Loss: 0.00043332381756044924, Valid Loss: 0.000643083534669131\n",
      "Epoch: 7646, Train Loss: 0.0004330739320721477, Valid Loss: 0.0006427388871088624\n",
      "Epoch: 7647, Train Loss: 0.00043282294063828886, Valid Loss: 0.0006424050661735237\n",
      "Epoch: 7648, Train Loss: 0.0004325704649090767, Valid Loss: 0.0006420576828531921\n",
      "Epoch: 7649, Train Loss: 0.0004323222383391112, Valid Loss: 0.000641722057480365\n",
      "Epoch: 7650, Train Loss: 0.0004320716252550483, Valid Loss: 0.0006413791561499238\n",
      "Epoch: 7651, Train Loss: 0.00043182133231312037, Valid Loss: 0.0006410494679585099\n",
      "Epoch: 7652, Train Loss: 0.0004315717378631234, Valid Loss: 0.000640703015960753\n",
      "Epoch: 7653, Train Loss: 0.00043132351129315794, Valid Loss: 0.0006403701845556498\n",
      "Epoch: 7654, Train Loss: 0.0004310722288209945, Valid Loss: 0.0006400229758583009\n",
      "Epoch: 7655, Train Loss: 0.0004308245552238077, Valid Loss: 0.0006396985845640302\n",
      "Epoch: 7656, Train Loss: 0.000430573767516762, Valid Loss: 0.000639355625025928\n",
      "Epoch: 7657, Train Loss: 0.0004303254827391356, Valid Loss: 0.0006390189519152045\n",
      "Epoch: 7658, Train Loss: 0.0004300764703657478, Valid Loss: 0.0006386724999174476\n",
      "Epoch: 7659, Train Loss: 0.000429827778134495, Valid Loss: 0.0006383454310707748\n",
      "Epoch: 7660, Train Loss: 0.0004295778344385326, Valid Loss: 0.0006380038103088737\n",
      "Epoch: 7661, Train Loss: 0.0004293304809834808, Valid Loss: 0.0006376752280630171\n",
      "Epoch: 7662, Train Loss: 0.00042908222530968487, Valid Loss: 0.0006373336655087769\n",
      "Epoch: 7663, Train Loss: 0.00042883455171249807, Valid Loss: 0.0006370010087266564\n",
      "Epoch: 7664, Train Loss: 0.0004285871400497854, Valid Loss: 0.0006366536836139858\n",
      "Epoch: 7665, Train Loss: 0.0004283377493266016, Valid Loss: 0.0006363291759043932\n",
      "Epoch: 7666, Train Loss: 0.000428091298090294, Valid Loss: 0.0006359834223985672\n",
      "Epoch: 7667, Train Loss: 0.00042784103425219655, Valid Loss: 0.0006356540252454579\n",
      "Epoch: 7668, Train Loss: 0.0004275962128303945, Valid Loss: 0.0006353167700581253\n",
      "Epoch: 7669, Train Loss: 0.00042734743328765035, Valid Loss: 0.0006349857430905104\n",
      "Epoch: 7670, Train Loss: 0.00042710243724286556, Valid Loss: 0.0006346412701532245\n",
      "Epoch: 7671, Train Loss: 0.0004268549964763224, Valid Loss: 0.0006343172281049192\n",
      "Epoch: 7672, Train Loss: 0.00042660554754547775, Valid Loss: 0.0006339721148833632\n",
      "Epoch: 7673, Train Loss: 0.00042635813588276505, Valid Loss: 0.0006336439400911331\n",
      "Epoch: 7674, Train Loss: 0.0004261136637069285, Valid Loss: 0.0006332990597002208\n",
      "Epoch: 7675, Train Loss: 0.00042586648487485945, Valid Loss: 0.0006329760071821511\n",
      "Epoch: 7676, Train Loss: 0.0004256207321304828, Valid Loss: 0.0006326338625513017\n",
      "Epoch: 7677, Train Loss: 0.000425373058533296, Valid Loss: 0.0006323072593659163\n",
      "Epoch: 7678, Train Loss: 0.0004251278005540371, Valid Loss: 0.0006319641834124923\n",
      "Epoch: 7679, Train Loss: 0.0004248818731866777, Valid Loss: 0.0006316427607089281\n",
      "Epoch: 7680, Train Loss: 0.0004246360913384706, Valid Loss: 0.0006312965415418148\n",
      "Epoch: 7681, Train Loss: 0.0004243904841132462, Valid Loss: 0.0006309652817435563\n",
      "Epoch: 7682, Train Loss: 0.0004241449641995132, Valid Loss: 0.0006306309369392693\n",
      "Epoch: 7683, Train Loss: 0.0004238991532474756, Valid Loss: 0.0006303050904534757\n",
      "Epoch: 7684, Train Loss: 0.00042365441913716495, Valid Loss: 0.000629962480161339\n",
      "Epoch: 7685, Train Loss: 0.0004234093939885497, Valid Loss: 0.0006296368665061891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7686, Train Loss: 0.0004231646016705781, Valid Loss: 0.0006292987382039428\n",
      "Epoch: 7687, Train Loss: 0.000422918499680236, Valid Loss: 0.000628972367849201\n",
      "Epoch: 7688, Train Loss: 0.00042267460958100855, Valid Loss: 0.0006286347052082419\n",
      "Epoch: 7689, Train Loss: 0.0004224300500936806, Valid Loss: 0.0006283078109845519\n",
      "Epoch: 7690, Train Loss: 0.00042218537419103086, Valid Loss: 0.000627970090135932\n",
      "Epoch: 7691, Train Loss: 0.0004219419206492603, Valid Loss: 0.0006276430212892592\n",
      "Epoch: 7692, Train Loss: 0.00042169701191596687, Valid Loss: 0.0006273060571402311\n",
      "Epoch: 7693, Train Loss: 0.0004214540240354836, Valid Loss: 0.000626987311989069\n",
      "Epoch: 7694, Train Loss: 0.0004212094936519861, Valid Loss: 0.0006266494747251272\n",
      "Epoch: 7695, Train Loss: 0.0004209665348753333, Valid Loss: 0.0006263205432333052\n",
      "Epoch: 7696, Train Loss: 0.00042072319774888456, Valid Loss: 0.0006259846850298345\n",
      "Epoch: 7697, Train Loss: 0.00042048125760629773, Valid Loss: 0.0006256622727960348\n",
      "Epoch: 7698, Train Loss: 0.0004202360287308693, Valid Loss: 0.0006253310129977763\n",
      "Epoch: 7699, Train Loss: 0.00041999269160442054, Valid Loss: 0.0006249959114938974\n",
      "Epoch: 7700, Train Loss: 0.0004197501693852246, Valid Loss: 0.0006246670964173973\n",
      "Epoch: 7701, Train Loss: 0.00041950977174565196, Valid Loss: 0.0006243409006856382\n",
      "Epoch: 7702, Train Loss: 0.0004192661144770682, Valid Loss: 0.0006240109214559197\n",
      "Epoch: 7703, Train Loss: 0.0004190219915471971, Valid Loss: 0.000623679778072983\n",
      "Epoch: 7704, Train Loss: 0.0004187792947050184, Valid Loss: 0.0006233521271497011\n",
      "Epoch: 7705, Train Loss: 0.0004185391589999199, Valid Loss: 0.0006230237195268273\n",
      "Epoch: 7706, Train Loss: 0.0004182959091849625, Valid Loss: 0.000622694322373718\n",
      "Epoch: 7707, Train Loss: 0.0004180543764960021, Valid Loss: 0.0006223677773959935\n",
      "Epoch: 7708, Train Loss: 0.00041781310574151576, Valid Loss: 0.0006220387876965106\n",
      "Epoch: 7709, Train Loss: 0.00041757087456062436, Valid Loss: 0.000621711544226855\n",
      "Epoch: 7710, Train Loss: 0.00041733006946742535, Valid Loss: 0.0006213843589648604\n",
      "Epoch: 7711, Train Loss: 0.0004170899628661573, Valid Loss: 0.000621055718511343\n",
      "Epoch: 7712, Train Loss: 0.0004168471787124872, Valid Loss: 0.0006207308615557849\n",
      "Epoch: 7713, Train Loss: 0.0004166074504610151, Valid Loss: 0.0006203991360962391\n",
      "Epoch: 7714, Train Loss: 0.000416365364799276, Valid Loss: 0.00062007230008021\n",
      "Epoch: 7715, Train Loss: 0.0004161252290941775, Valid Loss: 0.0006197474431246519\n",
      "Epoch: 7716, Train Loss: 0.00041588558815419674, Valid Loss: 0.0006194233428686857\n",
      "Epoch: 7717, Train Loss: 0.00041564388084225357, Valid Loss: 0.0006190938875079155\n",
      "Epoch: 7718, Train Loss: 0.00041540435631759465, Valid Loss: 0.0006187671096995473\n",
      "Epoch: 7719, Train Loss: 0.00041516474448144436, Valid Loss: 0.0006184425437822938\n",
      "Epoch: 7720, Train Loss: 0.00041492292075417936, Valid Loss: 0.0006181150674819946\n",
      "Epoch: 7721, Train Loss: 0.0004146838909946382, Valid Loss: 0.0006177822942845523\n",
      "Epoch: 7722, Train Loss: 0.0004144438717048615, Valid Loss: 0.0006174613372422755\n",
      "Epoch: 7723, Train Loss: 0.0004142042016610503, Valid Loss: 0.0006171382265165448\n",
      "Epoch: 7724, Train Loss: 0.00041396479355171323, Valid Loss: 0.0006168138352222741\n",
      "Epoch: 7725, Train Loss: 0.000413727160776034, Valid Loss: 0.0006164847873151302\n",
      "Epoch: 7726, Train Loss: 0.0004134868213441223, Valid Loss: 0.000616166100371629\n",
      "Epoch: 7727, Train Loss: 0.000413247209507972, Valid Loss: 0.0006158343749120831\n",
      "Epoch: 7728, Train Loss: 0.0004130093730054796, Valid Loss: 0.0006155085866339505\n",
      "Epoch: 7729, Train Loss: 0.0004127674037590623, Valid Loss: 0.0006151897250674665\n",
      "Epoch: 7730, Train Loss: 0.0004125316918361932, Valid Loss: 0.0006148646934889257\n",
      "Epoch: 7731, Train Loss: 0.0004122922837268561, Valid Loss: 0.0006145340739749372\n",
      "Epoch: 7732, Train Loss: 0.0004120555240660906, Valid Loss: 0.0006142101483419538\n",
      "Epoch: 7733, Train Loss: 0.00041181655251421034, Valid Loss: 0.0006138887256383896\n",
      "Epoch: 7734, Train Loss: 0.00041157795931212604, Valid Loss: 0.0006135649746283889\n",
      "Epoch: 7735, Train Loss: 0.0004113405884709209, Valid Loss: 0.0006132379057817161\n",
      "Epoch: 7736, Train Loss: 0.0004111024900339544, Valid Loss: 0.0006129152607172728\n",
      "Epoch: 7737, Train Loss: 0.00041086418787017465, Valid Loss: 0.0006125904037617147\n",
      "Epoch: 7738, Train Loss: 0.0004106295818928629, Valid Loss: 0.0006122710183262825\n",
      "Epoch: 7739, Train Loss: 0.00041039043571799994, Valid Loss: 0.0006119514000602067\n",
      "Epoch: 7740, Train Loss: 0.0004101546364836395, Valid Loss: 0.0006116251461207867\n",
      "Epoch: 7741, Train Loss: 0.0004099179932381958, Valid Loss: 0.0006113005802035332\n",
      "Epoch: 7742, Train Loss: 0.00040967942913994193, Valid Loss: 0.0006109772366471589\n",
      "Epoch: 7743, Train Loss: 0.0004094428732059896, Valid Loss: 0.0006106609362177551\n",
      "Epoch: 7744, Train Loss: 0.00040920847095549107, Valid Loss: 0.0006103349733166397\n",
      "Epoch: 7745, Train Loss: 0.00040897142025642097, Valid Loss: 0.0006100186728872359\n",
      "Epoch: 7746, Train Loss: 0.00040873390389606357, Valid Loss: 0.0006096956203691661\n",
      "Epoch: 7747, Train Loss: 0.00040849612560123205, Valid Loss: 0.0006093747797422111\n",
      "Epoch: 7748, Train Loss: 0.0004082619270775467, Valid Loss: 0.0006090510287322104\n",
      "Epoch: 7749, Train Loss: 0.0004080254875589162, Valid Loss: 0.0006087315850891173\n",
      "Epoch: 7750, Train Loss: 0.0004077896010130644, Valid Loss: 0.0006084077758714557\n",
      "Epoch: 7751, Train Loss: 0.0004075546166859567, Valid Loss: 0.0006080850143916905\n",
      "Epoch: 7752, Train Loss: 0.00040732044726610184, Valid Loss: 0.0006077697617001832\n",
      "Epoch: 7753, Train Loss: 0.000407082203309983, Valid Loss: 0.0006074496195651591\n",
      "Epoch: 7754, Train Loss: 0.0004068476555403322, Valid Loss: 0.0006071273819543421\n",
      "Epoch: 7755, Train Loss: 0.00040661392267793417, Valid Loss: 0.0006068036891520023\n",
      "Epoch: 7756, Train Loss: 0.0004063794040121138, Valid Loss: 0.0006064856424927711\n",
      "Epoch: 7757, Train Loss: 0.0004061433137394488, Valid Loss: 0.0006061704480089247\n",
      "Epoch: 7758, Train Loss: 0.0004059086786583066, Valid Loss: 0.0006058462313376367\n",
      "Epoch: 7759, Train Loss: 0.0004056745383422822, Valid Loss: 0.0006055302219465375\n",
      "Epoch: 7760, Train Loss: 0.0004054389719385654, Valid Loss: 0.000605205015745014\n",
      "Epoch: 7761, Train Loss: 0.00040520585025660694, Valid Loss: 0.0006048912182450294\n",
      "Epoch: 7762, Train Loss: 0.00040497019654139876, Valid Loss: 0.0006045725895091891\n",
      "Epoch: 7763, Train Loss: 0.00040473684202879667, Valid Loss: 0.0006042555323801935\n",
      "Epoch: 7764, Train Loss: 0.00040450418600812554, Valid Loss: 0.0006039335858076811\n",
      "Epoch: 7765, Train Loss: 0.0004042698419652879, Valid Loss: 0.0006036189734004438\n",
      "Epoch: 7766, Train Loss: 0.00040403573075309396, Valid Loss: 0.0006033014506101608\n",
      "Epoch: 7767, Train Loss: 0.0004038025508634746, Valid Loss: 0.0006029802025295794\n",
      "Epoch: 7768, Train Loss: 0.00040356977842748165, Valid Loss: 0.000602656917180866\n",
      "Epoch: 7769, Train Loss: 0.0004033360455650836, Valid Loss: 0.0006023418391123414\n",
      "Epoch: 7770, Train Loss: 0.0004031031276099384, Valid Loss: 0.000602029322180897\n",
      "Epoch: 7771, Train Loss: 0.00040286954026669264, Valid Loss: 0.0006017115083523095\n",
      "Epoch: 7772, Train Loss: 0.0004026378155685961, Valid Loss: 0.0006013908423483372\n",
      "Epoch: 7773, Train Loss: 0.00040240606176666915, Valid Loss: 0.0006010778597556055\n",
      "Epoch: 7774, Train Loss: 0.00040217337664216757, Valid Loss: 0.0006007613847032189\n",
      "Epoch: 7775, Train Loss: 0.0004019412735942751, Valid Loss: 0.000600443163421005\n",
      "Epoch: 7776, Train Loss: 0.00040170879219658673, Valid Loss: 0.0006001222645863891\n",
      "Epoch: 7777, Train Loss: 0.00040147601976059377, Valid Loss: 0.0005998113192617893\n",
      "Epoch: 7778, Train Loss: 0.00040124644874595106, Valid Loss: 0.0005994883249513805\n",
      "Epoch: 7779, Train Loss: 0.0004010113188996911, Valid Loss: 0.0005991721409372985\n",
      "Epoch: 7780, Train Loss: 0.0004007827374152839, Valid Loss: 0.0005988572374917567\n",
      "Epoch: 7781, Train Loss: 0.00040054955752566457, Valid Loss: 0.0005985514726489782\n",
      "Epoch: 7782, Train Loss: 0.0004003174544777721, Valid Loss: 0.0005982263828627765\n",
      "Epoch: 7783, Train Loss: 0.0004000876215286553, Valid Loss: 0.0005979090929031372\n",
      "Epoch: 7784, Train Loss: 0.0003998580214101821, Valid Loss: 0.0005975936073809862\n",
      "Epoch: 7785, Train Loss: 0.00039962545270100236, Valid Loss: 0.0005972851649858057\n",
      "Epoch: 7786, Train Loss: 0.00039939599810168147, Valid Loss: 0.000596962810959667\n",
      "Epoch: 7787, Train Loss: 0.00039916374953463674, Valid Loss: 0.000596656056586653\n",
      "Epoch: 7788, Train Loss: 0.0003989329852629453, Valid Loss: 0.0005963458097539842\n",
      "Epoch: 7789, Train Loss: 0.00039870402542874217, Valid Loss: 0.0005960289854556322\n",
      "Epoch: 7790, Train Loss: 0.0003984735521953553, Valid Loss: 0.0005957150715403259\n",
      "Epoch: 7791, Train Loss: 0.0003982433117926121, Valid Loss: 0.0005954027292318642\n",
      "Epoch: 7792, Train Loss: 0.0003980134497396648, Valid Loss: 0.0005950839258730412\n",
      "Epoch: 7793, Train Loss: 0.00039778448990546167, Valid Loss: 0.000594770535826683\n",
      "Epoch: 7794, Train Loss: 0.0003975546278525144, Valid Loss: 0.0005944568547420204\n",
      "Epoch: 7795, Train Loss: 0.0003973241546191275, Valid Loss: 0.0005941467243246734\n",
      "Epoch: 7796, Train Loss: 0.0003970947000198066, Valid Loss: 0.0005938317044638097\n",
      "Epoch: 7797, Train Loss: 0.0003968645469285548, Valid Loss: 0.0005935233202762902\n",
      "Epoch: 7798, Train Loss: 0.000396635674405843, Valid Loss: 0.0005932057392783463\n",
      "Epoch: 7799, Train Loss: 0.0003964075294788927, Valid Loss: 0.0005928917089477181\n",
      "Epoch: 7800, Train Loss: 0.0003961792681366205, Valid Loss: 0.0005925833247601986\n",
      "Epoch: 7801, Train Loss: 0.0003959498426411301, Valid Loss: 0.0005922762211412191\n",
      "Epoch: 7802, Train Loss: 0.000395722221583128, Valid Loss: 0.0005919535760767758\n",
      "Epoch: 7803, Train Loss: 0.0003954936400987208, Valid Loss: 0.0005916446098126471\n",
      "Epoch: 7804, Train Loss: 0.0003952643892262131, Valid Loss: 0.0005913276690989733\n",
      "Epoch: 7805, Train Loss: 0.0003950362151954323, Valid Loss: 0.000591025804169476\n",
      "Epoch: 7806, Train Loss: 0.0003948080411646515, Valid Loss: 0.0005907117738388479\n",
      "Epoch: 7807, Train Loss: 0.0003945806238334626, Valid Loss: 0.0005904025747440755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7808, Train Loss: 0.00039435201324522495, Valid Loss: 0.0005900856340304017\n",
      "Epoch: 7809, Train Loss: 0.00039412465412169695, Valid Loss: 0.0005897817900404334\n",
      "Epoch: 7810, Train Loss: 0.0003938988666050136, Valid Loss: 0.0005894646164961159\n",
      "Epoch: 7811, Train Loss: 0.0003936696157325059, Valid Loss: 0.0005891585606150329\n",
      "Epoch: 7812, Train Loss: 0.000393442518543452, Valid Loss: 0.000588840339332819\n",
      "Epoch: 7813, Train Loss: 0.00039321649819612503, Valid Loss: 0.0005885361460968852\n",
      "Epoch: 7814, Train Loss: 0.00039298925548791885, Valid Loss: 0.0005882253753952682\n",
      "Epoch: 7815, Train Loss: 0.000392762478441, Valid Loss: 0.0005879171076230705\n",
      "Epoch: 7816, Train Loss: 0.00039253506110981107, Valid Loss: 0.0005876051727682352\n",
      "Epoch: 7817, Train Loss: 0.00039230845868587494, Valid Loss: 0.0005872978363186121\n",
      "Epoch: 7818, Train Loss: 0.0003920816525351256, Valid Loss: 0.0005869824672117829\n",
      "Epoch: 7819, Train Loss: 0.0003918558359146118, Valid Loss: 0.0005866832798346877\n",
      "Epoch: 7820, Train Loss: 0.0003916303685400635, Valid Loss: 0.000586372276302427\n",
      "Epoch: 7821, Train Loss: 0.00039140533772297204, Valid Loss: 0.0005860655219294131\n",
      "Epoch: 7822, Train Loss: 0.0003911780077032745, Valid Loss: 0.000585741363465786\n",
      "Epoch: 7823, Train Loss: 0.0003909531224053353, Valid Loss: 0.0005854444461874664\n",
      "Epoch: 7824, Train Loss: 0.00039072762592695653, Valid Loss: 0.0005851348396390676\n",
      "Epoch: 7825, Train Loss: 0.0003905000921804458, Valid Loss: 0.0005848334985785186\n",
      "Epoch: 7826, Train Loss: 0.00039027605089358985, Valid Loss: 0.0005845184787176549\n",
      "Epoch: 7827, Train Loss: 0.00039005151484161615, Valid Loss: 0.0005842190585099161\n",
      "Epoch: 7828, Train Loss: 0.0003898248542100191, Valid Loss: 0.0005838991492055357\n",
      "Epoch: 7829, Train Loss: 0.00038959996891207993, Valid Loss: 0.0005836006603203714\n",
      "Epoch: 7830, Train Loss: 0.00038937508361414075, Valid Loss: 0.0005832838942296803\n",
      "Epoch: 7831, Train Loss: 0.0003891513915732503, Valid Loss: 0.0005829909932799637\n",
      "Epoch: 7832, Train Loss: 0.00038892810698598623, Valid Loss: 0.0005826668348163366\n",
      "Epoch: 7833, Train Loss: 0.00038870322168804705, Valid Loss: 0.0005823749816045165\n",
      "Epoch: 7834, Train Loss: 0.00038847746327519417, Valid Loss: 0.0005820568767376244\n",
      "Epoch: 7835, Train Loss: 0.0003882524906657636, Valid Loss: 0.0005817586788907647\n",
      "Epoch: 7836, Train Loss: 0.00038802981725893915, Valid Loss: 0.0005814374308101833\n",
      "Epoch: 7837, Train Loss: 0.00038780440809205174, Valid Loss: 0.0005811513983644545\n",
      "Epoch: 7838, Train Loss: 0.00038758033770136535, Valid Loss: 0.0005808296846225858\n",
      "Epoch: 7839, Train Loss: 0.0003873581299558282, Valid Loss: 0.0005805360851809382\n",
      "Epoch: 7840, Train Loss: 0.00038713315734639764, Valid Loss: 0.0005802161176688969\n",
      "Epoch: 7841, Train Loss: 0.00038691057125106454, Valid Loss: 0.000579926127102226\n",
      "Epoch: 7842, Train Loss: 0.00038668778142891824, Valid Loss: 0.0005796052282676101\n",
      "Epoch: 7843, Train Loss: 0.00038646580651402473, Valid Loss: 0.0005793184973299503\n",
      "Epoch: 7844, Train Loss: 0.00038624240551143885, Valid Loss: 0.000578998529817909\n",
      "Epoch: 7845, Train Loss: 0.00038601786945946515, Valid Loss: 0.0005787088884972036\n",
      "Epoch: 7846, Train Loss: 0.000385795661713928, Valid Loss: 0.0005783841479569674\n",
      "Epoch: 7847, Train Loss: 0.00038557464722543955, Valid Loss: 0.0005780968349426985\n",
      "Epoch: 7848, Train Loss: 0.00038535287603735924, Valid Loss: 0.0005777765763923526\n",
      "Epoch: 7849, Train Loss: 0.00038512906758114696, Valid Loss: 0.0005774855380877852\n",
      "Epoch: 7850, Train Loss: 0.000384905724786222, Valid Loss: 0.000577170925680548\n",
      "Epoch: 7851, Train Loss: 0.0003846852050628513, Valid Loss: 0.0005768820410594344\n",
      "Epoch: 7852, Train Loss: 0.00038446331745944917, Valid Loss: 0.0005765583482570946\n",
      "Epoch: 7853, Train Loss: 0.0003842406440526247, Valid Loss: 0.0005762714426964521\n",
      "Epoch: 7854, Train Loss: 0.0003840198914986104, Valid Loss: 0.0005759552586823702\n",
      "Epoch: 7855, Train Loss: 0.0003837977710645646, Valid Loss: 0.0005756660830229521\n",
      "Epoch: 7856, Train Loss: 0.0003835760580841452, Valid Loss: 0.0005753459990955889\n",
      "Epoch: 7857, Train Loss: 0.00038335580029524863, Valid Loss: 0.0005750617128796875\n",
      "Epoch: 7858, Train Loss: 0.00038313367986120284, Valid Loss: 0.0005747501272708178\n",
      "Epoch: 7859, Train Loss: 0.00038291141390800476, Valid Loss: 0.0005744551308453083\n",
      "Epoch: 7860, Train Loss: 0.0003826925822068006, Valid Loss: 0.0005741309723816812\n",
      "Epoch: 7861, Train Loss: 0.0003824704035650939, Valid Loss: 0.0005738442996516824\n",
      "Epoch: 7862, Train Loss: 0.00038224950549192727, Valid Loss: 0.0005735316080972552\n",
      "Epoch: 7863, Train Loss: 0.00038202881114557385, Valid Loss: 0.0005732487770728767\n",
      "Epoch: 7864, Train Loss: 0.0003818088152911514, Valid Loss: 0.0005729296826757491\n",
      "Epoch: 7865, Train Loss: 0.00038158870302140713, Valid Loss: 0.0005726352101191878\n",
      "Epoch: 7866, Train Loss: 0.0003813698422163725, Valid Loss: 0.0005723246722482145\n",
      "Epoch: 7867, Train Loss: 0.00038114775088615716, Valid Loss: 0.0005720381159335375\n",
      "Epoch: 7868, Train Loss: 0.0003809296467807144, Valid Loss: 0.0005717282765544951\n",
      "Epoch: 7869, Train Loss: 0.0003807085449807346, Valid Loss: 0.0005714299622923136\n",
      "Epoch: 7870, Train Loss: 0.0003804881707765162, Valid Loss: 0.0005711202975362539\n",
      "Epoch: 7871, Train Loss: 0.00038026925176382065, Valid Loss: 0.0005708324024453759\n",
      "Epoch: 7872, Train Loss: 0.00038004963425919414, Valid Loss: 0.000570527627132833\n",
      "Epoch: 7873, Train Loss: 0.0003798312391154468, Valid Loss: 0.0005702312337234616\n",
      "Epoch: 7874, Train Loss: 0.000379611476091668, Valid Loss: 0.0005699208122678101\n",
      "Epoch: 7875, Train Loss: 0.0003793927899096161, Valid Loss: 0.0005696305888704956\n",
      "Epoch: 7876, Train Loss: 0.00037917515146546066, Valid Loss: 0.000569321564398706\n",
      "Epoch: 7877, Train Loss: 0.0003789547481574118, Valid Loss: 0.0005690285470336676\n",
      "Epoch: 7878, Train Loss: 0.00037873658584430814, Valid Loss: 0.000568731629755348\n",
      "Epoch: 7879, Train Loss: 0.0003785194712691009, Valid Loss: 0.000568436284083873\n",
      "Epoch: 7880, Train Loss: 0.0003783008723985404, Valid Loss: 0.0005681272014044225\n",
      "Epoch: 7881, Train Loss: 0.0003780825063586235, Valid Loss: 0.0005678266752511263\n",
      "Epoch: 7882, Train Loss: 0.0003778650425374508, Valid Loss: 0.0005675323773175478\n",
      "Epoch: 7883, Train Loss: 0.00037764577427878976, Valid Loss: 0.0005672379047609866\n",
      "Epoch: 7884, Train Loss: 0.00037742842687293887, Valid Loss: 0.0005669330130331218\n",
      "Epoch: 7885, Train Loss: 0.00037721171975135803, Valid Loss: 0.0005666334764100611\n",
      "Epoch: 7886, Train Loss: 0.0003769932081922889, Valid Loss: 0.0005663398769684136\n",
      "Epoch: 7887, Train Loss: 0.00037677542422898114, Valid Loss: 0.0005660414462909102\n",
      "Epoch: 7888, Train Loss: 0.0003765586588997394, Valid Loss: 0.0005657405708916485\n",
      "Epoch: 7889, Train Loss: 0.0003763424465432763, Valid Loss: 0.0005654449923895299\n",
      "Epoch: 7890, Train Loss: 0.0003761251282412559, Valid Loss: 0.0005651495885103941\n",
      "Epoch: 7891, Train Loss: 0.0003759074315894395, Valid Loss: 0.0005648490623570979\n",
      "Epoch: 7892, Train Loss: 0.0003756905789487064, Valid Loss: 0.0005645533092319965\n",
      "Epoch: 7893, Train Loss: 0.00037547480314970016, Valid Loss: 0.0005642542382702231\n",
      "Epoch: 7894, Train Loss: 0.00037525707739405334, Valid Loss: 0.0005639567389152944\n",
      "Epoch: 7895, Train Loss: 0.00037504229112528265, Valid Loss: 0.0005636635469272733\n",
      "Epoch: 7896, Train Loss: 0.00037482494371943176, Valid Loss: 0.0005633699474856257\n",
      "Epoch: 7897, Train Loss: 0.0003746079746633768, Valid Loss: 0.0005630673258565366\n",
      "Epoch: 7898, Train Loss: 0.00037439336301758885, Valid Loss: 0.0005627690115943551\n",
      "Epoch: 7899, Train Loss: 0.00037417784915305674, Valid Loss: 0.0005624759942293167\n",
      "Epoch: 7900, Train Loss: 0.00037396192783489823, Valid Loss: 0.0005621816380880773\n",
      "Epoch: 7901, Train Loss: 0.00037374571547843516, Valid Loss: 0.000561882508918643\n",
      "Epoch: 7902, Train Loss: 0.0003735297068487853, Valid Loss: 0.0005615869304165244\n",
      "Epoch: 7903, Train Loss: 0.0003733128833118826, Valid Loss: 0.0005612935638055205\n",
      "Epoch: 7904, Train Loss: 0.0003730995813384652, Valid Loss: 0.0005610041553154588\n",
      "Epoch: 7905, Train Loss: 0.0003728860756382346, Valid Loss: 0.0005607030470855534\n",
      "Epoch: 7906, Train Loss: 0.000372668553609401, Valid Loss: 0.0005604096222668886\n",
      "Epoch: 7907, Train Loss: 0.0003724527487065643, Valid Loss: 0.0005601111333817244\n",
      "Epoch: 7908, Train Loss: 0.00037223967956379056, Valid Loss: 0.0005598259158432484\n",
      "Epoch: 7909, Train Loss: 0.00037202451494522393, Valid Loss: 0.0005595269612967968\n",
      "Epoch: 7910, Train Loss: 0.0003718096995726228, Valid Loss: 0.0005592295783571899\n",
      "Epoch: 7911, Train Loss: 0.0003715951752383262, Valid Loss: 0.000558932893909514\n",
      "Epoch: 7912, Train Loss: 0.00037138242623768747, Valid Loss: 0.0005586478509940207\n",
      "Epoch: 7913, Train Loss: 0.00037116717430762947, Valid Loss: 0.0005583512247540057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7914, Train Loss: 0.00037095346488058567, Valid Loss: 0.0005580561119131744\n",
      "Epoch: 7915, Train Loss: 0.0003707395226228982, Valid Loss: 0.0005577635602094233\n",
      "Epoch: 7916, Train Loss: 0.00037052747211419046, Valid Loss: 0.0005574715905822814\n",
      "Epoch: 7917, Train Loss: 0.00037031190004199743, Valid Loss: 0.0005571682704612613\n",
      "Epoch: 7918, Train Loss: 0.0003700983652379364, Valid Loss: 0.0005568854394368827\n",
      "Epoch: 7919, Train Loss: 0.00036988535430282354, Valid Loss: 0.0005565865430980921\n",
      "Epoch: 7920, Train Loss: 0.00036967129562981427, Valid Loss: 0.0005562991718761623\n",
      "Epoch: 7921, Train Loss: 0.00036945869214832783, Valid Loss: 0.0005559995188377798\n",
      "Epoch: 7922, Train Loss: 0.00036924704909324646, Valid Loss: 0.0005557110998779535\n",
      "Epoch: 7923, Train Loss: 0.00036903348518535495, Valid Loss: 0.0005554130766540766\n",
      "Epoch: 7924, Train Loss: 0.00036882166750729084, Valid Loss: 0.0005551276262849569\n",
      "Epoch: 7925, Train Loss: 0.0003686087438836694, Valid Loss: 0.0005548330955207348\n",
      "Epoch: 7926, Train Loss: 0.00036839680979028344, Valid Loss: 0.000554541707970202\n",
      "Epoch: 7927, Train Loss: 0.00036818330409005284, Valid Loss: 0.0005542446160688996\n",
      "Epoch: 7928, Train Loss: 0.0003679711662698537, Valid Loss: 0.0005539558478631079\n",
      "Epoch: 7929, Train Loss: 0.0003677582135424018, Valid Loss: 0.0005536705139093101\n",
      "Epoch: 7930, Train Loss: 0.0003675473853945732, Valid Loss: 0.0005533793591894209\n",
      "Epoch: 7931, Train Loss: 0.0003673343744594604, Valid Loss: 0.0005530829075723886\n",
      "Epoch: 7932, Train Loss: 0.00036712223663926125, Valid Loss: 0.0005527997273020446\n",
      "Epoch: 7933, Train Loss: 0.00036691283457912505, Valid Loss: 0.0005525078158825636\n",
      "Epoch: 7934, Train Loss: 0.0003667007840704173, Valid Loss: 0.0005522141582332551\n",
      "Epoch: 7935, Train Loss: 0.0003664883552119136, Valid Loss: 0.0005519180558621883\n",
      "Epoch: 7936, Train Loss: 0.0003662782546598464, Valid Loss: 0.0005516394157893956\n",
      "Epoch: 7937, Train Loss: 0.0003660682705231011, Valid Loss: 0.0005513441865332425\n",
      "Epoch: 7938, Train Loss: 0.0003658554924186319, Valid Loss: 0.0005510571645572782\n",
      "Epoch: 7939, Train Loss: 0.0003656442859210074, Valid Loss: 0.0005507656605914235\n",
      "Epoch: 7940, Train Loss: 0.0003654350293800235, Valid Loss: 0.0005504798609763384\n",
      "Epoch: 7941, Train Loss: 0.0003652252198662609, Valid Loss: 0.0005501800333149731\n",
      "Epoch: 7942, Train Loss: 0.0003650123835541308, Valid Loss: 0.0005498954560607672\n",
      "Epoch: 7943, Train Loss: 0.00036480461130850017, Valid Loss: 0.0005496108205989003\n",
      "Epoch: 7944, Train Loss: 0.00036459360853768885, Valid Loss: 0.0005493182106874883\n",
      "Epoch: 7945, Train Loss: 0.0003643833042588085, Valid Loss: 0.0005490279290825129\n",
      "Epoch: 7946, Train Loss: 0.0003641736402641982, Valid Loss: 0.0005487377638928592\n",
      "Epoch: 7947, Train Loss: 0.0003639628121163696, Valid Loss: 0.0005484475404955447\n",
      "Epoch: 7948, Train Loss: 0.0003637538757175207, Valid Loss: 0.0005481602856889367\n",
      "Epoch: 7949, Train Loss: 0.0003635438624769449, Valid Loss: 0.0005478736129589379\n",
      "Epoch: 7950, Train Loss: 0.00036333443131297827, Valid Loss: 0.00054758763872087\n",
      "Epoch: 7951, Train Loss: 0.0003631256986409426, Valid Loss: 0.0005472975317388773\n",
      "Epoch: 7952, Train Loss: 0.0003629163547884673, Valid Loss: 0.0005470069590955973\n",
      "Epoch: 7953, Train Loss: 0.0003627060214057565, Valid Loss: 0.0005467224982567132\n",
      "Epoch: 7954, Train Loss: 0.0003624986857175827, Valid Loss: 0.0005464328569360077\n",
      "Epoch: 7955, Train Loss: 0.000362289632903412, Valid Loss: 0.0005461438558995724\n",
      "Epoch: 7956, Train Loss: 0.0003620811039581895, Valid Loss: 0.0005458580562844872\n",
      "Epoch: 7957, Train Loss: 0.0003618719056248665, Valid Loss: 0.000545575690921396\n",
      "Epoch: 7958, Train Loss: 0.0003616631147451699, Valid Loss: 0.0005452874465845525\n",
      "Epoch: 7959, Train Loss: 0.000361455517122522, Valid Loss: 0.0005449997843243182\n",
      "Epoch: 7960, Train Loss: 0.0003612459695432335, Valid Loss: 0.0005447150324471295\n",
      "Epoch: 7961, Train Loss: 0.0003610404091887176, Valid Loss: 0.0005444295238703489\n",
      "Epoch: 7962, Train Loss: 0.00036083129816688597, Valid Loss: 0.0005441477405838668\n",
      "Epoch: 7963, Train Loss: 0.00036062224535271525, Valid Loss: 0.0005438545485958457\n",
      "Epoch: 7964, Train Loss: 0.000360415899194777, Valid Loss: 0.0005435774801298976\n",
      "Epoch: 7965, Train Loss: 0.0003602070501074195, Valid Loss: 0.0005432870821096003\n",
      "Epoch: 7966, Train Loss: 0.00036000131512992084, Valid Loss: 0.0005430032033473253\n",
      "Epoch: 7967, Train Loss: 0.000359792000381276, Valid Loss: 0.0005427153082564473\n",
      "Epoch: 7968, Train Loss: 0.0003595852176658809, Valid Loss: 0.0005424324190244079\n",
      "Epoch: 7969, Train Loss: 0.00035937849315814674, Valid Loss: 0.0005421453970484436\n",
      "Epoch: 7970, Train Loss: 0.0003591722634155303, Valid Loss: 0.0005418593646027148\n",
      "Epoch: 7971, Train Loss: 0.0003589650150388479, Valid Loss: 0.0005415730411186814\n",
      "Epoch: 7972, Train Loss: 0.00035875788307748735, Valid Loss: 0.0005412965547293425\n",
      "Epoch: 7973, Train Loss: 0.0003585507511161268, Valid Loss: 0.0005410059238784015\n",
      "Epoch: 7974, Train Loss: 0.00035834379377774894, Valid Loss: 0.0005407209973782301\n",
      "Epoch: 7975, Train Loss: 0.0003581391356419772, Valid Loss: 0.0005404376424849033\n",
      "Epoch: 7976, Train Loss: 0.0003579322074074298, Valid Loss: 0.0005401597009040415\n",
      "Epoch: 7977, Train Loss: 0.00035772606497630477, Valid Loss: 0.0005398670327849686\n",
      "Epoch: 7978, Train Loss: 0.0003575204173102975, Valid Loss: 0.0005395841435529292\n",
      "Epoch: 7979, Train Loss: 0.0003573143621906638, Valid Loss: 0.0005393028841353953\n",
      "Epoch: 7980, Train Loss: 0.00035710950032807887, Valid Loss: 0.0005390211008489132\n",
      "Epoch: 7981, Train Loss: 0.00035690178629010916, Valid Loss: 0.0005387369310483336\n",
      "Epoch: 7982, Train Loss: 0.0003566957311704755, Valid Loss: 0.0005384546238929033\n",
      "Epoch: 7983, Train Loss: 0.00035649086930789053, Valid Loss: 0.0005381713272072375\n",
      "Epoch: 7984, Train Loss: 0.00035628690966404974, Valid Loss: 0.0005378909991122782\n",
      "Epoch: 7985, Train Loss: 0.0003560804179869592, Valid Loss: 0.0005376077606342733\n",
      "Epoch: 7986, Train Loss: 0.0003558752068784088, Valid Loss: 0.0005373235326260328\n",
      "Epoch: 7987, Train Loss: 0.0003556697629392147, Valid Loss: 0.0005370394792407751\n",
      "Epoch: 7988, Train Loss: 0.00035546591971069574, Valid Loss: 0.0005367590929381549\n",
      "Epoch: 7989, Train Loss: 0.00035526021383702755, Valid Loss: 0.0005364725948311388\n",
      "Epoch: 7990, Train Loss: 0.00035505721461959183, Valid Loss: 0.0005361931398510933\n",
      "Epoch: 7991, Train Loss: 0.00035485366242937744, Valid Loss: 0.0005359103088267148\n",
      "Epoch: 7992, Train Loss: 0.0003546476364135742, Valid Loss: 0.0005356348701752722\n",
      "Epoch: 7993, Train Loss: 0.00035444472450762987, Valid Loss: 0.0005353479646146297\n",
      "Epoch: 7994, Train Loss: 0.00035424070665612817, Valid Loss: 0.0005350655992515385\n",
      "Epoch: 7995, Train Loss: 0.0003540354664437473, Valid Loss: 0.0005347884143702686\n",
      "Epoch: 7996, Train Loss: 0.0003538323799148202, Valid Loss: 0.0005345079116523266\n",
      "Epoch: 7997, Train Loss: 0.00035362818744033575, Valid Loss: 0.0005342253134585917\n",
      "Epoch: 7998, Train Loss: 0.000353425886714831, Valid Loss: 0.0005339446943253279\n",
      "Epoch: 7999, Train Loss: 0.0003532221307978034, Valid Loss: 0.0005336636677384377\n",
      "Epoch: 8000, Train Loss: 0.0003530173853505403, Valid Loss: 0.0005333846202120185\n",
      "Epoch: 8001, Train Loss: 0.0003528135421220213, Valid Loss: 0.0005331065040081739\n",
      "Epoch: 8002, Train Loss: 0.0003526108921505511, Valid Loss: 0.0005328264087438583\n",
      "Epoch: 8003, Train Loss: 0.0003524084168020636, Valid Loss: 0.0005325502133928239\n",
      "Epoch: 8004, Train Loss: 0.0003522050683386624, Valid Loss: 0.0005322672659531236\n",
      "Epoch: 8005, Train Loss: 0.0003520029713399708, Valid Loss: 0.0005319904303178191\n",
      "Epoch: 8006, Train Loss: 0.0003517995646689087, Valid Loss: 0.0005317082977853715\n",
      "Epoch: 8007, Train Loss: 0.0003515992721077055, Valid Loss: 0.000531431520357728\n",
      "Epoch: 8008, Train Loss: 0.00035139621468260884, Valid Loss: 0.0005311439745128155\n",
      "Epoch: 8009, Train Loss: 0.00035119318636134267, Valid Loss: 0.0005308704567141831\n",
      "Epoch: 8010, Train Loss: 0.0003509914968162775, Valid Loss: 0.0005305915838107467\n",
      "Epoch: 8011, Train Loss: 0.00035079033114016056, Valid Loss: 0.0005303194629959762\n",
      "Epoch: 8012, Train Loss: 0.0003505887580104172, Valid Loss: 0.0005300308694131672\n",
      "Epoch: 8013, Train Loss: 0.0003503854386508465, Valid Loss: 0.0005297584575600922\n",
      "Epoch: 8014, Train Loss: 0.00035018555354326963, Valid Loss: 0.0005294735892675817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8015, Train Loss: 0.000349981477484107, Valid Loss: 0.0005292041460052133\n",
      "Epoch: 8016, Train Loss: 0.00034978173789568245, Valid Loss: 0.0005289210821501911\n",
      "Epoch: 8017, Train Loss: 0.0003495796408969909, Valid Loss: 0.0005286518717184663\n",
      "Epoch: 8018, Train Loss: 0.0003493781841825694, Valid Loss: 0.0005283628706820309\n",
      "Epoch: 8019, Train Loss: 0.0003491768438834697, Valid Loss: 0.0005280929035507143\n",
      "Epoch: 8020, Train Loss: 0.0003489766095299274, Valid Loss: 0.0005278108874335885\n",
      "Epoch: 8021, Train Loss: 0.0003487731155473739, Valid Loss: 0.0005275427829474211\n",
      "Epoch: 8022, Train Loss: 0.0003485743363853544, Valid Loss: 0.0005272534908726811\n",
      "Epoch: 8023, Train Loss: 0.00034837384009733796, Valid Loss: 0.000526989926584065\n",
      "Epoch: 8024, Train Loss: 0.00034817290725186467, Valid Loss: 0.0005267006927169859\n",
      "Epoch: 8025, Train Loss: 0.0003479736333247274, Valid Loss: 0.0005264371866360307\n",
      "Epoch: 8026, Train Loss: 0.0003477732534520328, Valid Loss: 0.0005261493497528136\n",
      "Epoch: 8027, Train Loss: 0.0003475750854704529, Valid Loss: 0.0005258885794319212\n",
      "Epoch: 8028, Train Loss: 0.00034737290116027, Valid Loss: 0.0005255892756395042\n",
      "Epoch: 8029, Train Loss: 0.0003471745876595378, Valid Loss: 0.000525335140991956\n",
      "Epoch: 8030, Train Loss: 0.0003469738003332168, Valid Loss: 0.0005250407848507166\n",
      "Epoch: 8031, Train Loss: 0.00034677411895245314, Valid Loss: 0.0005247853696346283\n",
      "Epoch: 8032, Train Loss: 0.0003465753688942641, Valid Loss: 0.0005244891508482397\n",
      "Epoch: 8033, Train Loss: 0.0003463746979832649, Valid Loss: 0.0005242350162006915\n",
      "Epoch: 8034, Train Loss: 0.0003461767337284982, Valid Loss: 0.0005239367601461709\n",
      "Epoch: 8035, Train Loss: 0.0003459768486209214, Valid Loss: 0.0005236829165369272\n",
      "Epoch: 8036, Train Loss: 0.00034577943733893335, Valid Loss: 0.0005233847186900675\n",
      "Epoch: 8037, Train Loss: 0.00034557931940071285, Valid Loss: 0.0005231352988630533\n",
      "Epoch: 8038, Train Loss: 0.0003453811223153025, Valid Loss: 0.0005228365771472454\n",
      "Epoch: 8039, Train Loss: 0.00034518138272687793, Valid Loss: 0.0005225879140198231\n",
      "Epoch: 8040, Train Loss: 0.00034498286549933255, Valid Loss: 0.0005222863983362913\n",
      "Epoch: 8041, Train Loss: 0.0003447853960096836, Valid Loss: 0.0005220414604991674\n",
      "Epoch: 8042, Train Loss: 0.0003445864422246814, Valid Loss: 0.0005217341822572052\n",
      "Epoch: 8043, Train Loss: 0.000344388943631202, Valid Loss: 0.0005214932025410235\n",
      "Epoch: 8044, Train Loss: 0.00034418998984619975, Valid Loss: 0.0005211865063756704\n",
      "Epoch: 8045, Train Loss: 0.0003439930151216686, Valid Loss: 0.0005209481460042298\n",
      "Epoch: 8046, Train Loss: 0.0003437942359596491, Valid Loss: 0.000520638539455831\n",
      "Epoch: 8047, Train Loss: 0.0003435984253883362, Valid Loss: 0.0005204040207900107\n",
      "Epoch: 8048, Train Loss: 0.00034339987905696034, Valid Loss: 0.0005200941814109683\n",
      "Epoch: 8049, Train Loss: 0.0003432012163102627, Valid Loss: 0.0005198561120778322\n",
      "Epoch: 8050, Train Loss: 0.00034300534753128886, Valid Loss: 0.0005195448757149279\n",
      "Epoch: 8051, Train Loss: 0.0003428074123803526, Valid Loss: 0.0005193070974200964\n",
      "Epoch: 8052, Train Loss: 0.0003426096518523991, Valid Loss: 0.0005190043011680245\n",
      "Epoch: 8053, Train Loss: 0.000342412298778072, Valid Loss: 0.0005187633796595037\n",
      "Epoch: 8054, Train Loss: 0.00034221509122289717, Valid Loss: 0.000518455752171576\n",
      "Epoch: 8055, Train Loss: 0.00034201762173324823, Valid Loss: 0.0005182131426408887\n",
      "Epoch: 8056, Train Loss: 0.00034182105446234345, Valid Loss: 0.0005179129657335579\n",
      "Epoch: 8057, Train Loss: 0.0003416245453990996, Valid Loss: 0.0005176689010113478\n",
      "Epoch: 8058, Train Loss: 0.00034142748336307704, Valid Loss: 0.0005173709359951317\n",
      "Epoch: 8059, Train Loss: 0.00034123059595003724, Valid Loss: 0.0005171236116439104\n",
      "Epoch: 8060, Train Loss: 0.0003410347271710634, Valid Loss: 0.0005168283241800964\n",
      "Epoch: 8061, Train Loss: 0.0003408378397580236, Valid Loss: 0.000516579020768404\n",
      "Epoch: 8062, Train Loss: 0.0003406413597986102, Valid Loss: 0.0005162910674698651\n",
      "Epoch: 8063, Train Loss: 0.00034044607309624553, Valid Loss: 0.0005160307046025991\n",
      "Epoch: 8064, Train Loss: 0.00034025099012069404, Valid Loss: 0.000515744264703244\n",
      "Epoch: 8065, Train Loss: 0.0003400543937459588, Valid Loss: 0.0005154905375093222\n",
      "Epoch: 8066, Train Loss: 0.0003398580302018672, Valid Loss: 0.0005152093362994492\n",
      "Epoch: 8067, Train Loss: 0.0003396630345378071, Valid Loss: 0.0005149458302184939\n",
      "Epoch: 8068, Train Loss: 0.00033946847543120384, Valid Loss: 0.0005146687617525458\n",
      "Epoch: 8069, Train Loss: 0.00033927158801816404, Valid Loss: 0.0005144003662280738\n",
      "Epoch: 8070, Train Loss: 0.0003390766796655953, Valid Loss: 0.0005141280125826597\n",
      "Epoch: 8071, Train Loss: 0.0003388809273019433, Valid Loss: 0.0005138654378242791\n",
      "Epoch: 8072, Train Loss: 0.0003386866010259837, Valid Loss: 0.000513593084178865\n",
      "Epoch: 8073, Train Loss: 0.00033849081955850124, Valid Loss: 0.0005133191589266062\n",
      "Epoch: 8074, Train Loss: 0.0003382960567250848, Valid Loss: 0.0005130563513375819\n",
      "Epoch: 8075, Train Loss: 0.0003381026617716998, Valid Loss: 0.0005127845797687769\n",
      "Epoch: 8076, Train Loss: 0.00033790827728807926, Valid Loss: 0.0005125210154801607\n",
      "Epoch: 8077, Train Loss: 0.00033771255402825773, Valid Loss: 0.00051224569324404\n",
      "Epoch: 8078, Train Loss: 0.00033751947921700776, Valid Loss: 0.0005119785200804472\n",
      "Epoch: 8079, Train Loss: 0.00033732489100657403, Valid Loss: 0.0005117031396366656\n",
      "Epoch: 8080, Train Loss: 0.0003371298953425139, Valid Loss: 0.000511442543938756\n",
      "Epoch: 8081, Train Loss: 0.00033693702425807714, Valid Loss: 0.0005111685022711754\n",
      "Epoch: 8082, Train Loss: 0.00033674368751235306, Valid Loss: 0.0005109088378958404\n",
      "Epoch: 8083, Train Loss: 0.0003365501179359853, Valid Loss: 0.0005106338649056852\n",
      "Epoch: 8084, Train Loss: 0.0003363570140209049, Valid Loss: 0.0005103718140162528\n",
      "Epoch: 8085, Train Loss: 0.00033616175642237067, Valid Loss: 0.0005100970156490803\n",
      "Epoch: 8086, Train Loss: 0.00033597013680264354, Valid Loss: 0.0005098365363664925\n",
      "Epoch: 8087, Train Loss: 0.00033577810972929, Valid Loss: 0.0005095628439448774\n",
      "Epoch: 8088, Train Loss: 0.0003355840453878045, Valid Loss: 0.0005092985229566693\n",
      "Epoch: 8089, Train Loss: 0.00033539155265316367, Valid Loss: 0.0005090272170491517\n",
      "Epoch: 8090, Train Loss: 0.00033519824501127005, Valid Loss: 0.0005087671452201903\n",
      "Epoch: 8091, Train Loss: 0.0003350060142111033, Valid Loss: 0.0005084963049739599\n",
      "Epoch: 8092, Train Loss: 0.00033481433638371527, Valid Loss: 0.0005082298303022981\n",
      "Epoch: 8093, Train Loss: 0.00033461989369243383, Valid Loss: 0.0005079605616629124\n",
      "Epoch: 8094, Train Loss: 0.0003344278666190803, Valid Loss: 0.0005076987436041236\n",
      "Epoch: 8095, Train Loss: 0.0003342348209116608, Valid Loss: 0.0005074323271401227\n",
      "Epoch: 8096, Train Loss: 0.00033404296846129, Valid Loss: 0.0005071649211458862\n",
      "Epoch: 8097, Train Loss: 0.00033385257120244205, Valid Loss: 0.000506895943544805\n",
      "Epoch: 8098, Train Loss: 0.0003336589434184134, Valid Loss: 0.0005066335434094071\n",
      "Epoch: 8099, Train Loss: 0.0003334669745527208, Valid Loss: 0.0005063645076006651\n",
      "Epoch: 8100, Train Loss: 0.000333276460878551, Valid Loss: 0.0005060986732132733\n",
      "Epoch: 8101, Train Loss: 0.0003330835315864533, Valid Loss: 0.0005058373790234327\n",
      "Epoch: 8102, Train Loss: 0.0003328929597046226, Valid Loss: 0.0005055679357610643\n",
      "Epoch: 8103, Train Loss: 0.00033269866253249347, Valid Loss: 0.000505296338815242\n",
      "Epoch: 8104, Train Loss: 0.00033250966225750744, Valid Loss: 0.0005050412146374583\n",
      "Epoch: 8105, Train Loss: 0.0003323174605611712, Valid Loss: 0.0005047724698670208\n",
      "Epoch: 8106, Train Loss: 0.0003321289550513029, Valid Loss: 0.0005045117577537894\n",
      "Epoch: 8107, Train Loss: 0.0003319362585898489, Valid Loss: 0.00050424097571522\n",
      "Epoch: 8108, Train Loss: 0.00033174545387737453, Valid Loss: 0.0005039778188802302\n",
      "Epoch: 8109, Train Loss: 0.0003315550566185266, Valid Loss: 0.0005037193768657744\n",
      "Epoch: 8110, Train Loss: 0.00033136591082438827, Valid Loss: 0.0005034544155932963\n",
      "Epoch: 8111, Train Loss: 0.0003311742621008307, Valid Loss: 0.000503188231959939\n",
      "Epoch: 8112, Train Loss: 0.0003309825260657817, Valid Loss: 0.0005029240273870528\n",
      "Epoch: 8113, Train Loss: 0.000330795330228284, Valid Loss: 0.0005026584258303046\n",
      "Epoch: 8114, Train Loss: 0.0003306036232970655, Valid Loss: 0.0005023974808864295\n",
      "Epoch: 8115, Train Loss: 0.0003304116544313729, Valid Loss: 0.0005021318211220205\n",
      "Epoch: 8116, Train Loss: 0.00033022352727130055, Valid Loss: 0.000501869129948318\n",
      "Epoch: 8117, Train Loss: 0.00033003432326950133, Valid Loss: 0.0005016087088733912\n",
      "Epoch: 8118, Train Loss: 0.0003298429073765874, Valid Loss: 0.0005013439222238958\n",
      "Epoch: 8119, Train Loss: 0.00032965399441309273, Valid Loss: 0.0005010811728425324\n",
      "Epoch: 8120, Train Loss: 0.0003294642665423453, Valid Loss: 0.0005008158623240888\n",
      "Epoch: 8121, Train Loss: 0.00032927427673712373, Valid Loss: 0.000500555383041501\n",
      "Epoch: 8122, Train Loss: 0.00032908536377362907, Valid Loss: 0.0005002924590371549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8123, Train Loss: 0.0003288951702415943, Valid Loss: 0.0005000298842787743\n",
      "Epoch: 8124, Train Loss: 0.0003287065483164042, Valid Loss: 0.0004997643991373479\n",
      "Epoch: 8125, Train Loss: 0.00032851865398697555, Valid Loss: 0.0004995023482479155\n",
      "Epoch: 8126, Train Loss: 0.0003283295955043286, Valid Loss: 0.0004992368631064892\n",
      "Epoch: 8127, Train Loss: 0.00032814170117489994, Valid Loss: 0.0004989855224266648\n",
      "Epoch: 8128, Train Loss: 0.0003279517695773393, Valid Loss: 0.0004987145657651126\n",
      "Epoch: 8129, Train Loss: 0.00032776311854831874, Valid Loss: 0.000498456705827266\n",
      "Epoch: 8130, Train Loss: 0.0003275759518146515, Valid Loss: 0.0004981966922059655\n",
      "Epoch: 8131, Train Loss: 0.00032738567097112536, Valid Loss: 0.0004979387740604579\n",
      "Epoch: 8132, Train Loss: 0.00032719806768000126, Valid Loss: 0.0004976677009835839\n",
      "Epoch: 8133, Train Loss: 0.00032701011514291167, Valid Loss: 0.0004974075127393007\n",
      "Epoch: 8134, Train Loss: 0.00032682111486792564, Valid Loss: 0.0004971454036422074\n",
      "Epoch: 8135, Train Loss: 0.0003266352287027985, Valid Loss: 0.00049689068691805\n",
      "Epoch: 8136, Train Loss: 0.0003264466067776084, Valid Loss: 0.0004966259002685547\n",
      "Epoch: 8137, Train Loss: 0.00032625996391288936, Valid Loss: 0.0004963706014677882\n",
      "Epoch: 8138, Train Loss: 0.0003260727389715612, Valid Loss: 0.0004961055237799883\n",
      "Epoch: 8139, Train Loss: 0.00032588423346169293, Valid Loss: 0.000495844753459096\n",
      "Epoch: 8140, Train Loss: 0.00032569741597399116, Valid Loss: 0.000495583051815629\n",
      "Epoch: 8141, Train Loss: 0.0003255110059399158, Valid Loss: 0.0004953258321620524\n",
      "Epoch: 8142, Train Loss: 0.00032532308250665665, Valid Loss: 0.0004950638976879418\n",
      "Epoch: 8143, Train Loss: 0.0003251360321883112, Valid Loss: 0.0004948076093569398\n",
      "Epoch: 8144, Train Loss: 0.000324949185596779, Valid Loss: 0.0004945466062054038\n",
      "Epoch: 8145, Train Loss: 0.0003247630374971777, Valid Loss: 0.0004942898522131145\n",
      "Epoch: 8146, Train Loss: 0.0003245753177907318, Valid Loss: 0.000494026520755142\n",
      "Epoch: 8147, Train Loss: 0.000324389198794961, Valid Loss: 0.0004937701160088181\n",
      "Epoch: 8148, Train Loss: 0.00032420354546047747, Valid Loss: 0.0004935137112624943\n",
      "Epoch: 8149, Train Loss: 0.000324016174999997, Valid Loss: 0.0004932584124617279\n",
      "Epoch: 8150, Train Loss: 0.0003238299104850739, Valid Loss: 0.000492993276566267\n",
      "Epoch: 8151, Train Loss: 0.00032364451908506453, Valid Loss: 0.0004927377449348569\n",
      "Epoch: 8152, Train Loss: 0.00032345825457014143, Valid Loss: 0.0004924819804728031\n",
      "Epoch: 8153, Train Loss: 0.00032327204826287925, Valid Loss: 0.000492221093736589\n",
      "Epoch: 8154, Train Loss: 0.00032308761728927493, Valid Loss: 0.0004919613129459321\n",
      "Epoch: 8155, Train Loss: 0.00032290100352838635, Valid Loss: 0.0004917039768770337\n",
      "Epoch: 8156, Train Loss: 0.0003227155830245465, Valid Loss: 0.0004914455348625779\n",
      "Epoch: 8157, Train Loss: 0.0003225304535590112, Valid Loss: 0.0004911862779408693\n",
      "Epoch: 8158, Train Loss: 0.00032234532409347594, Valid Loss: 0.0004909299896098673\n",
      "Epoch: 8159, Train Loss: 0.0003221592924091965, Valid Loss: 0.0004906749236397445\n",
      "Epoch: 8160, Train Loss: 0.00032197506516240537, Valid Loss: 0.0004904162487946451\n",
      "Epoch: 8161, Train Loss: 0.00032179022673517466, Valid Loss: 0.0004901556530967355\n",
      "Epoch: 8162, Train Loss: 0.00032160570845007896, Valid Loss: 0.0004899039049632847\n",
      "Epoch: 8163, Train Loss: 0.0003214193566236645, Valid Loss: 0.0004896450554952025\n",
      "Epoch: 8164, Train Loss: 0.0003212372539564967, Valid Loss: 0.0004893902223557234\n",
      "Epoch: 8165, Train Loss: 0.0003210511349607259, Valid Loss: 0.0004891326534561813\n",
      "Epoch: 8166, Train Loss: 0.0003208681882824749, Valid Loss: 0.0004888738039880991\n",
      "Epoch: 8167, Train Loss: 0.000320683466270566, Valid Loss: 0.000488615594804287\n",
      "Epoch: 8168, Train Loss: 0.00032049985020421445, Valid Loss: 0.0004883624496869743\n",
      "Epoch: 8169, Train Loss: 0.00032031501177698374, Valid Loss: 0.0004881063068751246\n",
      "Epoch: 8170, Train Loss: 0.0003201304061803967, Valid Loss: 0.00048784897080622613\n",
      "Epoch: 8171, Train Loss: 0.0003199478378519416, Valid Loss: 0.00048758985940366983\n",
      "Epoch: 8172, Train Loss: 0.0003197614278178662, Valid Loss: 0.00048733846051618457\n",
      "Epoch: 8173, Train Loss: 0.00031957958708517253, Valid Loss: 0.00048708298709243536\n",
      "Epoch: 8174, Train Loss: 0.00031939646578393877, Valid Loss: 0.00048682474880479276\n",
      "Epoch: 8175, Train Loss: 0.0003192118019796908, Valid Loss: 0.0004865720111411065\n",
      "Epoch: 8176, Train Loss: 0.00031902879709377885, Valid Loss: 0.0004863170615863055\n",
      "Epoch: 8177, Train Loss: 0.000318845734000206, Valid Loss: 0.0004860600456595421\n",
      "Epoch: 8178, Train Loss: 0.0003186624380759895, Valid Loss: 0.00048580695874989033\n",
      "Epoch: 8179, Train Loss: 0.0003184801898896694, Valid Loss: 0.0004855534352827817\n",
      "Epoch: 8180, Train Loss: 0.000318296835757792, Valid Loss: 0.0004852958663832396\n",
      "Epoch: 8181, Train Loss: 0.00031811330700293183, Valid Loss: 0.00048504542792215943\n",
      "Epoch: 8182, Train Loss: 0.00031793079688213766, Valid Loss: 0.00048479216638952494\n",
      "Epoch: 8183, Train Loss: 0.0003177480539306998, Valid Loss: 0.00048453774070367217\n",
      "Epoch: 8184, Train Loss: 0.000317566329613328, Valid Loss: 0.00048428282025270164\n",
      "Epoch: 8185, Train Loss: 0.0003173828008584678, Valid Loss: 0.0004840290639549494\n",
      "Epoch: 8186, Train Loss: 0.0003172010474372655, Valid Loss: 0.000483773386804387\n",
      "Epoch: 8187, Train Loss: 0.00031701879925094545, Valid Loss: 0.00048352190060541034\n",
      "Epoch: 8188, Train Loss: 0.00031683756969869137, Valid Loss: 0.0004832692793570459\n",
      "Epoch: 8189, Train Loss: 0.0003166542446706444, Valid Loss: 0.000483016629004851\n",
      "Epoch: 8190, Train Loss: 0.00031647455762140453, Valid Loss: 0.00048275981680490077\n",
      "Epoch: 8191, Train Loss: 0.0003162923385389149, Valid Loss: 0.0004825080104637891\n",
      "Epoch: 8192, Train Loss: 0.0003161108761560172, Valid Loss: 0.0004822567861992866\n",
      "Epoch: 8193, Train Loss: 0.00031592807499691844, Valid Loss: 0.00048199945013038814\n",
      "Epoch: 8194, Train Loss: 0.0003157473402097821, Valid Loss: 0.00048175244592130184\n",
      "Epoch: 8195, Train Loss: 0.000315566489007324, Valid Loss: 0.00048149519716389477\n",
      "Epoch: 8196, Train Loss: 0.0003153836587443948, Valid Loss: 0.00048124586464837193\n",
      "Epoch: 8197, Train Loss: 0.0003152045246679336, Valid Loss: 0.0004809929523617029\n",
      "Epoch: 8198, Train Loss: 0.00031502178171649575, Valid Loss: 0.00048073791549541056\n",
      "Epoch: 8199, Train Loss: 0.0003148411342408508, Valid Loss: 0.0004804908821824938\n",
      "Epoch: 8200, Train Loss: 0.00031466077780351043, Valid Loss: 0.00048024154966697097\n",
      "Epoch: 8201, Train Loss: 0.0003144801303278655, Valid Loss: 0.00047998144873417914\n",
      "Epoch: 8202, Train Loss: 0.00031429968657903373, Valid Loss: 0.00047973409527912736\n",
      "Epoch: 8203, Train Loss: 0.0003141175548080355, Valid Loss: 0.00047948237624950707\n",
      "Epoch: 8204, Train Loss: 0.0003139394102618098, Valid Loss: 0.00047922981320880353\n",
      "Epoch: 8205, Train Loss: 0.00031375762773677707, Valid Loss: 0.00047897323383949697\n",
      "Epoch: 8206, Train Loss: 0.00031357741681858897, Valid Loss: 0.0004787298967130482\n",
      "Epoch: 8207, Train Loss: 0.0003133982536382973, Valid Loss: 0.0004784810880664736\n",
      "Epoch: 8208, Train Loss: 0.00031321850838139653, Valid Loss: 0.00047822706983424723\n",
      "Epoch: 8209, Train Loss: 0.00031303829746320844, Valid Loss: 0.0004779695300385356\n",
      "Epoch: 8210, Train Loss: 0.0003128595126327127, Valid Loss: 0.00047772619291208684\n",
      "Epoch: 8211, Train Loss: 0.0003126794472336769, Valid Loss: 0.00047747735516168177\n",
      "Epoch: 8212, Train Loss: 0.0003125008079223335, Valid Loss: 0.00047722310409881175\n",
      "Epoch: 8213, Train Loss: 0.00031232144101522863, Valid Loss: 0.00047697097761556506\n",
      "Epoch: 8214, Train Loss: 0.00031214143382385373, Valid Loss: 0.00047672761138528585\n",
      "Epoch: 8215, Train Loss: 0.0003119619796052575, Valid Loss: 0.00047647496103309095\n",
      "Epoch: 8216, Train Loss: 0.00031178281642496586, Valid Loss: 0.00047622117563150823\n",
      "Epoch: 8217, Train Loss: 0.00031160310027189553, Valid Loss: 0.0004759721923619509\n",
      "Epoch: 8218, Train Loss: 0.00031142504303716123, Valid Loss: 0.0004757281276397407\n",
      "Epoch: 8219, Train Loss: 0.0003112460544798523, Valid Loss: 0.00047547920257784426\n",
      "Epoch: 8220, Train Loss: 0.00031106709502637386, Valid Loss: 0.00047522757085971534\n",
      "Epoch: 8221, Train Loss: 0.00031088717514649034, Valid Loss: 0.0004749770450871438\n",
      "Epoch: 8222, Train Loss: 0.00031070891418494284, Valid Loss: 0.00047472643200308084\n",
      "Epoch: 8223, Train Loss: 0.0003105319628957659, Valid Loss: 0.00047448440454900265\n",
      "Epoch: 8224, Train Loss: 0.00031035408028401434, Valid Loss: 0.00047423504292964935\n",
      "Epoch: 8225, Train Loss: 0.0003101760521531105, Valid Loss: 0.0004739870491903275\n",
      "Epoch: 8226, Train Loss: 0.0003099975874647498, Valid Loss: 0.000473734806291759\n",
      "Epoch: 8227, Train Loss: 0.00030982063617557287, Valid Loss: 0.00047349289525300264\n",
      "Epoch: 8228, Train Loss: 0.00030964158941060305, Valid Loss: 0.00047323695616796613\n",
      "Epoch: 8229, Train Loss: 0.0003094645217061043, Valid Loss: 0.0004729897773358971\n",
      "Epoch: 8230, Train Loss: 0.00030928675550967455, Valid Loss: 0.00047274332609958947\n",
      "Epoch: 8231, Train Loss: 0.0003091090184170753, Valid Loss: 0.00047249841736629605\n",
      "Epoch: 8232, Train Loss: 0.000308930961182341, Valid Loss: 0.00047224824083968997\n",
      "Epoch: 8233, Train Loss: 0.0003087540972046554, Valid Loss: 0.00047200158587656915\n",
      "Epoch: 8234, Train Loss: 0.0003085770586039871, Valid Loss: 0.0004717515839729458\n",
      "Epoch: 8235, Train Loss: 0.00030840010731481016, Valid Loss: 0.0004715089744422585\n",
      "Epoch: 8236, Train Loss: 0.00030822301050648093, Valid Loss: 0.0004712556255981326\n",
      "Epoch: 8237, Train Loss: 0.0003080457972828299, Valid Loss: 0.0004710151697508991\n",
      "Epoch: 8238, Train Loss: 0.0003078696900047362, Valid Loss: 0.00047076205373741686\n",
      "Epoch: 8239, Train Loss: 0.0003076913708355278, Valid Loss: 0.0004705207538791001\n",
      "Epoch: 8240, Train Loss: 0.000307515321765095, Valid Loss: 0.000470270257210359\n",
      "Epoch: 8241, Train Loss: 0.000307338748825714, Valid Loss: 0.00047003384679555893\n",
      "Epoch: 8242, Train Loss: 0.0003071630490012467, Valid Loss: 0.0004697781696449965\n",
      "Epoch: 8243, Train Loss: 0.00030698662158101797, Valid Loss: 0.0004695364332292229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8244, Train Loss: 0.00030680978670716286, Valid Loss: 0.00046928576193749905\n",
      "Epoch: 8245, Train Loss: 0.00030663309735246, Valid Loss: 0.00046904495684430003\n",
      "Epoch: 8246, Train Loss: 0.00030645931838080287, Valid Loss: 0.00046879437286406755\n",
      "Epoch: 8247, Train Loss: 0.000306283647660166, Valid Loss: 0.000468559330329299\n",
      "Epoch: 8248, Train Loss: 0.0003061058814637363, Valid Loss: 0.00046829989878460765\n",
      "Epoch: 8249, Train Loss: 0.0003059320442844182, Valid Loss: 0.0004680634301621467\n",
      "Epoch: 8250, Train Loss: 0.0003057548019569367, Valid Loss: 0.0004678154073189944\n",
      "Epoch: 8251, Train Loss: 0.0003055814013350755, Valid Loss: 0.0004675801901612431\n",
      "Epoch: 8252, Train Loss: 0.00030540424631908536, Valid Loss: 0.0004673214862123132\n",
      "Epoch: 8253, Train Loss: 0.0003052292740903795, Valid Loss: 0.0004670848429668695\n",
      "Epoch: 8254, Train Loss: 0.0003050544182769954, Valid Loss: 0.00046683664550073445\n",
      "Epoch: 8255, Train Loss: 0.000304878456518054, Valid Loss: 0.0004665976739488542\n",
      "Epoch: 8256, Train Loss: 0.0003047053760383278, Valid Loss: 0.00046634257887490094\n",
      "Epoch: 8257, Train Loss: 0.00030453020008280873, Valid Loss: 0.0004661060811486095\n",
      "Epoch: 8258, Train Loss: 0.00030435624648816884, Valid Loss: 0.00046585482778027654\n",
      "Epoch: 8259, Train Loss: 0.0003041803720407188, Valid Loss: 0.00046561702038161457\n",
      "Epoch: 8260, Train Loss: 0.00030400542891584337, Valid Loss: 0.00046536928857676685\n",
      "Epoch: 8261, Train Loss: 0.0003038315044250339, Valid Loss: 0.0004651295894291252\n",
      "Epoch: 8262, Train Loss: 0.0003036577545572072, Valid Loss: 0.00046487973304465413\n",
      "Epoch: 8263, Train Loss: 0.00030348289874382317, Valid Loss: 0.00046463965554721653\n",
      "Epoch: 8264, Train Loss: 0.0003033083339687437, Valid Loss: 0.00046439096331596375\n",
      "Epoch: 8265, Train Loss: 0.0003031353699043393, Valid Loss: 0.0004641541454475373\n",
      "Epoch: 8266, Train Loss: 0.00030296147451736033, Valid Loss: 0.00046390347415581346\n",
      "Epoch: 8267, Train Loss: 0.00030278690974228084, Valid Loss: 0.00046366543392650783\n",
      "Epoch: 8268, Train Loss: 0.0003026140620931983, Valid Loss: 0.0004634203505702317\n",
      "Epoch: 8269, Train Loss: 0.0003024395846296102, Valid Loss: 0.0004631802439689636\n",
      "Epoch: 8270, Train Loss: 0.00030226618400774896, Valid Loss: 0.00046293222112581134\n",
      "Epoch: 8271, Train Loss: 0.00030209284159354866, Valid Loss: 0.00046269773156382143\n",
      "Epoch: 8272, Train Loss: 0.0003019203431904316, Valid Loss: 0.00046245119301602244\n",
      "Epoch: 8273, Train Loss: 0.00030174708808772266, Valid Loss: 0.0004622124251909554\n",
      "Epoch: 8274, Train Loss: 0.0003015733673237264, Valid Loss: 0.0004619666433427483\n",
      "Epoch: 8275, Train Loss: 0.00030139993759803474, Valid Loss: 0.0004617251397576183\n",
      "Epoch: 8276, Train Loss: 0.0003012276429217309, Valid Loss: 0.00046147522516548634\n",
      "Epoch: 8277, Train Loss: 0.00030105627956800163, Valid Loss: 0.00046124603250063956\n",
      "Epoch: 8278, Train Loss: 0.0003008826170116663, Valid Loss: 0.0004610015021171421\n",
      "Epoch: 8279, Train Loss: 0.00030070991488173604, Valid Loss: 0.0004607646260410547\n",
      "Epoch: 8280, Train Loss: 0.000300536717986688, Valid Loss: 0.00046051107347011566\n",
      "Epoch: 8281, Train Loss: 0.00030036622774787247, Valid Loss: 0.0004602783592417836\n",
      "Epoch: 8282, Train Loss: 0.0003001929144375026, Valid Loss: 0.0004600346146617085\n",
      "Epoch: 8283, Train Loss: 0.0003000202705152333, Valid Loss: 0.0004597982042469084\n",
      "Epoch: 8284, Train Loss: 0.0002998482377734035, Valid Loss: 0.00045955070527270436\n",
      "Epoch: 8285, Train Loss: 0.00029967635055072606, Valid Loss: 0.00045931394561193883\n",
      "Epoch: 8286, Train Loss: 0.0002995049871969968, Valid Loss: 0.0004590664175339043\n",
      "Epoch: 8287, Train Loss: 0.0002993335947394371, Valid Loss: 0.0004588376032188535\n",
      "Epoch: 8288, Train Loss: 0.0002991594956256449, Valid Loss: 0.000458590715425089\n",
      "Epoch: 8289, Train Loss: 0.00029898874345235527, Valid Loss: 0.00045835954369977117\n",
      "Epoch: 8290, Train Loss: 0.00029881755472160876, Valid Loss: 0.0004581094835884869\n",
      "Epoch: 8291, Train Loss: 0.00029864764655940235, Valid Loss: 0.0004578781081363559\n",
      "Epoch: 8292, Train Loss: 0.00029847558471374214, Valid Loss: 0.00045763063826598227\n",
      "Epoch: 8293, Train Loss: 0.00029830369749106467, Valid Loss: 0.000457399757578969\n",
      "Epoch: 8294, Train Loss: 0.0002981332945637405, Valid Loss: 0.0004571529570966959\n",
      "Epoch: 8295, Train Loss: 0.0002979632990900427, Valid Loss: 0.00045692198909819126\n",
      "Epoch: 8296, Train Loss: 0.00029779152828268707, Valid Loss: 0.0004566748102661222\n",
      "Epoch: 8297, Train Loss: 0.0002976204559672624, Valid Loss: 0.00045644654892385006\n",
      "Epoch: 8298, Train Loss: 0.000297451188089326, Valid Loss: 0.00045619384036399424\n",
      "Epoch: 8299, Train Loss: 0.00029727889341302216, Valid Loss: 0.0004559647641144693\n",
      "Epoch: 8300, Train Loss: 0.0002971092180814594, Valid Loss: 0.0004557159554678947\n",
      "Epoch: 8301, Train Loss: 0.00029693881515413523, Valid Loss: 0.00045549115748144686\n",
      "Epoch: 8302, Train Loss: 0.0002967682376038283, Valid Loss: 0.00045524106826633215\n",
      "Epoch: 8303, Train Loss: 0.00029659824213013053, Valid Loss: 0.0004550157464109361\n",
      "Epoch: 8304, Train Loss: 0.00029642722802236676, Valid Loss: 0.00045476347440853715\n",
      "Epoch: 8305, Train Loss: 0.00029625784372910857, Valid Loss: 0.0004545406554825604\n",
      "Epoch: 8306, Train Loss: 0.00029608700424432755, Valid Loss: 0.0004542833485174924\n",
      "Epoch: 8307, Train Loss: 0.0002959198027383536, Valid Loss: 0.00045406323624774814\n",
      "Epoch: 8308, Train Loss: 0.0002957488177344203, Valid Loss: 0.0004538099165074527\n",
      "Epoch: 8309, Train Loss: 0.00029557981179095805, Valid Loss: 0.0004535872139967978\n",
      "Epoch: 8310, Train Loss: 0.00029540882678702474, Valid Loss: 0.0004533322644419968\n",
      "Epoch: 8311, Train Loss: 0.0002952393260784447, Valid Loss: 0.0004531161393970251\n",
      "Epoch: 8312, Train Loss: 0.00029507174622267485, Valid Loss: 0.00045285889063961804\n",
      "Epoch: 8313, Train Loss: 0.000294903467874974, Valid Loss: 0.00045263650827109814\n",
      "Epoch: 8314, Train Loss: 0.0002947333559859544, Valid Loss: 0.00045238301390782\n",
      "Epoch: 8315, Train Loss: 0.0002945643791463226, Valid Loss: 0.0004521659284364432\n",
      "Epoch: 8316, Train Loss: 0.0002943947911262512, Valid Loss: 0.0004519048088695854\n",
      "Epoch: 8317, Train Loss: 0.0002942256978712976, Valid Loss: 0.00045169051736593246\n",
      "Epoch: 8318, Train Loss: 0.0002940565173048526, Valid Loss: 0.0004514333850238472\n",
      "Epoch: 8319, Train Loss: 0.0002938894904218614, Valid Loss: 0.0004512194136623293\n",
      "Epoch: 8320, Train Loss: 0.0002937208046205342, Valid Loss: 0.00045095907989889383\n",
      "Epoch: 8321, Train Loss: 0.0002935537195298821, Valid Loss: 0.00045074819354340434\n",
      "Epoch: 8322, Train Loss: 0.0002933834330178797, Valid Loss: 0.0004504899261519313\n",
      "Epoch: 8323, Train Loss: 0.00029321544570848346, Valid Loss: 0.0004502767988014966\n",
      "Epoch: 8324, Train Loss: 0.00029304783674888313, Valid Loss: 0.00045001550461165607\n",
      "Epoch: 8325, Train Loss: 0.00029287973302416503, Valid Loss: 0.0004498065391089767\n",
      "Epoch: 8326, Train Loss: 0.0002927128516603261, Valid Loss: 0.00044954181066714227\n",
      "Epoch: 8327, Train Loss: 0.00029254541732370853, Valid Loss: 0.0004493363085202873\n",
      "Epoch: 8328, Train Loss: 0.00029237710987217724, Valid Loss: 0.00044907256960868835\n",
      "Epoch: 8329, Train Loss: 0.0002922092389781028, Valid Loss: 0.0004488666309043765\n",
      "Epoch: 8330, Train Loss: 0.0002920406695920974, Valid Loss: 0.0004485981771722436\n",
      "Epoch: 8331, Train Loss: 0.0002918746613431722, Valid Loss: 0.00044839910697191954\n",
      "Epoch: 8332, Train Loss: 0.000291707314318046, Valid Loss: 0.00044813257409259677\n",
      "Epoch: 8333, Train Loss: 0.00029154011281207204, Valid Loss: 0.00044793260167352855\n",
      "Epoch: 8334, Train Loss: 0.000291372649371624, Valid Loss: 0.00044766219798475504\n",
      "Epoch: 8335, Train Loss: 0.0002912054769694805, Valid Loss: 0.0004474582092370838\n",
      "Epoch: 8336, Train Loss: 0.0002910394105128944, Valid Loss: 0.00044719292782247066\n",
      "Epoch: 8337, Train Loss: 0.00029087217990309, Valid Loss: 0.0004469987761694938\n",
      "Epoch: 8338, Train Loss: 0.00029070655000396073, Valid Loss: 0.00044672342482954264\n",
      "Epoch: 8339, Train Loss: 0.0002905399596784264, Valid Loss: 0.0004465267120394856\n",
      "Epoch: 8340, Train Loss: 0.00029037357307970524, Valid Loss: 0.0004462542710825801\n",
      "Epoch: 8341, Train Loss: 0.00029020613874308765, Valid Loss: 0.0004460633790586144\n",
      "Epoch: 8342, Train Loss: 0.0002900398103520274, Valid Loss: 0.0004457926843315363\n",
      "Epoch: 8343, Train Loss: 0.00028987423866055906, Valid Loss: 0.0004455982125364244\n",
      "Epoch: 8344, Train Loss: 0.00028970823041163385, Valid Loss: 0.000445323035819456\n",
      "Epoch: 8345, Train Loss: 0.0002895401557907462, Valid Loss: 0.00044512833119370043\n",
      "Epoch: 8346, Train Loss: 0.00028937606839463115, Valid Loss: 0.00044485583202913404\n",
      "Epoch: 8347, Train Loss: 0.00028921011835336685, Valid Loss: 0.0004446620587259531\n",
      "Epoch: 8348, Train Loss: 0.000289044895907864, Valid Loss: 0.0004443884245119989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8349, Train Loss: 0.00028887714142911136, Valid Loss: 0.0004441906639840454\n",
      "Epoch: 8350, Train Loss: 0.00028871247195638716, Valid Loss: 0.00044392861309461296\n",
      "Epoch: 8351, Train Loss: 0.00028854780248366296, Valid Loss: 0.00044372639968059957\n",
      "Epoch: 8352, Train Loss: 0.000288380280835554, Valid Loss: 0.0004434673464857042\n",
      "Epoch: 8353, Train Loss: 0.0002882159606087953, Valid Loss: 0.00044326268834993243\n",
      "Epoch: 8354, Train Loss: 0.0002880515530705452, Valid Loss: 0.00044300255831331015\n",
      "Epoch: 8355, Train Loss: 0.0002878843806684017, Valid Loss: 0.00044278817949816585\n",
      "Epoch: 8356, Train Loss: 0.00028772035147994757, Valid Loss: 0.00044254030217416584\n",
      "Epoch: 8357, Train Loss: 0.0002875557402148843, Valid Loss: 0.00044232659274712205\n",
      "Epoch: 8358, Train Loss: 0.0002873917401302606, Valid Loss: 0.0004420814220793545\n",
      "Epoch: 8359, Train Loss: 0.000287225324427709, Valid Loss: 0.0004418622993398458\n",
      "Epoch: 8360, Train Loss: 0.00028706021839752793, Valid Loss: 0.00044162425911054015\n",
      "Epoch: 8361, Train Loss: 0.00028689709142781794, Valid Loss: 0.00044139751116745174\n",
      "Epoch: 8362, Train Loss: 0.0002867346629500389, Valid Loss: 0.0004411645350046456\n",
      "Epoch: 8363, Train Loss: 0.0002865679853130132, Valid Loss: 0.00044093665201216936\n",
      "Epoch: 8364, Train Loss: 0.0002864027628675103, Valid Loss: 0.00044070312287658453\n",
      "Epoch: 8365, Train Loss: 0.0002862407127395272, Valid Loss: 0.00044046909897588193\n",
      "Epoch: 8366, Train Loss: 0.00028607691638171673, Valid Loss: 0.0004402389458846301\n",
      "Epoch: 8367, Train Loss: 0.000285910937236622, Valid Loss: 0.00044000890920870006\n",
      "Epoch: 8368, Train Loss: 0.00028574743191711605, Valid Loss: 0.0004397864977363497\n",
      "Epoch: 8369, Train Loss: 0.0002855852944776416, Valid Loss: 0.0004395536379888654\n",
      "Epoch: 8370, Train Loss: 0.00028542117797769606, Valid Loss: 0.0004393193230498582\n",
      "Epoch: 8371, Train Loss: 0.00028525784728117287, Valid Loss: 0.00043908628867939115\n",
      "Epoch: 8372, Train Loss: 0.0002850938471965492, Valid Loss: 0.0004388646921142936\n",
      "Epoch: 8373, Train Loss: 0.00028493176796473563, Valid Loss: 0.0004386313376016915\n",
      "Epoch: 8374, Train Loss: 0.0002847665164154023, Valid Loss: 0.00043840467697009444\n",
      "Epoch: 8375, Train Loss: 0.0002846029819920659, Valid Loss: 0.00043816782999783754\n",
      "Epoch: 8376, Train Loss: 0.00028444049530662596, Valid Loss: 0.0004379433812573552\n",
      "Epoch: 8377, Train Loss: 0.00028427905635908246, Valid Loss: 0.00043770685442723334\n",
      "Epoch: 8378, Train Loss: 0.00028411493985913694, Valid Loss: 0.0004374890704639256\n",
      "Epoch: 8379, Train Loss: 0.0002839520457200706, Valid Loss: 0.00043725670548155904\n",
      "Epoch: 8380, Train Loss: 0.00028379049035720527, Valid Loss: 0.00043703452683985233\n",
      "Epoch: 8381, Train Loss: 0.00028362771263346076, Valid Loss: 0.00043679476948454976\n",
      "Epoch: 8382, Train Loss: 0.0002834659826476127, Valid Loss: 0.0004365767817944288\n",
      "Epoch: 8383, Train Loss: 0.0002833012549672276, Valid Loss: 0.000436339876614511\n",
      "Epoch: 8384, Train Loss: 0.0002831392630469054, Valid Loss: 0.00043611283763311803\n",
      "Epoch: 8385, Train Loss: 0.00028297770768404007, Valid Loss: 0.00043588096741586924\n",
      "Epoch: 8386, Train Loss: 0.0002828144934028387, Valid Loss: 0.00043566085514612496\n",
      "Epoch: 8387, Train Loss: 0.0002826543932314962, Valid Loss: 0.00043542697676457465\n",
      "Epoch: 8388, Train Loss: 0.00028249245951883495, Valid Loss: 0.0004352043615654111\n",
      "Epoch: 8389, Train Loss: 0.0002823306422214955, Valid Loss: 0.00043497118167579174\n",
      "Epoch: 8390, Train Loss: 0.0002821673115249723, Valid Loss: 0.000434752058936283\n",
      "Epoch: 8391, Train Loss: 0.000282007415080443, Valid Loss: 0.0004345120396465063\n",
      "Epoch: 8392, Train Loss: 0.00028184495749883354, Valid Loss: 0.0004342937027104199\n",
      "Epoch: 8393, Train Loss: 0.00028168378048576415, Valid Loss: 0.0004340640443842858\n",
      "Epoch: 8394, Train Loss: 0.0002815214393194765, Valid Loss: 0.0004338384314905852\n",
      "Epoch: 8395, Train Loss: 0.000281361659290269, Valid Loss: 0.00043360612471587956\n",
      "Epoch: 8396, Train Loss: 0.0002811999584082514, Valid Loss: 0.0004333867400418967\n",
      "Epoch: 8397, Train Loss: 0.00028103971271775663, Valid Loss: 0.0004331570235081017\n",
      "Epoch: 8398, Train Loss: 0.0002808780409395695, Valid Loss: 0.0004329294024500996\n",
      "Epoch: 8399, Train Loss: 0.0002807169803418219, Valid Loss: 0.000432703091064468\n",
      "Epoch: 8400, Train Loss: 0.0002805556869134307, Valid Loss: 0.0004324779147282243\n",
      "Epoch: 8401, Train Loss: 0.0002803954412229359, Valid Loss: 0.00043225393164902925\n",
      "Epoch: 8402, Train Loss: 0.0002802342060022056, Valid Loss: 0.00043202441884204745\n",
      "Epoch: 8403, Train Loss: 0.0002800753863994032, Valid Loss: 0.0004318005230743438\n",
      "Epoch: 8404, Train Loss: 0.00027991418028250337, Valid Loss: 0.00043157365871593356\n",
      "Epoch: 8405, Train Loss: 0.00027975262491963804, Valid Loss: 0.00043134953011758626\n",
      "Epoch: 8406, Train Loss: 0.0002795920881908387, Valid Loss: 0.0004311208031140268\n",
      "Epoch: 8407, Train Loss: 0.0002794334723148495, Valid Loss: 0.0004308969946578145\n",
      "Epoch: 8408, Train Loss: 0.0002792739251162857, Valid Loss: 0.0004306680348236114\n",
      "Epoch: 8409, Train Loss: 0.00027911370852962136, Valid Loss: 0.0004304444300942123\n",
      "Epoch: 8410, Train Loss: 0.00027895355015061796, Valid Loss: 0.00043021977762691677\n",
      "Epoch: 8411, Train Loss: 0.0002787953708320856, Valid Loss: 0.0004299973079469055\n",
      "Epoch: 8412, Train Loss: 0.0002786342229228467, Valid Loss: 0.0004297711420804262\n",
      "Epoch: 8413, Train Loss: 0.00027847636374644935, Valid Loss: 0.0004295423277653754\n",
      "Epoch: 8414, Train Loss: 0.0002783157106023282, Valid Loss: 0.00042932198266498744\n",
      "Epoch: 8415, Train Loss: 0.00027815491193905473, Valid Loss: 0.0004291017830837518\n",
      "Epoch: 8416, Train Loss: 0.00027799728559330106, Valid Loss: 0.0004288766940589994\n",
      "Epoch: 8417, Train Loss: 0.0002778376510832459, Valid Loss: 0.0004286465118639171\n",
      "Epoch: 8418, Train Loss: 0.00027767723076976836, Valid Loss: 0.0004284238675609231\n",
      "Epoch: 8419, Train Loss: 0.00027752015739679337, Valid Loss: 0.00042820058297365904\n",
      "Epoch: 8420, Train Loss: 0.00027736066840589046, Valid Loss: 0.0004279795684851706\n",
      "Epoch: 8421, Train Loss: 0.00027720173238776624, Valid Loss: 0.00042775316978804767\n",
      "Epoch: 8422, Train Loss: 0.0002770418068394065, Valid Loss: 0.0004275327955838293\n",
      "Epoch: 8423, Train Loss: 0.000276884064078331, Valid Loss: 0.0004273048834875226\n",
      "Epoch: 8424, Train Loss: 0.00027672480791807175, Valid Loss: 0.0004270848003216088\n",
      "Epoch: 8425, Train Loss: 0.00027656799647957087, Valid Loss: 0.0004268585762474686\n",
      "Epoch: 8426, Train Loss: 0.00027640993357636034, Valid Loss: 0.0004266443429514766\n",
      "Epoch: 8427, Train Loss: 0.00027625070651993155, Valid Loss: 0.0004264121234882623\n",
      "Epoch: 8428, Train Loss: 0.000276093662250787, Valid Loss: 0.0004261920985300094\n",
      "Epoch: 8429, Train Loss: 0.00027593428967520595, Valid Loss: 0.00042596011189743876\n",
      "Epoch: 8430, Train Loss: 0.00027577747823670506, Valid Loss: 0.0004257455875631422\n",
      "Epoch: 8431, Train Loss: 0.0002756202593445778, Valid Loss: 0.0004255208477843553\n",
      "Epoch: 8432, Train Loss: 0.0002754617016762495, Valid Loss: 0.0004253014049027115\n",
      "Epoch: 8433, Train Loss: 0.000275303958915174, Valid Loss: 0.00042507314356043935\n",
      "Epoch: 8434, Train Loss: 0.00027514592511579394, Valid Loss: 0.0004248555633239448\n",
      "Epoch: 8435, Train Loss: 0.0002749889681581408, Valid Loss: 0.000424629426561296\n",
      "Epoch: 8436, Train Loss: 0.00027483003214001656, Valid Loss: 0.0004244087904226035\n",
      "Epoch: 8437, Train Loss: 0.0002746742975432426, Valid Loss: 0.00042418346856720746\n",
      "Epoch: 8438, Train Loss: 0.00027451745700091124, Valid Loss: 0.00042396795470267534\n",
      "Epoch: 8439, Train Loss: 0.0002743595978245139, Valid Loss: 0.00042373838368803263\n",
      "Epoch: 8440, Train Loss: 0.00027420115657150745, Valid Loss: 0.0004235199885442853\n",
      "Epoch: 8441, Train Loss: 0.0002740449272096157, Valid Loss: 0.00042329728603363037\n",
      "Epoch: 8442, Train Loss: 0.00027388858143240213, Valid Loss: 0.00042308398406021297\n",
      "Epoch: 8443, Train Loss: 0.0002737306640483439, Valid Loss: 0.0004228562756907195\n",
      "Epoch: 8444, Train Loss: 0.00027357370709069073, Valid Loss: 0.0004226393939461559\n",
      "Epoch: 8445, Train Loss: 0.0002734189620241523, Valid Loss: 0.00042241447954438627\n",
      "Epoch: 8446, Train Loss: 0.0002732611319515854, Valid Loss: 0.0004221971030347049\n",
      "Epoch: 8447, Train Loss: 0.0002731050772126764, Valid Loss: 0.0004219677357468754\n",
      "Epoch: 8448, Train Loss: 0.0002729491388890892, Valid Loss: 0.00042175338603556156\n",
      "Epoch: 8449, Train Loss: 0.00027279247296974063, Valid Loss: 0.00042152873356826603\n",
      "Epoch: 8450, Train Loss: 0.0002726367092691362, Valid Loss: 0.00042131493682973087\n",
      "Epoch: 8451, Train Loss: 0.0002724801888689399, Valid Loss: 0.00042109156493097544\n",
      "Epoch: 8452, Train Loss: 0.0002723236393649131, Valid Loss: 0.00042087427573278546\n",
      "Epoch: 8453, Train Loss: 0.00027216708986088634, Valid Loss: 0.0004206486919429153\n",
      "Epoch: 8454, Train Loss: 0.00027201182092539966, Valid Loss: 0.0004204367578495294\n",
      "Epoch: 8455, Train Loss: 0.00027185730868950486, Valid Loss: 0.00042020942782983184\n",
      "Epoch: 8456, Train Loss: 0.000271701836027205, Valid Loss: 0.0004199935356155038\n",
      "Epoch: 8457, Train Loss: 0.0002715451119001955, Valid Loss: 0.00041977185173891485\n",
      "Epoch: 8458, Train Loss: 0.0002713914436753839, Valid Loss: 0.0004195566871203482\n",
      "Epoch: 8459, Train Loss: 0.00027123570907860994, Valid Loss: 0.0004193320928607136\n",
      "Epoch: 8460, Train Loss: 0.00027108023641631007, Valid Loss: 0.00041911896551027894\n",
      "Epoch: 8461, Train Loss: 0.0002709252876229584, Valid Loss: 0.00041889463318511844\n",
      "Epoch: 8462, Train Loss: 0.0002707713283598423, Valid Loss: 0.0004186808073427528\n",
      "Epoch: 8463, Train Loss: 0.0002706144005060196, Valid Loss: 0.0004184575518593192\n",
      "Epoch: 8464, Train Loss: 0.00027045936440117657, Valid Loss: 0.00041824576328508556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8465, Train Loss: 0.00027030627825297415, Valid Loss: 0.0004180176474619657\n",
      "Epoch: 8466, Train Loss: 0.0002701509220059961, Valid Loss: 0.0004178025701548904\n",
      "Epoch: 8467, Train Loss: 0.00026999638066627085, Valid Loss: 0.0004175797221250832\n",
      "Epoch: 8468, Train Loss: 0.0002698413154575974, Valid Loss: 0.0004173704655840993\n",
      "Epoch: 8469, Train Loss: 0.0002696865703910589, Valid Loss: 0.00041714918916113675\n",
      "Epoch: 8470, Train Loss: 0.0002695317380130291, Valid Loss: 0.00041693326784297824\n",
      "Epoch: 8471, Train Loss: 0.0002693774877116084, Valid Loss: 0.00041671140934340656\n",
      "Epoch: 8472, Train Loss: 0.00026922477991320193, Valid Loss: 0.0004164958081673831\n",
      "Epoch: 8473, Train Loss: 0.00026907146093435585, Valid Loss: 0.00041627639438956976\n",
      "Epoch: 8474, Train Loss: 0.00026891622110269964, Valid Loss: 0.0004160609969403595\n",
      "Epoch: 8475, Train Loss: 0.0002687634259928018, Valid Loss: 0.00041583721758797765\n",
      "Epoch: 8476, Train Loss: 0.00026860888465307653, Valid Loss: 0.0004156219947617501\n",
      "Epoch: 8477, Train Loss: 0.0002684553328435868, Valid Loss: 0.000415408139815554\n",
      "Epoch: 8478, Train Loss: 0.000268302159383893, Valid Loss: 0.0004151911707594991\n",
      "Epoch: 8479, Train Loss: 0.00026814828743226826, Valid Loss: 0.0004149731248617172\n",
      "Epoch: 8480, Train Loss: 0.00026799572515301406, Valid Loss: 0.0004147530416958034\n",
      "Epoch: 8481, Train Loss: 0.00026784237707033753, Valid Loss: 0.00041453965241089463\n",
      "Epoch: 8482, Train Loss: 0.00026768731186166406, Valid Loss: 0.0004143225378356874\n",
      "Epoch: 8483, Train Loss: 0.0002675354771781713, Valid Loss: 0.0004141073441132903\n",
      "Epoch: 8484, Train Loss: 0.0002673808194231242, Valid Loss: 0.0004138871154282242\n",
      "Epoch: 8485, Train Loss: 0.00026722915936261415, Valid Loss: 0.00041367291123606265\n",
      "Epoch: 8486, Train Loss: 0.00026707706274464726, Valid Loss: 0.00041345536010339856\n",
      "Epoch: 8487, Train Loss: 0.00026692330720834434, Valid Loss: 0.00041324421181343496\n",
      "Epoch: 8488, Train Loss: 0.0002667709777597338, Valid Loss: 0.00041303024045191705\n",
      "Epoch: 8489, Train Loss: 0.00026661780430004, Valid Loss: 0.00041281161247752607\n",
      "Epoch: 8490, Train Loss: 0.0002664655330590904, Valid Loss: 0.0004125919076614082\n",
      "Epoch: 8491, Train Loss: 0.00026631387299858034, Valid Loss: 0.0004123807593714446\n",
      "Epoch: 8492, Train Loss: 0.0002661591279320419, Valid Loss: 0.0004121610545553267\n",
      "Epoch: 8493, Train Loss: 0.00026600828277878463, Valid Loss: 0.00041195086669176817\n",
      "Epoch: 8494, Train Loss: 0.0002658560697454959, Valid Loss: 0.00041172810597345233\n",
      "Epoch: 8495, Train Loss: 0.0002657037985045463, Valid Loss: 0.00041151829645968974\n",
      "Epoch: 8496, Train Loss: 0.00026555225485935807, Valid Loss: 0.0004113002505619079\n",
      "Epoch: 8497, Train Loss: 0.0002653998089954257, Valid Loss: 0.0004110911104362458\n",
      "Epoch: 8498, Train Loss: 0.00026524881832301617, Valid Loss: 0.00041086840792559087\n",
      "Epoch: 8499, Train Loss: 0.0002650979731697589, Valid Loss: 0.0004106567066628486\n",
      "Epoch: 8500, Train Loss: 0.00026494546909816563, Valid Loss: 0.0004104399704374373\n",
      "Epoch: 8501, Train Loss: 0.0002647941291797906, Valid Loss: 0.00041022952063940465\n",
      "Epoch: 8502, Train Loss: 0.0002646427310537547, Valid Loss: 0.00041001185309141874\n",
      "Epoch: 8503, Train Loss: 0.00026449188590049744, Valid Loss: 0.0004098013450857252\n",
      "Epoch: 8504, Train Loss: 0.0002643399056978524, Valid Loss: 0.0004095822514500469\n",
      "Epoch: 8505, Train Loss: 0.0002641896717250347, Valid Loss: 0.00040936723235063255\n",
      "Epoch: 8506, Train Loss: 0.00026403716765344143, Valid Loss: 0.000409154366934672\n",
      "Epoch: 8507, Train Loss: 0.00026388620608486235, Valid Loss: 0.0004089486610610038\n",
      "Epoch: 8508, Train Loss: 0.00026373573928140104, Valid Loss: 0.0004087247361894697\n",
      "Epoch: 8509, Train Loss: 0.00026358538889326155, Valid Loss: 0.0004085164109710604\n",
      "Epoch: 8510, Train Loss: 0.00026343457284383476, Valid Loss: 0.0004082965897396207\n",
      "Epoch: 8511, Train Loss: 0.0002632829418871552, Valid Loss: 0.0004080919607076794\n",
      "Epoch: 8512, Train Loss: 0.00026313273701816797, Valid Loss: 0.0004078687634319067\n",
      "Epoch: 8513, Train Loss: 0.00026298349257558584, Valid Loss: 0.0004076581681147218\n",
      "Epoch: 8514, Train Loss: 0.0002628309011925012, Valid Loss: 0.0004074423632118851\n",
      "Epoch: 8515, Train Loss: 0.00026268220972269773, Valid Loss: 0.0004072387528140098\n",
      "Epoch: 8516, Train Loss: 0.0002625311608426273, Valid Loss: 0.0004070175054948777\n",
      "Epoch: 8517, Train Loss: 0.0002623812761157751, Valid Loss: 0.00040681249811314046\n",
      "Epoch: 8518, Train Loss: 0.00026223191525787115, Valid Loss: 0.0004065869434271008\n",
      "Epoch: 8519, Train Loss: 0.00026208083727397025, Valid Loss: 0.0004063862143084407\n",
      "Epoch: 8520, Train Loss: 0.00026193077792413533, Valid Loss: 0.00040616720798425376\n",
      "Epoch: 8521, Train Loss: 0.0002617813879624009, Valid Loss: 0.0004059635102748871\n",
      "Epoch: 8522, Train Loss: 0.0002616317360661924, Valid Loss: 0.00040573696605861187\n",
      "Epoch: 8523, Train Loss: 0.0002614822587929666, Valid Loss: 0.00040553545113652945\n",
      "Epoch: 8524, Train Loss: 0.0002613342658150941, Valid Loss: 0.0004053172015119344\n",
      "Epoch: 8525, Train Loss: 0.00026118470123037696, Valid Loss: 0.0004051145224366337\n",
      "Epoch: 8526, Train Loss: 0.0002610348165035248, Valid Loss: 0.0004048907139804214\n",
      "Epoch: 8527, Train Loss: 0.00026088624144904315, Valid Loss: 0.0004046902759000659\n",
      "Epoch: 8528, Train Loss: 0.0002607359492685646, Valid Loss: 0.00040446556522510946\n",
      "Epoch: 8529, Train Loss: 0.0002605865884106606, Valid Loss: 0.0004042709188070148\n",
      "Epoch: 8530, Train Loss: 0.0002604381297715008, Valid Loss: 0.0004040477506350726\n",
      "Epoch: 8531, Train Loss: 0.00026028964202851057, Valid Loss: 0.0004038433835376054\n",
      "Epoch: 8532, Train Loss: 0.00026013984461314976, Valid Loss: 0.00040362266008742154\n",
      "Epoch: 8533, Train Loss: 0.00025999147328548133, Valid Loss: 0.00040342495776712894\n",
      "Epoch: 8534, Train Loss: 0.0002598419669084251, Valid Loss: 0.00040320478728972375\n",
      "Epoch: 8535, Train Loss: 0.0002596942940726876, Valid Loss: 0.000403002486564219\n",
      "Epoch: 8536, Train Loss: 0.00025954563170671463, Valid Loss: 0.00040277972584590316\n",
      "Epoch: 8537, Train Loss: 0.0002593965327832848, Valid Loss: 0.0004025810630992055\n",
      "Epoch: 8538, Train Loss: 0.00025924979127012193, Valid Loss: 0.0004023615620099008\n",
      "Epoch: 8539, Train Loss: 0.00025910307886078954, Valid Loss: 0.00040216586785390973\n",
      "Epoch: 8540, Train Loss: 0.00025895339786075056, Valid Loss: 0.00040194165194407105\n",
      "Epoch: 8541, Train Loss: 0.0002588056377135217, Valid Loss: 0.00040173716843128204\n",
      "Epoch: 8542, Train Loss: 0.00025865744100883603, Valid Loss: 0.00040152485598810017\n",
      "Epoch: 8543, Train Loss: 0.0002585092734079808, Valid Loss: 0.00040132380672730505\n",
      "Epoch: 8544, Train Loss: 0.00025836206623353064, Valid Loss: 0.00040110107511281967\n",
      "Epoch: 8545, Train Loss: 0.00025821299641393125, Valid Loss: 0.0004009020631201565\n",
      "Epoch: 8546, Train Loss: 0.00025806602207012475, Valid Loss: 0.00040068553062155843\n",
      "Epoch: 8547, Train Loss: 0.00025791823281906545, Valid Loss: 0.0004004886432085186\n",
      "Epoch: 8548, Train Loss: 0.00025777192786335945, Valid Loss: 0.0004002652713097632\n",
      "Epoch: 8549, Train Loss: 0.00025762224686332047, Valid Loss: 0.0004000687913503498\n",
      "Epoch: 8550, Train Loss: 0.00025747696054168046, Valid Loss: 0.00039984547765925527\n",
      "Epoch: 8551, Train Loss: 0.00025732937501743436, Valid Loss: 0.0003996488521806896\n",
      "Epoch: 8552, Train Loss: 0.00025718245888128877, Valid Loss: 0.00039942938019521534\n",
      "Epoch: 8553, Train Loss: 0.0002570351934991777, Valid Loss: 0.000399232201743871\n",
      "Epoch: 8554, Train Loss: 0.0002568882191553712, Valid Loss: 0.000399005482904613\n",
      "Epoch: 8555, Train Loss: 0.00025674112839624286, Valid Loss: 0.0003988113021478057\n",
      "Epoch: 8556, Train Loss: 0.0002565947361290455, Valid Loss: 0.00039859217940829694\n",
      "Epoch: 8557, Train Loss: 0.00025644872221164405, Valid Loss: 0.00039839945384301245\n",
      "Epoch: 8558, Train Loss: 0.000256300758337602, Valid Loss: 0.00039817721699364483\n",
      "Epoch: 8559, Train Loss: 0.0002561556757427752, Valid Loss: 0.0003979819593951106\n",
      "Epoch: 8560, Train Loss: 0.00025600811932235956, Valid Loss: 0.0003977566957473755\n",
      "Epoch: 8561, Train Loss: 0.00025586216361261904, Valid Loss: 0.00039756379555910826\n",
      "Epoch: 8562, Train Loss: 0.00025571612059138715, Valid Loss: 0.00039734833990223706\n",
      "Epoch: 8563, Train Loss: 0.0002555685059633106, Valid Loss: 0.0003971546539105475\n",
      "Epoch: 8564, Train Loss: 0.00025542351067997515, Valid Loss: 0.0003969270037487149\n",
      "Epoch: 8565, Train Loss: 0.0002552770311012864, Valid Loss: 0.0003967374505009502\n",
      "Epoch: 8566, Train Loss: 0.0002551322104409337, Valid Loss: 0.0003965205396525562\n",
      "Epoch: 8567, Train Loss: 0.000254985352512449, Valid Loss: 0.00039632676634937525\n",
      "Epoch: 8568, Train Loss: 0.00025483962963335216, Valid Loss: 0.0003961042675655335\n",
      "Epoch: 8569, Train Loss: 0.00025469347019679844, Valid Loss: 0.0003959131136070937\n",
      "Epoch: 8570, Train Loss: 0.00025455004652030766, Valid Loss: 0.00039569230284541845\n",
      "Epoch: 8571, Train Loss: 0.0002544025774113834, Valid Loss: 0.00039549742359668016\n",
      "Epoch: 8572, Train Loss: 0.0002542583679314703, Valid Loss: 0.0003952774277422577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8573, Train Loss: 0.0002541127905715257, Valid Loss: 0.00039508589543402195\n",
      "Epoch: 8574, Train Loss: 0.0002539670094847679, Valid Loss: 0.0003948641533497721\n",
      "Epoch: 8575, Train Loss: 0.0002538215194363147, Valid Loss: 0.0003946741053368896\n",
      "Epoch: 8576, Train Loss: 0.0002536778920330107, Valid Loss: 0.00039445533184334636\n",
      "Epoch: 8577, Train Loss: 0.00025353211094625294, Valid Loss: 0.00039426065632142127\n",
      "Epoch: 8578, Train Loss: 0.0002533858933020383, Valid Loss: 0.00039403990376740694\n",
      "Epoch: 8579, Train Loss: 0.0002532439830247313, Valid Loss: 0.0003938485751859844\n",
      "Epoch: 8580, Train Loss: 0.00025309761986136436, Valid Loss: 0.00039363050018437207\n",
      "Epoch: 8581, Train Loss: 0.00025295361410826445, Valid Loss: 0.00039343693060800433\n",
      "Epoch: 8582, Train Loss: 0.00025280853151343763, Valid Loss: 0.0003932180115953088\n",
      "Epoch: 8583, Train Loss: 0.0002526651951484382, Valid Loss: 0.0003930286329705268\n",
      "Epoch: 8584, Train Loss: 0.00025251921033486724, Valid Loss: 0.0003928074147552252\n",
      "Epoch: 8585, Train Loss: 0.0002523758157622069, Valid Loss: 0.0003926152712665498\n",
      "Epoch: 8586, Train Loss: 0.00025223111151717603, Valid Loss: 0.0003923988260794431\n",
      "Epoch: 8587, Train Loss: 0.0002520871057640761, Valid Loss: 0.0003922034811694175\n",
      "Epoch: 8588, Train Loss: 0.000251943216426298, Valid Loss: 0.000391979148844257\n",
      "Epoch: 8589, Train Loss: 0.00025179871590808034, Valid Loss: 0.00039179518353194\n",
      "Epoch: 8590, Train Loss: 0.0002516545355319977, Valid Loss: 0.0003915780398529023\n",
      "Epoch: 8591, Train Loss: 0.0002515105879865587, Valid Loss: 0.00039138467400334775\n",
      "Epoch: 8592, Train Loss: 0.00025136949261650443, Valid Loss: 0.00039116202970035374\n",
      "Epoch: 8593, Train Loss: 0.0002512251085136086, Valid Loss: 0.00039098094566725194\n",
      "Epoch: 8594, Train Loss: 0.0002510810154490173, Valid Loss: 0.00039075821405276656\n",
      "Epoch: 8595, Train Loss: 0.0002509379992261529, Valid Loss: 0.0003905683115590364\n",
      "Epoch: 8596, Train Loss: 0.0002507949247956276, Valid Loss: 0.0003903508186340332\n",
      "Epoch: 8597, Train Loss: 0.0002506511809770018, Valid Loss: 0.000390164292184636\n",
      "Epoch: 8598, Train Loss: 0.00025050927069969475, Valid Loss: 0.00038993742782622576\n",
      "Epoch: 8599, Train Loss: 0.00025036410079337656, Valid Loss: 0.0003897525602951646\n",
      "Epoch: 8600, Train Loss: 0.00025022277259267867, Valid Loss: 0.00038953364128246903\n",
      "Epoch: 8601, Train Loss: 0.00025007949443534017, Valid Loss: 0.00038934857002459466\n",
      "Epoch: 8602, Train Loss: 0.00024993615807034075, Valid Loss: 0.00038912182208150625\n",
      "Epoch: 8603, Train Loss: 0.00024979328736662865, Valid Loss: 0.0003889475774485618\n",
      "Epoch: 8604, Train Loss: 0.0002496510569471866, Valid Loss: 0.00038872050936333835\n",
      "Epoch: 8605, Train Loss: 0.00024950827355496585, Valid Loss: 0.00038853372097946703\n",
      "Epoch: 8606, Train Loss: 0.00024936473346315324, Valid Loss: 0.000388313113944605\n",
      "Epoch: 8607, Train Loss: 0.00024922206648625433, Valid Loss: 0.0003881393640767783\n",
      "Epoch: 8608, Train Loss: 0.0002490800397936255, Valid Loss: 0.0003879072901327163\n",
      "Epoch: 8609, Train Loss: 0.0002489388280082494, Valid Loss: 0.0003877309791278094\n",
      "Epoch: 8610, Train Loss: 0.00024879700504243374, Valid Loss: 0.00038750775274820626\n",
      "Epoch: 8611, Train Loss: 0.00024865480372682214, Valid Loss: 0.0003873260284308344\n",
      "Epoch: 8612, Train Loss: 0.00024851138005033135, Valid Loss: 0.0003871004737447947\n",
      "Epoch: 8613, Train Loss: 0.000248369004111737, Valid Loss: 0.0003869289648719132\n",
      "Epoch: 8614, Train Loss: 0.0002482283744029701, Valid Loss: 0.00038669799687340856\n",
      "Epoch: 8615, Train Loss: 0.00024808605667203665, Valid Loss: 0.0003865135076921433\n",
      "Epoch: 8616, Train Loss: 0.00024794446653686464, Valid Loss: 0.0003862897283397615\n",
      "Epoch: 8617, Train Loss: 0.0002478034293744713, Valid Loss: 0.0003861160948872566\n",
      "Epoch: 8618, Train Loss: 0.0002476610243320465, Valid Loss: 0.0003858865820802748\n",
      "Epoch: 8619, Train Loss: 0.00024752080207690597, Valid Loss: 0.00038571059121750295\n",
      "Epoch: 8620, Train Loss: 0.0002473791828379035, Valid Loss: 0.0003854838141705841\n",
      "Epoch: 8621, Train Loss: 0.0002472357009537518, Valid Loss: 0.0003853051457554102\n",
      "Epoch: 8622, Train Loss: 0.00024709655554033816, Valid Loss: 0.00038508069701492786\n",
      "Epoch: 8623, Train Loss: 0.0002469550527166575, Valid Loss: 0.0003849086642730981\n",
      "Epoch: 8624, Train Loss: 0.000246814830461517, Valid Loss: 0.00038467932608909905\n",
      "Epoch: 8625, Train Loss: 0.00024667356046848, Valid Loss: 0.0003845015889964998\n",
      "Epoch: 8626, Train Loss: 0.0002465331053826958, Valid Loss: 0.0003842740843538195\n",
      "Epoch: 8627, Train Loss: 0.0002463929995428771, Valid Loss: 0.00038410298293456435\n",
      "Epoch: 8628, Train Loss: 0.000246251467615366, Valid Loss: 0.00038387347012758255\n",
      "Epoch: 8629, Train Loss: 0.00024611022672615945, Valid Loss: 0.0003837037365883589\n",
      "Epoch: 8630, Train Loss: 0.00024597032461315393, Valid Loss: 0.00038347524241544306\n",
      "Epoch: 8631, Train Loss: 0.0002458302478771657, Valid Loss: 0.0003832939255516976\n",
      "Epoch: 8632, Train Loss: 0.00024569040397182107, Valid Loss: 0.00038307602517306805\n",
      "Epoch: 8633, Train Loss: 0.00024554890114814043, Valid Loss: 0.00038290006341412663\n",
      "Epoch: 8634, Train Loss: 0.0002454078057780862, Valid Loss: 0.00038267282070592046\n",
      "Epoch: 8635, Train Loss: 0.0002452688931953162, Valid Loss: 0.0003824950836133212\n",
      "Epoch: 8636, Train Loss: 0.00024512995150871575, Valid Loss: 0.00038227549521252513\n",
      "Epoch: 8637, Train Loss: 0.0002449883904773742, Valid Loss: 0.00038209333433769643\n",
      "Epoch: 8638, Train Loss: 0.0002448486920911819, Valid Loss: 0.0003818758705165237\n",
      "Epoch: 8639, Train Loss: 0.00024470966309309006, Valid Loss: 0.00038169315666891634\n",
      "Epoch: 8640, Train Loss: 0.00024456914979964495, Valid Loss: 0.000381479476345703\n",
      "Epoch: 8641, Train Loss: 0.0002444293349981308, Valid Loss: 0.0003812941431533545\n",
      "Epoch: 8642, Train Loss: 0.0002442896366119385, Valid Loss: 0.00038108666194602847\n",
      "Epoch: 8643, Train Loss: 0.0002441499091219157, Valid Loss: 0.00038089402369223535\n",
      "Epoch: 8644, Train Loss: 0.00024401147675234824, Valid Loss: 0.0003806848544627428\n",
      "Epoch: 8645, Train Loss: 0.0002438699739286676, Valid Loss: 0.00038049445720389485\n",
      "Epoch: 8646, Train Loss: 0.00024373113410547376, Valid Loss: 0.0003802920982707292\n",
      "Epoch: 8647, Train Loss: 0.00024359271628782153, Valid Loss: 0.00038010033313184977\n",
      "Epoch: 8648, Train Loss: 0.00024345298879779875, Valid Loss: 0.00037989416159689426\n",
      "Epoch: 8649, Train Loss: 0.00024331557506229728, Valid Loss: 0.0003796980599872768\n",
      "Epoch: 8650, Train Loss: 0.00024317542556673288, Valid Loss: 0.000379495439119637\n",
      "Epoch: 8651, Train Loss: 0.0002430369204375893, Valid Loss: 0.00037930390681140125\n",
      "Epoch: 8652, Train Loss: 0.0002428971929475665, Valid Loss: 0.00037910256651230156\n",
      "Epoch: 8653, Train Loss: 0.00024275928444694728, Valid Loss: 0.0003789061738643795\n",
      "Epoch: 8654, Train Loss: 0.00024262172519229352, Valid Loss: 0.00037870826781727374\n",
      "Epoch: 8655, Train Loss: 0.0002424825943307951, Valid Loss: 0.00037851333036087453\n",
      "Epoch: 8656, Train Loss: 0.0002423454134259373, Valid Loss: 0.0003783144347835332\n",
      "Epoch: 8657, Train Loss: 0.0002422051620669663, Valid Loss: 0.0003781135310418904\n",
      "Epoch: 8658, Train Loss: 0.00024206735542975366, Valid Loss: 0.00037791472277604043\n",
      "Epoch: 8659, Train Loss: 0.00024192903947550803, Valid Loss: 0.00037772092036902905\n",
      "Epoch: 8660, Train Loss: 0.00024179088359232992, Valid Loss: 0.00037752639036625624\n",
      "Epoch: 8661, Train Loss: 0.00024165396462194622, Valid Loss: 0.00037733290810137987\n",
      "Epoch: 8662, Train Loss: 0.00024151464458554983, Valid Loss: 0.0003771281335502863\n",
      "Epoch: 8663, Train Loss: 0.00024137708533089608, Valid Loss: 0.00037692830665037036\n",
      "Epoch: 8664, Train Loss: 0.00024123907496687025, Valid Loss: 0.00037673310725949705\n",
      "Epoch: 8665, Train Loss: 0.0002411020250292495, Valid Loss: 0.00037654227344319224\n",
      "Epoch: 8666, Train Loss: 0.00024096491688396782, Valid Loss: 0.0003763420390896499\n",
      "Epoch: 8667, Train Loss: 0.00024082760501187295, Valid Loss: 0.00037614640314131975\n",
      "Epoch: 8668, Train Loss: 0.00024068857601378113, Valid Loss: 0.000375949137378484\n",
      "Epoch: 8669, Train Loss: 0.00024055242829490453, Valid Loss: 0.0003757532685995102\n",
      "Epoch: 8670, Train Loss: 0.00024041428696364164, Valid Loss: 0.000375553296180442\n",
      "Epoch: 8671, Train Loss: 0.0002402783720754087, Valid Loss: 0.000375359202735126\n",
      "Epoch: 8672, Train Loss: 0.00024014072550926358, Valid Loss: 0.0003751594922505319\n",
      "Epoch: 8673, Train Loss: 0.00024000379198696464, Valid Loss: 0.00037496606819331646\n",
      "Epoch: 8674, Train Loss: 0.00023986666928976774, Valid Loss: 0.0003747741866391152\n",
      "Epoch: 8675, Train Loss: 0.0002397297357674688, Valid Loss: 0.0003745779686141759\n",
      "Epoch: 8676, Train Loss: 0.00023959387908689678, Valid Loss: 0.0003743767738342285\n",
      "Epoch: 8677, Train Loss: 0.0002394559414824471, Valid Loss: 0.00037417974090203643\n",
      "Epoch: 8678, Train Loss: 0.00023931921168696135, Valid Loss: 0.0003739875101018697\n",
      "Epoch: 8679, Train Loss: 0.00023918367514852434, Valid Loss: 0.00037379618152044713\n",
      "Epoch: 8680, Train Loss: 0.0002390476583968848, Valid Loss: 0.0003735967038664967\n",
      "Epoch: 8681, Train Loss: 0.00023891031742095947, Valid Loss: 0.00037340004928410053\n",
      "Epoch: 8682, Train Loss: 0.000238775261095725, Valid Loss: 0.0003732074692379683\n",
      "Epoch: 8683, Train Loss: 0.0002386385458521545, Valid Loss: 0.0003730138123501092\n",
      "Epoch: 8684, Train Loss: 0.00023850261641200632, Valid Loss: 0.0003728122392203659\n",
      "Epoch: 8685, Train Loss: 0.00023836526088416576, Valid Loss: 0.0003726203867699951\n",
      "Epoch: 8686, Train Loss: 0.0002382299571763724, Valid Loss: 0.00037242475082166493\n",
      "Epoch: 8687, Train Loss: 0.00023809289268683642, Valid Loss: 0.0003722367691807449\n",
      "Epoch: 8688, Train Loss: 0.00023795706511009485, Valid Loss: 0.00037203673855401576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8689, Train Loss: 0.00023782164498697966, Valid Loss: 0.0003718415682669729\n",
      "Epoch: 8690, Train Loss: 0.00023768568644300103, Valid Loss: 0.000371647096471861\n",
      "Epoch: 8691, Train Loss: 0.00023755073198117316, Valid Loss: 0.0003714613849297166\n",
      "Epoch: 8692, Train Loss: 0.00023741499171592295, Valid Loss: 0.0003712615289259702\n",
      "Epoch: 8693, Train Loss: 0.00023727955704089254, Valid Loss: 0.00037107127718627453\n",
      "Epoch: 8694, Train Loss: 0.00023714432609267533, Valid Loss: 0.00037086979136802256\n",
      "Epoch: 8695, Train Loss: 0.00023700868769083172, Valid Loss: 0.00037068629171699286\n",
      "Epoch: 8696, Train Loss: 0.00023687286011409014, Valid Loss: 0.0003704913251567632\n",
      "Epoch: 8697, Train Loss: 0.00023673840041738003, Valid Loss: 0.00037030072417110205\n",
      "Epoch: 8698, Train Loss: 0.00023660306760575622, Valid Loss: 0.00037009603693149984\n",
      "Epoch: 8699, Train Loss: 0.0002364686079090461, Valid Loss: 0.0003699121007230133\n",
      "Epoch: 8700, Train Loss: 0.00023633248929399997, Valid Loss: 0.0003697179490700364\n",
      "Epoch: 8701, Train Loss: 0.00023619894636794925, Valid Loss: 0.0003695321793202311\n",
      "Epoch: 8702, Train Loss: 0.00023606327886227518, Valid Loss: 0.00036932624061591923\n",
      "Epoch: 8703, Train Loss: 0.00023592835350427777, Valid Loss: 0.00036913660005666316\n",
      "Epoch: 8704, Train Loss: 0.00023579470871482044, Valid Loss: 0.00036893971264362335\n",
      "Epoch: 8705, Train Loss: 0.0002356599288759753, Valid Loss: 0.00036875702789984643\n",
      "Epoch: 8706, Train Loss: 0.00023552561469841748, Valid Loss: 0.00036855717189610004\n",
      "Epoch: 8707, Train Loss: 0.00023539036919828504, Valid Loss: 0.00036837163497693837\n",
      "Epoch: 8708, Train Loss: 0.00023525590950157493, Valid Loss: 0.0003681705566123128\n",
      "Epoch: 8709, Train Loss: 0.00023512110055889934, Valid Loss: 0.00036798272049054503\n",
      "Epoch: 8710, Train Loss: 0.00023498763039242476, Valid Loss: 0.00036778737558051944\n",
      "Epoch: 8711, Train Loss: 0.00023485337442252785, Valid Loss: 0.00036760300281457603\n",
      "Epoch: 8712, Train Loss: 0.0002347206318518147, Valid Loss: 0.0003673972678370774\n",
      "Epoch: 8713, Train Loss: 0.0002345864922972396, Valid Loss: 0.0003672122838906944\n",
      "Epoch: 8714, Train Loss: 0.00023445236729457974, Valid Loss: 0.00036701917997561395\n",
      "Epoch: 8715, Train Loss: 0.0002343174273846671, Valid Loss: 0.00036683413782157004\n",
      "Epoch: 8716, Train Loss: 0.00023418443743139505, Valid Loss: 0.00036663206992670894\n",
      "Epoch: 8717, Train Loss: 0.00023405109823215753, Valid Loss: 0.000366446387488395\n",
      "Epoch: 8718, Train Loss: 0.0002339183265576139, Valid Loss: 0.0003662552626337856\n",
      "Epoch: 8719, Train Loss: 0.00023378460900858045, Valid Loss: 0.0003660667280200869\n",
      "Epoch: 8720, Train Loss: 0.00023365025117527694, Valid Loss: 0.00036587449721992016\n",
      "Epoch: 8721, Train Loss: 0.00023351602430921048, Valid Loss: 0.0003656841581687331\n",
      "Epoch: 8722, Train Loss: 0.00023338437313213944, Valid Loss: 0.00036549338256008923\n",
      "Epoch: 8723, Train Loss: 0.0002332505100639537, Valid Loss: 0.0003653033054433763\n",
      "Epoch: 8724, Train Loss: 0.00023311914992518723, Valid Loss: 0.0003651134029496461\n",
      "Epoch: 8725, Train Loss: 0.00023298551968764514, Valid Loss: 0.00036492038634605706\n",
      "Epoch: 8726, Train Loss: 0.00023285254428628832, Valid Loss: 0.0003647305420599878\n",
      "Epoch: 8727, Train Loss: 0.00023271878308150917, Valid Loss: 0.000364545063348487\n",
      "Epoch: 8728, Train Loss: 0.00023258676810655743, Valid Loss: 0.0003643521049525589\n",
      "Epoch: 8729, Train Loss: 0.0002324540982954204, Valid Loss: 0.00036416362854652107\n",
      "Epoch: 8730, Train Loss: 0.00023232186504174024, Valid Loss: 0.00036396793439053\n",
      "Epoch: 8731, Train Loss: 0.00023218976275529712, Valid Loss: 0.00036378524964675307\n",
      "Epoch: 8732, Train Loss: 0.0002320569328730926, Valid Loss: 0.00036358681973069906\n",
      "Epoch: 8733, Train Loss: 0.0002319258637726307, Valid Loss: 0.0003634047170635313\n",
      "Epoch: 8734, Train Loss: 0.0002317919279448688, Valid Loss: 0.00036320657818578184\n",
      "Epoch: 8735, Train Loss: 0.00023165896709542722, Valid Loss: 0.00036302246735431254\n",
      "Epoch: 8736, Train Loss: 0.0002315285091754049, Valid Loss: 0.0003628275590017438\n",
      "Epoch: 8737, Train Loss: 0.00023139655240811408, Valid Loss: 0.0003626486286520958\n",
      "Epoch: 8738, Train Loss: 0.00023126429005060345, Valid Loss: 0.0003624499950092286\n",
      "Epoch: 8739, Train Loss: 0.00023113226052373648, Valid Loss: 0.0003622669610194862\n",
      "Epoch: 8740, Train Loss: 0.00023100117687135935, Valid Loss: 0.00036207272205501795\n",
      "Epoch: 8741, Train Loss: 0.00023086805595085025, Valid Loss: 0.0003618885239120573\n",
      "Epoch: 8742, Train Loss: 0.00023073807824403048, Valid Loss: 0.0003616889880504459\n",
      "Epoch: 8743, Train Loss: 0.00023060569947119802, Valid Loss: 0.0003615137538872659\n",
      "Epoch: 8744, Train Loss: 0.00023047324793878943, Valid Loss: 0.0003613180306274444\n",
      "Epoch: 8745, Train Loss: 0.00023034249898046255, Valid Loss: 0.00036113589885644615\n",
      "Epoch: 8746, Train Loss: 0.00023021172091830522, Valid Loss: 0.0003609324630815536\n",
      "Epoch: 8747, Train Loss: 0.00023007926938589662, Valid Loss: 0.00036075961543247104\n",
      "Epoch: 8748, Train Loss: 0.00022994873870629817, Valid Loss: 0.00036056156386621296\n",
      "Epoch: 8749, Train Loss: 0.00022981569054536521, Valid Loss: 0.00036038400139659643\n",
      "Epoch: 8750, Train Loss: 0.00022968600387685, Valid Loss: 0.0003601843782234937\n",
      "Epoch: 8751, Train Loss: 0.0002295559097547084, Valid Loss: 0.0003600041090976447\n",
      "Epoch: 8752, Train Loss: 0.00022942537907510996, Valid Loss: 0.00035980864777229726\n",
      "Epoch: 8753, Train Loss: 0.00022929323313292116, Valid Loss: 0.0003596329770516604\n",
      "Epoch: 8754, Train Loss: 0.00022916415764484555, Valid Loss: 0.000359433819539845\n",
      "Epoch: 8755, Train Loss: 0.00022903109493199736, Valid Loss: 0.00035925128031522036\n",
      "Epoch: 8756, Train Loss: 0.0002289028197992593, Valid Loss: 0.0003590568667277694\n",
      "Epoch: 8757, Train Loss: 0.0002287725656060502, Valid Loss: 0.00035888582351617515\n",
      "Epoch: 8758, Train Loss: 0.0002286405797349289, Valid Loss: 0.0003586811653804034\n",
      "Epoch: 8759, Train Loss: 0.00022851214453112334, Valid Loss: 0.00035850636777468026\n",
      "Epoch: 8760, Train Loss: 0.0002283810608787462, Valid Loss: 0.00035830505657941103\n",
      "Epoch: 8761, Train Loss: 0.0002282501955050975, Valid Loss: 0.0003581349446903914\n",
      "Epoch: 8762, Train Loss: 0.00022811976668890566, Valid Loss: 0.00035793293500319123\n",
      "Epoch: 8763, Train Loss: 0.00022799109865445644, Valid Loss: 0.0003577610186766833\n",
      "Epoch: 8764, Train Loss: 0.0002278602187288925, Valid Loss: 0.0003575557202566415\n",
      "Epoch: 8765, Train Loss: 0.00022773025557398796, Valid Loss: 0.00035738994483835995\n",
      "Epoch: 8766, Train Loss: 0.00022760019055567682, Valid Loss: 0.000357185082975775\n",
      "Epoch: 8767, Train Loss: 0.0002274713187944144, Valid Loss: 0.0003570187836885452\n",
      "Epoch: 8768, Train Loss: 0.00022734145750291646, Valid Loss: 0.0003568057727534324\n",
      "Epoch: 8769, Train Loss: 0.0002272115962114185, Valid Loss: 0.0003566470986697823\n",
      "Epoch: 8770, Train Loss: 0.00022708399046678096, Valid Loss: 0.00035644174204207957\n",
      "Epoch: 8771, Train Loss: 0.00022695245570503175, Valid Loss: 0.00035627480247057974\n",
      "Epoch: 8772, Train Loss: 0.00022682378767058253, Valid Loss: 0.00035606452729552984\n",
      "Epoch: 8773, Train Loss: 0.0002266929077450186, Valid Loss: 0.0003559023898560554\n",
      "Epoch: 8774, Train Loss: 0.00022656393412034959, Valid Loss: 0.0003556942683644593\n",
      "Epoch: 8775, Train Loss: 0.00022643496049568057, Valid Loss: 0.0003555334114935249\n",
      "Epoch: 8776, Train Loss: 0.000226305695832707, Valid Loss: 0.0003553240094333887\n",
      "Epoch: 8777, Train Loss: 0.0002261781191918999, Valid Loss: 0.0003551619593054056\n",
      "Epoch: 8778, Train Loss: 0.00022604917467106134, Valid Loss: 0.00035495308111421764\n",
      "Epoch: 8779, Train Loss: 0.0002259199827676639, Valid Loss: 0.00035479350481182337\n",
      "Epoch: 8780, Train Loss: 0.0002257913292851299, Valid Loss: 0.0003545824729371816\n",
      "Epoch: 8781, Train Loss: 0.00022566135157831013, Valid Loss: 0.00035442173248156905\n",
      "Epoch: 8782, Train Loss: 0.00022553269809577614, Valid Loss: 0.00035421032225713134\n",
      "Epoch: 8783, Train Loss: 0.00022540469944942743, Valid Loss: 0.00035405514063313603\n",
      "Epoch: 8784, Train Loss: 0.00022527642431668937, Valid Loss: 0.00035384122747927904\n",
      "Epoch: 8785, Train Loss: 0.00022514884767588228, Valid Loss: 0.0003536827862262726\n",
      "Epoch: 8786, Train Loss: 0.00022502047067973763, Valid Loss: 0.0003534654388204217\n",
      "Epoch: 8787, Train Loss: 0.0002248920063721016, Valid Loss: 0.00035331561230123043\n",
      "Epoch: 8788, Train Loss: 0.00022476352751255035, Valid Loss: 0.0003531008551362902\n",
      "Epoch: 8789, Train Loss: 0.0002246368385385722, Valid Loss: 0.0003529507666826248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8790, Train Loss: 0.00022450866526924074, Valid Loss: 0.00035273266257718205\n",
      "Epoch: 8791, Train Loss: 0.0002243795315735042, Valid Loss: 0.00035258173011243343\n",
      "Epoch: 8792, Train Loss: 0.00022425224597100168, Valid Loss: 0.00035236022085882723\n",
      "Epoch: 8793, Train Loss: 0.00022412545513361692, Valid Loss: 0.00035220966674387455\n",
      "Epoch: 8794, Train Loss: 0.00022399777662940323, Valid Loss: 0.00035199447302147746\n",
      "Epoch: 8795, Train Loss: 0.00022386990895029157, Valid Loss: 0.0003518460434861481\n",
      "Epoch: 8796, Train Loss: 0.00022374143009074032, Valid Loss: 0.0003516281140036881\n",
      "Epoch: 8797, Train Loss: 0.00022361474111676216, Valid Loss: 0.0003514796553645283\n",
      "Epoch: 8798, Train Loss: 0.0002234865678474307, Valid Loss: 0.0003512561088427901\n",
      "Epoch: 8799, Train Loss: 0.00022335896210279316, Valid Loss: 0.000351110240444541\n",
      "Epoch: 8800, Train Loss: 0.00022323211305774748, Valid Loss: 0.000350893969880417\n",
      "Epoch: 8801, Train Loss: 0.00022310386702883989, Valid Loss: 0.00035074353218078613\n",
      "Epoch: 8802, Train Loss: 0.00022297794930636883, Valid Loss: 0.000350528018316254\n",
      "Epoch: 8803, Train Loss: 0.0002228498924523592, Valid Loss: 0.00035037260386161506\n",
      "Epoch: 8804, Train Loss: 0.0002227242075605318, Valid Loss: 0.0003501607570797205\n",
      "Epoch: 8805, Train Loss: 0.0002225962234660983, Valid Loss: 0.0003500061866361648\n",
      "Epoch: 8806, Train Loss: 0.00022246963635552675, Valid Loss: 0.0003498005389701575\n",
      "Epoch: 8807, Train Loss: 0.00022234355856198817, Valid Loss: 0.000349645153619349\n",
      "Epoch: 8808, Train Loss: 0.00022221577819436789, Valid Loss: 0.00034943458740599453\n",
      "Epoch: 8809, Train Loss: 0.0002220902097178623, Valid Loss: 0.00034927777596749365\n",
      "Epoch: 8810, Train Loss: 0.0002219635935034603, Valid Loss: 0.00034907340887002647\n",
      "Epoch: 8811, Train Loss: 0.0002218364243162796, Valid Loss: 0.00034890873939730227\n",
      "Epoch: 8812, Train Loss: 0.0002217093569925055, Valid Loss: 0.00034870990202762187\n",
      "Epoch: 8813, Train Loss: 0.00022158445790410042, Valid Loss: 0.000348550034686923\n",
      "Epoch: 8814, Train Loss: 0.00022145807452034205, Valid Loss: 0.00034835058613680303\n",
      "Epoch: 8815, Train Loss: 0.00022133131278678775, Valid Loss: 0.0003481812891550362\n",
      "Epoch: 8816, Train Loss: 0.00022120619541965425, Valid Loss: 0.0003479884471744299\n",
      "Epoch: 8817, Train Loss: 0.00022107854601927102, Valid Loss: 0.0003478199359960854\n",
      "Epoch: 8818, Train Loss: 0.00022095335589256138, Valid Loss: 0.000347623776178807\n",
      "Epoch: 8819, Train Loss: 0.00022082736541051418, Valid Loss: 0.0003474562254268676\n",
      "Epoch: 8820, Train Loss: 0.00022070156410336494, Valid Loss: 0.0003472668176982552\n",
      "Epoch: 8821, Train Loss: 0.00022057587921153754, Valid Loss: 0.0003470923111308366\n",
      "Epoch: 8822, Train Loss: 0.0002204503834946081, Valid Loss: 0.00034690453321672976\n",
      "Epoch: 8823, Train Loss: 0.0002203239273512736, Valid Loss: 0.00034673427580855787\n",
      "Epoch: 8824, Train Loss: 0.00022019843163434416, Valid Loss: 0.00034654687624424696\n",
      "Epoch: 8825, Train Loss: 0.00022007313964422792, Valid Loss: 0.0003463676548562944\n",
      "Epoch: 8826, Train Loss: 0.00021994697453919798, Valid Loss: 0.0003461836604401469\n",
      "Epoch: 8827, Train Loss: 0.0002198222791776061, Valid Loss: 0.00034600633080117404\n",
      "Epoch: 8828, Train Loss: 0.0002196968562202528, Valid Loss: 0.00034582207445055246\n",
      "Epoch: 8829, Train Loss: 0.0002195718843722716, Valid Loss: 0.0003456522535998374\n",
      "Epoch: 8830, Train Loss: 0.00021944701438769698, Valid Loss: 0.0003454684338066727\n",
      "Epoch: 8831, Train Loss: 0.0002193223190261051, Valid Loss: 0.00034528470132499933\n",
      "Epoch: 8832, Train Loss: 0.0002191980165662244, Valid Loss: 0.00034510419936850667\n",
      "Epoch: 8833, Train Loss: 0.00021907294285483658, Valid Loss: 0.00034492730628699064\n",
      "Epoch: 8834, Train Loss: 0.00021894802921451628, Valid Loss: 0.00034474360290914774\n",
      "Epoch: 8835, Train Loss: 0.00021882285363972187, Valid Loss: 0.00034456513822078705\n",
      "Epoch: 8836, Train Loss: 0.00021869924967177212, Valid Loss: 0.00034438690636307\n",
      "Epoch: 8837, Train Loss: 0.00021857408864889294, Valid Loss: 0.0003442041634116322\n",
      "Epoch: 8838, Train Loss: 0.00021845057199243456, Valid Loss: 0.0003440254949964583\n",
      "Epoch: 8839, Train Loss: 0.00021832525089848787, Valid Loss: 0.00034384557511657476\n",
      "Epoch: 8840, Train Loss: 0.00021819991525262594, Valid Loss: 0.0003436699917074293\n",
      "Epoch: 8841, Train Loss: 0.0002180762094212696, Valid Loss: 0.00034348457120358944\n",
      "Epoch: 8842, Train Loss: 0.00021795379871036857, Valid Loss: 0.00034331006463617086\n",
      "Epoch: 8843, Train Loss: 0.00021782840485684574, Valid Loss: 0.00034312542993575335\n",
      "Epoch: 8844, Train Loss: 0.00021770363673567772, Valid Loss: 0.0003429515636526048\n",
      "Epoch: 8845, Train Loss: 0.0002175810222979635, Valid Loss: 0.0003427655901759863\n",
      "Epoch: 8846, Train Loss: 0.00021745565754827112, Valid Loss: 0.0003425960603635758\n",
      "Epoch: 8847, Train Loss: 0.0002173329412471503, Valid Loss: 0.00034240915556438267\n",
      "Epoch: 8848, Train Loss: 0.0002172087406506762, Valid Loss: 0.00034223904367536306\n",
      "Epoch: 8849, Train Loss: 0.00021708555868826807, Valid Loss: 0.000342049723258242\n",
      "Epoch: 8850, Train Loss: 0.00021696135809179395, Valid Loss: 0.0003418835112825036\n",
      "Epoch: 8851, Train Loss: 0.00021683817612938583, Valid Loss: 0.00034169628634117544\n",
      "Epoch: 8852, Train Loss: 0.000216715459828265, Valid Loss: 0.0003415274550206959\n",
      "Epoch: 8853, Train Loss: 0.00021659128833562136, Valid Loss: 0.0003413356898818165\n",
      "Epoch: 8854, Train Loss: 0.00021646807726938277, Valid Loss: 0.0003411662473808974\n",
      "Epoch: 8855, Train Loss: 0.00021634479344356805, Valid Loss: 0.0003409819328226149\n",
      "Epoch: 8856, Train Loss: 0.00021622059284709394, Valid Loss: 0.00034081857302226126\n",
      "Epoch: 8857, Train Loss: 0.00021609905525110662, Valid Loss: 0.0003406246250960976\n",
      "Epoch: 8858, Train Loss: 0.00021597636805381626, Valid Loss: 0.0003404546296223998\n",
      "Epoch: 8859, Train Loss: 0.0002158516872441396, Valid Loss: 0.00034026935463771224\n",
      "Epoch: 8860, Train Loss: 0.00021572930563706905, Valid Loss: 0.0003401048597879708\n",
      "Epoch: 8861, Train Loss: 0.00021560578898061067, Valid Loss: 0.00033991679083555937\n",
      "Epoch: 8862, Train Loss: 0.00021548278164118528, Valid Loss: 0.0003397463297005743\n",
      "Epoch: 8863, Train Loss: 0.00021536117128562182, Valid Loss: 0.00033955564140342176\n",
      "Epoch: 8864, Train Loss: 0.00021523689792957157, Valid Loss: 0.0003393955994397402\n",
      "Epoch: 8865, Train Loss: 0.00021511530212592334, Valid Loss: 0.0003392075886949897\n",
      "Epoch: 8866, Train Loss: 0.00021499318245332688, Valid Loss: 0.0003390374477021396\n",
      "Epoch: 8867, Train Loss: 0.00021487106278073043, Valid Loss: 0.0003388488257769495\n",
      "Epoch: 8868, Train Loss: 0.00021474897221196443, Valid Loss: 0.00033868488389998674\n",
      "Epoch: 8869, Train Loss: 0.000214627681998536, Valid Loss: 0.00033849544706754386\n",
      "Epoch: 8870, Train Loss: 0.00021450368512887508, Valid Loss: 0.0003383306320756674\n",
      "Epoch: 8871, Train Loss: 0.0002143818564945832, Valid Loss: 0.00033814500784501433\n",
      "Epoch: 8872, Train Loss: 0.00021425887825898826, Valid Loss: 0.00033798228832893074\n",
      "Epoch: 8873, Train Loss: 0.00021413776266854256, Valid Loss: 0.00033779125078581274\n",
      "Epoch: 8874, Train Loss: 0.00021401475532911718, Valid Loss: 0.00033762678503990173\n",
      "Epoch: 8875, Train Loss: 0.00021389394532889128, Valid Loss: 0.00033743996755219996\n",
      "Epoch: 8876, Train Loss: 0.00021377265511546284, Valid Loss: 0.0003372767532709986\n",
      "Epoch: 8877, Train Loss: 0.00021365113207139075, Valid Loss: 0.00033708836417645216\n",
      "Epoch: 8878, Train Loss: 0.0002135284448741004, Valid Loss: 0.0003369245387148112\n",
      "Epoch: 8879, Train Loss: 0.0002134073292836547, Valid Loss: 0.0003367340541444719\n",
      "Epoch: 8880, Train Loss: 0.0002132851368514821, Valid Loss: 0.0003365744196344167\n",
      "Epoch: 8881, Train Loss: 0.00021316483616828918, Valid Loss: 0.00033638335298746824\n",
      "Epoch: 8882, Train Loss: 0.0002130434149876237, Valid Loss: 0.00033622339833527803\n",
      "Epoch: 8883, Train Loss: 0.00021292180463206023, Valid Loss: 0.0003360344562679529\n",
      "Epoch: 8884, Train Loss: 0.00021280109649524093, Valid Loss: 0.0003358706017024815\n",
      "Epoch: 8885, Train Loss: 0.0002126787876477465, Valid Loss: 0.00033568107755854726\n",
      "Epoch: 8886, Train Loss: 0.00021255867613945156, Valid Loss: 0.00033551812521182\n",
      "Epoch: 8887, Train Loss: 0.00021243748778942972, Valid Loss: 0.00033533480018377304\n",
      "Epoch: 8888, Train Loss: 0.00021231765276752412, Valid Loss: 0.0003351755440235138\n",
      "Epoch: 8889, Train Loss: 0.0002121954457834363, Valid Loss: 0.0003349817998241633\n",
      "Epoch: 8890, Train Loss: 0.0002120733552146703, Valid Loss: 0.0003348200407344848\n",
      "Epoch: 8891, Train Loss: 0.00021195334556978196, Valid Loss: 0.00033463467843830585\n",
      "Epoch: 8892, Train Loss: 0.00021183262288104743, Valid Loss: 0.00033446840825490654\n",
      "Epoch: 8893, Train Loss: 0.00021171268599573523, Valid Loss: 0.00033427932066842914\n",
      "Epoch: 8894, Train Loss: 0.00021159171592444181, Valid Loss: 0.00033412218908779323\n",
      "Epoch: 8895, Train Loss: 0.00021147158986423165, Valid Loss: 0.00033393793273717165\n",
      "Epoch: 8896, Train Loss: 0.00021135206043254584, Valid Loss: 0.0003337699163239449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8897, Train Loss: 0.00021122986800037324, Valid Loss: 0.00033358755172230303\n",
      "Epoch: 8898, Train Loss: 0.00021111135720275342, Valid Loss: 0.0003334236389491707\n",
      "Epoch: 8899, Train Loss: 0.00021099013974890113, Valid Loss: 0.0003332390624564141\n",
      "Epoch: 8900, Train Loss: 0.0002108700282406062, Valid Loss: 0.00033307206467725337\n",
      "Epoch: 8901, Train Loss: 0.00021075013501103967, Valid Loss: 0.00033289322163909674\n",
      "Epoch: 8902, Train Loss: 0.00021063069289084524, Valid Loss: 0.00033272578730247915\n",
      "Epoch: 8903, Train Loss: 0.00021051187650300562, Valid Loss: 0.00033254886511713266\n",
      "Epoch: 8904, Train Loss: 0.00021039089187979698, Valid Loss: 0.0003323799464851618\n",
      "Epoch: 8905, Train Loss: 0.0002102716825902462, Valid Loss: 0.0003322003176435828\n",
      "Epoch: 8906, Train Loss: 0.00021015145466662943, Valid Loss: 0.00033203428029082716\n",
      "Epoch: 8907, Train Loss: 0.00021003260917495936, Valid Loss: 0.0003318564558867365\n",
      "Epoch: 8908, Train Loss: 0.00020991370547562838, Valid Loss: 0.0003316836664453149\n",
      "Epoch: 8909, Train Loss: 0.00020979389955755323, Valid Loss: 0.0003315064241178334\n",
      "Epoch: 8910, Train Loss: 0.00020967428281437606, Valid Loss: 0.00033134256955236197\n",
      "Epoch: 8911, Train Loss: 0.00020955446234438568, Valid Loss: 0.0003311635518912226\n",
      "Epoch: 8912, Train Loss: 0.00020943445269949734, Valid Loss: 0.0003309922176413238\n",
      "Epoch: 8913, Train Loss: 0.00020931573817506433, Valid Loss: 0.0003308164596091956\n",
      "Epoch: 8914, Train Loss: 0.00020919673261232674, Valid Loss: 0.00033065234310925007\n",
      "Epoch: 8915, Train Loss: 0.0002090776979457587, Valid Loss: 0.00033047294709831476\n",
      "Epoch: 8916, Train Loss: 0.00020895937632303685, Valid Loss: 0.0003303068224340677\n",
      "Epoch: 8917, Train Loss: 0.00020884015248157084, Valid Loss: 0.000330130074871704\n",
      "Epoch: 8918, Train Loss: 0.0002087203465634957, Valid Loss: 0.0003299587988294661\n",
      "Epoch: 8919, Train Loss: 0.00020860093354713172, Valid Loss: 0.00032978359377011657\n",
      "Epoch: 8920, Train Loss: 0.00020848397980444133, Valid Loss: 0.00032961659599095583\n",
      "Epoch: 8921, Train Loss: 0.00020836517796851695, Valid Loss: 0.00032943981932476163\n",
      "Epoch: 8922, Train Loss: 0.00020824605599045753, Valid Loss: 0.00032927459687925875\n",
      "Epoch: 8923, Train Loss: 0.00020812616276089102, Valid Loss: 0.0003290954336989671\n",
      "Epoch: 8924, Train Loss: 0.00020801032951567322, Valid Loss: 0.000328932044794783\n",
      "Epoch: 8925, Train Loss: 0.00020789049449376762, Valid Loss: 0.00032875436590984464\n",
      "Epoch: 8926, Train Loss: 0.00020777317695319653, Valid Loss: 0.0003285901329945773\n",
      "Epoch: 8927, Train Loss: 0.00020765475346706808, Valid Loss: 0.0003284105914644897\n",
      "Epoch: 8928, Train Loss: 0.00020753542776219547, Valid Loss: 0.00032824507798068225\n",
      "Epoch: 8929, Train Loss: 0.00020741831394843757, Valid Loss: 0.0003280683886259794\n",
      "Epoch: 8930, Train Loss: 0.00020729989046230912, Valid Loss: 0.00032790261320769787\n",
      "Epoch: 8931, Train Loss: 0.00020718216546811163, Valid Loss: 0.00032772854319773614\n",
      "Epoch: 8932, Train Loss: 0.00020706474606413394, Valid Loss: 0.0003275623603258282\n",
      "Epoch: 8933, Train Loss: 0.00020694523118436337, Valid Loss: 0.0003273857000749558\n",
      "Epoch: 8934, Train Loss: 0.00020682909234892577, Valid Loss: 0.0003272189060226083\n",
      "Epoch: 8935, Train Loss: 0.0002067126624751836, Valid Loss: 0.0003270476299803704\n",
      "Epoch: 8936, Train Loss: 0.00020659503934439272, Valid Loss: 0.0003268826403655112\n",
      "Epoch: 8937, Train Loss: 0.00020647603378165513, Valid Loss: 0.00032670542714186013\n",
      "Epoch: 8938, Train Loss: 0.00020635908003896475, Valid Loss: 0.0003265385748818517\n",
      "Epoch: 8939, Train Loss: 0.0002062414714600891, Valid Loss: 0.00032636162359267473\n",
      "Epoch: 8940, Train Loss: 0.00020612296066246927, Valid Loss: 0.0003261947713326663\n",
      "Epoch: 8941, Train Loss: 0.00020600682182703167, Valid Loss: 0.00032602332066744566\n",
      "Epoch: 8942, Train Loss: 0.00020588908228091896, Valid Loss: 0.00032585792359896004\n",
      "Epoch: 8943, Train Loss: 0.0002057726524071768, Valid Loss: 0.0003256831259932369\n",
      "Epoch: 8944, Train Loss: 0.00020565562590491027, Valid Loss: 0.0003255159535910934\n",
      "Epoch: 8945, Train Loss: 0.00020553641661535949, Valid Loss: 0.0003253445029258728\n",
      "Epoch: 8946, Train Loss: 0.00020542216952890158, Valid Loss: 0.00032518114312551916\n",
      "Epoch: 8947, Train Loss: 0.00020530493929982185, Valid Loss: 0.0003250004374422133\n",
      "Epoch: 8948, Train Loss: 0.00020518891687970608, Valid Loss: 0.0003248332068324089\n",
      "Epoch: 8949, Train Loss: 0.000205071090022102, Valid Loss: 0.00032466513221152127\n",
      "Epoch: 8950, Train Loss: 0.00020495435455814004, Valid Loss: 0.00032449717400595546\n",
      "Epoch: 8951, Train Loss: 0.0002048376336460933, Valid Loss: 0.00032432767329737544\n",
      "Epoch: 8952, Train Loss: 0.0002047219022642821, Valid Loss: 0.00032415546593256295\n",
      "Epoch: 8953, Train Loss: 0.00020460526866372675, Valid Loss: 0.0003239882062189281\n",
      "Epoch: 8954, Train Loss: 0.00020448774739634246, Valid Loss: 0.00032381739583797753\n",
      "Epoch: 8955, Train Loss: 0.00020437179773580283, Valid Loss: 0.00032365284278057516\n",
      "Epoch: 8956, Train Loss: 0.0002042549749603495, Valid Loss: 0.0003234810719732195\n",
      "Epoch: 8957, Train Loss: 0.00020414033497218043, Valid Loss: 0.0003233142488170415\n",
      "Epoch: 8958, Train Loss: 0.00020402352674864233, Valid Loss: 0.0003231409064028412\n",
      "Epoch: 8959, Train Loss: 0.00020390738791320473, Valid Loss: 0.00032297917641699314\n",
      "Epoch: 8960, Train Loss: 0.0002037928206846118, Valid Loss: 0.00032280496088787913\n",
      "Epoch: 8961, Train Loss: 0.00020367470278870314, Valid Loss: 0.0003226405824534595\n",
      "Epoch: 8962, Train Loss: 0.0002035603829426691, Valid Loss: 0.0003224666288588196\n",
      "Epoch: 8963, Train Loss: 0.0002034442441072315, Valid Loss: 0.00032230670331045985\n",
      "Epoch: 8964, Train Loss: 0.00020332919666543603, Valid Loss: 0.00032213187660090625\n",
      "Epoch: 8965, Train Loss: 0.0002032126794802025, Valid Loss: 0.0003219683712814003\n",
      "Epoch: 8966, Train Loss: 0.0002030966425081715, Valid Loss: 0.00032179319532588124\n",
      "Epoch: 8967, Train Loss: 0.00020298179879318923, Valid Loss: 0.0003216312325093895\n",
      "Epoch: 8968, Train Loss: 0.00020286637300159782, Valid Loss: 0.00032145940349437296\n",
      "Epoch: 8969, Train Loss: 0.00020275142742320895, Valid Loss: 0.0003212944429833442\n",
      "Epoch: 8970, Train Loss: 0.00020263488113414496, Valid Loss: 0.00032112133339978755\n",
      "Epoch: 8971, Train Loss: 0.00020252085232641548, Valid Loss: 0.0003209632996004075\n",
      "Epoch: 8972, Train Loss: 0.0002024065179284662, Valid Loss: 0.00032079347874969244\n",
      "Epoch: 8973, Train Loss: 0.00020228959328960627, Valid Loss: 0.00032063157414086163\n",
      "Epoch: 8974, Train Loss: 0.00020217563724145293, Valid Loss: 0.00032045302214100957\n",
      "Epoch: 8975, Train Loss: 0.00020206061890348792, Valid Loss: 0.0003202914376743138\n",
      "Epoch: 8976, Train Loss: 0.00020194366516079754, Valid Loss: 0.0003201203071512282\n",
      "Epoch: 8977, Train Loss: 0.00020182975276838988, Valid Loss: 0.00031996305915527046\n",
      "Epoch: 8978, Train Loss: 0.00020171540381852537, Valid Loss: 0.000319786777254194\n",
      "Epoch: 8979, Train Loss: 0.00020160124404355884, Valid Loss: 0.00031962833600118756\n",
      "Epoch: 8980, Train Loss: 0.0002014849305851385, Valid Loss: 0.00031944990041665733\n",
      "Epoch: 8981, Train Loss: 0.0002013723860727623, Valid Loss: 0.0003192906442563981\n",
      "Epoch: 8982, Train Loss: 0.00020125733863096684, Valid Loss: 0.00031911753467284143\n",
      "Epoch: 8983, Train Loss: 0.0002011441974900663, Valid Loss: 0.0003189619746990502\n",
      "Epoch: 8984, Train Loss: 0.0002010289317695424, Valid Loss: 0.00031878548907116055\n",
      "Epoch: 8985, Train Loss: 0.00020091321493964642, Valid Loss: 0.0003186300164088607\n",
      "Epoch: 8986, Train Loss: 0.0002008007577387616, Valid Loss: 0.00031845373450778425\n",
      "Epoch: 8987, Train Loss: 0.000200685128220357, Valid Loss: 0.00031830061925575137\n",
      "Epoch: 8988, Train Loss: 0.00020057168148923665, Valid Loss: 0.0003181195934303105\n",
      "Epoch: 8989, Train Loss: 0.00020045763812959194, Valid Loss: 0.0003179680206812918\n",
      "Epoch: 8990, Train Loss: 0.000200344089535065, Valid Loss: 0.00031778731499798596\n",
      "Epoch: 8991, Train Loss: 0.00020022915850859135, Valid Loss: 0.0003176329773850739\n",
      "Epoch: 8992, Train Loss: 0.0002001160173676908, Valid Loss: 0.00031745611340738833\n",
      "Epoch: 8993, Train Loss: 0.00020000267249997705, Valid Loss: 0.00031730334740132093\n",
      "Epoch: 8994, Train Loss: 0.00019988893473055214, Valid Loss: 0.0003171268617734313\n",
      "Epoch: 8995, Train Loss: 0.00019977378542535007, Valid Loss: 0.00031697555095888674\n",
      "Epoch: 8996, Train Loss: 0.00019966054242104292, Valid Loss: 0.00031679507810622454\n",
      "Epoch: 8997, Train Loss: 0.00019954897288698703, Valid Loss: 0.00031664318521507084\n",
      "Epoch: 8998, Train Loss: 0.00019943533698096871, Valid Loss: 0.0003164611989632249\n",
      "Epoch: 8999, Train Loss: 0.00019932059512939304, Valid Loss: 0.0003163136134389788\n",
      "Epoch: 9000, Train Loss: 0.00019920615886803716, Valid Loss: 0.0003161333443131298\n",
      "Epoch: 9001, Train Loss: 0.0001990951132029295, Valid Loss: 0.00031598162604495883\n",
      "Epoch: 9002, Train Loss: 0.00019898074970114976, Valid Loss: 0.0003158009785693139\n",
      "Epoch: 9003, Train Loss: 0.00019886900554411113, Valid Loss: 0.0003156549937557429\n",
      "Epoch: 9004, Train Loss: 0.00019875446741934866, Valid Loss: 0.00031547315302304924\n",
      "Epoch: 9005, Train Loss: 0.0001986411225516349, Valid Loss: 0.00031532239518128335\n",
      "Epoch: 9006, Train Loss: 0.0001985304697882384, Valid Loss: 0.00031514110742136836\n",
      "Epoch: 9007, Train Loss: 0.00019841542234644294, Valid Loss: 0.00031499634496867657\n",
      "Epoch: 9008, Train Loss: 0.000198304551304318, Valid Loss: 0.0003148112155031413\n",
      "Epoch: 9009, Train Loss: 0.00019819012959487736, Valid Loss: 0.00031466581276617944\n",
      "Epoch: 9010, Train Loss: 0.0001980789820663631, Valid Loss: 0.0003144860384054482\n",
      "Epoch: 9011, Train Loss: 0.00019796591368503869, Valid Loss: 0.00031433746335096657\n",
      "Epoch: 9012, Train Loss: 0.00019785277254413813, Valid Loss: 0.0003141549532301724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9013, Train Loss: 0.00019774193060584366, Valid Loss: 0.0003140105400234461\n",
      "Epoch: 9014, Train Loss: 0.00019762855663429946, Valid Loss: 0.00031382800079882145\n",
      "Epoch: 9015, Train Loss: 0.00019751621584873646, Valid Loss: 0.0003136812592856586\n",
      "Epoch: 9016, Train Loss: 0.00019740407878998667, Valid Loss: 0.0003135010483674705\n",
      "Epoch: 9017, Train Loss: 0.0001972911268239841, Valid Loss: 0.00031335701351054013\n",
      "Epoch: 9018, Train Loss: 0.00019717856775969267, Valid Loss: 0.0003131686826236546\n",
      "Epoch: 9019, Train Loss: 0.00019706643070094287, Valid Loss: 0.0003130319819319993\n",
      "Epoch: 9020, Train Loss: 0.00019695494847837836, Valid Loss: 0.0003128480166196823\n",
      "Epoch: 9021, Train Loss: 0.0001968439028132707, Valid Loss: 0.0003127020609099418\n",
      "Epoch: 9022, Train Loss: 0.00019673154747579247, Valid Loss: 0.00031251960899680853\n",
      "Epoch: 9023, Train Loss: 0.0001966206036740914, Valid Loss: 0.00031237700022757053\n",
      "Epoch: 9024, Train Loss: 0.00019650715694297105, Valid Loss: 0.00031219053198583424\n",
      "Epoch: 9025, Train Loss: 0.00019639650417957455, Valid Loss: 0.00031205581035465\n",
      "Epoch: 9026, Train Loss: 0.00019628385780379176, Valid Loss: 0.000311862415401265\n",
      "Epoch: 9027, Train Loss: 0.00019617329235188663, Valid Loss: 0.00031172536546364427\n",
      "Epoch: 9028, Train Loss: 0.00019606153364293277, Valid Loss: 0.0003115372091997415\n",
      "Epoch: 9029, Train Loss: 0.00019595016783569008, Valid Loss: 0.00031140627106651664\n",
      "Epoch: 9030, Train Loss: 0.00019583913672249764, Valid Loss: 0.00031121211941353977\n",
      "Epoch: 9031, Train Loss: 0.00019572737801354378, Valid Loss: 0.0003110788238700479\n",
      "Epoch: 9032, Train Loss: 0.00019561639055609703, Valid Loss: 0.0003108878736384213\n",
      "Epoch: 9033, Train Loss: 0.0001955055631697178, Valid Loss: 0.000310758245177567\n",
      "Epoch: 9034, Train Loss: 0.0001953956816578284, Valid Loss: 0.0003105643263552338\n",
      "Epoch: 9035, Train Loss: 0.0001952827296918258, Valid Loss: 0.00031043344642966986\n",
      "Epoch: 9036, Train Loss: 0.00019517277542036027, Valid Loss: 0.00031024159397929907\n",
      "Epoch: 9037, Train Loss: 0.00019506151147652417, Valid Loss: 0.0003101077163591981\n",
      "Epoch: 9038, Train Loss: 0.00019495084416121244, Valid Loss: 0.00030991839594207704\n",
      "Epoch: 9039, Train Loss: 0.0001948399149114266, Valid Loss: 0.0003097823355346918\n",
      "Epoch: 9040, Train Loss: 0.00019472984422463924, Valid Loss: 0.00030959592550061643\n",
      "Epoch: 9041, Train Loss: 0.00019461858028080314, Valid Loss: 0.0003094646381214261\n",
      "Epoch: 9042, Train Loss: 0.0001945081166923046, Valid Loss: 0.0003092748229391873\n",
      "Epoch: 9043, Train Loss: 0.00019439855532255024, Valid Loss: 0.000309136783471331\n",
      "Epoch: 9044, Train Loss: 0.00019428700034040958, Valid Loss: 0.00030895150848664343\n",
      "Epoch: 9045, Train Loss: 0.00019417704606894404, Valid Loss: 0.0003088179510086775\n",
      "Epoch: 9046, Train Loss: 0.00019406768842600286, Valid Loss: 0.0003086324722971767\n",
      "Epoch: 9047, Train Loss: 0.0001939563371706754, Valid Loss: 0.00030849254108034074\n",
      "Epoch: 9048, Train Loss: 0.0001938462519319728, Valid Loss: 0.0003083125047851354\n",
      "Epoch: 9049, Train Loss: 0.00019373638497199863, Valid Loss: 0.00030817309743724763\n",
      "Epoch: 9050, Train Loss: 0.00019362624152563512, Valid Loss: 0.0003079866582993418\n",
      "Epoch: 9051, Train Loss: 0.0001935170585056767, Valid Loss: 0.00030784757109358907\n",
      "Epoch: 9052, Train Loss: 0.0001934049214469269, Valid Loss: 0.00030767088173888624\n",
      "Epoch: 9053, Train Loss: 0.00019329575297888368, Valid Loss: 0.00030752216116525233\n",
      "Epoch: 9054, Train Loss: 0.0001931845908984542, Valid Loss: 0.00030735190375708044\n",
      "Epoch: 9055, Train Loss: 0.00019307683396618813, Valid Loss: 0.0003072038816753775\n",
      "Epoch: 9056, Train Loss: 0.00019296603568363935, Valid Loss: 0.00030702893855050206\n",
      "Epoch: 9057, Train Loss: 0.00019285708549432456, Valid Loss: 0.0003068781516049057\n",
      "Epoch: 9058, Train Loss: 0.00019274692749604583, Valid Loss: 0.0003067087091039866\n",
      "Epoch: 9059, Train Loss: 0.00019263745343778282, Valid Loss: 0.0003065611235797405\n",
      "Epoch: 9060, Train Loss: 0.00019252659694757313, Valid Loss: 0.00030639293254353106\n",
      "Epoch: 9061, Train Loss: 0.00019241913105361164, Valid Loss: 0.0003062375180888921\n",
      "Epoch: 9062, Train Loss: 0.00019230935140512884, Valid Loss: 0.0003060712188016623\n",
      "Epoch: 9063, Train Loss: 0.00019220019748900086, Valid Loss: 0.0003059201408177614\n",
      "Epoch: 9064, Train Loss: 0.00019208954472560436, Valid Loss: 0.00030575215350836515\n",
      "Epoch: 9065, Train Loss: 0.00019198167137801647, Valid Loss: 0.0003055983688682318\n",
      "Epoch: 9066, Train Loss: 0.00019187340512871742, Valid Loss: 0.00030543518369086087\n",
      "Epoch: 9067, Train Loss: 0.00019176353816874325, Valid Loss: 0.0003052824758924544\n",
      "Epoch: 9068, Train Loss: 0.0001916563487611711, Valid Loss: 0.0003051178646273911\n",
      "Epoch: 9069, Train Loss: 0.00019154709298163652, Valid Loss: 0.00030495895771309733\n",
      "Epoch: 9070, Train Loss: 0.00019143881218042225, Valid Loss: 0.0003047990903723985\n",
      "Epoch: 9071, Train Loss: 0.00019132907618768513, Valid Loss: 0.0003046428319066763\n",
      "Epoch: 9072, Train Loss: 0.00019122047524433583, Valid Loss: 0.0003044800541829318\n",
      "Epoch: 9073, Train Loss: 0.00019111142319161445, Valid Loss: 0.0003043276083189994\n",
      "Epoch: 9074, Train Loss: 0.00019100442295894027, Valid Loss: 0.00030416372464969754\n",
      "Epoch: 9075, Train Loss: 0.00019089617126155645, Valid Loss: 0.0003040084848180413\n",
      "Epoch: 9076, Train Loss: 0.00019078610057476908, Valid Loss: 0.0003038497525267303\n",
      "Epoch: 9077, Train Loss: 0.00019067851826548576, Valid Loss: 0.00030368607258424163\n",
      "Epoch: 9078, Train Loss: 0.00019057015015278012, Valid Loss: 0.0003035286208614707\n",
      "Epoch: 9079, Train Loss: 0.00019046058878302574, Valid Loss: 0.0003033705288544297\n",
      "Epoch: 9080, Train Loss: 0.00019035401055589318, Valid Loss: 0.00030321525991894305\n",
      "Epoch: 9081, Train Loss: 0.0001902443473227322, Valid Loss: 0.0003030574298463762\n",
      "Epoch: 9082, Train Loss: 0.00019013737619388849, Valid Loss: 0.0003029012877959758\n",
      "Epoch: 9083, Train Loss: 0.00019002761109732091, Valid Loss: 0.0003027437487617135\n",
      "Epoch: 9084, Train Loss: 0.0001899211056297645, Valid Loss: 0.00030258463812060654\n",
      "Epoch: 9085, Train Loss: 0.00018981395987793803, Valid Loss: 0.0003024246252607554\n",
      "Epoch: 9086, Train Loss: 0.0001897050824481994, Valid Loss: 0.00030226499075070024\n",
      "Epoch: 9087, Train Loss: 0.00018959819863084704, Valid Loss: 0.00030210791737772524\n",
      "Epoch: 9088, Train Loss: 0.00018949041259475052, Valid Loss: 0.00030195617000572383\n",
      "Epoch: 9089, Train Loss: 0.00018938117136713117, Valid Loss: 0.00030179278110153973\n",
      "Epoch: 9090, Train Loss: 0.00018927508790511638, Valid Loss: 0.00030163678457029164\n",
      "Epoch: 9091, Train Loss: 0.0001891673164209351, Valid Loss: 0.00030147581128403544\n",
      "Epoch: 9092, Train Loss: 0.0001890604180516675, Valid Loss: 0.0003013236855622381\n",
      "Epoch: 9093, Train Loss: 0.0001889518607640639, Valid Loss: 0.0003011612861882895\n",
      "Epoch: 9094, Train Loss: 0.00018884458404500037, Valid Loss: 0.00030100729782134295\n",
      "Epoch: 9095, Train Loss: 0.00018873809312935919, Valid Loss: 0.0003008487983606756\n",
      "Epoch: 9096, Train Loss: 0.0001886309328256175, Valid Loss: 0.00030069114291109145\n",
      "Epoch: 9097, Train Loss: 0.00018852335051633418, Valid Loss: 0.0003005345934070647\n",
      "Epoch: 9098, Train Loss: 0.00018841757264453918, Valid Loss: 0.00030037929536774755\n",
      "Epoch: 9099, Train Loss: 0.00018830910266842693, Valid Loss: 0.00030022155260667205\n",
      "Epoch: 9100, Train Loss: 0.00018820201512426138, Valid Loss: 0.0003000680299010128\n",
      "Epoch: 9101, Train Loss: 0.000188095320481807, Valid Loss: 0.00029990996699780226\n",
      "Epoch: 9102, Train Loss: 0.00018798834935296327, Valid Loss: 0.00029975795769132674\n",
      "Epoch: 9103, Train Loss: 0.0001878824841696769, Valid Loss: 0.00029959899256937206\n",
      "Epoch: 9104, Train Loss: 0.00018777490186039358, Valid Loss: 0.0002994427632074803\n",
      "Epoch: 9105, Train Loss: 0.00018766704306472093, Valid Loss: 0.0002992832742165774\n",
      "Epoch: 9106, Train Loss: 0.0001875613525044173, Valid Loss: 0.00029912820900790393\n",
      "Epoch: 9107, Train Loss: 0.00018745596753433347, Valid Loss: 0.00029897407512180507\n",
      "Epoch: 9108, Train Loss: 0.00018734850164037198, Valid Loss: 0.0002988163323607296\n",
      "Epoch: 9109, Train Loss: 0.00018724252004176378, Valid Loss: 0.0002986618783324957\n",
      "Epoch: 9110, Train Loss: 0.00018713712051976472, Valid Loss: 0.00029850774444639683\n",
      "Epoch: 9111, Train Loss: 0.00018703113892115653, Valid Loss: 0.0002983523590955883\n",
      "Epoch: 9112, Train Loss: 0.0001869239640654996, Valid Loss: 0.0002981974103022367\n",
      "Epoch: 9113, Train Loss: 0.00018681779329199344, Valid Loss: 0.0002980387071147561\n",
      "Epoch: 9114, Train Loss: 0.00018671169527806342, Valid Loss: 0.00029788134270347655\n",
      "Epoch: 9115, Train Loss: 0.0001866062229964882, Valid Loss: 0.0002977205440402031\n",
      "Epoch: 9116, Train Loss: 0.0001865001249825582, Valid Loss: 0.000297573977150023\n",
      "Epoch: 9117, Train Loss: 0.0001863943471107632, Valid Loss: 0.0002974161470774561\n",
      "Epoch: 9118, Train Loss: 0.00018628916586749256, Valid Loss: 0.0002972600341308862\n",
      "Epoch: 9119, Train Loss: 0.00018618337344378233, Valid Loss: 0.00029710549279116094\n",
      "Epoch: 9120, Train Loss: 0.0001860777847468853, Valid Loss: 0.00029695272678509355\n",
      "Epoch: 9121, Train Loss: 0.0001859720068750903, Valid Loss: 0.00029679539147764444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9122, Train Loss: 0.00018586512305773795, Valid Loss: 0.0002966402971651405\n",
      "Epoch: 9123, Train Loss: 0.00018576082948129624, Valid Loss: 0.00029648144845850766\n",
      "Epoch: 9124, Train Loss: 0.00018565522623248398, Valid Loss: 0.0002963317383546382\n",
      "Epoch: 9125, Train Loss: 0.00018555014685261995, Valid Loss: 0.0002961707941722125\n",
      "Epoch: 9126, Train Loss: 0.00018544457270763814, Valid Loss: 0.0002960252750199288\n",
      "Epoch: 9127, Train Loss: 0.00018533741240389645, Valid Loss: 0.00029586549499072134\n",
      "Epoch: 9128, Train Loss: 0.00018523400649428368, Valid Loss: 0.00029571462073363364\n",
      "Epoch: 9129, Train Loss: 0.00018512841779738665, Valid Loss: 0.00029555452056229115\n",
      "Epoch: 9130, Train Loss: 0.00018502392049413174, Valid Loss: 0.00029541144613176584\n",
      "Epoch: 9131, Train Loss: 0.00018491885566618294, Valid Loss: 0.00029525134596042335\n",
      "Epoch: 9132, Train Loss: 0.0001848131651058793, Valid Loss: 0.00029509817250072956\n",
      "Epoch: 9133, Train Loss: 0.00018470817303750664, Valid Loss: 0.0002949385961983353\n",
      "Epoch: 9134, Train Loss: 0.00018460408318787813, Valid Loss: 0.00029479077784344554\n",
      "Epoch: 9135, Train Loss: 0.00018449989147484303, Valid Loss: 0.000294630037387833\n",
      "Epoch: 9136, Train Loss: 0.0001843944046413526, Valid Loss: 0.00029448827262967825\n",
      "Epoch: 9137, Train Loss: 0.00018428900511935353, Valid Loss: 0.00029432057635858655\n",
      "Epoch: 9138, Train Loss: 0.00018418581748846918, Valid Loss: 0.0002941764541901648\n",
      "Epoch: 9139, Train Loss: 0.00018408132018521428, Valid Loss: 0.0002940164413303137\n",
      "Epoch: 9140, Train Loss: 0.00018397603707853705, Valid Loss: 0.0002938745601568371\n",
      "Epoch: 9141, Train Loss: 0.000183871467015706, Valid Loss: 0.000293705437798053\n",
      "Epoch: 9142, Train Loss: 0.0001837664603954181, Valid Loss: 0.00029356603045016527\n",
      "Epoch: 9143, Train Loss: 0.00018366386939305812, Valid Loss: 0.0002933974319603294\n",
      "Epoch: 9144, Train Loss: 0.00018355947395320982, Valid Loss: 0.0002932600036729127\n",
      "Epoch: 9145, Train Loss: 0.00018345488933846354, Valid Loss: 0.00029309303499758244\n",
      "Epoch: 9146, Train Loss: 0.00018335141066927463, Valid Loss: 0.00029295741114765406\n",
      "Epoch: 9147, Train Loss: 0.00018324708798900247, Valid Loss: 0.00029278776491992176\n",
      "Epoch: 9148, Train Loss: 0.00018314439512323588, Valid Loss: 0.0002926522574853152\n",
      "Epoch: 9149, Train Loss: 0.00018304010154679418, Valid Loss: 0.0002924822038039565\n",
      "Epoch: 9150, Train Loss: 0.00018293432367499918, Valid Loss: 0.00029234818066470325\n",
      "Epoch: 9151, Train Loss: 0.0001828306121751666, Valid Loss: 0.0002921727718785405\n",
      "Epoch: 9152, Train Loss: 0.00018272655142936856, Valid Loss: 0.00029204116435721517\n",
      "Epoch: 9153, Train Loss: 0.00018262471712660044, Valid Loss: 0.0002918719837907702\n",
      "Epoch: 9154, Train Loss: 0.00018251975416205823, Valid Loss: 0.0002917383098974824\n",
      "Epoch: 9155, Train Loss: 0.00018241716315969825, Valid Loss: 0.00029156592790968716\n",
      "Epoch: 9156, Train Loss: 0.00018231384456157684, Valid Loss: 0.0002914324577432126\n",
      "Epoch: 9157, Train Loss: 0.0001822085614548996, Valid Loss: 0.0002912639465648681\n",
      "Epoch: 9158, Train Loss: 0.00018210627604275942, Valid Loss: 0.0002911265764851123\n",
      "Epoch: 9159, Train Loss: 0.00018200265185441822, Valid Loss: 0.0002909587346948683\n",
      "Epoch: 9160, Train Loss: 0.00018189878028351814, Valid Loss: 0.0002908252354245633\n",
      "Epoch: 9161, Train Loss: 0.00018179634935222566, Valid Loss: 0.0002906577428802848\n",
      "Epoch: 9162, Train Loss: 0.00018169327813666314, Valid Loss: 0.0002905196452047676\n",
      "Epoch: 9163, Train Loss: 0.00018159058527089655, Valid Loss: 0.00029035337502136827\n",
      "Epoch: 9164, Train Loss: 0.00018148738308809698, Valid Loss: 0.00029021743102930486\n",
      "Epoch: 9165, Train Loss: 0.0001813846902223304, Valid Loss: 0.0002900526742450893\n",
      "Epoch: 9166, Train Loss: 0.00018128138617612422, Valid Loss: 0.00028991603176109493\n",
      "Epoch: 9167, Train Loss: 0.00018117859144695103, Valid Loss: 0.00028974685119464993\n",
      "Epoch: 9168, Train Loss: 0.00018107677169609815, Valid Loss: 0.00028961169300600886\n",
      "Epoch: 9169, Train Loss: 0.00018097339489031583, Valid Loss: 0.0002894479548558593\n",
      "Epoch: 9170, Train Loss: 0.00018087118223775178, Valid Loss: 0.0002893103228416294\n",
      "Epoch: 9171, Train Loss: 0.00018076799460686743, Valid Loss: 0.0002891438780352473\n",
      "Epoch: 9172, Train Loss: 0.00018066508346237242, Valid Loss: 0.0002890062751248479\n",
      "Epoch: 9173, Train Loss: 0.000180562783498317, Valid Loss: 0.00028884282801300287\n",
      "Epoch: 9174, Train Loss: 0.00018045939214061946, Valid Loss: 0.00028870912501588464\n",
      "Epoch: 9175, Train Loss: 0.00018035898392554373, Valid Loss: 0.0002885433204937726\n",
      "Epoch: 9176, Train Loss: 0.00018025646568275988, Valid Loss: 0.00028840056620538235\n",
      "Epoch: 9177, Train Loss: 0.0001801554608391598, Valid Loss: 0.0002882387489080429\n",
      "Epoch: 9178, Train Loss: 0.0001800519530661404, Valid Loss: 0.0002881040272768587\n",
      "Epoch: 9179, Train Loss: 0.00017994968220591545, Valid Loss: 0.00028794011450372636\n",
      "Epoch: 9180, Train Loss: 0.00017984697478823364, Valid Loss: 0.0002877996885217726\n",
      "Epoch: 9181, Train Loss: 0.00017974448564928025, Valid Loss: 0.0002876399375963956\n",
      "Epoch: 9182, Train Loss: 0.00017964285507332534, Valid Loss: 0.00028750134515576065\n",
      "Epoch: 9183, Train Loss: 0.00017954225768335164, Valid Loss: 0.0002873389166779816\n",
      "Epoch: 9184, Train Loss: 0.00017944043793249875, Valid Loss: 0.00028719549300149083\n",
      "Epoch: 9185, Train Loss: 0.0001793392439140007, Valid Loss: 0.0002870382450055331\n",
      "Epoch: 9186, Train Loss: 0.00017923495033755898, Valid Loss: 0.00028689534519799054\n",
      "Epoch: 9187, Train Loss: 0.00017913462943397462, Valid Loss: 0.00028674141503870487\n",
      "Epoch: 9188, Train Loss: 0.00017903331900015473, Valid Loss: 0.000286599068203941\n",
      "Epoch: 9189, Train Loss: 0.00017893231415655464, Valid Loss: 0.0002864377456717193\n",
      "Epoch: 9190, Train Loss: 0.00017882991232909262, Valid Loss: 0.00028629868756979704\n",
      "Epoch: 9191, Train Loss: 0.0001787277142284438, Valid Loss: 0.0002861456305254251\n",
      "Epoch: 9192, Train Loss: 0.00017862740787677467, Valid Loss: 0.00028600034420378506\n",
      "Epoch: 9193, Train Loss: 0.00017852539895102382, Valid Loss: 0.00028584347455762327\n",
      "Epoch: 9194, Train Loss: 0.00017842459783423692, Valid Loss: 0.0002857020008377731\n",
      "Epoch: 9195, Train Loss: 0.00017832359299063683, Valid Loss: 0.00028554725577123463\n",
      "Epoch: 9196, Train Loss: 0.0001782225735951215, Valid Loss: 0.00028540517087094486\n",
      "Epoch: 9197, Train Loss: 0.00017812047735787928, Valid Loss: 0.0002852504840120673\n",
      "Epoch: 9198, Train Loss: 0.00017802049114834517, Valid Loss: 0.00028510743868537247\n",
      "Epoch: 9199, Train Loss: 0.0001779198501026258, Valid Loss: 0.0002849491429515183\n",
      "Epoch: 9200, Train Loss: 0.0001778189471224323, Valid Loss: 0.00028480880428105593\n",
      "Epoch: 9201, Train Loss: 0.0001777167635736987, Valid Loss: 0.000284657726297155\n",
      "Epoch: 9202, Train Loss: 0.00017761594790499657, Valid Loss: 0.00028451503021642566\n",
      "Epoch: 9203, Train Loss: 0.00017751642735674977, Valid Loss: 0.00028436240972951055\n",
      "Epoch: 9204, Train Loss: 0.00017741501505952328, Valid Loss: 0.00028421790921129286\n",
      "Epoch: 9205, Train Loss: 0.00017731479601934552, Valid Loss: 0.00028406138881109655\n",
      "Epoch: 9206, Train Loss: 0.00017721489712130278, Valid Loss: 0.00028392262174747884\n",
      "Epoch: 9207, Train Loss: 0.00017711347027216107, Valid Loss: 0.00028376549016684294\n",
      "Epoch: 9208, Train Loss: 0.00017701338219922036, Valid Loss: 0.0002836243365891278\n",
      "Epoch: 9209, Train Loss: 0.0001769113732734695, Valid Loss: 0.0002834737242665142\n",
      "Epoch: 9210, Train Loss: 0.00017681265308056027, Valid Loss: 0.0002833323669619858\n",
      "Epoch: 9211, Train Loss: 0.00017671214300207794, Valid Loss: 0.00028317570104263723\n",
      "Epoch: 9212, Train Loss: 0.00017661192396190017, Valid Loss: 0.0002830370212905109\n",
      "Epoch: 9213, Train Loss: 0.00017651269445195794, Valid Loss: 0.0002828815777320415\n",
      "Epoch: 9214, Train Loss: 0.00017641240265220404, Valid Loss: 0.00028273899806663394\n",
      "Epoch: 9215, Train Loss: 0.00017631196533329785, Valid Loss: 0.00028258387465029955\n",
      "Epoch: 9216, Train Loss: 0.0001762124738888815, Valid Loss: 0.00028244490385986865\n",
      "Epoch: 9217, Train Loss: 0.0001761130552040413, Valid Loss: 0.00028229004237800837\n",
      "Epoch: 9218, Train Loss: 0.00017601244326215237, Valid Loss: 0.0002821540692821145\n",
      "Epoch: 9219, Train Loss: 0.00017591172945685685, Valid Loss: 0.00028199926600791514\n",
      "Epoch: 9220, Train Loss: 0.0001758124999469146, Valid Loss: 0.000281856075162068\n",
      "Epoch: 9221, Train Loss: 0.00017571329954080284, Valid Loss: 0.00028170188306830823\n",
      "Epoch: 9222, Train Loss: 0.0001756135025061667, Valid Loss: 0.00028156518237665296\n",
      "Epoch: 9223, Train Loss: 0.00017551446217112243, Valid Loss: 0.00028140778886154294\n",
      "Epoch: 9224, Train Loss: 0.0001754125696606934, Valid Loss: 0.00028126745019108057\n",
      "Epoch: 9225, Train Loss: 0.00017531373305246234, Valid Loss: 0.00028111215215176344\n",
      "Epoch: 9226, Train Loss: 0.00017521451809443533, Valid Loss: 0.00028097181348130107\n",
      "Epoch: 9227, Train Loss: 0.00017511501209810376, Valid Loss: 0.0002808186109177768\n",
      "Epoch: 9228, Train Loss: 0.00017501559341326356, Valid Loss: 0.00028067955281585455\n",
      "Epoch: 9229, Train Loss: 0.00017491717881057411, Valid Loss: 0.000280526903225109\n",
      "Epoch: 9230, Train Loss: 0.00017481774557381868, Valid Loss: 0.00028038726304657757\n",
      "Epoch: 9231, Train Loss: 0.00017471984028816223, Valid Loss: 0.0002802334201987833\n",
      "Epoch: 9232, Train Loss: 0.00017462052346672863, Valid Loss: 0.0002800946240313351\n",
      "Epoch: 9233, Train Loss: 0.00017452090105507523, Valid Loss: 0.0002799371723085642\n",
      "Epoch: 9234, Train Loss: 0.00017442277749069035, Valid Loss: 0.0002797984052449465\n",
      "Epoch: 9235, Train Loss: 0.00017432335880585015, Valid Loss: 0.0002796463668346405\n",
      "Epoch: 9236, Train Loss: 0.00017422264500055462, Valid Loss: 0.00027951327501796186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9237, Train Loss: 0.0001741252199281007, Valid Loss: 0.00027935890830121934\n",
      "Epoch: 9238, Train Loss: 0.00017402601952198893, Valid Loss: 0.00027921676519326866\n",
      "Epoch: 9239, Train Loss: 0.0001739278668537736, Valid Loss: 0.000279064173810184\n",
      "Epoch: 9240, Train Loss: 0.00017382996156811714, Valid Loss: 0.00027892814250662923\n",
      "Epoch: 9241, Train Loss: 0.00017373115406371653, Valid Loss: 0.0002787775592878461\n",
      "Epoch: 9242, Train Loss: 0.0001736319245537743, Valid Loss: 0.00027863550349138677\n",
      "Epoch: 9243, Train Loss: 0.00017353410657960922, Valid Loss: 0.00027848134050145745\n",
      "Epoch: 9244, Train Loss: 0.00017343625950161368, Valid Loss: 0.00027834350476041436\n",
      "Epoch: 9245, Train Loss: 0.0001733370590955019, Valid Loss: 0.000278195075225085\n",
      "Epoch: 9246, Train Loss: 0.00017323963402304798, Valid Loss: 0.0002780562499538064\n",
      "Epoch: 9247, Train Loss: 0.00017314111755695194, Valid Loss: 0.0002779040078166872\n",
      "Epoch: 9248, Train Loss: 0.00017304268840234727, Valid Loss: 0.00027776273782365024\n",
      "Epoch: 9249, Train Loss: 0.00017294427379965782, Valid Loss: 0.000277615908998996\n",
      "Epoch: 9250, Train Loss: 0.00017284693603869528, Valid Loss: 0.0002774776075966656\n",
      "Epoch: 9251, Train Loss: 0.00017274852143600583, Valid Loss: 0.0002773257438093424\n",
      "Epoch: 9252, Train Loss: 0.00017265108181163669, Valid Loss: 0.0002771804283838719\n",
      "Epoch: 9253, Train Loss: 0.00017255236161872745, Valid Loss: 0.00027703618980012834\n",
      "Epoch: 9254, Train Loss: 0.00017245514027308673, Valid Loss: 0.00027689264970831573\n",
      "Epoch: 9255, Train Loss: 0.00017235682753380388, Valid Loss: 0.00027674814919009805\n",
      "Epoch: 9256, Train Loss: 0.0001722600864013657, Valid Loss: 0.00027660420164465904\n",
      "Epoch: 9257, Train Loss: 0.00017216235573869199, Valid Loss: 0.0002764636592473835\n",
      "Epoch: 9258, Train Loss: 0.0001720643340377137, Valid Loss: 0.00027631278499029577\n",
      "Epoch: 9259, Train Loss: 0.00017196781118400395, Valid Loss: 0.00027617262094281614\n",
      "Epoch: 9260, Train Loss: 0.00017186879995279014, Valid Loss: 0.00027602462796494365\n",
      "Epoch: 9261, Train Loss: 0.000171771869645454, Valid Loss: 0.00027588423108682036\n",
      "Epoch: 9262, Train Loss: 0.00017167613259516656, Valid Loss: 0.0002757380425464362\n",
      "Epoch: 9263, Train Loss: 0.00017157741240225732, Valid Loss: 0.00027559848967939615\n",
      "Epoch: 9264, Train Loss: 0.00017148246115539223, Valid Loss: 0.00027545145712792873\n",
      "Epoch: 9265, Train Loss: 0.00017138324619736522, Valid Loss: 0.0002753119624685496\n",
      "Epoch: 9266, Train Loss: 0.000171287203556858, Valid Loss: 0.00027516906266100705\n",
      "Epoch: 9267, Train Loss: 0.00017118958930950612, Valid Loss: 0.0002750238636508584\n",
      "Epoch: 9268, Train Loss: 0.000171092979144305, Valid Loss: 0.0002748764818534255\n",
      "Epoch: 9269, Train Loss: 0.00017099632532335818, Valid Loss: 0.00027473692898638546\n",
      "Epoch: 9270, Train Loss: 0.00017089970060624182, Valid Loss: 0.0002745887322816998\n",
      "Epoch: 9271, Train Loss: 0.00017080039833672345, Valid Loss: 0.0002744458324741572\n",
      "Epoch: 9272, Train Loss: 0.00017070544708985835, Valid Loss: 0.0002743072109296918\n",
      "Epoch: 9273, Train Loss: 0.00017060711979866028, Valid Loss: 0.00027415950899012387\n",
      "Epoch: 9274, Train Loss: 0.00017051139730028808, Valid Loss: 0.0002740158815868199\n",
      "Epoch: 9275, Train Loss: 0.0001704138412605971, Valid Loss: 0.0002738740877248347\n",
      "Epoch: 9276, Train Loss: 0.0001703187299426645, Valid Loss: 0.00027373197372071445\n",
      "Epoch: 9277, Train Loss: 0.000170223880559206, Valid Loss: 0.0002735844755079597\n",
      "Epoch: 9278, Train Loss: 0.0001701248693279922, Valid Loss: 0.0002734420995693654\n",
      "Epoch: 9279, Train Loss: 0.00017002872482407838, Valid Loss: 0.00027330179000273347\n",
      "Epoch: 9280, Train Loss: 0.00016993298777379096, Valid Loss: 0.0002731609274633229\n",
      "Epoch: 9281, Train Loss: 0.0001698376436252147, Valid Loss: 0.0002730157575570047\n",
      "Epoch: 9282, Train Loss: 0.00016974081518128514, Valid Loss: 0.00027287405100651085\n",
      "Epoch: 9283, Train Loss: 0.00016964410315267742, Valid Loss: 0.0002727324899751693\n",
      "Epoch: 9284, Train Loss: 0.00016954906459432095, Valid Loss: 0.0002725937811192125\n",
      "Epoch: 9285, Train Loss: 0.00016945232346188277, Valid Loss: 0.00027244800003245473\n",
      "Epoch: 9286, Train Loss: 0.00016935489838942885, Valid Loss: 0.00027230812702327967\n",
      "Epoch: 9287, Train Loss: 0.00016926084936130792, Valid Loss: 0.0002721632772590965\n",
      "Epoch: 9288, Train Loss: 0.000169163933605887, Valid Loss: 0.0002720268676057458\n",
      "Epoch: 9289, Train Loss: 0.0001690693898126483, Valid Loss: 0.00027188085368834436\n",
      "Epoch: 9290, Train Loss: 0.00016897215391509235, Valid Loss: 0.0002717430761549622\n",
      "Epoch: 9291, Train Loss: 0.00016887651872821152, Valid Loss: 0.00027159962337464094\n",
      "Epoch: 9292, Train Loss: 0.00016878008318599313, Valid Loss: 0.0002714604197535664\n",
      "Epoch: 9293, Train Loss: 0.0001686859322944656, Valid Loss: 0.00027131426031701267\n",
      "Epoch: 9294, Train Loss: 0.00016858951130416244, Valid Loss: 0.0002711834677029401\n",
      "Epoch: 9295, Train Loss: 0.00016849339590407908, Valid Loss: 0.0002710357366595417\n",
      "Epoch: 9296, Train Loss: 0.00016839914314914495, Valid Loss: 0.00027089263312518597\n",
      "Epoch: 9297, Train Loss: 0.0001683022128418088, Valid Loss: 0.00027074586250819266\n",
      "Epoch: 9298, Train Loss: 0.0001682055735727772, Valid Loss: 0.0002706127124838531\n",
      "Epoch: 9299, Train Loss: 0.00016811313980724663, Valid Loss: 0.0002704640501178801\n",
      "Epoch: 9300, Train Loss: 0.0001680164859862998, Valid Loss: 0.0002703299978747964\n",
      "Epoch: 9301, Train Loss: 0.0001679230626905337, Valid Loss: 0.0002701789198908955\n",
      "Epoch: 9302, Train Loss: 0.00016782731108833104, Valid Loss: 0.0002700452459976077\n",
      "Epoch: 9303, Train Loss: 0.00016773196693975478, Valid Loss: 0.0002699010365176946\n",
      "Epoch: 9304, Train Loss: 0.0001676366664469242, Valid Loss: 0.0002697628806345165\n",
      "Epoch: 9305, Train Loss: 0.00016754110401961952, Valid Loss: 0.0002696129959076643\n",
      "Epoch: 9306, Train Loss: 0.00016744606546126306, Valid Loss: 0.0002694807481020689\n",
      "Epoch: 9307, Train Loss: 0.00016735172539483756, Valid Loss: 0.0002693281858228147\n",
      "Epoch: 9308, Train Loss: 0.00016725716704968363, Valid Loss: 0.00026920108939521015\n",
      "Epoch: 9309, Train Loss: 0.00016716185200493783, Valid Loss: 0.0002690532710403204\n",
      "Epoch: 9310, Train Loss: 0.0001670672936597839, Valid Loss: 0.0002689193934202194\n",
      "Epoch: 9311, Train Loss: 0.0001669731573201716, Valid Loss: 0.00026877052732743323\n",
      "Epoch: 9312, Train Loss: 0.0001668788172537461, Valid Loss: 0.0002686409279704094\n",
      "Epoch: 9313, Train Loss: 0.0001667845790507272, Valid Loss: 0.0002684875507839024\n",
      "Epoch: 9314, Train Loss: 0.00016668954049237072, Valid Loss: 0.0002683600760065019\n",
      "Epoch: 9315, Train Loss: 0.00016659438551869243, Valid Loss: 0.00026820486527867615\n",
      "Epoch: 9316, Train Loss: 0.00016650142788421363, Valid Loss: 0.0002680837351363152\n",
      "Epoch: 9317, Train Loss: 0.00016640809189993888, Valid Loss: 0.0002679290482774377\n",
      "Epoch: 9318, Train Loss: 0.0001663133589318022, Valid Loss: 0.0002678031742107123\n",
      "Epoch: 9319, Train Loss: 0.00016621820395812392, Valid Loss: 0.00026764842914417386\n",
      "Epoch: 9320, Train Loss: 0.00016612614854238927, Valid Loss: 0.00026752715348266065\n",
      "Epoch: 9321, Train Loss: 0.00016603103722445667, Valid Loss: 0.00026737176813185215\n",
      "Epoch: 9322, Train Loss: 0.00016593628970440477, Valid Loss: 0.00026724906638264656\n",
      "Epoch: 9323, Train Loss: 0.00016584312834311277, Valid Loss: 0.00026709167286753654\n",
      "Epoch: 9324, Train Loss: 0.00016574929759372026, Valid Loss: 0.00026697153225541115\n",
      "Epoch: 9325, Train Loss: 0.000165653953445144, Valid Loss: 0.00026680962764658034\n",
      "Epoch: 9326, Train Loss: 0.00016556261107325554, Valid Loss: 0.0002666967047844082\n",
      "Epoch: 9327, Train Loss: 0.00016546716506127268, Valid Loss: 0.0002665292704477906\n",
      "Epoch: 9328, Train Loss: 0.0001653751969570294, Valid Loss: 0.0002664182975422591\n",
      "Epoch: 9329, Train Loss: 0.00016528015839867294, Valid Loss: 0.0002662498445715755\n",
      "Epoch: 9330, Train Loss: 0.00016518721531610936, Valid Loss: 0.00026613895897753537\n",
      "Epoch: 9331, Train Loss: 0.00016509286069776863, Valid Loss: 0.0002659698366187513\n",
      "Epoch: 9332, Train Loss: 0.00016499971388839185, Valid Loss: 0.0002658620069269091\n",
      "Epoch: 9333, Train Loss: 0.00016490578127559274, Valid Loss: 0.0002656897995620966\n",
      "Epoch: 9334, Train Loss: 0.00016481333295814693, Valid Loss: 0.00026558691752143204\n",
      "Epoch: 9335, Train Loss: 0.0001647199533181265, Valid Loss: 0.0002654121199157089\n",
      "Epoch: 9336, Train Loss: 0.000164625613251701, Valid Loss: 0.0002653094124980271\n",
      "Epoch: 9337, Train Loss: 0.00016453268472105265, Valid Loss: 0.0002651303366292268\n",
      "Epoch: 9338, Train Loss: 0.0001644387375563383, Valid Loss: 0.00026503310073167086\n",
      "Epoch: 9339, Train Loss: 0.00016434748249594122, Valid Loss: 0.000264852395048365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9340, Train Loss: 0.0001642532297410071, Valid Loss: 0.0002647562068887055\n",
      "Epoch: 9341, Train Loss: 0.0001641605922486633, Valid Loss: 0.00026457480271346867\n",
      "Epoch: 9342, Train Loss: 0.00016406764916609973, Valid Loss: 0.0002644828346092254\n",
      "Epoch: 9343, Train Loss: 0.00016397547733504325, Valid Loss: 0.00026430017896927893\n",
      "Epoch: 9344, Train Loss: 0.0001638819376239553, Valid Loss: 0.00026420559152029455\n",
      "Epoch: 9345, Train Loss: 0.00016378988220822066, Valid Loss: 0.00026402383809909225\n",
      "Epoch: 9346, Train Loss: 0.00016369693912565708, Valid Loss: 0.00026393256848677993\n",
      "Epoch: 9347, Train Loss: 0.00016360457811970264, Valid Loss: 0.00026374743902124465\n",
      "Epoch: 9348, Train Loss: 0.0001635112421354279, Valid Loss: 0.0002636555873323232\n",
      "Epoch: 9349, Train Loss: 0.00016341828450094908, Valid Loss: 0.00026347258244641125\n",
      "Epoch: 9350, Train Loss: 0.00016332721861544997, Valid Loss: 0.0002633795083966106\n",
      "Epoch: 9351, Train Loss: 0.00016323209274560213, Valid Loss: 0.0002631962124723941\n",
      "Epoch: 9352, Train Loss: 0.00016314053209498525, Valid Loss: 0.00026310764951631427\n",
      "Epoch: 9353, Train Loss: 0.0001630496553843841, Valid Loss: 0.0002629199007060379\n",
      "Epoch: 9354, Train Loss: 0.0001629571197554469, Valid Loss: 0.00026282889302819967\n",
      "Epoch: 9355, Train Loss: 0.0001628642639843747, Valid Loss: 0.0002626459754537791\n",
      "Epoch: 9356, Train Loss: 0.00016277200484182686, Valid Loss: 0.0002625545603223145\n",
      "Epoch: 9357, Train Loss: 0.00016267996397800744, Valid Loss: 0.0002623723412398249\n",
      "Epoch: 9358, Train Loss: 0.00016258670075330883, Valid Loss: 0.00026228142087347806\n",
      "Epoch: 9359, Train Loss: 0.00016249694454018027, Valid Loss: 0.00026210054056718946\n",
      "Epoch: 9360, Train Loss: 0.00016240250261034817, Valid Loss: 0.00026200409047305584\n",
      "Epoch: 9361, Train Loss: 0.00016231132030952722, Valid Loss: 0.00026183112640865147\n",
      "Epoch: 9362, Train Loss: 0.00016221868281718343, Valid Loss: 0.00026172882644459605\n",
      "Epoch: 9363, Train Loss: 0.00016212882474064827, Valid Loss: 0.00026155580417253077\n",
      "Epoch: 9364, Train Loss: 0.00016203508130274713, Valid Loss: 0.00026145149604417384\n",
      "Epoch: 9365, Train Loss: 0.0001619444228708744, Valid Loss: 0.0002612864482216537\n",
      "Epoch: 9366, Train Loss: 0.00016185366257559508, Valid Loss: 0.00026117198285646737\n",
      "Epoch: 9367, Train Loss: 0.0001617615926079452, Valid Loss: 0.00026101653929799795\n",
      "Epoch: 9368, Train Loss: 0.00016167025023605675, Valid Loss: 0.0002609006769489497\n",
      "Epoch: 9369, Train Loss: 0.0001615777873666957, Valid Loss: 0.000260747445281595\n",
      "Epoch: 9370, Train Loss: 0.00016148613940458745, Valid Loss: 0.0002606236084830016\n",
      "Epoch: 9371, Train Loss: 0.00016139328363351524, Valid Loss: 0.000260473316302523\n",
      "Epoch: 9372, Train Loss: 0.00016130450239870697, Valid Loss: 0.0002603501488920301\n",
      "Epoch: 9373, Train Loss: 0.00016121265070978552, Valid Loss: 0.00026020934456028044\n",
      "Epoch: 9374, Train Loss: 0.00016112228331621736, Valid Loss: 0.0002600785228423774\n",
      "Epoch: 9375, Train Loss: 0.00016103082452900708, Valid Loss: 0.0002599381550680846\n",
      "Epoch: 9376, Train Loss: 0.00016093907470349222, Valid Loss: 0.0002598026767373085\n",
      "Epoch: 9377, Train Loss: 0.00016084722301457077, Valid Loss: 0.0002596694102976471\n",
      "Epoch: 9378, Train Loss: 0.00016075685562100261, Valid Loss: 0.0002595295663923025\n",
      "Epoch: 9379, Train Loss: 0.00016066500393208116, Valid Loss: 0.00025940092746168375\n",
      "Epoch: 9380, Train Loss: 0.00016057502944022417, Valid Loss: 0.0002592573582660407\n",
      "Epoch: 9381, Train Loss: 0.00016048428369686007, Valid Loss: 0.00025913093122653663\n",
      "Epoch: 9382, Train Loss: 0.0001603930868441239, Valid Loss: 0.00025898695457726717\n",
      "Epoch: 9383, Train Loss: 0.00016030124970711768, Valid Loss: 0.0002588657080195844\n",
      "Epoch: 9384, Train Loss: 0.00016021168266888708, Valid Loss: 0.00025871387333609164\n",
      "Epoch: 9385, Train Loss: 0.00016012131527531892, Valid Loss: 0.000258587853750214\n",
      "Epoch: 9386, Train Loss: 0.0001600301475264132, Valid Loss: 0.0002584453031886369\n",
      "Epoch: 9387, Train Loss: 0.00015993839770089835, Valid Loss: 0.00025832411483861506\n",
      "Epoch: 9388, Train Loss: 0.00015984923811629415, Valid Loss: 0.00025817289133556187\n",
      "Epoch: 9389, Train Loss: 0.0001597602677065879, Valid Loss: 0.0002580483560450375\n",
      "Epoch: 9390, Train Loss: 0.00015966841601766646, Valid Loss: 0.00025790042127482593\n",
      "Epoch: 9391, Train Loss: 0.00015957665164023638, Valid Loss: 0.0002577810373622924\n",
      "Epoch: 9392, Train Loss: 0.00015948788495734334, Valid Loss: 0.0002576348779257387\n",
      "Epoch: 9393, Train Loss: 0.00015939692093525082, Valid Loss: 0.00025751275825314224\n",
      "Epoch: 9394, Train Loss: 0.00015930607332848012, Valid Loss: 0.0002573642414063215\n",
      "Epoch: 9395, Train Loss: 0.00015921768499538302, Valid Loss: 0.0002572424418758601\n",
      "Epoch: 9396, Train Loss: 0.0001591282052686438, Valid Loss: 0.0002570992801338434\n",
      "Epoch: 9397, Train Loss: 0.0001590356696397066, Valid Loss: 0.0002569756761658937\n",
      "Epoch: 9398, Train Loss: 0.00015894610260147601, Valid Loss: 0.00025682899286039174\n",
      "Epoch: 9399, Train Loss: 0.00015885831089690328, Valid Loss: 0.0002567067858763039\n",
      "Epoch: 9400, Train Loss: 0.00015876805991865695, Valid Loss: 0.0002565595495980233\n",
      "Epoch: 9401, Train Loss: 0.00015867709589656442, Valid Loss: 0.0002564367314334959\n",
      "Epoch: 9402, Train Loss: 0.00015858834376558661, Valid Loss: 0.0002562942972872406\n",
      "Epoch: 9403, Train Loss: 0.00015849726332817227, Valid Loss: 0.00025616397033445537\n",
      "Epoch: 9404, Train Loss: 0.00015840861306060106, Valid Loss: 0.0002560257853474468\n",
      "Epoch: 9405, Train Loss: 0.00015831833297852427, Valid Loss: 0.000255900522461161\n",
      "Epoch: 9406, Train Loss: 0.00015822917339392006, Valid Loss: 0.0002557578554842621\n",
      "Epoch: 9407, Train Loss: 0.00015813989739399403, Valid Loss: 0.00025563189410604537\n",
      "Epoch: 9408, Train Loss: 0.00015804963186383247, Valid Loss: 0.0002554886741563678\n",
      "Epoch: 9409, Train Loss: 0.000157961665536277, Valid Loss: 0.00025536640896461904\n",
      "Epoch: 9410, Train Loss: 0.00015787099255248904, Valid Loss: 0.0002552252262830734\n",
      "Epoch: 9411, Train Loss: 0.00015778122178744525, Valid Loss: 0.00025509309489279985\n",
      "Epoch: 9412, Train Loss: 0.00015769305173307657, Valid Loss: 0.0002549536875449121\n",
      "Epoch: 9413, Train Loss: 0.00015760399401187897, Valid Loss: 0.00025483471108600497\n",
      "Epoch: 9414, Train Loss: 0.0001575131027493626, Valid Loss: 0.00025469085085205734\n",
      "Epoch: 9415, Train Loss: 0.00015742632967885584, Valid Loss: 0.0002545644238125533\n",
      "Epoch: 9416, Train Loss: 0.00015733575855847448, Valid Loss: 0.00025442379410378635\n",
      "Epoch: 9417, Train Loss: 0.0001572467153891921, Valid Loss: 0.00025429611559957266\n",
      "Epoch: 9418, Train Loss: 0.0001571571483509615, Valid Loss: 0.00025415862910449505\n",
      "Epoch: 9419, Train Loss: 0.000157069371198304, Valid Loss: 0.00025403295876458287\n",
      "Epoch: 9420, Train Loss: 0.00015698018250986934, Valid Loss: 0.0002538970438763499\n",
      "Epoch: 9421, Train Loss: 0.00015689201245550066, Valid Loss: 0.000253766484092921\n",
      "Epoch: 9422, Train Loss: 0.00015680314390920103, Valid Loss: 0.00025363420718349516\n",
      "Epoch: 9423, Train Loss: 0.00015671644359827042, Valid Loss: 0.0002535030653234571\n",
      "Epoch: 9424, Train Loss: 0.00015662680380046368, Valid Loss: 0.0002533677907194942\n",
      "Epoch: 9425, Train Loss: 0.00015653682930860668, Valid Loss: 0.00025324110174551606\n",
      "Epoch: 9426, Train Loss: 0.000156448659254238, Valid Loss: 0.00025310611817985773\n",
      "Epoch: 9427, Train Loss: 0.00015636028547305614, Valid Loss: 0.0002529749763198197\n",
      "Epoch: 9428, Train Loss: 0.00015627140237484127, Valid Loss: 0.0002528394397813827\n",
      "Epoch: 9429, Train Loss: 0.00015618432371411473, Valid Loss: 0.0002527121396269649\n",
      "Epoch: 9430, Train Loss: 0.00015609564434271306, Valid Loss: 0.00025257389643229544\n",
      "Epoch: 9431, Train Loss: 0.00015600727056153119, Valid Loss: 0.0002524474693927914\n",
      "Epoch: 9432, Train Loss: 0.00015591841656714678, Valid Loss: 0.00025231653125956655\n",
      "Epoch: 9433, Train Loss: 0.00015582992637064308, Valid Loss: 0.00025218285736627877\n",
      "Epoch: 9434, Train Loss: 0.0001557425712235272, Valid Loss: 0.00025205337442457676\n",
      "Epoch: 9435, Train Loss: 0.00015565477951895446, Valid Loss: 0.0002519187983125448\n",
      "Epoch: 9436, Train Loss: 0.00015556621656287462, Valid Loss: 0.0002517900138627738\n",
      "Epoch: 9437, Train Loss: 0.0001554798218421638, Valid Loss: 0.0002516600943636149\n",
      "Epoch: 9438, Train Loss: 0.0001553903566673398, Valid Loss: 0.00025152924354188144\n",
      "Epoch: 9439, Train Loss: 0.00015530198288615793, Valid Loss: 0.00025138893397524953\n",
      "Epoch: 9440, Train Loss: 0.00015521171735599637, Valid Loss: 0.0002512646606191993\n",
      "Epoch: 9441, Train Loss: 0.00015512722893618047, Valid Loss: 0.0002511317143216729\n",
      "Epoch: 9442, Train Loss: 0.00015503884060308337, Valid Loss: 0.00025100004859268665\n",
      "Epoch: 9443, Train Loss: 0.0001549507724121213, Valid Loss: 0.0002508686447981745\n",
      "Epoch: 9444, Train Loss: 0.00015486369375139475, Valid Loss: 0.0002507401804905385\n",
      "Epoch: 9445, Train Loss: 0.00015477552369702607, Valid Loss: 0.0002506021992303431\n",
      "Epoch: 9446, Train Loss: 0.00015468911442440003, Valid Loss: 0.00025047463714145124\n",
      "Epoch: 9447, Train Loss: 0.00015460165741387755, Valid Loss: 0.0002503405848983675\n",
      "Epoch: 9448, Train Loss: 0.0001545136619824916, Valid Loss: 0.0002502126735635102\n",
      "Epoch: 9449, Train Loss: 0.00015442637959495187, Valid Loss: 0.00025008164811879396\n",
      "Epoch: 9450, Train Loss: 0.00015433873340953141, Valid Loss: 0.00024995103012770414\n",
      "Epoch: 9451, Train Loss: 0.00015425034507643431, Valid Loss: 0.00024981616297736764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9452, Train Loss: 0.00015416355745401233, Valid Loss: 0.00024968874640762806\n",
      "Epoch: 9453, Train Loss: 0.00015407736646011472, Valid Loss: 0.00024955603294074535\n",
      "Epoch: 9454, Train Loss: 0.0001539905060781166, Valid Loss: 0.0002494250365998596\n",
      "Epoch: 9455, Train Loss: 0.00015390320913866162, Valid Loss: 0.00024929887149482965\n",
      "Epoch: 9456, Train Loss: 0.00015381643606815487, Valid Loss: 0.0002491670020390302\n",
      "Epoch: 9457, Train Loss: 0.0001537281641503796, Valid Loss: 0.00024903571465983987\n",
      "Epoch: 9458, Train Loss: 0.00015364267164841294, Valid Loss: 0.00024890602799132466\n",
      "Epoch: 9459, Train Loss: 0.0001535553892608732, Valid Loss: 0.0002487758465576917\n",
      "Epoch: 9460, Train Loss: 0.00015346820873674005, Valid Loss: 0.00024864712031558156\n",
      "Epoch: 9461, Train Loss: 0.00015338041703216732, Valid Loss: 0.00024851481430232525\n",
      "Epoch: 9462, Train Loss: 0.00015329531743191183, Valid Loss: 0.0002483848948031664\n",
      "Epoch: 9463, Train Loss: 0.00015320786042138934, Valid Loss: 0.0002482477866578847\n",
      "Epoch: 9464, Train Loss: 0.00015312126197386533, Valid Loss: 0.00024813011987134814\n",
      "Epoch: 9465, Train Loss: 0.00015303479449357837, Valid Loss: 0.00024799088714644313\n",
      "Epoch: 9466, Train Loss: 0.00015294920012820512, Valid Loss: 0.00024786381982266903\n",
      "Epoch: 9467, Train Loss: 0.0001528617285657674, Valid Loss: 0.0002477311063557863\n",
      "Epoch: 9468, Train Loss: 0.0001527756394352764, Valid Loss: 0.0002476120425853878\n",
      "Epoch: 9469, Train Loss: 0.00015268835704773664, Valid Loss: 0.0002474757784511894\n",
      "Epoch: 9470, Train Loss: 0.0001526029664091766, Valid Loss: 0.00024735197075642645\n",
      "Epoch: 9471, Train Loss: 0.00015251718286890537, Valid Loss: 0.0002472132910043001\n",
      "Epoch: 9472, Train Loss: 0.00015243068628478795, Valid Loss: 0.0002470926847308874\n",
      "Epoch: 9473, Train Loss: 0.00015234440797939897, Valid Loss: 0.0002469591563567519\n",
      "Epoch: 9474, Train Loss: 0.00015225782408379018, Valid Loss: 0.00024683683295734227\n",
      "Epoch: 9475, Train Loss: 0.00015217332111205906, Valid Loss: 0.0002467005397193134\n",
      "Epoch: 9476, Train Loss: 0.00015208704280667007, Valid Loss: 0.0002465806028340012\n",
      "Epoch: 9477, Train Loss: 0.00015199898916762322, Valid Loss: 0.00024644675431773067\n",
      "Epoch: 9478, Train Loss: 0.00015191329293884337, Valid Loss: 0.0002463228884153068\n",
      "Epoch: 9479, Train Loss: 0.00015182769857347012, Valid Loss: 0.0002461874973960221\n",
      "Epoch: 9480, Train Loss: 0.00015174200234469026, Valid Loss: 0.00024606124497950077\n",
      "Epoch: 9481, Train Loss: 0.00015165642253123224, Valid Loss: 0.00024593135458417237\n",
      "Epoch: 9482, Train Loss: 0.0001515701151220128, Valid Loss: 0.0002458086237311363\n",
      "Epoch: 9483, Train Loss: 0.00015148601960390806, Valid Loss: 0.00024567663786001503\n",
      "Epoch: 9484, Train Loss: 0.00015139926108531654, Valid Loss: 0.000245550530962646\n",
      "Epoch: 9485, Train Loss: 0.00015131464169826359, Valid Loss: 0.0002454207860864699\n",
      "Epoch: 9486, Train Loss: 0.00015123035700526088, Valid Loss: 0.00024528978974558413\n",
      "Epoch: 9487, Train Loss: 0.0001511439768364653, Valid Loss: 0.00024516484700143337\n",
      "Epoch: 9488, Train Loss: 0.00015105848433449864, Valid Loss: 0.00024503591703251004\n",
      "Epoch: 9489, Train Loss: 0.00015097219147719443, Valid Loss: 0.0002449069288559258\n",
      "Epoch: 9490, Train Loss: 0.0001508866116637364, Valid Loss: 0.00024477788247168064\n",
      "Epoch: 9491, Train Loss: 0.00015080231241881847, Valid Loss: 0.00024465814931318164\n",
      "Epoch: 9492, Train Loss: 0.00015071663074195385, Valid Loss: 0.0002445228456053883\n",
      "Epoch: 9493, Train Loss: 0.00015063173486851156, Valid Loss: 0.0002443996199872345\n",
      "Epoch: 9494, Train Loss: 0.00015054774121381342, Valid Loss: 0.0002442674885969609\n",
      "Epoch: 9495, Train Loss: 0.0001504615502199158, Valid Loss: 0.00024414461222477257\n",
      "Epoch: 9496, Train Loss: 0.00015037607226986438, Valid Loss: 0.00024400978873018175\n",
      "Epoch: 9497, Train Loss: 0.00015029167116153985, Valid Loss: 0.00024389017198700458\n",
      "Epoch: 9498, Train Loss: 0.0001502049999544397, Valid Loss: 0.0002437535731587559\n",
      "Epoch: 9499, Train Loss: 0.0001501209771959111, Valid Loss: 0.0002436300419503823\n",
      "Epoch: 9500, Train Loss: 0.00015003758016973734, Valid Loss: 0.00024350726744160056\n",
      "Epoch: 9501, Train Loss: 0.00014995288802310824, Valid Loss: 0.0002433827903587371\n",
      "Epoch: 9502, Train Loss: 0.00014986711903475225, Valid Loss: 0.0002432471956126392\n",
      "Epoch: 9503, Train Loss: 0.00014978292165324092, Valid Loss: 0.00024312507594004273\n",
      "Epoch: 9504, Train Loss: 0.00014969870971981436, Valid Loss: 0.0002429909654892981\n",
      "Epoch: 9505, Train Loss: 0.00014961422129999846, Valid Loss: 0.0002428721491014585\n",
      "Epoch: 9506, Train Loss: 0.00014952971832826734, Valid Loss: 0.0002427419531159103\n",
      "Epoch: 9507, Train Loss: 0.00014944412396289408, Valid Loss: 0.0002426159626338631\n",
      "Epoch: 9508, Train Loss: 0.00014935982471797615, Valid Loss: 0.00024248365662060678\n",
      "Epoch: 9509, Train Loss: 0.00014927516167517751, Valid Loss: 0.00024236452009063214\n",
      "Epoch: 9510, Train Loss: 0.00014919253590051085, Valid Loss: 0.00024223222862929106\n",
      "Epoch: 9511, Train Loss: 0.00014910656318534166, Valid Loss: 0.0002421089302515611\n",
      "Epoch: 9512, Train Loss: 0.00014902187103871256, Valid Loss: 0.00024198323080781847\n",
      "Epoch: 9513, Train Loss: 0.00014893985644448549, Valid Loss: 0.0002418581279926002\n",
      "Epoch: 9514, Train Loss: 0.00014885426207911223, Valid Loss: 0.00024172430858016014\n",
      "Epoch: 9515, Train Loss: 0.00014877086505293846, Valid Loss: 0.00024160221801139414\n",
      "Epoch: 9516, Train Loss: 0.00014868687139824033, Valid Loss: 0.00024147411750163883\n",
      "Epoch: 9517, Train Loss: 0.0001486027758801356, Valid Loss: 0.00024135228886734694\n",
      "Epoch: 9518, Train Loss: 0.00014851847663521767, Valid Loss: 0.00024122210743371397\n",
      "Epoch: 9519, Train Loss: 0.00014843407552689314, Valid Loss: 0.00024109968217089772\n",
      "Epoch: 9520, Train Loss: 0.0001483514643041417, Valid Loss: 0.00024097520508803427\n",
      "Epoch: 9521, Train Loss: 0.00014826648111920804, Valid Loss: 0.0002408510190434754\n",
      "Epoch: 9522, Train Loss: 0.0001481822837376967, Valid Loss: 0.00024071597727015615\n",
      "Epoch: 9523, Train Loss: 0.0001480991777498275, Valid Loss: 0.00024059299903456122\n",
      "Epoch: 9524, Train Loss: 0.00014801559154875576, Valid Loss: 0.00024046188627835363\n",
      "Epoch: 9525, Train Loss: 0.0001479318889323622, Valid Loss: 0.00024034483067225665\n",
      "Epoch: 9526, Train Loss: 0.00014784649829380214, Valid Loss: 0.0002402128593530506\n",
      "Epoch: 9527, Train Loss: 0.0001477644982514903, Valid Loss: 0.00024008925538510084\n",
      "Epoch: 9528, Train Loss: 0.00014768049004487693, Valid Loss: 0.00023995786614250392\n",
      "Epoch: 9529, Train Loss: 0.00014759827172383666, Valid Loss: 0.00023983871506061405\n",
      "Epoch: 9530, Train Loss: 0.00014751488924957812, Valid Loss: 0.00023970913025550544\n",
      "Epoch: 9531, Train Loss: 0.00014743118663318455, Valid Loss: 0.00023958488600328565\n",
      "Epoch: 9532, Train Loss: 0.00014734729484189302, Valid Loss: 0.00023945895372889936\n",
      "Epoch: 9533, Train Loss: 0.00014726330118719488, Valid Loss: 0.00023933977354317904\n",
      "Epoch: 9534, Train Loss: 0.00014718028251081705, Valid Loss: 0.00023920754028949887\n",
      "Epoch: 9535, Train Loss: 0.00014709748211316764, Valid Loss: 0.00023908598814159632\n",
      "Epoch: 9536, Train Loss: 0.0001470154820708558, Valid Loss: 0.0002389606088399887\n",
      "Epoch: 9537, Train Loss: 0.00014693167759105563, Valid Loss: 0.00023883605899754912\n",
      "Epoch: 9538, Train Loss: 0.00014684817870147526, Valid Loss: 0.00023870983568485826\n",
      "Epoch: 9539, Train Loss: 0.00014676587306894362, Valid Loss: 0.00023858854547142982\n",
      "Epoch: 9540, Train Loss: 0.0001466827525291592, Valid Loss: 0.00023845784016884863\n",
      "Epoch: 9541, Train Loss: 0.00014659947191830724, Valid Loss: 0.00023833534214645624\n",
      "Epoch: 9542, Train Loss: 0.00014651735546067357, Valid Loss: 0.00023821396462153643\n",
      "Epoch: 9543, Train Loss: 0.00014643515169154853, Valid Loss: 0.0002380890364293009\n",
      "Epoch: 9544, Train Loss: 0.000146350750583224, Valid Loss: 0.00023796320601832122\n",
      "Epoch: 9545, Train Loss: 0.00014626933261752129, Valid Loss: 0.00023783730284776539\n",
      "Epoch: 9546, Train Loss: 0.0001461864449083805, Valid Loss: 0.00023771422274876386\n",
      "Epoch: 9547, Train Loss: 0.00014610463404096663, Valid Loss: 0.00023758439056109637\n",
      "Epoch: 9548, Train Loss: 0.00014602101873606443, Valid Loss: 0.00023746881925035268\n",
      "Epoch: 9549, Train Loss: 0.00014593930973205715, Valid Loss: 0.00023733892885502428\n",
      "Epoch: 9550, Train Loss: 0.0001458570040995255, Valid Loss: 0.00023721625620964915\n",
      "Epoch: 9551, Train Loss: 0.00014577539695892483, Valid Loss: 0.00023709269589744508\n",
      "Epoch: 9552, Train Loss: 0.00014569319318979979, Valid Loss: 0.00023697085271123797\n",
      "Epoch: 9553, Train Loss: 0.0001456110767321661, Valid Loss: 0.00023684609914198518\n",
      "Epoch: 9554, Train Loss: 0.000145527403219603, Valid Loss: 0.00023672815586905926\n",
      "Epoch: 9555, Train Loss: 0.00014544438454322517, Valid Loss: 0.00023659472935833037\n",
      "Epoch: 9556, Train Loss: 0.00014536347589455545, Valid Loss: 0.00023647616035304964\n",
      "Epoch: 9557, Train Loss: 0.00014528188330587, Valid Loss: 0.000236352309002541\n",
      "Epoch: 9558, Train Loss: 0.00014519966498482972, Valid Loss: 0.00023623078595846891\n",
      "Epoch: 9559, Train Loss: 0.00014511725748889148, Valid Loss: 0.0002361068909522146\n",
      "Epoch: 9560, Train Loss: 0.00014503573765978217, Valid Loss: 0.00023598507686983794\n",
      "Epoch: 9561, Train Loss: 0.000144952951814048, Valid Loss: 0.0002358566998736933\n",
      "Epoch: 9562, Train Loss: 0.00014487162115983665, Valid Loss: 0.0002357406192459166\n",
      "Epoch: 9563, Train Loss: 0.00014478981029242277, Valid Loss: 0.00023561489069834352\n",
      "Epoch: 9564, Train Loss: 0.00014470632595475763, Valid Loss: 0.00023549070465378463\n",
      "Epoch: 9565, Train Loss: 0.00014462579565588385, Valid Loss: 0.00023536680964753032\n",
      "Epoch: 9566, Train Loss: 0.00014454418851528317, Valid Loss: 0.00023524834250565618\n",
      "Epoch: 9567, Train Loss: 0.00014446437126025558, Valid Loss: 0.00023512140614911914\n",
      "Epoch: 9568, Train Loss: 0.0001443815417587757, Valid Loss: 0.00023500261886510998\n",
      "Epoch: 9569, Train Loss: 0.00014430025476031005, Valid Loss: 0.00023487329599447548\n",
      "Epoch: 9570, Train Loss: 0.00014421873493120074, Valid Loss: 0.0002347530098631978\n",
      "Epoch: 9571, Train Loss: 0.00014413733151741326, Valid Loss: 0.00023462851822841913\n",
      "Epoch: 9572, Train Loss: 0.00014405422552954406, Valid Loss: 0.00023451153538189828\n",
      "Epoch: 9573, Train Loss: 0.0001439736079191789, Valid Loss: 0.00023438222706317902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9574, Train Loss: 0.00014389310672413558, Valid Loss: 0.00023426493862643838\n",
      "Epoch: 9575, Train Loss: 0.0001438123726984486, Valid Loss: 0.00023413621238432825\n",
      "Epoch: 9576, Train Loss: 0.00014373067824635655, Valid Loss: 0.00023401863290928304\n",
      "Epoch: 9577, Train Loss: 0.00014364966773428023, Valid Loss: 0.00023389473790302873\n",
      "Epoch: 9578, Train Loss: 0.00014356676547322422, Valid Loss: 0.00023377408797387034\n",
      "Epoch: 9579, Train Loss: 0.00014348783588502556, Valid Loss: 0.00023364454682450742\n",
      "Epoch: 9580, Train Loss: 0.0001434051082469523, Valid Loss: 0.00023352386779151857\n",
      "Epoch: 9581, Train Loss: 0.00014332501450553536, Valid Loss: 0.0002334003511350602\n",
      "Epoch: 9582, Train Loss: 0.00014324398944154382, Valid Loss: 0.0002332790318178013\n",
      "Epoch: 9583, Train Loss: 0.00014316347369458526, Valid Loss: 0.0002331513969693333\n",
      "Epoch: 9584, Train Loss: 0.0001430837728548795, Valid Loss: 0.00023303244961425662\n",
      "Epoch: 9585, Train Loss: 0.00014300165639724582, Valid Loss: 0.0002329107519472018\n",
      "Epoch: 9586, Train Loss: 0.00014292134437710047, Valid Loss: 0.00023278914159163833\n",
      "Epoch: 9587, Train Loss: 0.00014284001372288913, Valid Loss: 0.00023266690550372005\n",
      "Epoch: 9588, Train Loss: 0.00014275842113420367, Valid Loss: 0.00023254497500602156\n",
      "Epoch: 9589, Train Loss: 0.0001426777889719233, Valid Loss: 0.000232419726671651\n",
      "Epoch: 9590, Train Loss: 0.00014259769523050636, Valid Loss: 0.00023230130318552256\n",
      "Epoch: 9591, Train Loss: 0.00014251776156015694, Valid Loss: 0.00023218242859002203\n",
      "Epoch: 9592, Train Loss: 0.00014243544137571007, Valid Loss: 0.00023205656907521188\n",
      "Epoch: 9593, Train Loss: 0.000142357122967951, Valid Loss: 0.0002319409541087225\n",
      "Epoch: 9594, Train Loss: 0.00014227729116100818, Valid Loss: 0.00023181535652838647\n",
      "Epoch: 9595, Train Loss: 0.00014219539298210293, Valid Loss: 0.0002316950267413631\n",
      "Epoch: 9596, Train Loss: 0.00014211528468877077, Valid Loss: 0.00023157476971391588\n",
      "Epoch: 9597, Train Loss: 0.0001420362532371655, Valid Loss: 0.0002314583252882585\n",
      "Epoch: 9598, Train Loss: 0.000141955038998276, Valid Loss: 0.00023133539070840925\n",
      "Epoch: 9599, Train Loss: 0.0001418736355844885, Valid Loss: 0.00023121626873034984\n",
      "Epoch: 9600, Train Loss: 0.00014179669960867614, Valid Loss: 0.00023109147150535136\n",
      "Epoch: 9601, Train Loss: 0.00014171488874126226, Valid Loss: 0.00023097265511751175\n",
      "Epoch: 9602, Train Loss: 0.00014163507148623466, Valid Loss: 0.00023085119028110057\n",
      "Epoch: 9603, Train Loss: 0.0001415559381712228, Valid Loss: 0.000230733014177531\n",
      "Epoch: 9604, Train Loss: 0.00014147661568131298, Valid Loss: 0.00023060791136231273\n",
      "Epoch: 9605, Train Loss: 0.0001413952122675255, Valid Loss: 0.00023049209266901016\n",
      "Epoch: 9606, Train Loss: 0.00014131538046058267, Valid Loss: 0.00023036435595713556\n",
      "Epoch: 9607, Train Loss: 0.00014123636356089264, Valid Loss: 0.00023025093832984567\n",
      "Epoch: 9608, Train Loss: 0.00014115673548076302, Valid Loss: 0.00023012880410533398\n",
      "Epoch: 9609, Train Loss: 0.00014107782044447958, Valid Loss: 0.0002300118503626436\n",
      "Epoch: 9610, Train Loss: 0.00014099669351708144, Valid Loss: 0.00022988402633927763\n",
      "Epoch: 9611, Train Loss: 0.00014091796765569597, Valid Loss: 0.00022977154003456235\n",
      "Epoch: 9612, Train Loss: 0.00014083756832405925, Valid Loss: 0.00022964585514273494\n",
      "Epoch: 9613, Train Loss: 0.000140758536872454, Valid Loss: 0.00022952882864046842\n",
      "Epoch: 9614, Train Loss: 0.00014067921438254416, Valid Loss: 0.0002294070873176679\n",
      "Epoch: 9615, Train Loss: 0.00014059939712751657, Valid Loss: 0.00022928760154172778\n",
      "Epoch: 9616, Train Loss: 0.00014052135520614684, Valid Loss: 0.00022916620946489275\n",
      "Epoch: 9617, Train Loss: 0.0001404421345796436, Valid Loss: 0.00022904672368895262\n",
      "Epoch: 9618, Train Loss: 0.0001403611240675673, Valid Loss: 0.00022892838751431555\n",
      "Epoch: 9619, Train Loss: 0.00014028210716787726, Valid Loss: 0.00022880578762851655\n",
      "Epoch: 9620, Train Loss: 0.00014020365779288113, Valid Loss: 0.00022869046370033175\n",
      "Epoch: 9621, Train Loss: 0.00014012426254339516, Valid Loss: 0.0002285630616825074\n",
      "Epoch: 9622, Train Loss: 0.00014004562399350107, Valid Loss: 0.00022844690829515457\n",
      "Epoch: 9623, Train Loss: 0.0001399660250172019, Valid Loss: 0.0002283230423927307\n",
      "Epoch: 9624, Train Loss: 0.00013988808495923877, Valid Loss: 0.00022820878075435758\n",
      "Epoch: 9625, Train Loss: 0.00013980775838717818, Valid Loss: 0.00022808575886301696\n",
      "Epoch: 9626, Train Loss: 0.00013973032764624804, Valid Loss: 0.00022796972189098597\n",
      "Epoch: 9627, Train Loss: 0.00013965080142952502, Valid Loss: 0.00022784454631619155\n",
      "Epoch: 9628, Train Loss: 0.00013957178452983499, Valid Loss: 0.00022773275850340724\n",
      "Epoch: 9629, Train Loss: 0.0001394930441165343, Valid Loss: 0.0002276055165566504\n",
      "Epoch: 9630, Train Loss: 0.00013941472570877522, Valid Loss: 0.00022749304480385035\n",
      "Epoch: 9631, Train Loss: 0.0001393357088090852, Valid Loss: 0.00022736788378097117\n",
      "Epoch: 9632, Train Loss: 0.00013925628445576876, Valid Loss: 0.0002272558049298823\n",
      "Epoch: 9633, Train Loss: 0.0001391788391629234, Valid Loss: 0.00022713154612574726\n",
      "Epoch: 9634, Train Loss: 0.00013910001143813133, Valid Loss: 0.00022701853595208377\n",
      "Epoch: 9635, Train Loss: 0.00013902020873501897, Valid Loss: 0.0002268914831802249\n",
      "Epoch: 9636, Train Loss: 0.00013894197763875127, Valid Loss: 0.0002267797099193558\n",
      "Epoch: 9637, Train Loss: 0.0001388648379361257, Valid Loss: 0.00022665245342068374\n",
      "Epoch: 9638, Train Loss: 0.0001387857337249443, Valid Loss: 0.00022654666099697351\n",
      "Epoch: 9639, Train Loss: 0.00013870728434994817, Valid Loss: 0.00022641787654720247\n",
      "Epoch: 9640, Train Loss: 0.00013862884952686727, Valid Loss: 0.00022630725288763642\n",
      "Epoch: 9641, Train Loss: 0.00013855121505912393, Valid Loss: 0.0002261790941702202\n",
      "Epoch: 9642, Train Loss: 0.0001384741917718202, Valid Loss: 0.00022606909624300897\n",
      "Epoch: 9643, Train Loss: 0.00013839655730407685, Valid Loss: 0.00022594662732444704\n",
      "Epoch: 9644, Train Loss: 0.00013831713295076042, Valid Loss: 0.00022583240934181958\n",
      "Epoch: 9645, Train Loss: 0.00013823820336256176, Valid Loss: 0.0002257063752040267\n",
      "Epoch: 9646, Train Loss: 0.0001381614856654778, Valid Loss: 0.0002255990111734718\n",
      "Epoch: 9647, Train Loss: 0.0001380832545692101, Valid Loss: 0.00022547299158759415\n",
      "Epoch: 9648, Train Loss: 0.00013800384476780891, Valid Loss: 0.00022536536562256515\n",
      "Epoch: 9649, Train Loss: 0.00013792708341497928, Valid Loss: 0.00022524081578012556\n",
      "Epoch: 9650, Train Loss: 0.00013784956536255777, Valid Loss: 0.00022512994473800063\n",
      "Epoch: 9651, Train Loss: 0.0001377713488182053, Valid Loss: 0.00022499755141325295\n",
      "Epoch: 9652, Train Loss: 0.00013769498036708683, Valid Loss: 0.00022489264665637165\n",
      "Epoch: 9653, Train Loss: 0.0001376159634673968, Valid Loss: 0.00022476685990113765\n",
      "Epoch: 9654, Train Loss: 0.0001375381398247555, Valid Loss: 0.00022465629444923252\n",
      "Epoch: 9655, Train Loss: 0.0001374599087284878, Valid Loss: 0.00022452956181950867\n",
      "Epoch: 9656, Train Loss: 0.00013738326379097998, Valid Loss: 0.00022442376939579844\n",
      "Epoch: 9657, Train Loss: 0.0001373065315419808, Valid Loss: 0.0002242986229248345\n",
      "Epoch: 9658, Train Loss: 0.00013722821313422173, Valid Loss: 0.00022418891603592783\n",
      "Epoch: 9659, Train Loss: 0.0001371502730762586, Valid Loss: 0.00022406164498534054\n",
      "Epoch: 9660, Train Loss: 0.00013707394828088582, Valid Loss: 0.00022394776169676334\n",
      "Epoch: 9661, Train Loss: 0.00013699501869268715, Valid Loss: 0.00022383038594853133\n",
      "Epoch: 9662, Train Loss: 0.00013691825733985752, Valid Loss: 0.000223720635403879\n",
      "Epoch: 9663, Train Loss: 0.00013684233999811113, Valid Loss: 0.00022359458671417087\n",
      "Epoch: 9664, Train Loss: 0.00013676569506060332, Valid Loss: 0.00022348397760652006\n",
      "Epoch: 9665, Train Loss: 0.0001366879732813686, Valid Loss: 0.000223358569201082\n",
      "Epoch: 9666, Train Loss: 0.00013660923286806792, Valid Loss: 0.00022324940073303878\n",
      "Epoch: 9667, Train Loss: 0.00013653260248247534, Valid Loss: 0.00022312723740469664\n",
      "Epoch: 9668, Train Loss: 0.00013645607396028936, Valid Loss: 0.0002230154350399971\n",
      "Epoch: 9669, Train Loss: 0.00013637902156915516, Valid Loss: 0.0002228879020549357\n",
      "Epoch: 9670, Train Loss: 0.00013630259491037577, Valid Loss: 0.00022278747928794473\n",
      "Epoch: 9671, Train Loss: 0.0001362254552077502, Valid Loss: 0.00022266015002969652\n",
      "Epoch: 9672, Train Loss: 0.00013614882482215762, Valid Loss: 0.00022255057410802692\n",
      "Epoch: 9673, Train Loss: 0.0001360707829007879, Valid Loss: 0.00022242430713959038\n",
      "Epoch: 9674, Train Loss: 0.0001359961461275816, Valid Loss: 0.0002223211486125365\n",
      "Epoch: 9675, Train Loss: 0.00013591890456154943, Valid Loss: 0.00022218881349544972\n",
      "Epoch: 9676, Train Loss: 0.0001358410663669929, Valid Loss: 0.00022209566668607295\n",
      "Epoch: 9677, Train Loss: 0.00013576702622231096, Valid Loss: 0.000221954207518138\n",
      "Epoch: 9678, Train Loss: 0.00013568888243753463, Valid Loss: 0.00022185540001373738\n",
      "Epoch: 9679, Train Loss: 0.00013561385276261717, Valid Loss: 0.0002217228466179222\n",
      "Epoch: 9680, Train Loss: 0.00013553632015828043, Valid Loss: 0.00022162721143104136\n",
      "Epoch: 9681, Train Loss: 0.0001354587875539437, Valid Loss: 0.0002214886189904064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9682, Train Loss: 0.0001353822590317577, Valid Loss: 0.00022140164219308645\n",
      "Epoch: 9683, Train Loss: 0.00013530600699596107, Valid Loss: 0.00022125609393697232\n",
      "Epoch: 9684, Train Loss: 0.0001352294784737751, Valid Loss: 0.0002211641112808138\n",
      "Epoch: 9685, Train Loss: 0.00013515373575501144, Valid Loss: 0.00022102327784523368\n",
      "Epoch: 9686, Train Loss: 0.00013507888070307672, Valid Loss: 0.0002209373633377254\n",
      "Epoch: 9687, Train Loss: 0.00013500104250852019, Valid Loss: 0.0002207884390372783\n",
      "Epoch: 9688, Train Loss: 0.0001349256926914677, Valid Loss: 0.0002207082143286243\n",
      "Epoch: 9689, Train Loss: 0.00013484836381394416, Valid Loss: 0.00022056039597373456\n",
      "Epoch: 9690, Train Loss: 0.00013477362517733127, Valid Loss: 0.0002204766497015953\n",
      "Epoch: 9691, Train Loss: 0.00013469847908709198, Valid Loss: 0.0002203249605372548\n",
      "Epoch: 9692, Train Loss: 0.00013462273636832833, Valid Loss: 0.00022024601639714092\n",
      "Epoch: 9693, Train Loss: 0.00013454600411932915, Valid Loss: 0.00022009396343491971\n",
      "Epoch: 9694, Train Loss: 0.00013447084347717464, Valid Loss: 0.00022001622710376978\n",
      "Epoch: 9695, Train Loss: 0.00013439480972010642, Valid Loss: 0.00021986447973176837\n",
      "Epoch: 9696, Train Loss: 0.000134318572236225, Valid Loss: 0.00021978345466777682\n",
      "Epoch: 9697, Train Loss: 0.00013424373173620552, Valid Loss: 0.00021963202743791044\n",
      "Epoch: 9698, Train Loss: 0.00013416798901744187, Valid Loss: 0.0002195548586314544\n",
      "Epoch: 9699, Train Loss: 0.00013409194070845842, Valid Loss: 0.00021940740407444537\n",
      "Epoch: 9700, Train Loss: 0.0001340160088147968, Valid Loss: 0.00021931965602561831\n",
      "Epoch: 9701, Train Loss: 0.00013394065899774432, Valid Loss: 0.00021917495178058743\n",
      "Epoch: 9702, Train Loss: 0.00013386362115852535, Valid Loss: 0.00021908656344749033\n",
      "Epoch: 9703, Train Loss: 0.00013378958101384342, Valid Loss: 0.00021894703968428075\n",
      "Epoch: 9704, Train Loss: 0.00013371353270485997, Valid Loss: 0.00021885587193537503\n",
      "Epoch: 9705, Train Loss: 0.00013363780453801155, Valid Loss: 0.00021872004435863346\n",
      "Epoch: 9706, Train Loss: 0.00013356345880310982, Valid Loss: 0.00021862571884412318\n",
      "Epoch: 9707, Train Loss: 0.0001334869011770934, Valid Loss: 0.00021849272889085114\n",
      "Epoch: 9708, Train Loss: 0.00013341214798856527, Valid Loss: 0.00021839712280780077\n",
      "Epoch: 9709, Train Loss: 0.00013333630340639502, Valid Loss: 0.00021826362353749573\n",
      "Epoch: 9710, Train Loss: 0.0001332616520812735, Valid Loss: 0.0002181633753934875\n",
      "Epoch: 9711, Train Loss: 0.000133186811581254, Valid Loss: 0.0002180332812713459\n",
      "Epoch: 9712, Train Loss: 0.0001331120729446411, Valid Loss: 0.0002179297007387504\n",
      "Epoch: 9713, Train Loss: 0.00013303692685440183, Valid Loss: 0.00021781167015433311\n",
      "Epoch: 9714, Train Loss: 0.0001329623773926869, Valid Loss: 0.0002177065034629777\n",
      "Epoch: 9715, Train Loss: 0.00013288664922583848, Valid Loss: 0.00021758527145721018\n",
      "Epoch: 9716, Train Loss: 0.00013281138672027737, Valid Loss: 0.00021747186838183552\n",
      "Epoch: 9717, Train Loss: 0.00013273634249344468, Valid Loss: 0.0002173561224481091\n",
      "Epoch: 9718, Train Loss: 0.00013266260793898255, Valid Loss: 0.00021724417456425726\n",
      "Epoch: 9719, Train Loss: 0.000132587636471726, Valid Loss: 0.00021713034948334098\n",
      "Epoch: 9720, Train Loss: 0.00013251180644147098, Valid Loss: 0.0002170143707189709\n",
      "Epoch: 9721, Train Loss: 0.00013243853754829615, Valid Loss: 0.00021690328139811754\n",
      "Epoch: 9722, Train Loss: 0.00013236419181339443, Valid Loss: 0.00021679088240489364\n",
      "Epoch: 9723, Train Loss: 0.00013228916213847697, Valid Loss: 0.00021667772671207786\n",
      "Epoch: 9724, Train Loss: 0.00013221398694440722, Valid Loss: 0.00021655693126376718\n",
      "Epoch: 9725, Train Loss: 0.00013214006321504712, Valid Loss: 0.0002164500328944996\n",
      "Epoch: 9726, Train Loss: 0.00013206432049628347, Valid Loss: 0.00021633287542499602\n",
      "Epoch: 9727, Train Loss: 0.0001319904695264995, Valid Loss: 0.00021622121857944876\n",
      "Epoch: 9728, Train Loss: 0.00013191491598263383, Valid Loss: 0.00021611092961393297\n",
      "Epoch: 9729, Train Loss: 0.00013184314593672752, Valid Loss: 0.00021600013133138418\n",
      "Epoch: 9730, Train Loss: 0.00013176779611967504, Valid Loss: 0.00021588176605291665\n",
      "Epoch: 9731, Train Loss: 0.00013169345038477331, Valid Loss: 0.00021577009465545416\n",
      "Epoch: 9732, Train Loss: 0.00013161930837668478, Valid Loss: 0.00021565947099588811\n",
      "Epoch: 9733, Train Loss: 0.0001315443660132587, Valid Loss: 0.0002155481488443911\n",
      "Epoch: 9734, Train Loss: 0.00013147130084689707, Valid Loss: 0.00021543001639656723\n",
      "Epoch: 9735, Train Loss: 0.00013139615475665778, Valid Loss: 0.00021532291430048645\n",
      "Epoch: 9736, Train Loss: 0.0001313227112405002, Valid Loss: 0.00021520414156839252\n",
      "Epoch: 9737, Train Loss: 0.00013124884571880102, Valid Loss: 0.00021509498765226454\n",
      "Epoch: 9738, Train Loss: 0.00013117628986947238, Valid Loss: 0.00021497676789294928\n",
      "Epoch: 9739, Train Loss: 0.00013110194413457066, Valid Loss: 0.00021487420599441975\n",
      "Epoch: 9740, Train Loss: 0.00013102639059070498, Valid Loss: 0.00021475236280821264\n",
      "Epoch: 9741, Train Loss: 0.00013095235044602305, Valid Loss: 0.00021464568271767348\n",
      "Epoch: 9742, Train Loss: 0.00013087948900647461, Valid Loss: 0.00021452471264638007\n",
      "Epoch: 9743, Train Loss: 0.00013080702046863735, Valid Loss: 0.00021441621356643736\n",
      "Epoch: 9744, Train Loss: 0.00013073207810521126, Valid Loss: 0.00021430007473099977\n",
      "Epoch: 9745, Train Loss: 0.00013065723760519177, Valid Loss: 0.00021419725089799613\n",
      "Epoch: 9746, Train Loss: 0.00013058555487077683, Valid Loss: 0.00021407754684332758\n",
      "Epoch: 9747, Train Loss: 0.00013051211135461926, Valid Loss: 0.00021397050295490772\n",
      "Epoch: 9748, Train Loss: 0.00013043756189290434, Valid Loss: 0.0002138555864803493\n",
      "Epoch: 9749, Train Loss: 0.0001303635217482224, Valid Loss: 0.00021374881907831877\n",
      "Epoch: 9750, Train Loss: 0.00013028936518821865, Valid Loss: 0.00021363217092584819\n",
      "Epoch: 9751, Train Loss: 0.00013021689665038139, Valid Loss: 0.00021352415205910802\n",
      "Epoch: 9752, Train Loss: 0.00013014345313422382, Valid Loss: 0.0002134075330104679\n",
      "Epoch: 9753, Train Loss: 0.00013006990775465965, Valid Loss: 0.00021330098388716578\n",
      "Epoch: 9754, Train Loss: 0.00012999643513467163, Valid Loss: 0.0002131864457624033\n",
      "Epoch: 9755, Train Loss: 0.000129923879285343, Valid Loss: 0.000213077844819054\n",
      "Epoch: 9756, Train Loss: 0.0001298489369219169, Valid Loss: 0.00021296361228451133\n",
      "Epoch: 9757, Train Loss: 0.00012977606093045324, Valid Loss: 0.00021285383263602853\n",
      "Epoch: 9758, Train Loss: 0.00012970351963303983, Valid Loss: 0.00021273715537972748\n",
      "Epoch: 9759, Train Loss: 0.0001296324480790645, Valid Loss: 0.0002126324106939137\n",
      "Epoch: 9760, Train Loss: 0.00012955759302712977, Valid Loss: 0.00021251763973850757\n",
      "Epoch: 9761, Train Loss: 0.00012948484800290316, Valid Loss: 0.0002124053571606055\n",
      "Epoch: 9762, Train Loss: 0.0001294123794650659, Valid Loss: 0.00021229386038612574\n",
      "Epoch: 9763, Train Loss: 0.00012933803373016417, Valid Loss: 0.00021218217443674803\n",
      "Epoch: 9764, Train Loss: 0.00012926496856380254, Valid Loss: 0.0002120707358699292\n",
      "Epoch: 9765, Train Loss: 0.00012919350410811603, Valid Loss: 0.00021196500165387988\n",
      "Epoch: 9766, Train Loss: 0.0001291206426685676, Valid Loss: 0.0002118490810971707\n",
      "Epoch: 9767, Train Loss: 0.0001290470827370882, Valid Loss: 0.0002117385738529265\n",
      "Epoch: 9768, Train Loss: 0.00012897442502435297, Valid Loss: 0.00021162803750485182\n",
      "Epoch: 9769, Train Loss: 0.0001289023639401421, Valid Loss: 0.0002115148090524599\n",
      "Epoch: 9770, Train Loss: 0.00012882970622740686, Valid Loss: 0.00021140069293323904\n",
      "Epoch: 9771, Train Loss: 0.00012875765969511122, Valid Loss: 0.00021129495871718973\n",
      "Epoch: 9772, Train Loss: 0.00012868379417341202, Valid Loss: 0.00021117989672347903\n",
      "Epoch: 9773, Train Loss: 0.00012861393042840064, Valid Loss: 0.00021107360953465104\n",
      "Epoch: 9774, Train Loss: 0.00012853986117988825, Valid Loss: 0.00021096240379847586\n",
      "Epoch: 9775, Train Loss: 0.00012846641766373068, Valid Loss: 0.0002108520275214687\n",
      "Epoch: 9776, Train Loss: 0.000128394560306333, Valid Loss: 0.00021073623793199658\n",
      "Epoch: 9777, Train Loss: 0.0001283229939872399, Valid Loss: 0.0002106321626342833\n",
      "Epoch: 9778, Train Loss: 0.00012824904115404934, Valid Loss: 0.00021051429212093353\n",
      "Epoch: 9779, Train Loss: 0.00012817815877497196, Valid Loss: 0.0002104126033373177\n",
      "Epoch: 9780, Train Loss: 0.00012810521002393216, Valid Loss: 0.00021029557683505118\n",
      "Epoch: 9781, Train Loss: 0.00012803325080312788, Valid Loss: 0.0002101882710121572\n",
      "Epoch: 9782, Train Loss: 0.00012796117516700178, Valid Loss: 0.000210071200854145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9783, Train Loss: 0.0001278891140827909, Valid Loss: 0.00020997172396164387\n",
      "Epoch: 9784, Train Loss: 0.00012781695113517344, Valid Loss: 0.00020984957518521696\n",
      "Epoch: 9785, Train Loss: 0.00012774499191436917, Valid Loss: 0.00020974922517780215\n",
      "Epoch: 9786, Train Loss: 0.0001276732364203781, Valid Loss: 0.00020963119459338486\n",
      "Epoch: 9787, Train Loss: 0.00012760187382809818, Valid Loss: 0.00020952847262378782\n",
      "Epoch: 9788, Train Loss: 0.00012752920156344771, Valid Loss: 0.00020940623653586954\n",
      "Epoch: 9789, Train Loss: 0.00012745805724989623, Valid Loss: 0.00020931009203195572\n",
      "Epoch: 9790, Train Loss: 0.00012738507939502597, Valid Loss: 0.00020918849622830749\n",
      "Epoch: 9791, Train Loss: 0.00012731451715808362, Valid Loss: 0.00020908845181111246\n",
      "Epoch: 9792, Train Loss: 0.00012724184489343315, Valid Loss: 0.00020896803471259773\n",
      "Epoch: 9793, Train Loss: 0.00012717058416455984, Valid Loss: 0.00020887042046524584\n",
      "Epoch: 9794, Train Loss: 0.00012709862494375557, Valid Loss: 0.00020875180780421942\n",
      "Epoch: 9795, Train Loss: 0.00012702765525318682, Valid Loss: 0.00020865742408204824\n",
      "Epoch: 9796, Train Loss: 0.00012695598707068712, Valid Loss: 0.00020853317982982844\n",
      "Epoch: 9797, Train Loss: 0.0001268845226150006, Valid Loss: 0.00020843010861426592\n",
      "Epoch: 9798, Train Loss: 0.00012681324733421206, Valid Loss: 0.00020831359142903239\n",
      "Epoch: 9799, Train Loss: 0.000126741491840221, Valid Loss: 0.00020821327052544802\n",
      "Epoch: 9800, Train Loss: 0.00012667050759773701, Valid Loss: 0.00020809349371120334\n",
      "Epoch: 9801, Train Loss: 0.0001265985774807632, Valid Loss: 0.00020799459889531136\n",
      "Epoch: 9802, Train Loss: 0.00012652759323827922, Valid Loss: 0.00020787844550795853\n",
      "Epoch: 9803, Train Loss: 0.00012645671085920185, Valid Loss: 0.00020777600002475083\n",
      "Epoch: 9804, Train Loss: 0.00012638565385714173, Valid Loss: 0.00020766156376339495\n",
      "Epoch: 9805, Train Loss: 0.00012631418940145522, Valid Loss: 0.00020756000594701618\n",
      "Epoch: 9806, Train Loss: 0.00012624332157429308, Valid Loss: 0.00020744025823660195\n",
      "Epoch: 9807, Train Loss: 0.00012617096945177764, Valid Loss: 0.0002073419891530648\n",
      "Epoch: 9808, Train Loss: 0.00012610136764124036, Valid Loss: 0.00020722545741591603\n",
      "Epoch: 9809, Train Loss: 0.00012603092181961983, Valid Loss: 0.000207125412998721\n",
      "Epoch: 9810, Train Loss: 0.00012595955922733992, Valid Loss: 0.00020700534514617175\n",
      "Epoch: 9811, Train Loss: 0.00012588906974997371, Valid Loss: 0.00020690978271886706\n",
      "Epoch: 9812, Train Loss: 0.00012581700866576284, Valid Loss: 0.00020679179579019547\n",
      "Epoch: 9813, Train Loss: 0.00012574574793688953, Valid Loss: 0.00020669233344960958\n",
      "Epoch: 9814, Train Loss: 0.00012567656813189387, Valid Loss: 0.0002065710286842659\n",
      "Epoch: 9815, Train Loss: 0.0001256038958672434, Valid Loss: 0.0002064742729999125\n",
      "Epoch: 9816, Train Loss: 0.00012553374108392745, Valid Loss: 0.00020635660621337593\n",
      "Epoch: 9817, Train Loss: 0.00012546346988528967, Valid Loss: 0.00020625803153961897\n",
      "Epoch: 9818, Train Loss: 0.00012539149611257017, Valid Loss: 0.00020613825472537428\n",
      "Epoch: 9819, Train Loss: 0.00012532330583781004, Valid Loss: 0.00020604301244020462\n",
      "Epoch: 9820, Train Loss: 0.0001252521324204281, Valid Loss: 0.00020592079090420157\n",
      "Epoch: 9821, Train Loss: 0.0001251821668120101, Valid Loss: 0.00020582255092449486\n",
      "Epoch: 9822, Train Loss: 0.00012510882515925914, Valid Loss: 0.00020570243941619992\n",
      "Epoch: 9823, Train Loss: 0.0001250409404747188, Valid Loss: 0.00020560876873787493\n",
      "Epoch: 9824, Train Loss: 0.00012496915587689728, Valid Loss: 0.00020548982138279825\n",
      "Epoch: 9825, Train Loss: 0.00012490019435063004, Valid Loss: 0.00020539220713544637\n",
      "Epoch: 9826, Train Loss: 0.00012483033060561866, Valid Loss: 0.00020527235756162554\n",
      "Epoch: 9827, Train Loss: 0.00012476003030315042, Valid Loss: 0.00020518136443570256\n",
      "Epoch: 9828, Train Loss: 0.00012468778004404157, Valid Loss: 0.00020505701832007617\n",
      "Epoch: 9829, Train Loss: 0.0001246176107088104, Valid Loss: 0.00020496452634688467\n",
      "Epoch: 9830, Train Loss: 0.0001245478488272056, Valid Loss: 0.00020484140259213746\n",
      "Epoch: 9831, Train Loss: 0.00012447776680346578, Valid Loss: 0.0002047470916295424\n",
      "Epoch: 9832, Train Loss: 0.00012440758291631937, Valid Loss: 0.0002046287409029901\n",
      "Epoch: 9833, Train Loss: 0.00012433801020961255, Valid Loss: 0.00020453502656891942\n",
      "Epoch: 9834, Train Loss: 0.00012426773901097476, Valid Loss: 0.00020441313972696662\n",
      "Epoch: 9835, Train Loss: 0.00012419697304721922, Valid Loss: 0.0002043158165179193\n",
      "Epoch: 9836, Train Loss: 0.0001241287827724591, Valid Loss: 0.00020420165674295276\n",
      "Epoch: 9837, Train Loss: 0.0001240583078470081, Valid Loss: 0.00020410763681866229\n",
      "Epoch: 9838, Train Loss: 0.00012398834223859012, Valid Loss: 0.00020398547349032015\n",
      "Epoch: 9839, Train Loss: 0.00012391895870678127, Valid Loss: 0.0002038893144344911\n",
      "Epoch: 9840, Train Loss: 0.00012384868750814348, Valid Loss: 0.00020377371401991695\n",
      "Epoch: 9841, Train Loss: 0.00012377920211292803, Valid Loss: 0.00020367691467981786\n",
      "Epoch: 9842, Train Loss: 0.00012370914919301867, Valid Loss: 0.00020356137247290462\n",
      "Epoch: 9843, Train Loss: 0.00012363937275949866, Valid Loss: 0.0002034597855526954\n",
      "Epoch: 9844, Train Loss: 0.0001235702948179096, Valid Loss: 0.00020334309374447912\n",
      "Epoch: 9845, Train Loss: 0.00012350091128610075, Valid Loss: 0.00020324651268310845\n",
      "Epoch: 9846, Train Loss: 0.00012343033449724317, Valid Loss: 0.00020313344430178404\n",
      "Epoch: 9847, Train Loss: 0.00012336214422248304, Valid Loss: 0.00020303268684074283\n",
      "Epoch: 9848, Train Loss: 0.00012329156743362546, Valid Loss: 0.00020291874534450471\n",
      "Epoch: 9849, Train Loss: 0.00012322282418608665, Valid Loss: 0.00020281918114051223\n",
      "Epoch: 9850, Train Loss: 0.00012315322237554938, Valid Loss: 0.00020270845561753958\n",
      "Epoch: 9851, Train Loss: 0.00012308206351008266, Valid Loss: 0.00020260830933693796\n",
      "Epoch: 9852, Train Loss: 0.00012301358219701797, Valid Loss: 0.00020249193767085671\n",
      "Epoch: 9853, Train Loss: 0.0001229455810971558, Valid Loss: 0.00020239237346686423\n",
      "Epoch: 9854, Train Loss: 0.00012287510617170483, Valid Loss: 0.0002022792905336246\n",
      "Epoch: 9855, Train Loss: 0.00012280643568374217, Valid Loss: 0.00020218215649947524\n",
      "Epoch: 9856, Train Loss: 0.00012273836182430387, Valid Loss: 0.0002020684041781351\n",
      "Epoch: 9857, Train Loss: 0.00012266836711205542, Valid Loss: 0.00020196470723021775\n",
      "Epoch: 9858, Train Loss: 0.00012260078801773489, Valid Loss: 0.00020185251196380705\n",
      "Epoch: 9859, Train Loss: 0.00012252981832716614, Valid Loss: 0.00020175715326331556\n",
      "Epoch: 9860, Train Loss: 0.00012246124970261008, Valid Loss: 0.00020164497254882008\n",
      "Epoch: 9861, Train Loss: 0.00012239305942784995, Valid Loss: 0.0002015430509345606\n",
      "Epoch: 9862, Train Loss: 0.00012232478184159845, Valid Loss: 0.00020143228175584227\n",
      "Epoch: 9863, Train Loss: 0.0001222550927195698, Valid Loss: 0.00020133009820710868\n",
      "Epoch: 9864, Train Loss: 0.0001221852289745584, Valid Loss: 0.00020121790294069797\n",
      "Epoch: 9865, Train Loss: 0.00012211734429001808, Valid Loss: 0.0002011240867432207\n",
      "Epoch: 9866, Train Loss: 0.00012204864469822496, Valid Loss: 0.0002010064636124298\n",
      "Epoch: 9867, Train Loss: 0.00012197918113088235, Valid Loss: 0.0002009096060646698\n",
      "Epoch: 9868, Train Loss: 0.00012191179121145979, Valid Loss: 0.0002007964940275997\n",
      "Epoch: 9869, Train Loss: 0.00012184250954305753, Valid Loss: 0.00020070273603778332\n",
      "Epoch: 9870, Train Loss: 0.00012177492317277938, Valid Loss: 0.00020058985683135688\n",
      "Epoch: 9871, Train Loss: 0.00012170545960543677, Valid Loss: 0.000200492751901038\n",
      "Epoch: 9872, Train Loss: 0.00012163676001364365, Valid Loss: 0.00020037300419062376\n",
      "Epoch: 9873, Train Loss: 0.00012156738375779241, Valid Loss: 0.00020027926075272262\n",
      "Epoch: 9874, Train Loss: 0.00012150178372394294, Valid Loss: 0.00020016756025142968\n",
      "Epoch: 9875, Train Loss: 0.00012143311323598027, Valid Loss: 0.0002000741515075788\n",
      "Epoch: 9876, Train Loss: 0.00012136491568526253, Valid Loss: 0.0001999510423047468\n",
      "Epoch: 9877, Train Loss: 0.00012129644892411307, Valid Loss: 0.00019985969993285835\n",
      "Epoch: 9878, Train Loss: 0.00012122676707804203, Valid Loss: 0.00019974443421233445\n",
      "Epoch: 9879, Train Loss: 0.00012115907884435728, Valid Loss: 0.00019965153478551656\n",
      "Epoch: 9880, Train Loss: 0.0001210914779221639, Valid Loss: 0.00019953686569351703\n",
      "Epoch: 9881, Train Loss: 0.00012102380424039438, Valid Loss: 0.0001994377380469814\n",
      "Epoch: 9882, Train Loss: 0.00012095571582904086, Valid Loss: 0.00019932517898268998\n",
      "Epoch: 9883, Train Loss: 0.00012088624498574063, Valid Loss: 0.00019923191575799137\n",
      "Epoch: 9884, Train Loss: 0.00012081894965376705, Valid Loss: 0.0001991200406337157\n",
      "Epoch: 9885, Train Loss: 0.00012074978440068662, Valid Loss: 0.0001990144664887339\n",
      "Epoch: 9886, Train Loss: 0.000120683187560644, Valid Loss: 0.00019890534167643636\n",
      "Epoch: 9887, Train Loss: 0.00012061460438417271, Valid Loss: 0.00019881202024407685\n",
      "Epoch: 9888, Train Loss: 0.00012054661783622578, Valid Loss: 0.00019870079995598644\n",
      "Epoch: 9889, Train Loss: 0.00012047952623106539, Valid Loss: 0.0001985960843740031\n",
      "Epoch: 9890, Train Loss: 0.00012041183799738064, Valid Loss: 0.00019849027739837766\n",
      "Epoch: 9891, Train Loss: 0.00012034396058879793, Valid Loss: 0.00019838793377857655\n",
      "Epoch: 9892, Train Loss: 0.00012027596676489338, Valid Loss: 0.0001982881803996861\n",
      "Epoch: 9893, Train Loss: 0.00012020987924188375, Valid Loss: 0.000198183988686651\n",
      "Epoch: 9894, Train Loss: 0.00012014000094495714, Valid Loss: 0.00019807527132797986\n",
      "Epoch: 9895, Train Loss: 0.00012007320765405893, Valid Loss: 0.00019797045388258994\n",
      "Epoch: 9896, Train Loss: 0.000120005221106112, Valid Loss: 0.00019787043856922537\n",
      "Epoch: 9897, Train Loss: 0.0001199383259518072, Valid Loss: 0.0001977641659323126\n",
      "Epoch: 9898, Train Loss: 0.00011987024481641129, Valid Loss: 0.00019766022160183638\n",
      "Epoch: 9899, Train Loss: 0.00011980185809079558, Valid Loss: 0.00019755905668716878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9900, Train Loss: 0.00011973517393926159, Valid Loss: 0.00019745294412132353\n",
      "Epoch: 9901, Train Loss: 0.00011966768943239003, Valid Loss: 0.00019735118257813156\n",
      "Epoch: 9902, Train Loss: 0.00011960147821810097, Valid Loss: 0.0001972487079910934\n",
      "Epoch: 9903, Train Loss: 0.00011953340435866266, Valid Loss: 0.00019714640802703798\n",
      "Epoch: 9904, Train Loss: 0.00011946701852139086, Valid Loss: 0.00019703939324244857\n",
      "Epoch: 9905, Train Loss: 0.00011939951218664646, Valid Loss: 0.00019694186630658805\n",
      "Epoch: 9906, Train Loss: 0.00011933103087358177, Valid Loss: 0.00019683007849380374\n",
      "Epoch: 9907, Train Loss: 0.00011926494335057214, Valid Loss: 0.00019673224596772343\n",
      "Epoch: 9908, Train Loss: 0.00011919725511688739, Valid Loss: 0.00019662428530864418\n",
      "Epoch: 9909, Train Loss: 0.00011913125490536913, Valid Loss: 0.00019652531773317605\n",
      "Epoch: 9910, Train Loss: 0.00011906465806532651, Valid Loss: 0.00019641706603579223\n",
      "Epoch: 9911, Train Loss: 0.00011899696983164176, Valid Loss: 0.00019632084877230227\n",
      "Epoch: 9912, Train Loss: 0.00011893048940692097, Valid Loss: 0.0001962098467629403\n",
      "Epoch: 9913, Train Loss: 0.00011886420543305576, Valid Loss: 0.00019611539028119296\n",
      "Epoch: 9914, Train Loss: 0.00011879601515829563, Valid Loss: 0.00019600380619522184\n",
      "Epoch: 9915, Train Loss: 0.0001187293091788888, Valid Loss: 0.0001959102664841339\n",
      "Epoch: 9916, Train Loss: 0.000118662828754168, Valid Loss: 0.00019580015214160085\n",
      "Epoch: 9917, Train Loss: 0.0001185958317364566, Valid Loss: 0.00019570272706914693\n",
      "Epoch: 9918, Train Loss: 0.00011852872557938099, Valid Loss: 0.00019558962958399206\n",
      "Epoch: 9919, Train Loss: 0.0001184622451546602, Valid Loss: 0.00019549726857803762\n",
      "Epoch: 9920, Train Loss: 0.00011839743820019066, Valid Loss: 0.00019538569904398173\n",
      "Epoch: 9921, Train Loss: 0.00011832815653178841, Valid Loss: 0.0001952915481524542\n",
      "Epoch: 9922, Train Loss: 0.00011826345144072548, Valid Loss: 0.00019518117187544703\n",
      "Epoch: 9923, Train Loss: 0.0001181964689749293, Valid Loss: 0.00019508521654643118\n",
      "Epoch: 9924, Train Loss: 0.00011813097808044404, Valid Loss: 0.00019497814355418086\n",
      "Epoch: 9925, Train Loss: 0.0001180630933959037, Valid Loss: 0.00019487856479827315\n",
      "Epoch: 9926, Train Loss: 0.00011799579806393012, Valid Loss: 0.00019477034220471978\n",
      "Epoch: 9927, Train Loss: 0.00011793029989348724, Valid Loss: 0.00019467314996290952\n",
      "Epoch: 9928, Train Loss: 0.00011786489631049335, Valid Loss: 0.0001945655094459653\n",
      "Epoch: 9929, Train Loss: 0.00011779819760704413, Valid Loss: 0.00019447073282208294\n",
      "Epoch: 9930, Train Loss: 0.00011773259757319465, Valid Loss: 0.00019436249567661434\n",
      "Epoch: 9931, Train Loss: 0.00011766582611016929, Valid Loss: 0.00019426557992119342\n",
      "Epoch: 9932, Train Loss: 0.00011759931658161804, Valid Loss: 0.00019415646966081113\n",
      "Epoch: 9933, Train Loss: 0.00011753381841117516, Valid Loss: 0.00019406080537009984\n",
      "Epoch: 9934, Train Loss: 0.00011746643576771021, Valid Loss: 0.00019395376148167998\n",
      "Epoch: 9935, Train Loss: 0.00011740093759726733, Valid Loss: 0.0001938571222126484\n",
      "Epoch: 9936, Train Loss: 0.00011733503197319806, Valid Loss: 0.00019374834664631635\n",
      "Epoch: 9937, Train Loss: 0.00011726894445018843, Valid Loss: 0.00019365077605471015\n",
      "Epoch: 9938, Train Loss: 0.0001172024494735524, Valid Loss: 0.00019354803953319788\n",
      "Epoch: 9939, Train Loss: 0.00011713764251908287, Valid Loss: 0.0001934492465807125\n",
      "Epoch: 9940, Train Loss: 0.00011707213707268238, Valid Loss: 0.00019334621902089566\n",
      "Epoch: 9941, Train Loss: 0.00011700495815603063, Valid Loss: 0.00019324290042277426\n",
      "Epoch: 9942, Train Loss: 0.00011693955457303673, Valid Loss: 0.00019314320525154471\n",
      "Epoch: 9943, Train Loss: 0.00011687396909110248, Valid Loss: 0.0001930407015606761\n",
      "Epoch: 9944, Train Loss: 0.00011680786701617762, Valid Loss: 0.00019293994409963489\n",
      "Epoch: 9945, Train Loss: 0.00011674256529659033, Valid Loss: 0.00019283738220110536\n",
      "Epoch: 9946, Train Loss: 0.00011667636863421649, Valid Loss: 0.0001927390112541616\n",
      "Epoch: 9947, Train Loss: 0.00011661295866360888, Valid Loss: 0.00019263075955677778\n",
      "Epoch: 9948, Train Loss: 0.00011654655099846423, Valid Loss: 0.00019253815116826445\n",
      "Epoch: 9949, Train Loss: 0.00011647996871033683, Valid Loss: 0.00019242889538872987\n",
      "Epoch: 9950, Train Loss: 0.00011641477613011375, Valid Loss: 0.0001923353993333876\n",
      "Epoch: 9951, Train Loss: 0.00011634956899797544, Valid Loss: 0.00019222583796363324\n",
      "Epoch: 9952, Train Loss: 0.00011628497304627672, Valid Loss: 0.00019213811901863664\n",
      "Epoch: 9953, Train Loss: 0.00011621856538113207, Valid Loss: 0.00019202163093723357\n",
      "Epoch: 9954, Train Loss: 0.00011615247785812244, Valid Loss: 0.00019193415937479585\n",
      "Epoch: 9955, Train Loss: 0.00011608836211962625, Valid Loss: 0.00019181761308573186\n",
      "Epoch: 9956, Train Loss: 0.00011602337326621637, Valid Loss: 0.00019173030159436166\n",
      "Epoch: 9957, Train Loss: 0.00011595687828958035, Valid Loss: 0.00019161429372616112\n",
      "Epoch: 9958, Train Loss: 0.00011589186760829762, Valid Loss: 0.00019153539324179292\n",
      "Epoch: 9959, Train Loss: 0.00011582646402530372, Valid Loss: 0.0001914091844810173\n",
      "Epoch: 9960, Train Loss: 0.00011576087854336947, Valid Loss: 0.0001913275773404166\n",
      "Epoch: 9961, Train Loss: 0.0001156964644906111, Valid Loss: 0.00019120762590318918\n",
      "Epoch: 9962, Train Loss: 0.00011563135922187939, Valid Loss: 0.00019112967129331082\n",
      "Epoch: 9963, Train Loss: 0.00011556686513358727, Valid Loss: 0.000191008803085424\n",
      "Epoch: 9964, Train Loss: 0.00011550225462997332, Valid Loss: 0.00019092875299975276\n",
      "Epoch: 9965, Train Loss: 0.00011543664732016623, Valid Loss: 0.00019080517813563347\n",
      "Epoch: 9966, Train Loss: 0.00011537136015249416, Valid Loss: 0.00019072750001214445\n",
      "Epoch: 9967, Train Loss: 0.00011530755728017539, Valid Loss: 0.00019061204511672258\n",
      "Epoch: 9968, Train Loss: 0.000115240465675015, Valid Loss: 0.0001905284298118204\n",
      "Epoch: 9969, Train Loss: 0.0001151763426605612, Valid Loss: 0.0001904069649754092\n",
      "Epoch: 9970, Train Loss: 0.00011511313641676679, Valid Loss: 0.00019032415002584457\n",
      "Epoch: 9971, Train Loss: 0.00011504843860166147, Valid Loss: 0.00019021026673726737\n",
      "Epoch: 9972, Train Loss: 0.00011498344247229397, Valid Loss: 0.00019013015844393522\n",
      "Epoch: 9973, Train Loss: 0.00011491832992760465, Valid Loss: 0.00019001233158633113\n",
      "Epoch: 9974, Train Loss: 0.00011485333379823714, Valid Loss: 0.00018992619880009443\n",
      "Epoch: 9975, Train Loss: 0.0001147890361608006, Valid Loss: 0.00018981144239660352\n",
      "Epoch: 9976, Train Loss: 0.00011472609912743792, Valid Loss: 0.0001897252514027059\n",
      "Epoch: 9977, Train Loss: 0.00011466130672488362, Valid Loss: 0.00018961651949211955\n",
      "Epoch: 9978, Train Loss: 0.00011459689267212525, Valid Loss: 0.00018952465325128287\n",
      "Epoch: 9979, Train Loss: 0.00011453060869826004, Valid Loss: 0.00018941177404485643\n",
      "Epoch: 9980, Train Loss: 0.00011446690768934786, Valid Loss: 0.00018932366219814867\n",
      "Epoch: 9981, Train Loss: 0.00011440250091254711, Valid Loss: 0.00018921685114037246\n",
      "Epoch: 9982, Train Loss: 0.00011433838517405093, Valid Loss: 0.00018912513041868806\n",
      "Epoch: 9983, Train Loss: 0.00011427478602854535, Valid Loss: 0.00018901508883573115\n",
      "Epoch: 9984, Train Loss: 0.00011420976079534739, Valid Loss: 0.00018892479420173913\n",
      "Epoch: 9985, Train Loss: 0.00011414596519898623, Valid Loss: 0.00018881834694184363\n",
      "Epoch: 9986, Train Loss: 0.00011408075806684792, Valid Loss: 0.00018872595683205873\n",
      "Epoch: 9987, Train Loss: 0.00011401804658817127, Valid Loss: 0.00018862403521779925\n",
      "Epoch: 9988, Train Loss: 0.00011395305045880377, Valid Loss: 0.00018852502398658544\n",
      "Epoch: 9989, Train Loss: 0.0001138900188379921, Valid Loss: 0.00018842284043785185\n",
      "Epoch: 9990, Train Loss: 0.00011382502998458222, Valid Loss: 0.00018832858768291771\n",
      "Epoch: 9991, Train Loss: 0.00011376103066140786, Valid Loss: 0.00018822673882823437\n",
      "Epoch: 9992, Train Loss: 0.00011369732237653807, Valid Loss: 0.00018812823691405356\n",
      "Epoch: 9993, Train Loss: 0.00011363400699337944, Valid Loss: 0.00018802972044795752\n",
      "Epoch: 9994, Train Loss: 0.00011357048788340762, Valid Loss: 0.00018792734772432595\n",
      "Epoch: 9995, Train Loss: 0.00011350559361744672, Valid Loss: 0.00018783545237965882\n",
      "Epoch: 9996, Train Loss: 0.0001134422782342881, Valid Loss: 0.00018773652845993638\n",
      "Epoch: 9997, Train Loss: 0.00011337768228258938, Valid Loss: 0.00018763482512440532\n",
      "Epoch: 9998, Train Loss: 0.00011331387213431299, Valid Loss: 0.0001875314919743687\n",
      "Epoch: 9999, Train Loss: 0.00011325104424031451, Valid Loss: 0.0001874414156191051\n"
     ]
    }
   ],
   "source": [
    "model.train(train_x, train_y)\n",
    "d2v_train_loss = pd.Series(model.train_loss)\n",
    "d2v_valid_loss = pd.Series(model.valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3946dfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(test_x) >= 0.5).numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87c066f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79591c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((model.predict(test_x) >= 0.5).numpy().astype(int) == test_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e85ad",
   "metadata": {},
   "source": [
    "# Compare Perfomance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fd1c46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [t2v_train_loss, t2v_valid_loss, d2v_train_loss, d2v_valid_loss], \n",
    "    index=['t2v_train_loss', 't2v_valid_loss', 'd2v_train_loss', 'd2v_valid_loss'],\n",
    ").T.iloc[1000:].plot(figsize=(18, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef106567",
   "metadata": {},
   "source": [
    "# Classic Model with date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fb4afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68df75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_dataset(\n",
    "    feature=['year', 'dayofyear', 'month', 'dayofmonth','week', 'dayofweek'], split_loc=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d10e40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, criterion='entropy')\n",
    "clf.fit(train_x, train_y)\n",
    "clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991b827c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_x, train_y)\n",
    "clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f42bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
